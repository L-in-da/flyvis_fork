{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Flyvis","text":"<p>A connectome constrained deep mechanistic network (DMN) model of the fruit fly visual system in Pytorch as discovery tool for generating and testing hypotheses about neural computations with connectomes.</p> <p>It\u2019s our official implementation of Connectome-constrained deep mechanistic networks predict neural responses across the fly visual system at single-neuron resolution.</p> <p>Besides pretrained models and analyses, the library includes abstractions and extension points for building DMNs and dynamic stimulus datasets in Pytorch.</p>"},{"location":"#quickstart","title":"Quickstart","text":"<p>Try the models and code inside our Google Colab notebooks for a quickstart.</p> <ul> <li>Explore the connectome</li> <li>Provide custom stimuli</li> <li>Optic flow task</li> <li>Flash responses</li> <li>Moving edge responses</li> <li>Umap and clustering</li> <li>Maximally excitatory stimuli</li> </ul>"},{"location":"#local-installation","title":"Local installation","text":"<ol> <li>create a new conda environment <code>conda create --name flyvision -y</code></li> <li>activate the new conda environment <code>conda activate flyvision</code></li> <li>install python <code>conda install \"python&gt;=3.7.11,&lt;3.10.0\"</code></li> <li>clone the repository <code>git clone https://github.com/TuragaLab/flyvis.git</code></li> <li>navigate to the repo <code>cd flyvis</code> and install in developer mode <code>pip install -e .</code></li> </ol>"},{"location":"#download-pretrained-models","title":"Download pretrained models","text":"<ol> <li>run <code>python scripts/download_pretrained_models.py</code> from active conda environment</li> </ol>"},{"location":"#background","title":"Background","text":"<p>How useful is a connectome? We show that you can predict quite a bit about the neural activity of a circuit from just measurements of its connectivity.</p> <p> </p> <p>We built a convolutional recurrent network of the fly visual system\u2013on a hexagonal grid, matching the columnar structure of the optic lobe. Weights (connections + filter weights) come from the connectome: A deep neural network which precisely maps onto a real brain circuit!</p> <p> </p> <p>Our connectome-constrained \u201cdeep mechanistic network\u201d (DMN) has 64 identified cell-types, 44K neurons + over 1 Mio. connections. We trained its free parameters (single-cell + synapse dynamics) on optic flow computation from naturalistic movie inputs.</p> <p> </p>"},{"location":"#citation","title":"Citation","text":"<pre><code>@article{lappalainen2023connectome,\n  title={Connectome-constrained deep mechanistic networks predict neural\n  responses across the fly visual system at single-neuron resolution},\n  author={Lappalainen, Janne K and Tschopp, Fabian D and Prakhya, Sridhama and\n  McGill, Mason and Nern, Aljoscha and Shinomiya, Kazunori and Takemura, Shin-ya\n   and Gruntman, Eyal and Macke, Jakob H and Turaga, Srinivas C},\n  journal={bioRxiv},\n  year={2023}\n}\n</code></pre>"},{"location":"#correspondence","title":"Correspondence","text":"<p>mailto:lappalainenjk@gmail.com</p>"},{"location":"acknowledgements/","title":"Credits","text":"<p><code>Jaxley</code> is a collaborative project between the groups of Jakob Macke (Uni T\u00fcbingen), Pedro Gon\u00e7alves (KU Leuven / NERF), and Philipp Berens (Uni T\u00fcbingen).</p>"},{"location":"acknowledgements/#license","title":"License","text":"<p><code>Jaxley</code> is licensed under the Apache License Version 2.0 (Apache-2.0) and</p> <p>Copyright (C) 2024 Michael Deistler, Jakob H. Macke, Pedro J. Goncalves, Philipp Berens.</p>"},{"location":"acknowledgements/#important-dependencies-and-prior-art","title":"Important dependencies and prior art","text":"<ul> <li>We greatly benefited from previous toolboxes for simulating multicompartment neurons, in particular NEURON.</li> </ul>"},{"location":"acknowledgements/#funding","title":"Funding","text":"<p>This work was supported by the German Research Foundation (DFG) through Germany\u2019s Excellence Strategy (EXC 2064 \u2013 Project number 390727645) and the CRC 1233 \u201cRobust Vision\u201d, the German Federal Ministry of Education and Research (Tu\u0308bingen AI Center, FKZ: 01IS18039A), the \u2018Certification and Foundations of Safe Machine Learning Systems in Healthcare\u2019 project funded by the Carl Zeiss Foundation, and the European Union (ERC, \u201cDeepCoMechTome\u201d, ref. 101089288, \u201cNextMechMod\u201d, ref. 101039115).</p>"},{"location":"contribute/","title":"Contributing","text":""},{"location":"faq/","title":"Frequently asked questions","text":"<ul> <li>What kinds of models can be implemented in <code>Jaxley</code>? </li> <li>What units does <code>Jaxley</code> use? </li> <li>How can I save and load cells and networks? </li> </ul> <p>See also the discussion page and the issue tracker on the <code>Jaxley</code> GitHub repository for recent questions and problems.</p>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#install-the-most-recent-stable-version","title":"Install the most recent stable version","text":"<p><code>Jaxley</code> is available on <code>PyPI</code>: <pre><code>pip install jaxley\n</code></pre> This will install <code>Jaxley</code> with CPU support. If you want GPU support, follow the instructions on the <code>JAX</code> github repository to install <code>JAX</code> with GPU support (in addition to installing <code>Jaxley</code>). For example, for NVIDIA GPUs, run <pre><code>pip install -U \"jax[cuda12]\"\n</code></pre></p>"},{"location":"install/#install-from-source","title":"Install from source","text":"<p>You can also install <code>Jaxley</code> from source: <pre><code>git clone https://github.com/jaxleyverse/jaxley.git\ncd jaxley\npip install -e .\n</code></pre></p> <p>Note that <code>pip&gt;=21.3</code> is required to install the editable version with <code>pyproject.toml</code> see pip docs. </p>"},{"location":"examples/01_flyvision_connectome/","title":"Explore the connectome","text":"<pre><code>import flyvision\nfrom flyvision import connectome_file\nfrom flyvision import ConnectomeDir, ConnectomeView\n</code></pre>"},{"location":"examples/01_flyvision_connectome/#connectome","title":"Connectome","text":"<p>This notebook illustrates the constructed spatially invariant connectome from local reconstructions that builds the scaffold of the network.</p> <p>Select GPU runtime</p> <p>To run the notebook on a GPU select Menu -&gt; Runtime -&gt; Change runtime type -&gt; GPU.</p> <pre><code># @markdown **Check access to GPU**\n\ntry:\n    import google.colab\n\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n\nif IN_COLAB:\n    import torch\n\n    try:\n        cuda_name = torch.cuda.get_device_name()\n        print(f\"Name of the assigned GPU / CUDA device: {cuda_name}\")\n    except RuntimeError:\n        import warnings\n\n        warnings.warn(\n            \"You have not selected Runtime Type: 'GPU' or Google could not assign you one. Please revisit the settings as described above or proceed on CPU (slow).\"\n        )\n</code></pre> <p>Install Flyvis</p> <p>The notebook requires installing our package <code>flyvis</code>. You may need to restart your session after running the code block below with Menu -&gt; Runtime -&gt; Restart session. Then, imports from <code>flyvis</code> should succeed without issue.</p> <pre><code>if IN_COLAB:\n    #@markdown **Install Flyvis**\n    %%capture\n    !git clone https://github.com/flyvis/flyvis-dev.git\n    %cd /content/flyvis-dev\n    !pip install -e .\n</code></pre> <pre><code># The ConnectomeDir class compiles the network graph from `data/connectome/fib25-fib19_v2.2.json`.\n# This json-file includes a list of cell types (`nodes`) and average convolutional filters \n# (anatomical receptive fields) (`edges`) that are scattered across a regular hexagonal lattice \n# of 15 column extent and stored on the hierarchical filesystem as h5-files.\nconfig = dict(file=connectome_file, extent=15, n_syn_fill=1)\nconnectome = ConnectomeDir(config)\n</code></pre> <pre><code># our network models 45,669 cells represented in this table of nodes\nconnectome.nodes.to_df()\n</code></pre> role type u v 0 input R1 -15 0 1 input R1 -15 1 2 input R1 -15 2 3 input R1 -15 3 4 input R1 -15 4 ... ... ... ... ... 45664 output TmY18 15 -4 45665 output TmY18 15 -3 45666 output TmY18 15 -2 45667 output TmY18 15 -1 45668 output TmY18 15 0 <p>45669 rows \u00d7 4 columns</p> <pre><code># our network models 1,513,231 synapses represented in this table of edges\nconnectome.edges.to_df()\n</code></pre> du dv edge_type n_syn n_syn_certainty sign source_index source_type source_u source_v target_index target_type target_u target_v 0 0 0 chem 40.0 5.859477 -1.0 0 R1 -15 0 5768 L1 -15 0 1 0 0 chem 40.0 5.859477 -1.0 1 R1 -15 1 5769 L1 -15 1 2 0 0 chem 40.0 5.859477 -1.0 2 R1 -15 2 5770 L1 -15 2 3 0 0 chem 40.0 5.859477 -1.0 3 R1 -15 3 5771 L1 -15 3 4 0 0 chem 40.0 5.859477 -1.0 4 R1 -15 4 5772 L1 -15 4 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1513226 0 0 chem 1.0 2.239571 1.0 45664 TmY18 15 -4 45664 TmY18 15 -4 1513227 0 0 chem 1.0 2.239571 1.0 45665 TmY18 15 -3 45665 TmY18 15 -3 1513228 0 0 chem 1.0 2.239571 1.0 45666 TmY18 15 -2 45666 TmY18 15 -2 1513229 0 0 chem 1.0 2.239571 1.0 45667 TmY18 15 -1 45667 TmY18 15 -1 1513230 0 0 chem 1.0 2.239571 1.0 45668 TmY18 15 0 45668 TmY18 15 0 <p>1513231 rows \u00d7 14 columns</p>"},{"location":"examples/01_flyvision_connectome/#connectivity-between-identified-cell-types","title":"Connectivity between identified cell types","text":"<p>Identified connectivity between 64 cell types, represented by total number of input synapses from all neurons of a given presynaptic cell type to a single postsynaptic of a given cell type. Blue color indicates putative hyperpolarizing inputs, red putative depolarizing inputs as inferred from neurotransmitter and receptor profiling. Size of squares indicates number of input synapses.</p> <pre><code># the ConnectomeView class provides visualizations of the connectome data\nconnectome_view = ConnectomeView(connectome)\n</code></pre> <pre><code>fig = connectome_view.connectivity_matrix(\"n_syn\")\n</code></pre> <p></p>"},{"location":"examples/01_flyvision_connectome/#example-receptive-fields","title":"Example receptive fields","text":"<p>Example of convolutional filter, representing inputs onto cells of the target cell type. Values represent the average number of synapses projecting from presynaptic cells in columns with indicated offset onto the postsynaptic dendrite. Values indicate connection strength derived from electron microscopy data.</p> <pre><code>fig = connectome_view.receptive_fields_grid(\"T4c\")\n</code></pre> <p></p>"},{"location":"examples/01_flyvision_connectome/#example-projective-fields","title":"Example projective fields","text":"<p>Example of projective fields, representing outputs of a source cell type onto target cells. Values represent the average number of synapses projecting from the presynaptic cell onto postsynaptic dendrites in columns with indicated offset. Values indicate connection strength derived from electron microscopy data.</p> <pre><code>fig = connectome_view.projective_fields_grid(\"T4c\")\n</code></pre> <p></p>"},{"location":"examples/01_flyvision_connectome/#network-layout","title":"Network layout","text":"<p>Our retinotopic hexagonal lattice network organizes cells of each cell type into visual columns corresponding to photoreceptor locations to capture the crystalline, hexagonal structure of the fly eye. Some cell types are non-columnar, i.e. their cells occur only in every other column\u2014here Lawf1 and Lawf2 cell types\u2014as estimated by our connectome construction algorithm. The edges represent pairs of connected cell types. For the task, we decoded from T-shaped and transmedullary cells (within the black box).</p> <pre><code># cause the layout is spatially periodic it suffices to visualize a few columns\n# to get the gist of the layout which can be controlled using max_extent\nfig = connectome_view.network_layout(max_extent=6)\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/","title":"Train the network","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre>"},{"location":"examples/02_flyvision_optic_flow_task/#optic-flow-task","title":"Optic flow task","text":"<p>This notebook illustrates the optic flow task and how to use it with our pretrained fly visual system model and decoder.</p> <p>Select GPU runtime</p> <p>To run the notebook on a GPU select Menu -&gt; Runtime -&gt; Change runtime type -&gt; GPU.</p> <pre><code># @markdown **Check access to GPU**\n\ntry:\n    import google.colab\n\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n\nif IN_COLAB:\n    import torch\n\n    try:\n        cuda_name = torch.cuda.get_device_name()\n        print(f\"Name of the assigned GPU / CUDA device: {cuda_name}\")\n    except RuntimeError:\n        import warnings\n\n        warnings.warn(\n            \"You have not selected Runtime Type: 'GPU' or Google could not assign you one. Please revisit the settings as described above or proceed on CPU (slow).\"\n        )\n</code></pre> <p>Install Flyvis</p> <p>The notebook requires installing our package <code>flyvis</code>. You may need to restart your session after running the code block below with Menu -&gt; Runtime -&gt; Restart session. Then, imports from <code>flyvis</code> should succeed without issue.</p> <pre><code>if IN_COLAB:\n    #@markdown **Install Flyvis**\n    %%capture\n    !git clone https://github.com/flyvis/flyvis-dev.git\n    %cd /content/flyvis-dev\n    !pip install -e .\n</code></pre> <pre><code># basic imports\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nplt.rcParams['figure.dpi'] = 200\n</code></pre>"},{"location":"examples/02_flyvision_optic_flow_task/#the-sintel-dataset","title":"The Sintel dataset","text":"<p>We use the Sintel dataset to train out models as described in the paper. More infos about the Sintel dataset can be found on the official Sintel website: http://sintel.is.tue.mpg.de/.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nfrom flyvision.datasets.sintel import MultiTaskSintel\nfrom flyvision.animations.sintel import SintelSample\n\n%load_ext autoreload\n%autoreload 2\n</code></pre> <pre><code>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</code></pre> <p>The class <code>MultiTaskSintel</code> loads, preprocesses, renders, and augments the sintel data. It adheres to the pytorch dataset primitive. It provides the interface to the input data and the output data for the flyvision networks. Note: the fly-eye rendering we use here, we introduce in the notebook on creating custom stimuli already.</p> <p>This is the full setting:</p> <pre><code>dataset = MultiTaskSintel(tasks=[\"flow\"],\n        boxfilter=dict(extent=15, kernel_size=13),\n        # Because the fly eye rendering is square \n        # and sintel is wide, we can crop sintel \n        # in width and render three sequences from one. \n        # This allows us to statically augment our dataset \n        # a bit already before we proceed with the random augmentations. \n        # We end up with 3 * 23 sequences. \n        vertical_splits=3,\n        n_frames=19,\n        center_crop_fraction=0.7,\n        dt=1 / 50,\n        augment=True,\n        # From sequences with more than n_frames, we randomly sample the start frame.\n        random_temporal_crop=True,\n        all_frames=False,\n        # We resample movie frames to the effective framerate given by 1/dt\n        resampling=True,\n        # We interpolate the flow arrows to 1/dt.\n        interpolate=True,\n        # We flip with equal probability (using one flip-axis).\n        p_flip=0.5,\n        # We rotate with equal probability (using five fold rotation symmetry of the hex-grid).\n        p_rot=5 / 6,\n        # We randomly adjust contrast and brightness.\n        contrast_std=0.2,\n        brightness_std=0.1,\n        # We add random white noise pixelweise.\n        gaussian_white_noise=0.08,\n        gamma_std=None,\n        _init_cache=True,\n        unittest=False,\n        flip_axes=[0, 1],\n        task_weights=None,)\n</code></pre> <pre><code># The `dataset.arg_df` tracks the sequence index, identity etc.\ndataset.arg_df\n</code></pre> index original_index name original_n_frames 0 0 0 sequence_00_alley_1_split_00 50 1 1 0 sequence_00_alley_1_split_01 50 2 2 0 sequence_00_alley_1_split_02 50 3 3 1 sequence_01_alley_2_split_00 50 4 4 1 sequence_01_alley_2_split_01 50 ... ... ... ... ... 64 64 21 sequence_21_temple_2_split_01 50 65 65 21 sequence_21_temple_2_split_02 50 66 66 22 sequence_22_temple_3_split_00 50 67 67 22 sequence_22_temple_3_split_01 50 68 68 22 sequence_22_temple_3_split_02 50 <p>69 rows \u00d7 4 columns</p>"},{"location":"examples/02_flyvision_optic_flow_task/#single-sample","title":"Single sample","text":"<p>First, let\u2019s chunk this into smaller digestable pieces.</p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=1,\n    dt=1 / 24,\n    augment=False,\n)\n</code></pre> <p>The first sample. For the target, the pixel-accurate motion vectors, the color indicates the direction of motion of the respective input pixel. The saturation indicates the magnitude of motion.</p> <pre><code>lum = dataset[0][\"lum\"]\nflow = dataset[0][\"flow\"]\n\nanimation = SintelSample(lum[None], flow[None])\nanimation.animate_in_notebook()\n</code></pre> <p></p> <p>Sintel has more groundtruth annotations. We support depth and flow because we know with certainty that these are relevant for the fly.</p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"depth\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=1,\n    dt=1 / 24,\n    augment=False,\n)\n</code></pre> <pre><code>lum1 = dataset[0][\"lum\"]\ndepth1 = dataset[0][\"depth\"]\n\nanimation = SintelSample(lum1[None], depth1[None])\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#augmenting-the-dataset-step-by-step","title":"Augmenting the dataset step-by-step","text":"<p>We apply rich augmentations to the dataset of naturalistic sequences because the dataset is otherwise relatively small. This might lead to overfitting to, e.g., predicting motion mostly into well-represented directons or of objects of specific contrasts etc. Using rich augmentations, we \u2018ask\u2019 the network to generalize better and invariantly compute motion regardless of direction, contrast, brightness, pixel noise, temporal appearance etc.</p>"},{"location":"examples/02_flyvision_optic_flow_task/#vertical-splits","title":"Vertical splits","text":"<p>First, we split each sequence into three sequences vertically to leverage a wider extent of the video than if we would only render the center. We precompute these renderings.</p> <pre><code>from flyvision.plots.plots import quick_hex_scatter\n</code></pre> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=3,\n    dt=1 / 24,\n    augment=False,\n)\n</code></pre> <p>Sintel has 23 movie sequences originally.</p> <pre><code>len(np.unique(dataset.arg_df.original_index))\n</code></pre> <pre><code>23\n</code></pre> <p>Each original sequence is 436 pixel in height times 1024 pixel in width in cartesian coordinates.</p> <pre><code>sequence = dataset.cartesian_sequence(0, vertical_splits=1, center_crop_fraction=1.0)\nprint(sequence.shape)\n</code></pre> <pre><code>(1, 49, 436, 1024)\n</code></pre> <p>With the vertical crops, we end up with 3 * 23 sequences. The <code>dataset.arg_df</code> tracks the sequence index, identity etc.</p> <pre><code>dataset.arg_df\n</code></pre> index original_index name original_n_frames 0 0 0 sequence_00_alley_1_split_00 50 1 1 0 sequence_00_alley_1_split_01 50 2 2 0 sequence_00_alley_1_split_02 50 3 3 1 sequence_01_alley_2_split_00 50 4 4 1 sequence_01_alley_2_split_01 50 ... ... ... ... ... 64 64 21 sequence_21_temple_2_split_01 50 65 65 21 sequence_21_temple_2_split_02 50 66 66 22 sequence_22_temple_3_split_00 50 67 67 22 sequence_22_temple_3_split_01 50 68 68 22 sequence_22_temple_3_split_02 50 <p>69 rows \u00d7 4 columns</p> <pre><code>_ = plt.imshow(sequence[0, 0], cmap=plt.cm.binary_r)\n</code></pre> <p></p> <pre><code>fig, axes = plt.subplots(1, 3)\n_ = quick_hex_scatter(dataset[0]['lum'][0].flatten(), fig=fig, ax=axes[0], cbar=False)\n_ = quick_hex_scatter(dataset[1]['lum'][0].flatten(), fig=fig, ax=axes[1], cbar=False)\n_ = quick_hex_scatter(dataset[2]['lum'][0].flatten(), fig=fig, ax=axes[2], cbar=False)\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#random-temporal-crops","title":"Random temporal crops","text":"<p>We train on 19 frames ~ 792ms movie. Most sequences have 49 frames. To use the whole temporal content, we stochastically sample start and end frame ~ ((1, 19), (2, 20), \u2026, (31, 49)).</p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=3,\n    n_frames=19,\n    dt=1 / 24,\n    augment=True,\n    random_temporal_crop=True,\n    all_frames=False,\n    resampling=False,\n    interpolate=False,\n    p_flip=0,\n    p_rot=0,\n    contrast_std=None,\n    brightness_std=None,\n    gaussian_white_noise=None,\n)\n</code></pre> <pre><code># These two samples from the same original sequence should have stochastically different start and end frames.\nlum1 = dataset[0]['lum']\nlum2 = dataset[0]['lum']\n</code></pre> <pre><code>animation = SintelSample(lum1[None], lum2[None], title2=\"input\")\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#flips-and-rotations","title":"Flips and rotations","text":"<p>Next, we flip stochastically across 2 axes and or rotate a random number of times around the center. We implement this to be fast to do so at runtime.</p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=3,\n    n_frames=19,\n    dt=1 / 24,\n    augment=True,\n    random_temporal_crop=False,\n    all_frames=False,\n    resampling=False,\n    interpolate=False,\n    p_flip=1/2,\n    p_rot=5/6,\n    contrast_std=None,\n    brightness_std=None,\n    gaussian_white_noise=None,\n)\n</code></pre> <pre><code># These two samples from the same original sequence should have stochastically different orientation.\nlum1 = dataset[0]['lum']\nlum2 = dataset[0]['lum']\n</code></pre> <pre><code>animation = SintelSample(lum1[None], lum2[None], title2=\"input\")\nanimation.animate_in_notebook()\n</code></pre> <p></p> <p>Flow vectors need to be flipped and rotated accordingly.</p> <pre><code># These two samples from the same original sequence should have stochastically different orientation.\ndata = dataset[0]\nlum1 = data['lum']\nflow1 = data['flow']\n</code></pre> <pre><code>animation = SintelSample(lum1[None], flow1[None])\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#further-augmentations","title":"Further augmentations","text":"<p>Besides that, we also augment the input with random contrasts and brightnesses and random gaussian pixel noise, while the motion stays the same. This pretends that the same motion takes place under different illumination conditions and signal to noise ratios.  </p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=3,\n    n_frames=19,\n    dt=1 / 24,\n    augment=True,\n    random_temporal_crop=False,\n    all_frames=False,\n    resampling=False,\n    interpolate=False,\n    p_flip=0,\n    p_rot=0,\n    contrast_std=0.2,\n    brightness_std=0.1,\n    gaussian_white_noise=0.08,\n)\n</code></pre> <pre><code># These two samples from the same original sequence have \n# stochastically different contrast, brightness and pixel-wise noise.\nlum1 = dataset[0]['lum']\nlum2 = dataset[0]['lum']\n</code></pre> <pre><code>animation = SintelSample(lum1[None], lum2[None], title2=\"input\")\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#framerate-of-the-dataset-and-integration-time-step","title":"Framerate of the dataset and integration time step","text":"<p>The Sintel dataset is originally rendered at 24 frames per second, i.e., one frame every 42ms. The fruit fly neurons are able to respond to temporal differences as fast as 5-20ms. Therefore, we resample every frame multiple times to pretend that the movie was originally sampled at such a faster framerate. For the motion fields, we interpolate flow vectors in time instead of resampling them, which hopefully gives a better learning signal to the network. We have to trade-off speed of the numerical integration and memory consumption during optimization with the simulation accuracy by choosing time steps between 5-20ms. We chose to train networks at the upper bount of 20ms and evaluate them more accurately at 5-10ms.</p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=3,\n    n_frames=19,\n    dt=1 / 50,\n    augment=False,\n    resampling=True,\n    interpolate=True,\n)\n</code></pre> <pre><code># Now, every input frame appears twice and target frames are interpolated.\ndata = dataset[0]\nlum1 = data['lum']\nflow1 = data['flow']\n</code></pre> <pre><code>animation = SintelSample(lum1[None], flow1[None])\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#computing-responses-to-the-sintel-data","title":"Computing responses to the Sintel data","text":"<p>Before we get to training a network, we look at a few responses to these type of sequences of individual neurons.</p> <pre><code>from flyvision.network import NetworkView, Network\nfrom flyvision.utils.activity_utils import LayerActivity\n\nfrom flyvision.datasets.sintel import MultiTaskSintel\n</code></pre> <pre><code># new network instance\nnetwork = Network()\n\n# Alternative: uncomment to use a pretrained network\n# network_view = NetworkView(results_dir / \"flow/0000/000\")\n# network = network_view.init_network(network)\n</code></pre> <pre><code>[2024-09-23 15:50:20] network:252 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n</code></pre> <pre><code>layer_activity = LayerActivity(None, network.connectome, keepref=True)\n</code></pre> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=1,\n    n_frames=19,\n    dt=1/50,\n    augment=False,\n    resampling=True,\n    interpolate=True,\n)\n</code></pre> <pre><code>stationary_state = network.fade_in_state(1.0, dataset.dt, dataset[0][\"lum\"][[0]])\nresponses = network.simulate(dataset[0][\"lum\"][None], dataset.dt, initial_state=stationary_state).cpu()\n</code></pre> <pre><code>plt.figure(figsize=[3, 2])\nlayer_activity.update(responses)\nr = layer_activity.central.T4c.squeeze().numpy()\ntime = np.arange(0, r.shape[0], 1) * dataset.dt\nplt.plot(time, r)\nplt.xlabel(\"time in s\")\nplt.ylabel(\"voltage (a.u.)\")\nplt.title(\"response of central T4c cell\")\n</code></pre> <pre><code>Text(0.5, 1.0, 'response of central T4c cell')\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#decoding-the-task-from-neural-activity","title":"Decoding the task from neural activity","text":"<p>We need to predict the pixel-accurate flow field that Sintel gives us. For that we decode the voltages of a bunch of cell types. The decoder and the network are trained end-to-end. Here an example of a forward pass through the whole pipeline in code.</p> <pre><code>from flyvision.network import NetworkView\nfrom flyvision.utils.activity_utils import LayerActivity\n\nfrom flyvision.datasets.sintel import MultiTaskSintel\nfrom flyvision.decoder import DecoderGAVP\n</code></pre> <pre><code>network = Network()\n</code></pre> <pre><code>[2024-09-23 15:50:36] network:252 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n</code></pre> <pre><code>decoder = DecoderGAVP(network.connectome, shape=[8, 2], kernel_size=5)\n</code></pre> <pre><code>[2024-09-23 15:50:40] decoder:213 Initialized decoder with NumberOfParams(free=7427, fixed=0) parameters.\n[2024-09-23 15:50:40] decoder:214 DecoderGAVP(\n  (base): Sequential(\n    (0): Conv2dHexSpace(34, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Softplus(beta=1, threshold=20)\n    (3): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Sequential(\n    (0): Conv2dHexSpace(8, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  )\n  (head): Sequential()\n)\n</code></pre> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=1,\n    all_frames=True,\n    dt=1/50,\n    augment=False,\n    resampling=True,\n    interpolate=True,\n)\n</code></pre> <pre><code>data = dataset[0]\nlum = data[\"lum\"]\nflow = data[\"flow\"]\n\nstationary_state = network.fade_in_state(1.0, dataset.dt, lum[[0]])\nresponses = network.simulate(lum[None], dataset.dt, initial_state=stationary_state)\n</code></pre> <pre><code>y_pred = decoder(responses)\n</code></pre> <p>We predict motion with an untrained decoder from an untrained network with randomly initialized parameters.  We do not expect this to work.</p> <pre><code>animation = SintelSample(lum[None], flow[None], prediction=y_pred.detach().cpu())\nanimation.animate_in_notebook(frames=np.arange(lum.shape[0])[::10])\n</code></pre> <p></p> <pre><code>((y_pred - flow) ** 2).sqrt().mean()\n</code></pre> <pre><code>tensor(1.0214, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n</code></pre>"},{"location":"examples/02_flyvision_optic_flow_task/#training-network-and-decoder-on-a-single-batch","title":"Training network and decoder on a single batch","text":"<p>We now train the network on a single batch to validate that the pipeline works. We do not expect these networks to generalize their function.</p> <pre><code>from tqdm.notebook import tqdm\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\n\nfrom flyvision.network import NetworkView, Network\nfrom flyvision.decoder import DecoderGAVP\nfrom flyvision.utils.activity_utils import LayerActivity\n\nfrom flyvision.datasets.sintel import MultiTaskSintel\nfrom flyvision.objectives import l2norm, epe\n</code></pre> <pre><code>network = Network()\n</code></pre> <pre><code>[2024-09-23 15:51:17] network:252 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n</code></pre> <pre><code>decoder = DecoderGAVP(network.connectome, shape=[8, 2], kernel_size=5)\n</code></pre> <pre><code>[2024-09-23 15:51:21] decoder:213 Initialized decoder with NumberOfParams(free=7427, fixed=0) parameters.\n[2024-09-23 15:51:21] decoder:214 DecoderGAVP(\n  (base): Sequential(\n    (0): Conv2dHexSpace(34, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Softplus(beta=1, threshold=20)\n    (3): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Sequential(\n    (0): Conv2dHexSpace(8, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  )\n  (head): Sequential()\n)\n</code></pre> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=1,\n    n_frames=19,\n    dt=1/50,\n    augment=False,\n    resampling=True,\n    interpolate=True,\n)\n</code></pre> <pre><code>t_pre=0.5\ndt = 1/50\nbatch_size=4\ntrain_loader = DataLoader(dataset, batch_size=batch_size)\n</code></pre> <pre><code>optimizer = Adam((*network.parameters(), *decoder.parameters()), lr=1e-5)\n</code></pre> <pre><code>batch = next(iter(train_loader))\n</code></pre> <pre><code>loss_fn = epe\n</code></pre> <pre><code>epochs = 1000\n\nerrors = []\n\ninitial_state = network.steady_state(t_pre, dt, batch_size)\n\nfor e in tqdm(range(epochs)):\n    lum = batch[\"lum\"]\n    flow = batch[\"flow\"]\n\n\n    optimizer.zero_grad()\n    network.stimulus.zero()\n    network.stimulus.add_input(lum)\n\n    activity = network(network.stimulus(), dt=1/50, state=initial_state)\n    y_pred = decoder(activity)\n\n    batch_error = loss_fn(y_pred, flow)\n    errors.append(batch_error.cpu().item())\n    batch_error.backward()\n    optimizer.step()\n</code></pre> <pre><code>  0%|          | 0/1000 [00:00&lt;?, ?it/s]\n</code></pre> <pre><code>plt.plot(errors)\n</code></pre> <pre><code>[&lt;matplotlib.lines.Line2D at 0x7f7f5467f580&gt;]\n</code></pre> <p></p> <p>We expect that the prediction from this overfitted network on the sample it was trained on is ok.</p> <pre><code>data = dataset[0]\nlum = data[\"lum\"]\nflow = data[\"flow\"]\n\nstationary_state = network.fade_in_state(1.0, dataset.dt, lum[[0]])\nresponses = network.simulate(lum[None], dataset.dt, initial_state=stationary_state)\n</code></pre> <pre><code>y_pred = decoder(responses)\n</code></pre> <pre><code>animation = SintelSample(lum[None], flow[None], prediction=y_pred.detach().cpu())\nanimation.animate_in_notebook()\n</code></pre> <p></p> <pre><code>((y_pred - flow) ** 2).sqrt().mean()\n</code></pre> <pre><code>tensor(0.8250, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n</code></pre>"},{"location":"examples/02_flyvision_optic_flow_task/#evaluating-trained-networks","title":"Evaluating trained networks","text":"<pre><code>from flyvision import results_dir\nfrom flyvision.network import NetworkView\nfrom flyvision.utils.activity_utils import LayerActivity\n\nfrom flyvision.datasets.sintel import MultiTaskSintel\nfrom flyvision.decoder import DecoderGAVP\n</code></pre> <pre><code># we load the best task-performing model from the presorted ensemble\nnetwork_view = NetworkView(results_dir / \"flow/0000/000\")\n</code></pre> <pre><code>[2024-09-23 15:54:46] network:1005 Initialized network view at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000.\n</code></pre> <pre><code>network = network_view.init_network()\n</code></pre> <pre><code>[2024-09-23 15:54:55] network:252 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n[2024-09-23 15:54:55] chkpt_utils:72 Recovered network state.\n</code></pre> <pre><code>decoder = network_view.init_decoder()[\"flow\"]\n</code></pre> <pre><code>[2024-09-23 15:54:56] chkpt_utils:72 Recovered network state.\n[2024-09-23 15:55:00] decoder:213 Initialized decoder with NumberOfParams(free=7427, fixed=0) parameters.\n[2024-09-23 15:55:00] decoder:214 DecoderGAVP(\n  (base): Sequential(\n    (0): Conv2dHexSpace(34, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Softplus(beta=1, threshold=20)\n    (3): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Sequential(\n    (0): Conv2dHexSpace(8, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  )\n  (head): Sequential()\n)\n[2024-09-23 15:55:00] chkpt_utils:91 Recovered flow decoder state.\n</code></pre> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=1,\n    all_frames=False,\n    n_frames=19,\n    dt=1/50,\n    augment=False,\n    resampling=True,\n    interpolate=True,\n)\n</code></pre> <pre><code>data = [dataset[i] for i in range(4)]\nlum = torch.stack([d[\"lum\"] for d in data])\nflow = torch.stack([d[\"flow\"] for d in data])\n\nstationary_state = network.fade_in_state(1.0, dataset.dt, lum[:, 0])\nresponses = network.simulate(lum, dataset.dt, initial_state=stationary_state)\n</code></pre> <pre><code>y_pred = decoder(responses)\n</code></pre> <p>We expect this network to generalize across sequences. This network sees motion into all directions.</p> <pre><code>animation = SintelSample(lum, flow, prediction=y_pred.detach().cpu())\nanimation.animate_in_notebook()\n</code></pre> <p></p> <p>We expect the accuracy is not as good as the overfitted example because this network generalized across the whole-dataset.</p> <pre><code>((y_pred - flow) ** 2).sqrt().mean()\n</code></pre> <pre><code>tensor(6.4063, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n</code></pre>"},{"location":"examples/02_flyvision_optic_flow_task/#evaluating-ensembles","title":"Evaluating ensembles","text":"<p>Last, we evaluated the task error of the 50 trained networks on a held out set of sequences. We evaluated the task error across all checkpoints during training and show the minimal one in the histrogram below. This checkpoint we analyse with respect to it\u2019s tuning predictions as shown in the next notebooks.</p> <pre><code>from flyvision import EnsembleView\n</code></pre> <pre><code>ensemble = EnsembleView(results_dir / \"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-09-23 15:57:24] ensemble:138 Loaded 50 networks.\n</code></pre> <pre><code>ensemble.task_error_histogram()\n</code></pre> <pre><code>(&lt;Figure size 300x300 with 1 Axes&gt;,\n &lt;Axes: xlabel='task error', ylabel='number models'&gt;)\n</code></pre> <p></p>"},{"location":"examples/03_flyvision_flash_responses/","title":"Flash responses","text":"<p>This notebook introduces flash responses and the flash response index (FRI). </p> <p>The FRI measures whether a cell depolarizes to bright or to dark increments in a visual input.</p>"},{"location":"examples/03_flyvision_flash_responses/#you-can-skip-the-next-cells-if-you-are-not-on-google-colab-but-run-this-locally","title":"You can skip the next cells if you are not on google colab but run this locally","text":"<p>Select GPU runtime</p> <p>Only for usage on google colab: to run the notebook on a GPU select Menu -&gt; Runtime -&gt; Change runtime type -&gt; GPU.</p> <pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre> <pre><code>#@markdown **Check access to GPU**\n\ntry:\n    import google.colab\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n\nif IN_COLAB:\n    import torch\n    try:\n      cuda_name = torch.cuda.get_device_name()\n      print(f\"Name of the assigned GPU / CUDA device: {cuda_name}\")\n    except RuntimeError:\n      import warnings\n      warnings.warn(\"You have not selected Runtime Type: 'GPU' or Google could not assign you one. Please revisit the settings as described above or proceed on CPU (slow).\")\n</code></pre> <p>Install Flyvis</p> <p>The notebook requires installing our package <code>flyvis</code>. You may need to restart your session after running the code block below with Menu -&gt; Runtime -&gt; Restart session. Then, imports from <code>flyvis</code> should succeed without issue.</p> <pre><code>if IN_COLAB:\n    #@markdown **Install Flyvis**\n    %%capture\n    !git clone https://github.com/flyvis/flyvis-dev.git\n    %cd /content/flyvis-dev\n    !pip install -e .\n</code></pre> <pre><code># basic imports\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport logging\nlogging.disable(100)\n\nplt.rcParams['figure.dpi'] = 200\n</code></pre>"},{"location":"examples/03_flyvision_flash_responses/#flash-stimuli","title":"Flash stimuli","text":"<p>To elicit flash responses, experimenters show a flashing dot to the subject in the center of their field of view. We generate and render these stimuli with the <code>Flashes</code> dataset.</p> <pre><code># import dataset and visualization helper\nfrom flyvision.animations.hexscatter import HexScatter\nfrom flyvision.datasets.flashes import Flashes\n</code></pre> <pre><code># initialize dataset\ndataset = Flashes(\n    dynamic_range=[0, 1],  # min and max pixel intensity values, must be in range [0, 1]\n    t_stim=1.0,  # duration of flash\n    t_pre=1.0,  # duration of period between flashes\n    dt=1 / 200,  # temporal resolution of rendered video\n    radius=[-1, 6],  # radius of flashing dot. -1 fills entire field of view\n    alternations=(0, 1, 0),  # flashing pattern, off - on - off\n)\n</code></pre> <pre><code># view stimulus parameters\ndataset.arg_df\n# the dataset has four samples, one corresponding to each row\n</code></pre> <pre><code># visualize single sample\nanimation = HexScatter(\n    dataset[3][None, ::50, None], vmin=0, vmax=1\n)  # intensity=1, radius=6\nanimation.animate_in_notebook()\n</code></pre>"},{"location":"examples/03_flyvision_flash_responses/#network-flash-response","title":"Network flash response","text":"<p>Now that we have generated the stimulus, we can use it to drive a trained connectome-constrained network.</p> <pre><code>from flyvision import results_dir\nfrom flyvision.network import NetworkView\n\n# model are already sorted by task error\n# we take the best task-performing model from the pre-sorted ensemble\nnetwork_view = NetworkView(results_dir / \"flow/0000/000\")\n</code></pre> <pre><code>stims_and_resps = network_view.flash_responses(dataset=dataset)\n</code></pre> <pre><code>stims_and_resps['responses'].custom.where(cell_type=\"L1\", radius=6).custom.plot_traces(x='time')\nfig = plt.gcf()\nfig.axes[-1].set_title(\"L1 flash responses\")\n</code></pre>"},{"location":"examples/03_flyvision_flash_responses/#flash-response-index-fri","title":"Flash response index (FRI)","text":"<p>The flash response index (FRI) is a measure of the strength of contrast tuning of a particular cell. It is computed as the difference between the cell\u2019s peak voltage in response to on-flashes (intensity = 1) and off-flashes (intensity = 0), divided by the sum of those peak values.</p> <p>That is, given a single neuron\u2019s response to on-flashes <code>r_on</code> and off-flashes <code>r_off</code> (both of <code>shape=(T,)</code>), we can compute the flash response index with</p> <pre><code>r_on_max = max(r_on)\nr_off_max = max(r_off)\nfri = (r_on_max - r_off_max) / (r_on_max + r_off_max + 1e-16)\n</code></pre> <p>with the additional <code>1e-16</code> simply for numerical stability. Before this calculation, the response traces are shifted to be non-negative.</p> <p>The flash response index can take on values between \\(-1\\), when the off response is much stronger (or more positive) than the on response, to \\(1\\), when the on response is much stronger (or more positive) than the off response.</p> <p>For the L1 cell plotted before, we can see that it displays a positive response to off flashes and a negative response to on flashes, so we expect a negative flash response index.</p> <pre><code>from flyvision.analysis.flash_responses import flash_response_index\n</code></pre> <pre><code>fris = flash_response_index(stims_and_resps, radius=6)\n</code></pre> <pre><code>fris.custom.where(cell_type=\"L1\")\n</code></pre>"},{"location":"examples/03_flyvision_flash_responses/#fri-correlation","title":"FRI correlation","text":"<p>Since the tuning of some cell types have been determined experimentally, we can then compare our model to experimental findings by computing the correlation between the model FRIs for known cell types with their expected tuning.</p> <pre><code>from flyvision.analysis.flash_responses import fri_correlation_to_known\nfrom flyvision.utils.groundtruth_utils import polarity\n</code></pre> <pre><code>fri_corr = fri_correlation_to_known(fris)\n</code></pre> <pre><code># manually extract model and true FRIs for plotting\nknown_cell_types = [k for k, v in polarity.items() if v != 0]\nmodel_fris = [fris.custom.where(cell_type=k).item() for k in known_cell_types]\ntrue_fris = [polarity[k] for k in known_cell_types]\n# plot\nplt.figure(figsize=[2, 1])\nplt.scatter(model_fris, true_fris, color=\"k\", s=10)\nplt.xlabel(\"predicted FRI\")\nplt.ylabel(\"putative FRI (true tuning)\")\nplt.axvline(0, linestyle=\"--\", color=\"black\")\nplt.axhline(0, linestyle=\"--\", color=\"black\")\n\nplt.axhspan(0, 2, 0, 0.5, color=\"red\", zorder=-10)\nplt.axhspan(0, 2, 0.5, 1.0, color=\"green\", zorder=-10)\nplt.axhspan(-2, 0, 0, 0.5, color=\"green\", zorder=-10)\nplt.axhspan(-2, 0, 0.5, 1.0, color=\"red\", zorder=-10)\n\nplt.xlim(-1.05, 1.05)\nplt.ylim(-2, 2)\nplt.title(f\"Correlation = {fri_corr[0].item():.2g}\")\nplt.yticks([-1, 1], [\"OFF\", \"ON\"])\nplt.show()\n</code></pre> <p>As we can see, for all except two cell types, the model correctly predicts the cell\u2019s tuning (positive or negative).</p>"},{"location":"examples/03_flyvision_flash_responses/#ensemble-responses","title":"Ensemble responses","text":"<p>Now we can compare tuning properties across an ensemble of trained models. First we need to again simulate the network responses.</p> <pre><code>from flyvision import EnsembleView\n\nensemble = EnsembleView(results_dir / \"flow/0000\")\n</code></pre> <pre><code>stims_and_resps = ensemble.flash_responses(dataset=dataset)\n</code></pre>"},{"location":"examples/03_flyvision_flash_responses/#response-traces","title":"Response traces","text":"<p>We can once again plot response traces for a single cell type. We subtract the initial value of each trace to center the data before plotting, as the network neuron activities are in arbitrary units.</p> <pre><code>centered = stims_and_resps['responses'] - stims_and_resps['responses'].custom.where(time=0.0).values\n</code></pre> <pre><code>centered.sel(network_id=ensemble.argsort()[:10]).custom.where(cell_type=\"L1\", radius=6, intensity=1).custom.plot_traces(x='time', plot_kwargs=dict(color='orange', linewidth=0.5))\nax = plt.gca()\ncentered.sel(network_id=ensemble.argsort()[:10]).custom.where(cell_type=\"L1\", radius=6, intensity=0).custom.plot_traces(x='time', plot_kwargs=dict(ax=ax, color='blue', linewidth=0.5))\nax.set_title(\"L1 flash responses\")\n</code></pre> <p>Though the scaling varies, all networks predict depolarization to OFF-flashes for L1.</p>"},{"location":"examples/03_flyvision_flash_responses/#flash-response-index-fri_1","title":"Flash response index (FRI)","text":"<p>We can also compute flash response indices for each network in the ensemble.</p> <pre><code># get FRI for L1 cell\nfri_l1 = flash_response_index(stims_and_resps, radius=6).sel(network_id=ensemble.argsort()[:10]).custom.where(cell_type=\"L1\")\nprint(fri_l1.squeeze().values)\n</code></pre> <p>All models recover similar flash response indices for this cell type. We can also plot the distribution of FRIs per cell type across the ensemble.</p> <pre><code>with ensemble.select_items(ensemble.argsort()[:10]):\n    ensemble.flash_response_index()\n</code></pre>"},{"location":"examples/03_flyvision_flash_responses/#fri-correlation_1","title":"FRI correlation","text":"<p>Lastly, we look at the correlations to ground-truth tuning across the ensemble.</p> <pre><code>from flyvision.analysis.flash_responses import flash_response_index\n</code></pre> <pre><code>fris = flash_response_index(stims_and_resps, radius=6)\n</code></pre> <pre><code>from flyvision.plots.plots import violin_groups\n\n# compute correlation\nfri_corr = fri_correlation_to_known(fris)\n\nfig, ax, *_ = violin_groups(\n    np.array(fri_corr)[None, None, :].squeeze(-1),\n    ylabel=\"FRI correlation\",\n    figsize=(2, 2),\n    xlim=(0, 1),\n    xticklabels=[],\n    colors=[plt.get_cmap(\"Pastel1\")(0.0)],\n    scatter_edge_color=\"gray\",\n    scatter_radius=10,\n)\n</code></pre> <p>Models in general have very good match to known single-neuron tuning properties, with median correlation around 0.8.</p>"},{"location":"examples/04_flyvision_moving_edge_responses/","title":"Moving edge responses","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre>"},{"location":"examples/04_flyvision_moving_edge_responses/#moving-edge-responses","title":"Moving edge responses","text":"<p>This notebook introduces moving edge responses and the direction selectivity index (DSI). The DSI measures motion selectivity of cells to visual input.</p> <p>Select GPU runtime</p> <p>To run the notebook on a GPU select Menu -&gt; Runtime -&gt; Change runtime type -&gt; GPU.</p> <pre><code># @markdown **Check access to GPU**\n\ntry:\n    import google.colab\n\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n\nif IN_COLAB:\n    import torch\n\n    try:\n        cuda_name = torch.cuda.get_device_name()\n        print(f\"Name of the assigned GPU / CUDA device: {cuda_name}\")\n    except RuntimeError:\n        import warnings\n\n        warnings.warn(\n            \"You have not selected Runtime Type: 'GPU' or Google could not assign you one. Please revisit the settings as described above or proceed on CPU (slow).\"\n        )\n</code></pre> <p>Install Flyvis</p> <p>The notebook requires installing our package <code>flyvis</code>. You may need to restart your session after running the code block below with Menu -&gt; Runtime -&gt; Restart session. Then, imports from <code>flyvis</code> should succeed without issue.</p> <pre><code>if IN_COLAB:\n    #@markdown **Install Flyvis**\n    %%capture\n    !git clone https://github.com/flyvis/flyvis-dev.git\n    %cd /content/flyvis-dev\n    !pip install -e .\n</code></pre> <pre><code># basic imports\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nplt.rcParams[\"figure.dpi\"] = 200\n</code></pre>"},{"location":"examples/04_flyvision_moving_edge_responses/#moving-edge-stimuli","title":"Moving edge stimuli","text":"<p>To elicit moving edge responses and characterise the motion selectivity of neurons, experimenters show an ON or OFF edge moving in different cardinal directions. We generate and render these stimuli with the <code>MovingEdge</code> dataset.</p> <pre><code># import dataset and visualization helper\nfrom flyvision.datasets.moving_bar import MovingEdge\nfrom flyvision.animations.hexscatter import HexScatter\n</code></pre> <pre><code># initialize dataset\n# make the dataset\ndataset = MovingEdge(\n    offsets=[-10, 11],  # offset of bar from center in 1 * radians(2.25) led size\n    intensities=[0, 1],  # intensity of bar\n    speeds=[19],  # speed of bar in 1 * radians(5.8) / s\n    height=80,  # height of moving bar in 1 * radians(2.25) led size\n    post_pad_mode=\"continue\",  # for post-stimulus period, continue with the last frame of the stimulus\n    t_pre=1.0,  # duration of pre-stimulus period\n    t_post=1.0,  # duration of post-stimulus period\n    dt=1 / 200,  # temporal resolution of rendered video\n    angles=list(np.arange(0, 360, 30)),  # motion direction (orthogonal to edge)\n)\n</code></pre> <pre><code># view stimulus parameters\ndataset.arg_df\n# the dataset has four samples, one corresponding to each row\n</code></pre> angle width intensity t_stim speed 0 0 80 0 0.428766 19 1 0 80 1 0.428766 19 2 30 80 0 0.428766 19 3 30 80 1 0.428766 19 4 60 80 0 0.428766 19 5 60 80 1 0.428766 19 6 90 80 0 0.428766 19 7 90 80 1 0.428766 19 8 120 80 0 0.428766 19 9 120 80 1 0.428766 19 10 150 80 0 0.428766 19 11 150 80 1 0.428766 19 12 180 80 0 0.428766 19 13 180 80 1 0.428766 19 14 210 80 0 0.428766 19 15 210 80 1 0.428766 19 16 240 80 0 0.428766 19 17 240 80 1 0.428766 19 18 270 80 0 0.428766 19 19 270 80 1 0.428766 19 20 300 80 0 0.428766 19 21 300 80 1 0.428766 19 22 330 80 0 0.428766 19 23 330 80 1 0.428766 19 <pre><code># visualize single sample\n# %#matplotlib notebook\nanimation = HexScatter(\n    dataset[3][None, ::25, None], vmin=0, vmax=1\n)  # intensity=1, radius=6\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/04_flyvision_moving_edge_responses/#moving-edge-response","title":"Moving edge response","text":"<p>Now that we have generated the stimulus, we can use it to drive a trained connectome-constrained network.</p> <pre><code>from flyvision import results_dir\nfrom flyvision.network import NetworkView\n\n# model are already sorted by task error\n# we take the best task-performing model from the pre-sorted ensemble\nnetwork_view = NetworkView(results_dir / \"flow/0000/000\")\n</code></pre> <pre><code>[2024-09-25 15:35:49] network:1005 Initialized network view at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000.\n</code></pre> <pre><code>stims_and_resps = network_view.movingedge_responses(dataset)\n</code></pre> <pre><code>[2024-09-25 15:35:49] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f3082758790&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/000', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f30798ac430&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'angles': [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n  'bar_loc_horizontal': 0.0,\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': [-10, 11],\n  'post_pad_mode': 'continue',\n  'shuffle_offsets': False,\n  'speeds': [19],\n  't_post': 1.0,\n  't_pre': 1.0,\n  'widths': [80]}, \n4, 1.0, 0.0).\n\n                        (argument hash 3b098d8fe94f37eebf7369247554b311)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-25 15:35:49] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses/3b098d8fe94f37eebf7369247554b311/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.1s, 0.0min\n</code></pre> <p>We\u2019ve now computed network moving edge responses for all cells in the network.</p>"},{"location":"examples/04_flyvision_moving_edge_responses/#response-traces","title":"Response traces","text":"<p>We can plot single-cell response traces with <code>stims_and_resps['responses'].custom.plot_traces()</code>. Here, we plot responses of T4c cells to edges with intensity 1 (ON edges).</p> <pre><code>stims_and_resps[\"responses\"].custom.where(\n    cell_type=\"T4c\", intensity=1, time=\"&gt;-0.5,&lt;1.0\"\n).custom.plot_traces(x=\"time\", legend_labels=[\"angle\"])\nax = plt.gca()\nax.set_title(\"T4c responses to moving edge\")\n</code></pre> <pre><code>Text(0.5, 1.0, 'T4c responses to moving edge')\n</code></pre> <p></p>"},{"location":"examples/04_flyvision_moving_edge_responses/#direction-selectivity-index-dsi","title":"Direction selectivity index (DSI)","text":"<p>The Direction Selectivity Index (DSI) quantifies a cell\u2019s preference for stimuli moving in a particular direction.</p> <p>The DSI is derived from the following steps: 1. Obtain the neuron\u2019s peak responses to stimuli moving in different directions \\(\\theta\\) and at different speeds \\(S\\). 2. Rectify these peak responses to ensure they are non-negative. 3. Compute the DSI using the equation:</p> \\[ DSI_{t_i}(I) = \\frac{1}{\\lvert S \\rvert} \\sum_{S \\in S} \\left\\lvert \\frac{\\sum_{\\theta \\in \\Theta} r^{peak}_{t_{central}}(I, S, \\theta) e^{i\\theta}}{\\max_{I \\in I} \\left\\lvert \\sum_{\\theta \\in \\Theta} r^{peak}_{t_{central}}(I, S, \\theta) \\right\\rvert} \\right\\rvert \\] <p>Where: - \\(DSI_{t_i}(I)\\) is the Direction Selectivity Index for cell type \\(t_i\\) at stimulus intensity \\(I\\). - \\(\\lvert S \\rvert\\) is the number of different speeds at which stimuli are moved. - \\(r^{peak}_{t_{central}}(I, S, \\theta)\\) represents the rectified peak response of the central cell in hexagonal space of a cell type, for a given stimulus intensity \\(I\\), speed \\(S\\), and direction \\(\\theta\\). - \\(\\theta\\) is varied across all tested directions \\(\\Theta\\). - \\(e^{i\\theta}\\) introduces the directional component by weighting the response by the complex exponential of the angle of movement. - The denominator normalizes the responses, ensuring that DSI values range from 0 to 1.</p> <p>The DSI values range from 0 to 1. A DSI of 0 indicates no directional preference, while a DSI of 1 indicates a strong preference for a specific direction.</p> <p>For the T4c cell plotted before, we can see that it preferentially responds to ON edges moving at an angle of 60 degrees, so we expect to see a large DSI.</p> <p>We compute the DSI with <code>flyvision.analysis.direction_selectivity_index</code>.</p> <pre><code>from flyvision.analysis import direction_selectivity_index\n</code></pre> <pre><code># get DSI for T4c cell\ndsis = direction_selectivity_index(stims_and_resps)\nprint(f\"T4c DSI: {dsis.custom.where(cell_type='T4c', intensity=1).item():.2f}\")\n</code></pre> <pre><code>T4c DSI: 0.63\n</code></pre> <p>We compute the preferred direction of the cell with <code>flyvision.analysis.preferred_direction</code> (this is the direction that the tuning lobe points towards). We would expect the preferred direction to be around 60 degrees based on the response traces.</p> <pre><code>from flyvision.analysis import preferred_direction\n</code></pre> <pre><code>pds = preferred_direction(stims_and_resps)\nprint(\n    f\"T4c preferred direction: {pds.custom.where(cell_type='T4c', intensity=1).item() / np.pi * 180:.2f} degrees\"\n)\n</code></pre> <pre><code>T4c preferred direction: 56.24 degrees\n</code></pre> <p>We can also inspect the direction selecity of a cell type visually, by plotting the angular tuning with <code>plot_angular_tuning</code>.</p> <p>Here we see clearly how the cell is tuned to stimuli moving at a 60 degree angle.</p> <pre><code>from flyvision.analysis import plot_angular_tuning\n</code></pre> <pre><code>plot_angular_tuning(stims_and_resps, cell_type=\"T4c\", intensity=1)\n</code></pre> <pre><code>(&lt;Figure size 300x300 with 1 Axes&gt;, &lt;PolarAxes: &gt;)\n</code></pre> <p></p>"},{"location":"examples/04_flyvision_moving_edge_responses/#dsi-and-tuning-curve-correlation","title":"DSI  and tuning curve correlation","text":"<p>With the <code>dsi()</code> function we can also compute DSIs for every cell type at once. Since the selectivity of some cell types have been determined experimentally, we can then compare our model to experimental findings by computing the correlation between the model DSIs for known cell types with their expected motion selectivity.</p> <pre><code>from flyvision.analysis import dsi_correlation_to_known\n</code></pre> <pre><code>dsi_corr = dsi_correlation_to_known(\n    direction_selectivity_index(stims_and_resps)\n).median()\n</code></pre> <pre><code>print(f\"DSI correlation = {dsi_corr.item(): .2f}\")\n</code></pre> <pre><code>DSI correlation =  0.65\n</code></pre> <p>Further, for certain cell types, their actual tuning curves have also been measured experimentally, so we can correlate our model cell\u2019s tuning to the true values. For T4c, the cell is known to tune to stimuli moving at 90 degrees, so the correlation should be relatively high.</p> <pre><code>from flyvision.analysis import correlation_to_known_tuning_curves\n</code></pre> <pre><code>corrs = correlation_to_known_tuning_curves(stims_and_resps)\n</code></pre> <pre><code>print(\n    f\"T4c tuning curve correlation = {corrs.custom.where(cell_type='T4c', intensity=1).squeeze().item():.2f}\"\n)\n</code></pre> <pre><code>T4c tuning curve correlation = 0.54\n</code></pre> <p>In fact, tuning curves for all T4 and T5 cells have been measured, so we can compute the correlation for all 8 cell types.</p> <pre><code>t4_corrs = corrs.custom.where(cell_type=[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], intensity=1)\nt5_corrs = corrs.custom.where(cell_type=[\"T5a\", \"T5b\", \"T5c\", \"T5d\"], intensity=0)\n</code></pre> <pre><code>print(\n    f\"T4 tuning curve correlations: {t4_corrs.cell_type.values}\\n{t4_corrs.squeeze().values}\"\n)\n</code></pre> <pre><code>T4 tuning curve correlations: ['T4a' 'T4b' 'T4c' 'T4d']\n[0.93699976 0.71944943 0.53721794 0.85661069]\n</code></pre> <pre><code>print(\n    f\"T5 tuning curve correlations: {t5_corrs.cell_type.values}\\n{t5_corrs.squeeze().values}\"\n)\n</code></pre> <pre><code>T5 tuning curve correlations: ['T5a' 'T5b' 'T5c' 'T5d']\n[0.84125435 0.90320946 0.94956466 0.90100504]\n</code></pre> <p>So, the model yields accurate predictions for all T4 and T5 cell types.</p>"},{"location":"examples/04_flyvision_moving_edge_responses/#ensemble-responses","title":"Ensemble responses","text":"<p>Now we can compare motion selectivity properties across an ensemble of trained models. First we need to again simulate the network responses.</p> <pre><code>from flyvision import EnsembleView\n\nensemble = EnsembleView(results_dir / \"flow/0000\")\n# choose best 10\nensemble = ensemble[ensemble.argsort()[:10]]\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-09-25 15:36:10] ensemble:138 Loaded 50 networks.\n\n\n\nLoading ensemble:   0%|          | 0/10 [00:00&lt;?, ?it/s]\n\n\n[2024-09-25 15:36:15] ensemble:138 Loaded 10 networks.\n</code></pre> <pre><code>%%capture\nstims_and_resps = ensemble.movingedge_responses(dataset=dataset)\n</code></pre> <pre><code>[2024-09-25 15:36:16] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f3082758790&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/000', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f30798ac430&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'angles': [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n  'bar_loc_horizontal': 0.0,\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': [-10, 11],\n  'post_pad_mode': 'continue',\n  'shuffle_offsets': False,\n  'speeds': [19],\n  't_post': 1.0,\n  't_pre': 1.0,\n  'widths': [80]}, \n4, 1.0, 0.0).\n\n                        (argument hash 3b098d8fe94f37eebf7369247554b311)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-25 15:36:16] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses/3b098d8fe94f37eebf7369247554b311/output.h5\n[2024-09-25 15:36:16] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f3082758790&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/001', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f30798ac430&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'angles': [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n  'bar_loc_horizontal': 0.0,\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': [-10, 11],\n  'post_pad_mode': 'continue',\n  'shuffle_offsets': False,\n  'speeds': [19],\n  't_post': 1.0,\n  't_pre': 1.0,\n  'widths': [80]}, \n4, 1.0, 0.0).\n\n                        (argument hash 325e88a715551d0a149b5dae673c8f83)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-25 15:36:16] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses/325e88a715551d0a149b5dae673c8f83/output.h5\n[2024-09-25 15:36:16] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f3082758790&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/002', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f30798ac430&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'angles': [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n  'bar_loc_horizontal': 0.0,\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': [-10, 11],\n  'post_pad_mode': 'continue',\n  'shuffle_offsets': False,\n  'speeds': [19],\n  't_post': 1.0,\n  't_pre': 1.0,\n  'widths': [80]}, \n4, 1.0, 0.0).\n\n                        (argument hash 8912ba93ac77a2d8a372a9aedbce0d4b)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-25 15:36:16] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__/flyvision/analysis/stimulus_responses/compute_responses/8912ba93ac77a2d8a372a9aedbce0d4b/output.h5\n[2024-09-25 15:36:16] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f3082758790&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/003', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f30798ac430&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'angles': [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n  'bar_loc_horizontal': 0.0,\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': [-10, 11],\n  'post_pad_mode': 'continue',\n  'shuffle_offsets': False,\n  'speeds': [19],\n  't_post': 1.0,\n  't_pre': 1.0,\n  'widths': [80]}, \n4, 1.0, 0.0).\n\n                        (argument hash 34abd51c78f6409009acc6ec30fb6e54)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-25 15:36:16] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__/flyvision/analysis/stimulus_responses/compute_responses/34abd51c78f6409009acc6ec30fb6e54/output.h5\n[2024-09-25 15:36:16] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f3082758790&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/004', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f30798ac430&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'angles': [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n  'bar_loc_horizontal': 0.0,\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': [-10, 11],\n  'post_pad_mode': 'continue',\n  'shuffle_offsets': False,\n  'speeds': [19],\n  't_post': 1.0,\n  't_pre': 1.0,\n  'widths': [80]}, \n4, 1.0, 0.0).\n\n                        (argument hash 757735e00ab721a6bcd14c8ac50f65c9)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-25 15:36:16] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__/flyvision/analysis/stimulus_responses/compute_responses/757735e00ab721a6bcd14c8ac50f65c9/output.h5\n[2024-09-25 15:36:16] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f3082758790&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/005', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f30798ac430&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'angles': [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n  'bar_loc_horizontal': 0.0,\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': [-10, 11],\n  'post_pad_mode': 'continue',\n  'shuffle_offsets': False,\n  'speeds': [19],\n  't_post': 1.0,\n  't_pre': 1.0,\n  'widths': [80]}, \n4, 1.0, 0.0).\n\n                        (argument hash 761b503cb11d83b87ccca4437485a05c)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-25 15:36:16] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__/flyvision/analysis/stimulus_responses/compute_responses/761b503cb11d83b87ccca4437485a05c/output.h5\n[2024-09-25 15:36:17] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f3082758790&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/006', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f30798ac430&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'angles': [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n  'bar_loc_horizontal': 0.0,\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': [-10, 11],\n  'post_pad_mode': 'continue',\n  'shuffle_offsets': False,\n  'speeds': [19],\n  't_post': 1.0,\n  't_pre': 1.0,\n  'widths': [80]}, \n4, 1.0, 0.0).\n\n                        (argument hash 2ef227637edf3421104836b79b8dd061)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-25 15:36:17] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__/flyvision/analysis/stimulus_responses/compute_responses/2ef227637edf3421104836b79b8dd061/output.h5\n[2024-09-25 15:36:17] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f3082758790&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/007', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f30798ac430&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'angles': [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n  'bar_loc_horizontal': 0.0,\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': [-10, 11],\n  'post_pad_mode': 'continue',\n  'shuffle_offsets': False,\n  'speeds': [19],\n  't_post': 1.0,\n  't_pre': 1.0,\n  'widths': [80]}, \n4, 1.0, 0.0).\n\n                        (argument hash e2e8db05a1a5046ed0ec8793ea1bf1ec)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-25 15:36:17] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__/flyvision/analysis/stimulus_responses/compute_responses/e2e8db05a1a5046ed0ec8793ea1bf1ec/output.h5\n[2024-09-25 15:36:17] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f3082758790&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/008', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f30798ac430&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'angles': [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n  'bar_loc_horizontal': 0.0,\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': [-10, 11],\n  'post_pad_mode': 'continue',\n  'shuffle_offsets': False,\n  'speeds': [19],\n  't_post': 1.0,\n  't_pre': 1.0,\n  'widths': [80]}, \n4, 1.0, 0.0).\n\n                        (argument hash 93e70ecb95c60d98cdc493ee50ba177b)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-25 15:36:17] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__/flyvision/analysis/stimulus_responses/compute_responses/93e70ecb95c60d98cdc493ee50ba177b/output.h5\n[2024-09-25 15:36:17] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f3082758790&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/009', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f30798ac430&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'angles': [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n  'bar_loc_horizontal': 0.0,\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': [-10, 11],\n  'post_pad_mode': 'continue',\n  'shuffle_offsets': False,\n  'speeds': [19],\n  't_post': 1.0,\n  't_pre': 1.0,\n  'widths': [80]}, \n4, 1.0, 0.0).\n\n                        (argument hash bf2f8033eea3ff6c92e1e5f355f18096)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-25 15:36:17] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__/flyvision/analysis/stimulus_responses/compute_responses/bf2f8033eea3ff6c92e1e5f355f18096/output.h5\n</code></pre>"},{"location":"examples/04_flyvision_moving_edge_responses/#response-traces_1","title":"Response traces","text":"<p>We can once again plot response traces for a single cell type. </p> <p>We subtract the initial value of each trace and divide by the max as the network neuron activities are in arbitrary units. </p> <p>We plot only T4c responses to ON edges moving at a 90-degree angle.</p> <pre><code>responses = (\n    stims_and_resps[\"responses\"]\n    - stims_and_resps[\"responses\"].custom.where(time=0).values\n)\n</code></pre> <pre><code>responses = responses / np.abs(responses).max((\"sample\", \"frame\"))\n</code></pre> <pre><code>responses.custom.where(\n    cell_type=\"T4c\",\n    intensity=1,\n    time=\"&gt;-0.5,&lt;1.0\",\n    angle=90,\n).custom.plot_traces(\n    x=\"time\", plot_kwargs=dict(color=\"tab:blue\"), legend_labels=[\"network_id\"]\n)\n</code></pre> <pre><code>&lt;Axes: xlabel='time', ylabel='responses'&gt;\n</code></pre> <p></p> <p>Though for most networks T4c responses are correctly predicted to the stimuli, there are some networks in the ensemble with different responses.</p>"},{"location":"examples/04_flyvision_moving_edge_responses/#direction-selectivity-index-dsi_1","title":"Direction selectivity index (DSI)","text":"<p>We can also compute direction selectivity indices for each network in the ensemble.</p> <pre><code>dsis = direction_selectivity_index(stims_and_resps)\n</code></pre> <pre><code>dsis.custom.where(cell_type=\"T4c\", intensity=1).plot.hist()\nax = plt.gca()\nax.set_title(\"T4c DSI distribution\")\nax.set_ylabel(\"Number of networks\")\n</code></pre> <pre><code>Text(0, 0.5, 'Number of networks')\n</code></pre> <p></p> <p>Most networks in this group recover some direction selectivity for T4c. We can also plot the distribution of DSIs per cell type for both ON and OFF-edge stimuli across the ensemble.</p> <pre><code>from flyvision.analysis.moving_bar_responses import plot_dsis\n\nfig, ax = plot_dsis(\n    dsis,\n    dsis.cell_type,\n    bold_output_type_labels=True,\n    output_cell_types=ensemble[ensemble.names[0]]\n    .connectome.output_cell_types[:]\n    .astype(str),\n    figsize=[10, 1.2],\n    color_known_types=True,\n    fontsize=6,\n    scatter_best_index=0,\n    scatter_best_color=plt.get_cmap(\"Blues\")(1.0),\n)\n</code></pre> <p></p>"},{"location":"examples/04_flyvision_moving_edge_responses/#dsi-correlation","title":"DSI correlation","text":"<p>Lastly, we look at the correlations to ground-truth DSIs and tuning curves across the ensemble. This provides us with a high-level understanding of the accuracy of known motion tuning predictions. </p> <pre><code>dsi_corr = dsi_correlation_to_known(\n    direction_selectivity_index(stims_and_resps)\n).median(\"intensity\")\n</code></pre> <pre><code>tuning_corrs = correlation_to_known_tuning_curves(stims_and_resps)\n</code></pre> <pre><code>t4_corrs = tuning_corrs.custom.where(cell_type=[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], intensity=1).median(\"neuron\").squeeze()\nt5_corrs = tuning_corrs.custom.where(cell_type=[\"T5a\", \"T5b\", \"T5c\", \"T5d\"], intensity=0).median(\"neuron\").squeeze()\n</code></pre> <pre><code>dsi_corr.shape, t4_corrs.shape, t5_corrs.shape\n</code></pre> <pre><code>((10,), (10,), (10,))\n</code></pre> <pre><code>from flyvision.plots.plots import violin_groups\n\nfig, ax, *_ = violin_groups(\n    np.stack([dsi_corr.values, t4_corrs.values, t5_corrs.values], axis=0)[:, None, :],\n    [\"DSI\", \"T4 tuning\", \"T5 tuning\"],\n    ylabel=\"correlation\",\n    figsize=(1.8, 1.5),\n    ylim=(-1, 1),\n    colors=[\n        plt.get_cmap(\"Dark2\")(0.125),\n        plt.get_cmap(\"Dark2\")(0),\n        plt.get_cmap(\"Dark2\")(0.25),\n    ],\n    color_by=\"experiments\",\n    scatter_edge_color=\"gray\",\n    scatter_radius=5,\n    violin_alpha=0.8,\n)\n</code></pre> <p></p>"},{"location":"examples/05_flyvision_umap_and_clustering_models/","title":"Ensemble clustering","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#cluster-analysis-based-on-naturalistic-stimuli-responses","title":"Cluster analysis based on naturalistic stimuli responses","text":"<p>This notebook illustrates how to cluster the models of an ensemble after nonlinear dimensionality reduction on their predicted responses to naturalistic stimuli. This can be done for any cell type. Here we provide a detailed example focusing on clustering based on T4c responses.</p> <p>Select GPU runtime</p> <p>To run the notebook on a GPU select Menu -&gt; Runtime -&gt; Change runtime type -&gt; GPU.</p> <pre><code># @markdown **Check access to GPU**\n\ntry:\n    import google.colab\n\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n\nif IN_COLAB:\n    import torch\n\n    try:\n        cuda_name = torch.cuda.get_device_name()\n        print(f\"Name of the assigned GPU / CUDA device: {cuda_name}\")\n    except RuntimeError:\n        import warnings\n\n        warnings.warn(\n            \"You have not selected Runtime Type: 'GPU' or Google could not assign you one. Please revisit the settings as described above or proceed on CPU (slow).\"\n        )\n</code></pre> <p>Install Flyvis</p> <p>The notebook requires installing our package <code>flyvis</code>. You may need to restart your session after running the code block below with Menu -&gt; Runtime -&gt; Restart session. Then, imports from <code>flyvis</code> should succeed without issue.</p> <pre><code>if IN_COLAB:\n    #@markdown **Install Flyvis**\n    %%capture\n    !git clone https://github.com/flyvis/flyvis-dev.git\n    %cd /content/flyvis-dev\n    !pip install -e .\n</code></pre> <pre><code># basic imports\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nplt.rcParams['figure.dpi'] = 200\n</code></pre>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#naturalistic-stimuli-dataset-sintel","title":"Naturalistic stimuli dataset (Sintel)","text":"<p>We load the dataset with our custom augmentations. The dataset contains movie sequences from the publicly available computer-animated movie Sintel rendered to the hexagonal lattice structure of the fly eye. For a more detailed introduction to the dataset class and parameters see the notebook on the optic flow task.</p> <pre><code>import flyvision\nfrom flyvision.datasets.sintel import AugmentedSintel\nimport numpy as np\n</code></pre> <pre><code>dt = 1 / 100  # can be changed for other temporal resolutions\ndataset = AugmentedSintel(\n    tasks=[\"lum\"],\n    interpolate=False,\n    boxfilter={'extent': 15, 'kernel_size': 13},\n    temporal_split=True,\n    dt=dt,\n)\n</code></pre> <pre><code># view stimulus parameters\ndataset.arg_df\n</code></pre> name original_index vertical_split_index temporal_split_index frames flip_ax n_rot 0 sequence_00_alley_1_split_00 0 0 0 19 0 0 1 sequence_00_alley_1_split_00 0 0 0 19 0 1 2 sequence_00_alley_1_split_00 0 0 0 19 0 2 3 sequence_00_alley_1_split_00 0 0 0 19 0 3 4 sequence_00_alley_1_split_00 0 0 0 19 0 4 ... ... ... ... ... ... ... ... 2263 sequence_22_temple_3_split_02 22 68 188 19 1 1 2264 sequence_22_temple_3_split_02 22 68 188 19 1 2 2265 sequence_22_temple_3_split_02 22 68 188 19 1 3 2266 sequence_22_temple_3_split_02 22 68 188 19 1 4 2267 sequence_22_temple_3_split_02 22 68 188 19 1 5 <p>2268 rows \u00d7 7 columns</p> <pre><code>sequence = dataset[0][\"lum\"]\n</code></pre> <pre><code># one sequence contains 80 frames with 721 hexals each\nsequence.shape\n</code></pre> <pre><code>torch.Size([80, 1, 721])\n</code></pre> <pre><code>animation = flyvision.animations.HexScatter(sequence[None], vmin=0, vmax=1)\nanimation.animate_in_notebook(frames=np.arange(5))\n</code></pre> <p></p>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#ensemble-responses-to-a-single-sequence","title":"Ensemble responses to a single sequence","text":"<p>We compute the responses of all models in the stored ensemble to the first sequence of the augmented Sintel dataset.</p> <pre><code>from flyvision import results_dir\n</code></pre> <pre><code># We load the ensemble trained on the optic flow task\nensemble = flyvision.EnsembleView(results_dir / \"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-09-28 03:44:52] ensemble:138 Loaded 50 networks.\n</code></pre> <p>We use <code>ensemble.naturalistic_stimuli_responses</code> to return responses of all networks within the ensemble.</p> <pre><code>stims_and_resps = ensemble.naturalistic_stimuli_responses()\n</code></pre> <pre><code>[2024-09-28 03:44:52] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/000', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash bef8ab0b1f1206171b1e38bf67305c6f)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:52] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses/bef8ab0b1f1206171b1e38bf67305c6f/output.h5\n[2024-09-28 03:44:52] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/001', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 5dfcd34808931599c6e27e5ad94909ca)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:52] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses/5dfcd34808931599c6e27e5ad94909ca/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.1s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:52] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/002', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 34b1b21c2f716dc063336dbecbacd359)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:52] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__/flyvision/analysis/stimulus_responses/compute_responses/34b1b21c2f716dc063336dbecbacd359/output.h5\n[2024-09-28 03:44:52] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/003', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 5ad5a3d978297c698566ab6886508aab)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:52] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__/flyvision/analysis/stimulus_responses/compute_responses/5ad5a3d978297c698566ab6886508aab/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:53] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/004', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 31d213c49b6e1131d94d309a37bba639)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:53] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__/flyvision/analysis/stimulus_responses/compute_responses/31d213c49b6e1131d94d309a37bba639/output.h5\n[2024-09-28 03:44:53] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/005', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 4dabb28b09b5a639c029a18ce380d46e)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:53] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__/flyvision/analysis/stimulus_responses/compute_responses/4dabb28b09b5a639c029a18ce380d46e/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:53] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/006', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash a38274cdad5b947ed2e463bb2f899add)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:53] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__/flyvision/analysis/stimulus_responses/compute_responses/a38274cdad5b947ed2e463bb2f899add/output.h5\n[2024-09-28 03:44:53] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/007', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 24ae2d0f3817eeb1c1747a513378f4d2)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:53] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__/flyvision/analysis/stimulus_responses/compute_responses/24ae2d0f3817eeb1c1747a513378f4d2/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:53] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/008', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 0123be8edce88ec2f710d1fd9dfff14a)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:53] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__/flyvision/analysis/stimulus_responses/compute_responses/0123be8edce88ec2f710d1fd9dfff14a/output.h5\n[2024-09-28 03:44:53] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/009', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 718237993c1fb18418d915b2968ff3c2)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:53] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__/flyvision/analysis/stimulus_responses/compute_responses/718237993c1fb18418d915b2968ff3c2/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:53] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/010/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/010', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/010/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash ff2491ccb529684a8e9a7df2d7b79bf9)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/010/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:53] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/010/__cache__/flyvision/analysis/stimulus_responses/compute_responses/ff2491ccb529684a8e9a7df2d7b79bf9/output.h5\n[2024-09-28 03:44:54] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/011/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/011', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/011/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 83252c4949e38c210f3aa72e7ef22069)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/011/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:54] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/011/__cache__/flyvision/analysis/stimulus_responses/compute_responses/83252c4949e38c210f3aa72e7ef22069/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:54] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/012/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/012', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/012/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 1538b2fc8f46ad04617796f998332762)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/012/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:54] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/012/__cache__/flyvision/analysis/stimulus_responses/compute_responses/1538b2fc8f46ad04617796f998332762/output.h5\n[2024-09-28 03:44:54] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/013/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/013', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/013/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 585cfb92bccb448a82653108abb70ff3)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/013/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:54] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/013/__cache__/flyvision/analysis/stimulus_responses/compute_responses/585cfb92bccb448a82653108abb70ff3/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:54] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/014/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/014', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/014/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash a52998e5072aa7b3f390b8dfd1c6889c)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/014/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:54] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/014/__cache__/flyvision/analysis/stimulus_responses/compute_responses/a52998e5072aa7b3f390b8dfd1c6889c/output.h5\n[2024-09-28 03:44:54] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/015/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/015', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/015/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash a402afd786b7a1463e110a73ff0d319e)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/015/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:54] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/015/__cache__/flyvision/analysis/stimulus_responses/compute_responses/a402afd786b7a1463e110a73ff0d319e/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:54] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/016/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/016', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/016/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash f0efdcc46faa20ab4ce5c963b0ca7d8d)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/016/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:54] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/016/__cache__/flyvision/analysis/stimulus_responses/compute_responses/f0efdcc46faa20ab4ce5c963b0ca7d8d/output.h5\n[2024-09-28 03:44:54] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/017/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/017', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/017/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash b12b5469a747e95fc2ce4e7b5bf73b9a)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/017/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:54] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/017/__cache__/flyvision/analysis/stimulus_responses/compute_responses/b12b5469a747e95fc2ce4e7b5bf73b9a/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:55] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/018/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/018', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/018/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 72b6cc7f982a87e845f2e393a185ef96)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/018/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:55] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/018/__cache__/flyvision/analysis/stimulus_responses/compute_responses/72b6cc7f982a87e845f2e393a185ef96/output.h5\n[2024-09-28 03:44:55] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/019/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/019', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/019/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 55e904c1132161ff29d7476e20b2cbea)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/019/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:55] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/019/__cache__/flyvision/analysis/stimulus_responses/compute_responses/55e904c1132161ff29d7476e20b2cbea/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:55] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/020/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/020', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/020/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 5fcbf0ff71289c927d78ab82b8b658e1)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/020/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:55] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/020/__cache__/flyvision/analysis/stimulus_responses/compute_responses/5fcbf0ff71289c927d78ab82b8b658e1/output.h5\n[2024-09-28 03:44:55] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/021/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/021', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/021/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 8206028404679417dccf5dada182bcce)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/021/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:55] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/021/__cache__/flyvision/analysis/stimulus_responses/compute_responses/8206028404679417dccf5dada182bcce/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:55] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/022/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/022', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/022/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 399d668f254864b6559e7efb3769bd0a)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/022/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:55] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/022/__cache__/flyvision/analysis/stimulus_responses/compute_responses/399d668f254864b6559e7efb3769bd0a/output.h5\n[2024-09-28 03:44:55] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/023/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/023', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/023/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 23cc9baf9d310beceb3262e6c4da1743)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/023/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:55] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/023/__cache__/flyvision/analysis/stimulus_responses/compute_responses/23cc9baf9d310beceb3262e6c4da1743/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:55] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/024/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/024', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/024/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 60b4790394985973a5e808cb0a7869c0)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/024/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:55] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/024/__cache__/flyvision/analysis/stimulus_responses/compute_responses/60b4790394985973a5e808cb0a7869c0/output.h5\n[2024-09-28 03:44:55] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/025/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/025', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/025/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 6d866edcf636ca2c5de322d90262cc52)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/025/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:56] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/025/__cache__/flyvision/analysis/stimulus_responses/compute_responses/6d866edcf636ca2c5de322d90262cc52/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:56] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/026/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/026', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/026/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash f7c36c5c21211df0f419b5284403d88b)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/026/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:56] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/026/__cache__/flyvision/analysis/stimulus_responses/compute_responses/f7c36c5c21211df0f419b5284403d88b/output.h5\n[2024-09-28 03:44:56] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/027/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/027', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/027/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 459546e87c028c04222599bc967a4a61)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/027/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:56] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/027/__cache__/flyvision/analysis/stimulus_responses/compute_responses/459546e87c028c04222599bc967a4a61/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:56] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/028/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/028', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/028/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash b1ca46217250705cd80c3356d9084f7e)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/028/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:56] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/028/__cache__/flyvision/analysis/stimulus_responses/compute_responses/b1ca46217250705cd80c3356d9084f7e/output.h5\n[2024-09-28 03:44:56] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/029/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/029', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/029/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 7907dbe75d0ae5ecc252d7abc2fc21ba)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/029/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:56] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/029/__cache__/flyvision/analysis/stimulus_responses/compute_responses/7907dbe75d0ae5ecc252d7abc2fc21ba/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:56] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/030/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/030', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/030/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash bb38c7354699e2a69caae52e10193d6c)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/030/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:56] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/030/__cache__/flyvision/analysis/stimulus_responses/compute_responses/bb38c7354699e2a69caae52e10193d6c/output.h5\n[2024-09-28 03:44:56] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/031/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/031', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/031/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash a48b16337cba74c9740c8892c0d694ed)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/031/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:56] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/031/__cache__/flyvision/analysis/stimulus_responses/compute_responses/a48b16337cba74c9740c8892c0d694ed/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:56] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/032/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/032', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/032/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 3f4fec610bd93e077866f41e9f14be97)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/032/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:56] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/032/__cache__/flyvision/analysis/stimulus_responses/compute_responses/3f4fec610bd93e077866f41e9f14be97/output.h5\n[2024-09-28 03:44:57] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/033/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/033', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/033/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 7af457beb2a5448a382a401f87c6c43b)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/033/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:57] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/033/__cache__/flyvision/analysis/stimulus_responses/compute_responses/7af457beb2a5448a382a401f87c6c43b/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:57] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/034/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/034', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/034/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash f4d5d3e124a1707086a4b9571dcf88fd)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/034/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:57] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/034/__cache__/flyvision/analysis/stimulus_responses/compute_responses/f4d5d3e124a1707086a4b9571dcf88fd/output.h5\n[2024-09-28 03:44:57] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/035/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/035', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/035/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 066e0e5617f86c1a995fd9593f6ae50d)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/035/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:57] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/035/__cache__/flyvision/analysis/stimulus_responses/compute_responses/066e0e5617f86c1a995fd9593f6ae50d/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:57] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/036/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/036', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/036/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 6dc79549ae41d127ad03473dd19d7191)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/036/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:57] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/036/__cache__/flyvision/analysis/stimulus_responses/compute_responses/6dc79549ae41d127ad03473dd19d7191/output.h5\n[2024-09-28 03:44:57] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/037/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/037', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/037/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 11242a4bd086271b04d8b381fe536d34)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/037/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:57] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/037/__cache__/flyvision/analysis/stimulus_responses/compute_responses/11242a4bd086271b04d8b381fe536d34/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:57] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/038/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/038', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/038/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 4de539f0328a62b7b7b2e2f406ac512f)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/038/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:57] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/038/__cache__/flyvision/analysis/stimulus_responses/compute_responses/4de539f0328a62b7b7b2e2f406ac512f/output.h5\n[2024-09-28 03:44:57] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/039/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/039', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/039/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 54037e45c494136e3ec0df5c68b144b9)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/039/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:57] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/039/__cache__/flyvision/analysis/stimulus_responses/compute_responses/54037e45c494136e3ec0df5c68b144b9/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:58] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/040/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/040', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/040/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash aee145f08d47e04be77524fff9b97a0e)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/040/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:58] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/040/__cache__/flyvision/analysis/stimulus_responses/compute_responses/aee145f08d47e04be77524fff9b97a0e/output.h5\n[2024-09-28 03:44:58] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/041/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/041', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/041/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 8d00acd269369e38751d2eebc739cfad)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/041/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:58] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/041/__cache__/flyvision/analysis/stimulus_responses/compute_responses/8d00acd269369e38751d2eebc739cfad/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:58] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/042/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/042', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/042/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 1df07a8c6046bb4b1e015fddfdc522bd)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/042/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:58] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/042/__cache__/flyvision/analysis/stimulus_responses/compute_responses/1df07a8c6046bb4b1e015fddfdc522bd/output.h5\n[2024-09-28 03:44:58] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/043/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/043', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/043/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 118907b7b0db15c9a12ebe485363b677)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/043/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:58] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/043/__cache__/flyvision/analysis/stimulus_responses/compute_responses/118907b7b0db15c9a12ebe485363b677/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:58] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/044/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/044', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/044/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash b7cbac573ab7f8613e90b80217af416a)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/044/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:58] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/044/__cache__/flyvision/analysis/stimulus_responses/compute_responses/b7cbac573ab7f8613e90b80217af416a/output.h5\n[2024-09-28 03:44:58] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/045/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/045', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/045/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 47d58ea044d58bb33a1e19bb6d6da424)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/045/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:58] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/045/__cache__/flyvision/analysis/stimulus_responses/compute_responses/47d58ea044d58bb33a1e19bb6d6da424/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:58] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/046/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/046', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/046/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 4934fc3026c637ce814154f98aaee621)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/046/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:58] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/046/__cache__/flyvision/analysis/stimulus_responses/compute_responses/4934fc3026c637ce814154f98aaee621/output.h5\n[2024-09-28 03:44:59] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/047/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/047', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/047/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 35cb033dfacc17e90bc630ef8cd25ebc)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/047/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:59] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/047/__cache__/flyvision/analysis/stimulus_responses/compute_responses/35cb033dfacc17e90bc630ef8cd25ebc/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:44:59] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/048/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/048', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/048/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 0cd0d09b9f5f4a64c8e753aca75bbdb0)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/048/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:59] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/048/__cache__/flyvision/analysis/stimulus_responses/compute_responses/0cd0d09b9f5f4a64c8e753aca75bbdb0/output.h5\n[2024-09-28 03:44:59] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/049/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/049', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/049/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash 22e903adf1516c4f5bcf3461281e707d)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/049/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:44:59] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/049/__cache__/flyvision/analysis/stimulus_responses/compute_responses/22e903adf1516c4f5bcf3461281e707d/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n</code></pre> <pre><code>norm = ensemble.responses_norm()\n</code></pre> <pre><code>responses = stims_and_resps[\"responses\"] / (norm + 1e-6)\n</code></pre> <pre><code>responses.custom.where(cell_type=\"T4c\", u=0, v=0, sample=0).custom.plot_traces(\n    x=\"time\", plot_kwargs=dict(color=\"tab:blue\", add_legend=False)\n)\nax = plt.gca()\nax.set_title(\"T4c responses to naturalistic stimuli\")\n</code></pre> <pre><code>Text(0.5, 1.0, 'T4c responses to naturalistic stimuli')\n</code></pre> <p></p> <p>We see that the across models of the ensemble the predictions for T4c vary. Our goal is to understand the underlying structure in those variations.</p>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#nonlinear-dimensionality-reduction-umap-and-gaussian-mixtures","title":"Nonlinear dimensionality reduction (UMAP) and Gaussian Mixtures","text":"<pre><code>from flyvision.analysis.clustering import EnsembleEmbedding, get_cluster_to_indices\nfrom flyvision.utils.activity_utils import CentralActivity\n</code></pre> <pre><code># specify parameters for umap embedding\n\nembedding_kwargs = {\n    \"min_dist\": 0.105,\n    \"spread\": 9.0,\n    \"n_neighbors\": 5,\n    \"random_state\": 42,\n    \"n_epochs\": 1500,\n}\n</code></pre> <p>We compute the UMAP embedding of the ensemble based on the T4c responses of the single models to the single sequence for illustration.</p> <pre><code>central_responses = CentralActivity(responses.values, \n                                    connectome=ensemble.connectome)\n</code></pre> <pre><code>embedding = EnsembleEmbedding(central_responses)\nt4c_embedding = embedding(\"T4c\", embedding_kwargs=embedding_kwargs)\n</code></pre> <pre><code>[2024-09-28 03:45:09] clustering:346 reshaped X from (50, 2268, 80) to (50, 181440)\n\n\n/home/lappalainenj@hhmi.org/miniconda3/envs/flyvision/lib/python3.9/site-packages/umap/umap_.py:1356: RuntimeWarning: divide by zero encountered in power\n  return 1.0 / (1.0 + a * x ** (2 * b))\n</code></pre> <pre><code>task_error = ensemble.task_error()\n</code></pre> <pre><code>embeddingplot = t4c_embedding.plot(colors=task_error.colors)\n</code></pre> <p></p> <p>Each of these scatterpoints in 2d represents a single time series plotted above.</p> <p>We fit a Gaussian Mixture of 2 to 5 components to this embedding to label the clusters. We select the final number of Gaussian Mixture components that minimize the Bayesian Information Criterion (BIC).</p> <pre><code># specifiy parameters for Gaussian Mixture\n\ngm_kwargs = {\n    \"range_n_clusters\": [1, 2, 3, 4, 5],\n    \"n_init\": 100,\n    \"max_iter\": 1000,\n    \"random_state\": 42,\n    \"tol\": 0.001,\n}\n</code></pre> <pre><code>gm_clustering = t4c_embedding.cluster.gaussian_mixture(**gm_kwargs)\n</code></pre> <pre><code>embeddingplot = gm_clustering.plot(\n    task_error=task_error.values, colors=task_error.colors\n)\n</code></pre> <p></p> <p>We can use the labels to disambiguate the time series data that we plotted above. We expect that these labels aggregate similar time series together and different time series separately.</p> <pre><code>import matplotlib.colors as mcolors\n</code></pre> <pre><code>cluster_to_indices = get_cluster_to_indices(\n    embeddingplot.cluster.embedding.mask,\n    embeddingplot.cluster.labels,\n    ensemble.task_error(),\n)\n</code></pre> <pre><code>fig, axes = plt.subplots(1, len(cluster_to_indices), figsize=(6, 2))\ncolors = {i: color for i, color in enumerate(mcolors.TABLEAU_COLORS.values())}\nfor cluster_id, indices in cluster_to_indices.items():\n    responses.sel(network_id=indices, sample=[0]).custom.where(\n        cell_type=\"T4c\"\n    ).custom.plot_traces(\n        x=\"time\",\n        plot_kwargs=dict(\n            color=colors[cluster_id], add_legend=False, ax=axes[cluster_id]\n        ),\n    )\n    axes[cluster_id].set_title(f\"Cluster {cluster_id + 1}\")\nplt.subplots_adjust(wspace=0.3)\n</code></pre> <p></p> <p>The clustering has led us to three qualitatively distinct predictions from the ensemble for this cell and sequence. This is a first lead for an underlying structure in these predictions. We will get an even better estimate once we use more sequences for the clustering.</p>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#using-the-clustering-to-discover-tuning-predictions-in-responses-to-simple-stimuli","title":"Using the clustering to discover tuning predictions in responses to simple stimuli","text":"<p>We expect that the clustering based on naturalistic stimuli will also disambiguate the different tuning predictions from different models for simple stimuli.</p> <pre><code>cluster_to_indices = get_cluster_to_indices(\n    embeddingplot.cluster.embedding.mask,\n    embeddingplot.cluster.labels,\n    ensemble.task_error(),\n)\n</code></pre> <pre><code># define different colormaps for clusters\ncluster_colors = {}\nCMAPS = [\"Blues_r\", \"Reds_r\", \"Greens_r\", \"Oranges_r\", \"Purples_r\"]\n\nfor cluster_id in cluster_to_indices:\n    cluster_colors[cluster_id] = ensemble.task_error(cmap=CMAPS[cluster_id]).colors\n</code></pre>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#clustered-voltage-responses-to-moving-edges","title":"Clustered voltage responses to moving edges","text":"<pre><code>from flyvision.analysis.moving_bar_responses import plot_angular_tuning\nfrom flyvision.plots.plt_utils import add_cluster_marker, get_marker\nfrom flyvision.utils.color_utils import color_to_cmap\n</code></pre> <pre><code>stims_and_resps_moving_edge = ensemble.movingedge_responses()\n</code></pre> <pre><code>[2024-09-28 03:45:27] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/000', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 77be693699aefc8a65b21a471879e324)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:27] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses/77be693699aefc8a65b21a471879e324/output.h5\n[2024-09-28 03:45:27] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/001', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 1d2c73d297130e58bf05418b7385227e)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:27] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses/1d2c73d297130e58bf05418b7385227e/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:27] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/002', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash a492cccda41a28f65f6051985f0cd6fc)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:27] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__/flyvision/analysis/stimulus_responses/compute_responses/a492cccda41a28f65f6051985f0cd6fc/output.h5\n[2024-09-28 03:45:27] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/003', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 86e7a776a281aa3c6274211ff33649db)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:27] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__/flyvision/analysis/stimulus_responses/compute_responses/86e7a776a281aa3c6274211ff33649db/output.h5\n[2024-09-28 03:45:27] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/004', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash cbb23a582ff5ce0c06961764a957f0d0)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:27] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__/flyvision/analysis/stimulus_responses/compute_responses/cbb23a582ff5ce0c06961764a957f0d0/output.h5\n[2024-09-28 03:45:27] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/005', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash ef1adddb6ce7d96ba6e3dba901c05dd7)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:27] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__/flyvision/analysis/stimulus_responses/compute_responses/ef1adddb6ce7d96ba6e3dba901c05dd7/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:28] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/006', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 17643fb00254698b3a84bd93a2e0903d)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:28] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__/flyvision/analysis/stimulus_responses/compute_responses/17643fb00254698b3a84bd93a2e0903d/output.h5\n[2024-09-28 03:45:28] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/007', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash c6e2af646c29f24a4c697b4c066d8916)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:28] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__/flyvision/analysis/stimulus_responses/compute_responses/c6e2af646c29f24a4c697b4c066d8916/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:28] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/008', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 88dff80cbdda9c384ba9384e600e62a6)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:28] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__/flyvision/analysis/stimulus_responses/compute_responses/88dff80cbdda9c384ba9384e600e62a6/output.h5\n[2024-09-28 03:45:28] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/009', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 395a0cfb766f550893c991f34a74ce3d)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:28] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__/flyvision/analysis/stimulus_responses/compute_responses/395a0cfb766f550893c991f34a74ce3d/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:28] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/010/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/010', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/010/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 1b50a7069c7e4554c7d0eb916570aef1)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/010/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:28] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/010/__cache__/flyvision/analysis/stimulus_responses/compute_responses/1b50a7069c7e4554c7d0eb916570aef1/output.h5\n[2024-09-28 03:45:28] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/011/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/011', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/011/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 79f834efef624b1e9d60c43d17276867)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/011/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:28] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/011/__cache__/flyvision/analysis/stimulus_responses/compute_responses/79f834efef624b1e9d60c43d17276867/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:28] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/012/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/012', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/012/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash e06aa1ed77434be8547758c8c99f9e46)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/012/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:28] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/012/__cache__/flyvision/analysis/stimulus_responses/compute_responses/e06aa1ed77434be8547758c8c99f9e46/output.h5\n[2024-09-28 03:45:28] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/013/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/013', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/013/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 925a6e44c1bab90e390b5ad9c2b6981c)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/013/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:28] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/013/__cache__/flyvision/analysis/stimulus_responses/compute_responses/925a6e44c1bab90e390b5ad9c2b6981c/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:29] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/014/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/014', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/014/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 9e020caeb163c1d9ba05f97942ae5dcf)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/014/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:29] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/014/__cache__/flyvision/analysis/stimulus_responses/compute_responses/9e020caeb163c1d9ba05f97942ae5dcf/output.h5\n[2024-09-28 03:45:29] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/015/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/015', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/015/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 0d688cabf8fc136bfd108ba052e269aa)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/015/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:29] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/015/__cache__/flyvision/analysis/stimulus_responses/compute_responses/0d688cabf8fc136bfd108ba052e269aa/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:29] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/016/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/016', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/016/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 288293f54c15e1f1a01bb3fc172da208)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/016/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:29] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/016/__cache__/flyvision/analysis/stimulus_responses/compute_responses/288293f54c15e1f1a01bb3fc172da208/output.h5\n[2024-09-28 03:45:29] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/017/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/017', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/017/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 5f9706358964c27cab147f777ab3532d)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/017/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:29] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/017/__cache__/flyvision/analysis/stimulus_responses/compute_responses/5f9706358964c27cab147f777ab3532d/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:29] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/018/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/018', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/018/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 91cbd372e15242b67cc575d217793c77)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/018/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:29] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/018/__cache__/flyvision/analysis/stimulus_responses/compute_responses/91cbd372e15242b67cc575d217793c77/output.h5\n[2024-09-28 03:45:29] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/019/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/019', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/019/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 83afbe6c8322f3ae8730b5a6ef08810c)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/019/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:29] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/019/__cache__/flyvision/analysis/stimulus_responses/compute_responses/83afbe6c8322f3ae8730b5a6ef08810c/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:29] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/020/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/020', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/020/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 39a733fede1ec19c0cf72d18c654c9ea)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/020/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:29] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/020/__cache__/flyvision/analysis/stimulus_responses/compute_responses/39a733fede1ec19c0cf72d18c654c9ea/output.h5\n[2024-09-28 03:45:30] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/021/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/021', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/021/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 23b9b479ad5e7a60ac2968d5be088b01)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/021/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:30] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/021/__cache__/flyvision/analysis/stimulus_responses/compute_responses/23b9b479ad5e7a60ac2968d5be088b01/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:30] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/022/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/022', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/022/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 09cccac26f2c0bdfd79875647c896f91)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/022/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:30] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/022/__cache__/flyvision/analysis/stimulus_responses/compute_responses/09cccac26f2c0bdfd79875647c896f91/output.h5\n[2024-09-28 03:45:30] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/023/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/023', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/023/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 3eb89a8b21395702eeeb5688fa041b25)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/023/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:30] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/023/__cache__/flyvision/analysis/stimulus_responses/compute_responses/3eb89a8b21395702eeeb5688fa041b25/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:30] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/024/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/024', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/024/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash fffb6b84d25a66672dcf7e1c01337efe)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/024/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:30] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/024/__cache__/flyvision/analysis/stimulus_responses/compute_responses/fffb6b84d25a66672dcf7e1c01337efe/output.h5\n[2024-09-28 03:45:30] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/025/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/025', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/025/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 30a8def9735fa87e11508ff3667b9657)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/025/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:30] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/025/__cache__/flyvision/analysis/stimulus_responses/compute_responses/30a8def9735fa87e11508ff3667b9657/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:30] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/026/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/026', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/026/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 67b400f5402ea2331da87fbbc98819a9)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/026/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:30] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/026/__cache__/flyvision/analysis/stimulus_responses/compute_responses/67b400f5402ea2331da87fbbc98819a9/output.h5\n[2024-09-28 03:45:30] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/027/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/027', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/027/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 311992d8d68da98c9765828039f1e273)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/027/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:30] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/027/__cache__/flyvision/analysis/stimulus_responses/compute_responses/311992d8d68da98c9765828039f1e273/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:31] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/028/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/028', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/028/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash dfb813caf89e1b3d059c9919f59268f6)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/028/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:31] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/028/__cache__/flyvision/analysis/stimulus_responses/compute_responses/dfb813caf89e1b3d059c9919f59268f6/output.h5\n[2024-09-28 03:45:31] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/029/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/029', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/029/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash fa256c3c26d9ee5218c9f04a7b1a1d4a)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/029/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:31] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/029/__cache__/flyvision/analysis/stimulus_responses/compute_responses/fa256c3c26d9ee5218c9f04a7b1a1d4a/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:31] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/030/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/030', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/030/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 2c4e1d3435c7d860f2a28d085ebe60b8)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/030/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:31] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/030/__cache__/flyvision/analysis/stimulus_responses/compute_responses/2c4e1d3435c7d860f2a28d085ebe60b8/output.h5\n[2024-09-28 03:45:31] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/031/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/031', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/031/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash fba723386be5ff554eeee43e00ed9864)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/031/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:31] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/031/__cache__/flyvision/analysis/stimulus_responses/compute_responses/fba723386be5ff554eeee43e00ed9864/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:31] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/032/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/032', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/032/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 2f3d76e84ab24b947c7f702e13e2c492)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/032/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:31] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/032/__cache__/flyvision/analysis/stimulus_responses/compute_responses/2f3d76e84ab24b947c7f702e13e2c492/output.h5\n[2024-09-28 03:45:31] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/033/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/033', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/033/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 8b7b59496e349519b4e73a33521bc534)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/033/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:31] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/033/__cache__/flyvision/analysis/stimulus_responses/compute_responses/8b7b59496e349519b4e73a33521bc534/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:31] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/034/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/034', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/034/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash a41b1afbd9774383cf1d9c27a872c18f)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/034/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:31] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/034/__cache__/flyvision/analysis/stimulus_responses/compute_responses/a41b1afbd9774383cf1d9c27a872c18f/output.h5\n[2024-09-28 03:45:32] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/035/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/035', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/035/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 008ad9d6c9d8e45c8bd399b790db37b7)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/035/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:32] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/035/__cache__/flyvision/analysis/stimulus_responses/compute_responses/008ad9d6c9d8e45c8bd399b790db37b7/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:32] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/036/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/036', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/036/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 73de418ea2de244810e4551b90c7d0c4)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/036/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:32] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/036/__cache__/flyvision/analysis/stimulus_responses/compute_responses/73de418ea2de244810e4551b90c7d0c4/output.h5\n[2024-09-28 03:45:32] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/037/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/037', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/037/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 6bcd62a2a8814c0fe7b141d7cc7a697b)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/037/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:32] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/037/__cache__/flyvision/analysis/stimulus_responses/compute_responses/6bcd62a2a8814c0fe7b141d7cc7a697b/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:32] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/038/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/038', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/038/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 35f979e9a8e3b715c48e2c77dc19b7e7)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/038/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:32] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/038/__cache__/flyvision/analysis/stimulus_responses/compute_responses/35f979e9a8e3b715c48e2c77dc19b7e7/output.h5\n[2024-09-28 03:45:32] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/039/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/039', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/039/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash c00f70d0ec34030129daf8d8e590c9af)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/039/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:32] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/039/__cache__/flyvision/analysis/stimulus_responses/compute_responses/c00f70d0ec34030129daf8d8e590c9af/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:32] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/040/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/040', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/040/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 6df6b75392955b45e5eb38727672181f)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/040/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:32] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/040/__cache__/flyvision/analysis/stimulus_responses/compute_responses/6df6b75392955b45e5eb38727672181f/output.h5\n[2024-09-28 03:45:32] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/041/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/041', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/041/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 3c4cbbdfafe431a0b4d4fba40eea79ae)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/041/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:32] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/041/__cache__/flyvision/analysis/stimulus_responses/compute_responses/3c4cbbdfafe431a0b4d4fba40eea79ae/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:33] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/042/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/042', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/042/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 7b6ff84c5542a888c65a2d9deb92e590)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/042/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:33] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/042/__cache__/flyvision/analysis/stimulus_responses/compute_responses/7b6ff84c5542a888c65a2d9deb92e590/output.h5\n[2024-09-28 03:45:33] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/043/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/043', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/043/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 307ee913c057f0dd1174186d199d5206)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/043/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:33] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/043/__cache__/flyvision/analysis/stimulus_responses/compute_responses/307ee913c057f0dd1174186d199d5206/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:33] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/044/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/044', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/044/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 1bf587096948fa0bc762bf8ea1cdc812)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/044/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:33] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/044/__cache__/flyvision/analysis/stimulus_responses/compute_responses/1bf587096948fa0bc762bf8ea1cdc812/output.h5\n[2024-09-28 03:45:33] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/045/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/045', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/045/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash fa0575c9275e23ba7b3f6c3e200f7439)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/045/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:33] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/045/__cache__/flyvision/analysis/stimulus_responses/compute_responses/fa0575c9275e23ba7b3f6c3e200f7439/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:34] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/046/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/046', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/046/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 43205473c0733c1640466cae80b7ef1b)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/046/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:34] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/046/__cache__/flyvision/analysis/stimulus_responses/compute_responses/43205473c0733c1640466cae80b7ef1b/output.h5\n[2024-09-28 03:45:34] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/047/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/047', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/047/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 68b9c9f4751b092c82426454cd0c68ca)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/047/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:34] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/047/__cache__/flyvision/analysis/stimulus_responses/compute_responses/68b9c9f4751b092c82426454cd0c68ca/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 03:45:34] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/048/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/048', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/048/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 8b2c68af76beb5bea7f8c1643bc93a77)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/048/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:34] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/048/__cache__/flyvision/analysis/stimulus_responses/compute_responses/8b2c68af76beb5bea7f8c1643bc93a77/output.h5\n[2024-09-28 03:45:34] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fda303570d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/049/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/049', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/049/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7fda27385d30&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash c7036d5becf2c39915e36f3a2a1adfd4)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/049/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 03:45:34] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/049/__cache__/flyvision/analysis/stimulus_responses/compute_responses/c7036d5becf2c39915e36f3a2a1adfd4/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n</code></pre> <pre><code># invariant to different magnitudes of responses, only to assess direction tuning\nstims_and_resps_moving_edge[\"responses\"] /= np.abs(stims_and_resps_moving_edge[\"responses\"]).max(dim=(\"sample\", \"frame\"))\n\n# relative to the norm of the responses to naturalistic stimuli (used for averaging) \n# stims_and_resps_moving_edge['responses'] /= (norm + 1e-6)\n</code></pre> <pre><code>fig, axes = plt.subplots(1, len(cluster_to_indices), figsize=(6, 2))\ncolors = {i: color for i, color in enumerate(mcolors.TABLEAU_COLORS.values())}\nfor cluster_id, indices in cluster_to_indices.items():\n    stims_and_resps_moving_edge['responses'].sel(network_id=indices).custom.where(\n        cell_type=\"T4c\", intensity=1, speed=19, angle=90\n    ).custom.plot_traces(\n        x=\"time\",\n        plot_kwargs=dict(\n            color=colors[cluster_id], add_legend=False, ax=axes[cluster_id]\n        ),\n    )\n    axes[cluster_id].set_title(f\"Cluster {cluster_id + 1}\")\nplt.subplots_adjust(wspace=0.3)\n</code></pre> <pre><code>plot_angular_tuning(\n        stims_and_resps_moving_edge,\n        \"T4c\",\n        intensity=1,\n        )\n</code></pre> <pre><code>(&lt;Figure size 300x300 with 1 Axes&gt;, &lt;PolarAxes: &gt;)\n</code></pre> <pre><code>tabcolors = list(mcolors.TABLEAU_COLORS.values())\ncolors = [ensemble.task_error(cmap=color_to_cmap(tabcolors[cluster_id]).reversed()).colors[indices] for cluster_id, indices in cluster_to_indices.items()]\nfig, axes = plt.subplots(\n    1, len(cluster_to_indices), subplot_kw={\"projection\": \"polar\"}, figsize=[2, 1]\n)\nfor cluster_id, indices in cluster_to_indices.items():\n    plot_angular_tuning(\n        stims_and_resps_moving_edge.sel(network_id=indices),\n        \"T4c\",\n        intensity=1,\n        colors=colors[cluster_id],\n        zorder=ensemble.zorder()[indices],\n        groundtruth=True if cluster_id == 0 else False,\n        fig=fig,\n        ax=axes[cluster_id],\n    )\n    add_cluster_marker(fig, axes[cluster_id], marker=get_marker(cluster_id))\n    axes[cluster_id].set_title(f\"Cluster {cluster_id + 1}\")\nplt.subplots_adjust(wspace=0.5)\n</code></pre> <p>As we can see here, the models predict clustered neural responses.</p>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#load-precomputed-umap-and-clustering","title":"Load precomputed umap and clustering","text":"<p>Due to the computational requirement of recording and embedding all responses and for consistency we also show how to use the precomputed embeddings and clusterings from the paper.</p> <pre><code>cell_type = \"T4c\"\nclustering = ensemble.clustering(cell_type)\n</code></pre> <pre><code>[2024-09-28 03:45:53] clustering:640 Loaded T4c embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n</code></pre> <pre><code>task_error = ensemble.task_error()\n</code></pre> <pre><code>embeddingplot = clustering.plot(task_error=task_error.values,\n                                colors=task_error.colors)\n</code></pre> <p></p> <p>With this embedding and clustering one can proceed in the same way as above to plot the tunings.</p>"},{"location":"examples/06_flyvision_maximally_excitatory_stimuli/","title":"Maximally excitatory stimuli","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre>"},{"location":"examples/06_flyvision_maximally_excitatory_stimuli/#maximally-excitatory-stimuli-from-trained-models","title":"Maximally excitatory stimuli from trained models","text":"<p>This notebook illustrates how to compute the stimuli that maximally excite a specific neuron.</p> <p>Select GPU runtime</p> <p>To run the notebook on a GPU select Menu -&gt; Runtime -&gt; Change runtime type -&gt; GPU.</p> <pre><code># @markdown **Check access to GPU**\n\ntry:\n    import google.colab\n\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n\nif IN_COLAB:\n    import torch\n\n    try:\n        cuda_name = torch.cuda.get_device_name()\n        print(f\"Name of the assigned GPU / CUDA device: {cuda_name}\")\n    except RuntimeError:\n        import warnings\n\n        warnings.warn(\n            \"You have not selected Runtime Type: 'GPU' or Google could not assign you one. Please revisit the settings as described above or proceed on CPU (slow).\"\n        )\n</code></pre> <p>Install Flyvis</p> <p>The notebook requires installing our package <code>flyvis</code>. You may need to restart your session after running the code block below with Menu -&gt; Runtime -&gt; Restart session. Then, imports from <code>flyvis</code> should succeed without issue.</p> <pre><code>if IN_COLAB:\n    #@markdown **Install Flyvis**\n    %%capture\n    !git clone https://github.com/flyvis/flyvis-dev.git\n    %cd /content/flyvis-dev\n    !pip install -e .\n</code></pre> <pre><code># basic imports\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nplt.rcParams['figure.dpi'] = 200\n</code></pre>"},{"location":"examples/06_flyvision_maximally_excitatory_stimuli/#optimal-naturalistic-stimuli","title":"Optimal naturalistic stimuli","text":"<p>We first find the optimal naturalistic stimuli. To do that, we simulate the responses of  the network (including the neuron of interest) to all stimuli from a fixed dataset of stimuli.  The optimal, or here maximally exctitatory naturalistic stimulus to be precise, is the stimulus  for which the response of the chosen neuron is maximal. Finding this is simple and does not require numerical optimization with gradients. We find the stimulus per cell type based on its cell in the central column. At least in our coarse model,  the offset version of this stimulus would also maximally excite the equivalently offset neighboring cells of the same type.</p> <pre><code>from flyvision import NetworkView, results_dir\nfrom flyvision.datasets.sintel import AugmentedSintel\nfrom flyvision.analysis.optimal_stimuli import FindOptimalStimuli, GenerateOptimalStimuli,  plot_stim_response\n</code></pre> <pre><code># let's load the dataset and the pretrained network\ndataset = AugmentedSintel(tasks=[\"lum\"], temporal_split=True)\nnetwork_view = NetworkView(results_dir / \"flow/0000/000\")\n</code></pre> <pre><code>[2024-09-25 18:08:10] network:1005 Initialized network view at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000.\n</code></pre> <pre><code>findoptstim = FindOptimalStimuli(network_view, dataset)\n</code></pre> <pre><code>[2024-09-25 18:08:20] network:252 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n[2024-09-25 18:08:20] chkpt_utils:72 Recovered network state.\n</code></pre> <p>For the T4c neuron, we would expect that the maximally excitatory stimulus is an ON-edge moving upward.</p> <pre><code>optstim = network_view.optimal_stimulus_responses(\"T4c\")\n</code></pre> <pre><code>[2024-09-25 18:08:21] logger:83 [MemorizedFunc(func=&lt;function compute_optimal_stimulus_responses at 0x7fba9d1b1dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__)]: \n                        Querying compute_optimal_stimulus_responses with signature\n                        compute_optimal_stimulus_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n'T4c', { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;).\n\n                        (argument hash 2281c4887178168b7aaa6dc2c0005a0b)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_optimal_stimulus_responses.\n\n[2024-09-25 18:08:21] logger:80 [MemorizedFunc(func=&lt;function compute_optimal_stimulus_responses at 0x7fba9d1b1dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__)]: Computing func compute_optimal_stimulus_responses, argument hash 2281c4887178168b7aaa6dc2c0005a0b in location /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_optimal_stimulus_responses\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_optimal_stimulus_responses...\ncompute_optimal_stimulus_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n'T4c', { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;)\n\n\n[2024-09-25 18:08:21] network:1005 Initialized network view at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000.\n[2024-09-25 18:08:34] network:252 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n[2024-09-25 18:08:34] chkpt_utils:72 Recovered network state.\n[2024-09-25 18:08:34] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7fba9d193670&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['lum'],\n  'temporal_split': True}, \n4, 0.0, 2.0).\n\n                        (argument hash bef8ab0b1f1206171b1e38bf67305c6f)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-25 18:08:34] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses/bef8ab0b1f1206171b1e38bf67305c6f/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\nPersisting in /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_optimal_stimulus_responses/2281c4887178168b7aaa6dc2c0005a0b\n______________________________compute_optimal_stimulus_responses - 43.0s, 0.7min\n</code></pre> <pre><code>stim_resp_plot = plot_stim_response(optstim.stimulus.stimulus, optstim.stimulus.response, 1/100, *network_view.connectome_view.get_uv(\"T4c\"), figsize=[5, 1.6], ylabel=None, label_peak_response=False)\n</code></pre> <p></p> <p>We see that the the stimulus indeed contains an ON-edge component moving upward and this is the portion of the stimulus that T4c cells respond most to. What\u2019s unclear is whether the other parts of the stimulus have an influence on the response.</p>"},{"location":"examples/06_flyvision_maximally_excitatory_stimuli/#regularized-optimal-stimuli","title":"Regularized optimal stimuli","text":"<p>We can regularize the optimal stimuli with the objective to keep the response of the cell intact while bringing the stimulus pixels to a neutral grey value.</p> <pre><code>stim_resp_plot = plot_stim_response(optstim.regularized_stimulus, optstim.response, 1/100, *network_view.connectome_view.get_uv(\"T4c\"), figsize=[5, 1.6], ylabel=None, label_peak_response=False)\n</code></pre> <p></p> <p>This looks remarkably different! Now only a central black portion follow by the ON-edge moving upward remains in the stimulus. Let\u2019s make sure that the central cell response is really the same as before! This is the entire time trace.</p> <pre><code>fig = plt.figure(figsize=[2, 1])\ntime = np.arange(len(optstim.central_target_response)) / 100\nplt.plot(time, optstim.central_target_response)\nplt.plot(time, optstim.central_predicted_response)\nplt.xlabel(\"time (s)\")\nplt.ylabel(\"response\")\n</code></pre> <pre><code>Text(0, 0.5, 'response')\n</code></pre> <p></p> <p>This looks quite similar! One can play with the regularization optimization and its parameters of the function <code>regularized_optimal_stimuli</code>.</p>"},{"location":"examples/06_flyvision_maximally_excitatory_stimuli/#generate-artificial-optimal-stimuli-from-scratch","title":"Generate artificial optimal stimuli from scratch","text":"<p>If one is able to optimize the naturalistic stimulus with the gradient, why don\u2019t we use the gradient to generate an optimal stimulus from scratch (or rather random noise). We do that in the following. Again for T4c, we would expect that it would have some sort of ON-edge moving upwards.</p> <pre><code>genoptstim = GenerateOptimalStimuli(network_view)\n</code></pre> <pre><code>[2024-09-25 18:09:34] chkpt_utils:72 Recovered network state.\n</code></pre> <pre><code>artoptstim = genoptstim.artificial_optimal_stimuli(\"T4c\", t_stim=0.8)\n</code></pre> <pre><code>stim_resp_plot = plot_stim_response(artoptstim.stimulus, artoptstim.response, 1/100, *network_view.connectome_view.get_uv(\"T4c\"), figsize=[5, 1.6], ylabel=None, label_peak_response=False)\n</code></pre> <p></p> <p>Wow! This stimulus is contains very similar components to the one before and is much more saturated! It also contains new ON-components already from the beginning!</p> <p>Last, let\u2019s compare which stimulus excited the neuron the most.</p> <pre><code>fig = plt.figure(figsize=[2, 1])\ntime = np.arange(len(optstim.central_target_response)) / 100\nplt.plot(time, optstim.central_target_response, label='naturalistic')\nplt.plot(time, optstim.central_predicted_response, label='regularized naturalistic')\nplt.plot(time, artoptstim.response[:, :, artoptstim.response.shape[-1]//2].flatten(), label='artificial')\nplt.xlabel(\"time (s)\")\nplt.ylabel(\"response\")\nplt.legend()\n</code></pre> <pre><code>&lt;matplotlib.legend.Legend at 0x7fba75d0d7f0&gt;\n</code></pre> <p></p> <pre><code>\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/","title":"Providing custom stimuli","text":"<p>Follow this notebook to learn how to use our models for generating hypothesis about neural computations with custom stimuli.</p> <p>Select GPU runtime</p> <p>To run the notebook on a GPU select Menu -&gt; Runtime -&gt; Change runtime type -&gt; GPU.</p> <pre><code># @markdown **Check access to GPU**\n\ntry:\n    import google.colab\n\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n\nif IN_COLAB:\n    import torch\n\n    try:\n        cuda_name = torch.cuda.get_device_name()\n        print(f\"Name of the assigned GPU / CUDA device: {cuda_name}\")\n    except RuntimeError:\n        import warnings\n\n        warnings.warn(\n            \"You have not selected Runtime Type: 'GPU' or Google could not assign you one. Please revisit the settings as described above or proceed on CPU (slow).\"\n        )\n</code></pre> <p>Install Flyvis</p> <p>The notebook requires installing our package <code>flyvis</code>. You may need to restart your session after running the code block below with Menu -&gt; Runtime -&gt; Restart session. Then, imports from <code>flyvis</code> should succeed without issue.</p> <pre><code>if IN_COLAB:\n    #@markdown **Install Flyvis**\n    %%capture\n    !git clone https://github.com/flyvis/flyvis-dev.git\n    %cd /content/flyvis-dev\n    !pip install -e .\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#example-dataset","title":"Example dataset","text":"<p>We take the public Moving MNIST sequence dataset as an example for a custom stimulus dataset. Moving MNIST consists of short grey-scale videos of numbers from 1-10 which move in arbitrary directions. The dataset entails 10,000 sequences of 20 frames each. Individual frames are 64x64 pixels in height and width.</p> <pre><code>import torch\nimport numpy as np\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.dpi'] = 200\n\nimport flyvision\nfrom flyvision.utils.dataset_utils import load_moving_mnist\n</code></pre> <pre><code>sequences = load_moving_mnist()\n</code></pre> <pre><code># the whole dataset has dims (n_sequences, n_frames, height, width)\nsequences.shape\n</code></pre> <pre><code>(10000, 20, 64, 64)\n</code></pre> <pre><code>animation = flyvision.animations.Imshow(sequences, cmap=plt.cm.binary_r)\nanimation.animate_in_notebook(samples=[0, 1, 2])\n</code></pre> <p></p> <p>Alternative: for an alternative dataset that is generated at runtime and does not require a download try <code>random_walk_of_blocks</code>. As a simple drop-in replacement, this requires to replace <code>load_moving_mnist</code> with <code>random_walk_of_blocks</code> across the notebook.</p> <pre><code>from flyvision.utils.dataset_utils import random_walk_of_blocks\n</code></pre> <pre><code>sequences = random_walk_of_blocks()\n</code></pre> <pre><code>animation = flyvision.animations.Imshow(sequences, cmap=plt.cm.binary_r)\nanimation.animate_in_notebook(samples=[0, 1, 2])\n</code></pre> <p></p>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#boxeye-rendering","title":"BoxEye rendering","text":""},{"location":"examples/07_flyvision_providing_custom_stimuli/#rendering-cartesian-images-to-hexagonal-lattice","title":"Rendering cartesian images to hexagonal lattice","text":"<p>We translate cartesian frames into receptor activations by placing simulated photoreceptors in a two-dimensional hexagonal array in pixel space (blue dots below), 31 columns across resulting in 721 columns in total, spaced 13 pixels apart. The transduced luminance at each photoreceptor is the greyscale mean value in the 13\u00d713-pixel region surrounding it (black boxes).</p> <pre><code>import flyvision\n</code></pre> <pre><code>receptors = flyvision.rendering.BoxEye(extent=15, kernel_size=13)\n</code></pre> <pre><code>fig = receptors.illustrate()\n</code></pre> <p></p>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#render-a-single-frame","title":"Render a single frame","text":"<p>To illustrate, this is what rendering a single frame looks like.</p> <pre><code>import torch\nimport numpy as np\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.dpi'] = 200\n\nimport flyvision\nfrom flyvision.utils.dataset_utils import load_moving_mnist\n</code></pre> <pre><code>sequences = load_moving_mnist()\n</code></pre> <pre><code>single_frame = sequences[0, 0]\n</code></pre> <pre><code>fig, ax = flyvision.plots.plt_utils.init_plot(figsize=[1, 1], fontsize=5)\nax = flyvision.plots.plt_utils.rm_spines(ax)\nax.imshow(single_frame, cmap=plt.cm.binary_r)\n_ = ax.set_title('example frame', fontsize=5)\n</code></pre> <p></p> <pre><code># the rendering uses pytorch native Conv2d module so it can be executed on GPU and fast\n# we first move the frame to GPU\nsingle_frame = torch.tensor(single_frame)\n</code></pre> <pre><code># because the inputs to the receptors instance must have four dimensions (samples, frames, height, width),\n# we create two empty dimensions for samples and frames\nsingle_frame = single_frame[None, None]\n</code></pre> <pre><code>single_frame.shape\n</code></pre> <pre><code>torch.Size([1, 1, 64, 64])\n</code></pre> <pre><code># to render the single frame we simply call the instance\n# this automatically rescales the frame to match the receptor layout as illustrated above\n# and then places the average pixel value of the 13x13 boxes at the receptor positions\nreceptors = flyvision.rendering.BoxEye()\nrendered = receptors(single_frame)\n</code></pre> <pre><code>/home/lappalainenj@hhmi.org/miniconda3/envs/flyvision/lib/python3.9/site-packages/torch/utils/_device.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return func(*args, **kwargs)\n/home/lappalainenj@hhmi.org/miniconda3/envs/flyvision/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n  warnings.warn(\n</code></pre> <pre><code># the 721 receptor coordinates are implicitly given in the last dimension\n# they correspond to sorted hexagonal coordinates (u-coordinate, v-coordinate, value)\nrendered.shape\n</code></pre> <pre><code>torch.Size([1, 1, 1, 721])\n</code></pre> <pre><code># the rendered frame is a slightly blurred version of the example\nfig, ax, _ = flyvision.plots.plots.quick_hex_scatter(\n    rendered.squeeze(), vmin=0, vmax=1, cbar_x_offset=0, fontsize=5\n)\n_ = ax.set_title(\"example frame rendered\", fontsize=5)\n</code></pre> <p></p> <pre><code># Disclaimer: thinking in hex coordinates can be unfamiliar.\n# Therefore, we circumvent dealing with them explicitly.\n# Still - to understand how the above plot infers the pixel-plane coordinates \n# from the implicit hexagonal coordinates, you can inspect the following code.\n</code></pre> <pre><code># # we can explicitly create sorted hex-coordinates from the integer radius of the hexagonal grid\n# # for a regular hexagonal lattice, the radius is uniquely determined from the number of hexagons\n\n# radius = flyvision.utils.hex_utils.get_hextent(rendered.shape[-1])\n\n# # here we create integer u, v coordinates, and we stick to the same function and convention \n# # everywhere in the code\n# u, v = flyvision.utils.hex_utils.get_hex_coords(radius)\n\n# # we transform them to pixel coordinates using our convention\n# x, y = flyvision.utils.hex_utils.hex_to_pixel(u, v)\n\n# # and can just scatter them to be back at the photoreceptor layout\n# fig, ax = flyvision.plots.plt_utils.init_plot(figsize=[2, 2], fontsize=5)\n# ax.scatter(x, y, s=0.5)\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#render-a-whole-dataset-to-disk","title":"Render a whole dataset to disk","text":"<p>We save rendered sequences to disk to retrieve them faster at runtime.</p> <p>We will use our library datamate here because it provides a powerful interface for writing and reading arrayfiles.</p> <pre><code>from typing import List\nfrom tqdm import tqdm\nimport torch\nimport numpy as np\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.dpi'] = 200\n\nfrom pathlib import Path\nfrom datamate import root, Directory\n\nimport flyvision\nfrom flyvision.utils.dataset_utils import load_moving_mnist\n</code></pre> <pre><code># the Directory class is a smart pointer to a specific directory\n# on the filesystem\n\n# directory to store the rendered stimuli\nfrom flyvision import renderings_dir\n\n\n# root tells where the Directory-tree starts\n@root(renderings_dir)\nclass RenderedData(Directory):\n    class Config(dict):\n        extent: int  # radius, in number of receptors of the hexagonal array.\n        kernel_size: int  # photon collection radius, in pixels.\n        subset_idx: List[int]  # if specified, subset of sequences to render\n\n    def __init__(self, config: Config):\n        # here comes the preprocessing and rendering as above or similar -- depending on the dataset etc.\n        # this code will be executed automatically once for each unique configuration to store preprocessed\n        # data on disk and later simply provide a reference to it.\n        sequences = load_moving_mnist()\n\n        # we use the configuration to control the settings under which we render the stimuli\n        receptors = flyvision.rendering.BoxEye(\n            extent=config.extent, kernel_size=config.kernel_size\n        )\n\n        # for memory-friendly rendering we can loop over individual sequences\n        # and subsets of the dataset\n        rendered_sequences = []\n        subset_idx = getattr(config, \"subset_idx\", []) or list(\n            range(sequences.shape[0])\n        )\n        with tqdm(total=len(subset_idx)) as pbar:\n            for index in subset_idx:\n                rendered_sequences.append(receptors(sequences[[index]]).cpu().numpy())\n                pbar.update()\n\n        # to join individual sequences along their first dimension\n        # to obtain (n_sequences, n_frames, 1, receptors.hexals)\n        rendered_sequences = np.concatenate(rendered_sequences, axis=0)\n\n        # the __setattr__ method of the Directory class saves sequences to self.path/\"sequences.h5\"\n        # that can be later retrieved using self.sequences[:]\n        self.sequences = rendered_sequences\n</code></pre> <pre><code># note, to render the whole dataset provide an empty list for `subset_idx` or delete the key word argument \nmoving_mnist_rendered = RenderedData(\n    dict(extent=15, kernel_size=13, subset_idx=[0, 1, 2, 3])\n)\n</code></pre> <pre><code># this is how we can retrieve the sequences from the disk into memory\nrendered_sequences = moving_mnist_rendered.sequences[:]\n</code></pre> <pre><code>rendered_sequences.shape\n</code></pre> <pre><code>(4, 20, 1, 721)\n</code></pre> <pre><code>animation = flyvision.animations.HexScatter(rendered_sequences, vmin=0, vmax=1)\nanimation.animate_in_notebook()\n</code></pre> <p></p> <pre><code># Note, to delete a Directory, e.g. to change the __init__ and reinstantiate,\n# run moving_mnist_rendered.rmtree(\"y\").\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#create-a-sequence-dataset","title":"Create a sequence dataset","text":"<p>Next we create a Pytorch dataset for loading the sequences.</p> <pre><code>from typing import List\nfrom tqdm import tqdm\nimport torch\nimport numpy as np\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.dpi'] = 200\n\nfrom pathlib import Path\nfrom datamate import root, Directory\n\nimport flyvision\nfrom flyvision.utils.dataset_utils import load_moving_mnist\nfrom flyvision.datasets.datasets import SequenceDataset\n</code></pre> <pre><code># the Directory class is a smart pointer to a specific directory\n# on the filesystem\n\n# directory to store the rendered stimuli\nfrom flyvision import renderings_dir\n\n\n# root tells where the Directory-tree starts\n@root(renderings_dir)\nclass RenderedData(Directory):\n    class Config(dict):\n        extent: int  # radius, in number of receptors of the hexagonal array.\n        kernel_size: int  # photon collection radius, in pixels.\n        subset_idx: List[int]  # if specified, subset of sequences to render\n\n    def __init__(self, config: Config):\n        # here comes the preprocessing and rendering as above or similar -- depending on the dataset etc.\n        # this code will be executed automatically once for each unique configuration to store preprocessed\n        # data on disk and later simply provide a reference to it.\n        sequences = load_moving_mnist()\n\n        # we use the configuration to control the settings under which we render the stimuli\n        receptors = flyvision.rendering.BoxEye(\n            extent=config.extent, kernel_size=config.kernel_size\n        )\n\n        # for memory-friendly rendering we can loop over individual sequences\n        # and subsets of the dataset\n        rendered_sequences = []\n        subset_idx = getattr(config, \"subset_idx\", []) or list(\n            range(sequences.shape[0])\n        )\n        with tqdm(total=len(subset_idx)) as pbar:\n            for index in subset_idx:\n                rendered_sequences.append(receptors(sequences[[index]]).cpu().numpy())\n                pbar.update()\n\n        # to join individual sequences along their first dimension\n        # to obtain (n_sequences, n_frames, 1, receptors.hexals)\n        rendered_sequences = np.concatenate(rendered_sequences, axis=0)\n\n        # the __setattr__ method of the Directory class saves sequences to self.path/\"sequences.h5\"\n        # that can be later retrieved using self.sequences[:]\n        self.sequences = rendered_sequences\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#create-a-custom-dataset","title":"Create a custom dataset","text":"<p>We create a generic interface for custom datasets to make dataloading consistent\u2014this interface can tell the sampler what the framerate, the integration time steps, durations for pre-, and post grey-scale stimulation, and the number of sequences are.</p> <p>In this case, we inherit a SequenceDataset, that also obeys (and extends) the interface of Pytorch\u2019s Dataset.</p> <pre><code>class CustomStimuli(SequenceDataset):\n\n    # implementing the SequenceDataset interface \n    dt = 1/100\n    framerate = 24\n    t_pre = 0.5\n    t_post = 0.5\n    n_sequences = None\n    augment = False\n\n    def __init__(self, rendered_data_config: dict):\n        self.dir = RenderedData(rendered_data_config)\n        self.sequences = torch.tensor(self.dir.sequences[:])\n        self.n_sequences = self.sequences.shape[0]\n\n    def get_item(self, key):\n        sequence = self.sequences[key]\n        # to match the framerate to the integration time dt, we can resample frames\n        # from these indices. note, when dt = 1/framerate, this will return the exact sequence\n        resample = self.get_temporal_sample_indices(sequence.shape[0], sequence.shape[0])\n        return sequence[resample]\n</code></pre> <pre><code># note, to render the whole dataset provide an empty list for `subset_idx` or delete the key word argument \ndata = CustomStimuli(dict(extent=15, kernel_size=13, subset_idx=[0, 1, 2, 3]))\n</code></pre> <pre><code>data[0].shape\n</code></pre> <pre><code>torch.Size([84, 1, 721])\n</code></pre> <pre><code>animation = flyvision.animations.HexScatter(data[0][None], vmin=0, vmax=1)\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#compute-model-responses-to-custom-stimuli","title":"Compute model responses to custom stimuli","text":"<p>Now, we can compute model responses across individual models or the whole ensemble to our custom stimulus.</p> <pre><code>from typing import List\nfrom tqdm import tqdm\nimport torch\nimport numpy as np\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.dpi'] = 200\n\nfrom pathlib import Path\nfrom datamate import root, Directory\n\nimport flyvision\nfrom flyvision.utils.dataset_utils import load_moving_mnist\nfrom flyvision.datasets.datasets import SequenceDataset\nfrom flyvision.utils.activity_utils import LayerActivity\nfrom flyvision.animations import StimulusResponse\n</code></pre> <pre><code># the Directory class is a smart pointer to a specific directory\n# on the filesystem\n\n# directory to store the rendered stimuli\nfrom flyvision import renderings_dir\n\n\n# root tells where the Directory-tree starts\n@root(renderings_dir)\nclass RenderedData(Directory):\n    class Config(dict):\n        extent: int  # radius, in number of receptors of the hexagonal array.\n        kernel_size: int  # photon collection radius, in pixels.\n        subset_idx: List[int]  # if specified, subset of sequences to render\n\n    def __init__(self, config: Config):\n        # here comes the preprocessing and rendering as above or similar -- depending on the dataset etc.\n        # this code will be executed automatically once for each unique configuration to store preprocessed\n        # data on disk and later simply provide a reference to it.\n        sequences = load_moving_mnist()\n\n        # we use the configuration to control the settings under which we render the stimuli\n        receptors = flyvision.rendering.BoxEye(\n            extent=config.extent, kernel_size=config.kernel_size\n        )\n\n        # for memory-friendly rendering we can loop over individual sequences\n        # and subsets of the dataset\n        rendered_sequences = []\n        subset_idx = getattr(config, \"subset_idx\", []) or list(\n            range(sequences.shape[0])\n        )\n        with tqdm(total=len(subset_idx)) as pbar:\n            for index in subset_idx:\n                rendered_sequences.append(receptors(sequences[[index]]).cpu().numpy())\n                pbar.update()\n\n        # to join individual sequences along their first dimension\n        # to obtain (n_sequences, n_frames, 1, receptors.hexals)\n        rendered_sequences = np.concatenate(rendered_sequences, axis=0)\n\n        # the __setattr__ method of the Directory class saves sequences to self.path/\"sequences.h5\"\n        # that can be later retrieved using self.sequences[:]\n        self.sequences = rendered_sequences\n</code></pre> <pre><code>class CustomStimuli(SequenceDataset):\n\n    # implementing the SequenceDataset interface \n    dt = 1/100\n    framerate = 24\n    t_pre = 0.5\n    t_post = 0.5\n    n_sequences = None\n    augment = False\n\n    def __init__(self, rendered_data_config: dict):\n        self.dir = RenderedData(rendered_data_config)\n        self.sequences = torch.tensor(self.dir.sequences[:])\n        self.n_sequences = self.sequences.shape[0]\n\n    def get_item(self, key):\n        sequence = self.sequences[key]\n        # to match the framerate to the integration time dt, we can resample frames\n        # from these indices. note, when dt = 1/framerate, this will return the exact sequence\n        resample = self.get_temporal_sample_indices(sequence.shape[0], sequence.shape[0])\n        return sequence[resample]\n</code></pre> <pre><code># note, to render the whole dataset provide an empty list for `subset_idx` or delete the key word argument \ndata = CustomStimuli(dict(extent=15, kernel_size=13, subset_idx=[0, 1, 2, 3]))\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#select-a-pretrained-network","title":"Select a pretrained network","text":"<p>To select a network from the ensemble of 50 pretrained networks, let\u2019s see what our options are.</p> <p>Paths to pretrained models from the ensemble end with four digit numbers which are sorted by task error (0-49 from best to worst).</p> <pre><code>sorted(\n    [\n        p.relative_to(flyvision.results_dir)\n        for p in (flyvision.results_dir / \"flow/0000\").iterdir()\n        if p.name.isnumeric()\n    ]\n)\n</code></pre> <pre><code>[PosixPath('flow/0000/000'),\n PosixPath('flow/0000/001'),\n PosixPath('flow/0000/002'),\n PosixPath('flow/0000/003'),\n PosixPath('flow/0000/004'),\n PosixPath('flow/0000/005'),\n PosixPath('flow/0000/006'),\n PosixPath('flow/0000/007'),\n PosixPath('flow/0000/008'),\n PosixPath('flow/0000/009'),\n PosixPath('flow/0000/010'),\n PosixPath('flow/0000/011'),\n PosixPath('flow/0000/012'),\n PosixPath('flow/0000/013'),\n PosixPath('flow/0000/014'),\n PosixPath('flow/0000/015'),\n PosixPath('flow/0000/016'),\n PosixPath('flow/0000/017'),\n PosixPath('flow/0000/018'),\n PosixPath('flow/0000/019'),\n PosixPath('flow/0000/020'),\n PosixPath('flow/0000/021'),\n PosixPath('flow/0000/022'),\n PosixPath('flow/0000/023'),\n PosixPath('flow/0000/024'),\n PosixPath('flow/0000/025'),\n PosixPath('flow/0000/026'),\n PosixPath('flow/0000/027'),\n PosixPath('flow/0000/028'),\n PosixPath('flow/0000/029'),\n PosixPath('flow/0000/030'),\n PosixPath('flow/0000/031'),\n PosixPath('flow/0000/032'),\n PosixPath('flow/0000/033'),\n PosixPath('flow/0000/034'),\n PosixPath('flow/0000/035'),\n PosixPath('flow/0000/036'),\n PosixPath('flow/0000/037'),\n PosixPath('flow/0000/038'),\n PosixPath('flow/0000/039'),\n PosixPath('flow/0000/040'),\n PosixPath('flow/0000/041'),\n PosixPath('flow/0000/042'),\n PosixPath('flow/0000/043'),\n PosixPath('flow/0000/044'),\n PosixPath('flow/0000/045'),\n PosixPath('flow/0000/046'),\n PosixPath('flow/0000/047'),\n PosixPath('flow/0000/048'),\n PosixPath('flow/0000/049')]\n</code></pre> <p>We use the <code>NetworkView</code> class to point to a model. This object can implement plots plus methods to initialize network, stimuli etc. </p> <pre><code>network_view = flyvision.network.NetworkView(flyvision.results_dir / \"flow/0000/000\")\n</code></pre> <pre><code>[2024-09-28 03:47:48] network:1005 Initialized network view at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000.\n</code></pre> <pre><code># to load the Pytorch module with pretrained parameters\nnetwork = network_view.init_network()\n</code></pre> <pre><code>[2024-09-28 03:47:58] network:252 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n[2024-09-28 03:47:58] chkpt_utils:72 Recovered network state.\n</code></pre> <pre><code>movie_input = data[0]\n</code></pre> <pre><code>movie_input.shape\n</code></pre> <pre><code>torch.Size([84, 1, 721])\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#compute-a-stationary-state","title":"Compute a stationary state","text":"<p>We initialize the network at a stationary state, to remove transient responses due to stimulus onset from functional stimulus responses like motion detection. The network provides two methods for stationary state computation <code>network.fade_in_state</code> and <code>network.steady_state</code>. We use <code>fade_in_state</code> here, which slowly ramps up the intensity of the first frame in the sequence to compute a stationary state that minimizes the transient response. The method <code>steady_state</code> computes a sequence-independent stationary state by providing a whole-field grey-scale stimulus at medium intensity (but it does not get rid of a transient response).</p> <pre><code>stationary_state = network.fade_in_state(1.0, data.dt, movie_input[[0]])\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#obtain-network-responses","title":"Obtain network responses","text":"<p>A convenient way to obtain network responses is to call <code>network.simulate</code> which calls the forward function of the Pytorch module without tracking gradients (plus it provides a simpler interface than <code>network.forward</code> because it already maps stimulus to receptors using the <code>network.stimulus</code> attribute).</p> <pre><code># For analysis, we move the returned tensor to cpu.\nresponses = network.simulate(movie_input[None], data.dt, initial_state=stationary_state).cpu()\n</code></pre> <pre><code>responses.shape\n</code></pre> <pre><code>torch.Size([1, 84, 45669])\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#visualize-responses-of-specific-cells","title":"Visualize responses of specific cells","text":"<p><code>LayerActivity</code> is an interface to the response tensor of 45k cells that allows dict- and attribute-style access to the responses of individual cell types and to the responses of their central cells.</p> <pre><code>responses = LayerActivity(responses, network.connectome, keepref=True)\n</code></pre> <pre><code>cell_type = \"T4c\"\n</code></pre> <p>The stimulus on the left, and the response on the right described by passive point neuron voltage dynamics. Cells depolarize (red) and hyperpolarize (blue) in response to the stimulus. A single \u201chexal\u201d corresponds to one neuron of the cell type.</p> <pre><code>anim = StimulusResponse(\n    movie_input[None],\n    responses[cell_type][:, :, None]\n)\nanim.animate_in_notebook(frames=np.arange(anim.frames)[::2])\n</code></pre> <p></p> <p>Often, we are interested in a canonical response of a specific cell type to a specific stimulus to generate hypotheses for their role in a computation. In our model, we can take the central cell as a proxy for all cells of the given type, because cells share their parameters and in- and output connections. I.e. the responses of all cells of a given type would be the same (not taking boundary effects into account) when the same stimulus would cross their identical but spatially offset receptive field in the same way.</p> <pre><code>n_frames = movie_input.shape[0]\ntime = np.arange(0, n_frames * data.dt, data.dt)\n</code></pre> <pre><code>fig, ax = flyvision.plots.plt_utils.init_plot([2, 2], fontsize=5)\nax.plot(time, responses.central[cell_type].squeeze())\nax.set_xlabel(\"time in s\", fontsize=5)\nax.set_ylabel(\"central response (a.u.)\", fontsize=5)\n</code></pre> <pre><code>Text(0, 0.5, 'central response (a.u.)')\n</code></pre> <p></p>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#compute-responses-over-the-whole-ensemble","title":"Compute responses over the whole ensemble","text":"<p>In addition to looking at individual models, we next compute responses across the whole ensemble at once to look at them jointly.</p> <pre><code>from typing import List\nfrom tqdm import tqdm\nimport torch\nimport numpy as np\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.dpi'] = 200\n\nfrom pathlib import Path\nfrom datamate import root, Directory\n\nimport flyvision\nfrom flyvision.utils.dataset_utils import load_moving_mnist\nfrom flyvision.datasets.datasets import SequenceDataset\nfrom flyvision.utils.activity_utils import LayerActivity\nfrom flyvision.animations import StimulusResponse\nfrom flyvision import EnsembleView\n</code></pre> <pre><code># the Directory class is a smart pointer to a specific directory\n# on the filesystem\n\n# directory to store the rendered stimuli\nfrom flyvision import renderings_dir\n\n\n# root tells where the Directory-tree starts\n@root(renderings_dir)\nclass RenderedData(Directory):\n    class Config(dict):\n        extent: int  # radius, in number of receptors of the hexagonal array.\n        kernel_size: int  # photon collection radius, in pixels.\n        subset_idx: List[int]  # if specified, subset of sequences to render\n\n    def __init__(self, config: Config):\n        # here comes the preprocessing and rendering as above or similar -- depending on the dataset etc.\n        # this code will be executed automatically once for each unique configuration to store preprocessed\n        # data on disk and later simply provide a reference to it.\n        sequences = load_moving_mnist()\n\n        # we use the configuration to control the settings under which we render the stimuli\n        receptors = flyvision.rendering.BoxEye(\n            extent=config.extent, kernel_size=config.kernel_size\n        )\n\n        # for memory-friendly rendering we can loop over individual sequences\n        # and subsets of the dataset\n        rendered_sequences = []\n        subset_idx = getattr(config, \"subset_idx\", []) or list(\n            range(sequences.shape[0])\n        )\n        with tqdm(total=len(subset_idx)) as pbar:\n            for index in subset_idx:\n                rendered_sequences.append(receptors(sequences[[index]]).cpu().numpy())\n                pbar.update()\n\n        # to join individual sequences along their first dimension\n        # to obtain (n_sequences, n_frames, 1, receptors.hexals)\n        rendered_sequences = np.concatenate(rendered_sequences, axis=0)\n\n        # the __setattr__ method of the Directory class saves sequences to self.path/\"sequences.h5\"\n        # that can be later retrieved using self.sequences[:]\n        self.sequences = rendered_sequences\n</code></pre> <pre><code>class CustomStimuli(SequenceDataset):\n\n    # implementing the SequenceDataset interface \n    dt = 1/100\n    framerate = 24\n    t_pre = 0.5\n    t_post = 0.5\n    n_sequences = None\n    augment = False\n\n    def __init__(self, rendered_data_config: dict):\n        self.dir = RenderedData(rendered_data_config)\n        self.sequences = torch.tensor(self.dir.sequences[:])\n        self.n_sequences = self.sequences.shape[0]\n\n    def get_item(self, key):\n        sequence = self.sequences[key]\n        # to match the framerate to the integration time dt, we can resample frames\n        # from these indices. note, when dt = 1/framerate, this will return the exact sequence\n        resample = self.get_temporal_sample_indices(sequence.shape[0], sequence.shape[0])\n        return sequence[resample]\n</code></pre> <pre><code># note, to render the whole dataset provide an empty list for `subset_idx` or delete the key word argument \ndata = CustomStimuli(dict(extent=15, kernel_size=13, subset_idx=[0, 1, 2, 3]))\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#select-the-pretrained-ensemble","title":"Select the pretrained ensemble","text":"<p>Similar to the <code>NetworkView</code> object, the <code>EnsembleView</code> object points to an ensemble and implements plots plus methods to initialize networks, stimuli etc. This object provides dict- and attribute-style access to individual <code>NetworkView</code> instances.</p> <pre><code>ensemble = EnsembleView(flyvision.results_dir / \"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-09-28 03:49:18] ensemble:138 Loaded 50 networks.\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#simulate-responses-for-each-network","title":"Simulate responses for each network","text":"<pre><code>movie_input = data[0]\n</code></pre> <p><code>ensemble.simulate</code> provides an efficient method to return responses of all networks within the ensemble.</p> <pre><code># ensemble.simulate returns an iterator over `network.simulate` for each network.\n# we exhaust it and stack responses from all models in the first dimension\nresponses = np.array(list(ensemble.simulate(movie_input[None], data.dt, fade_in=True)))\n</code></pre> <pre><code>Simulating network:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-09-28 03:49:27] network:252 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n[2024-09-28 03:49:27] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:27] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:28] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:28] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:28] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:28] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:29] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:29] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:29] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:29] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:30] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:30] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:30] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:30] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:30] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:31] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:31] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:31] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:31] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:32] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:32] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:32] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:32] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:32] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:33] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:33] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:33] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:33] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:34] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:34] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:34] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:34] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:34] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:35] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:35] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:35] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:35] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:35] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:36] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:36] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:36] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:36] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:36] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:37] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:37] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:37] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:37] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:37] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:38] chkpt_utils:72 Recovered network state.\n[2024-09-28 03:49:38] chkpt_utils:72 Recovered network state.\n</code></pre> <pre><code># dims are (n_models, n_sequences, n_frames, n_cells)\nresponses.shape\n</code></pre> <pre><code>(50, 1, 84, 45669)\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#visualize-responses-of-specific-cells-across-the-ensemble","title":"Visualize responses of specific cells across the ensemble","text":"<pre><code>responses = LayerActivity(responses, ensemble[0].connectome, keepref=True)\n</code></pre> <p>We look at responses of all cells of a specific cell-type in the hexagonal lattice.</p> <pre><code>cell_type = \"T4c\"\n\n# (n_models, n_sequences, n_frames, n_hexals)\nresponses[cell_type].shape\n</code></pre> <pre><code>(50, 1, 84, 721)\n</code></pre> <p>We can look at all model responses in succession to see how the stimulus causes depolarization and hyperpolarization in the cells. To speed this up a bit, we specify <code>frames</code> to look at every tenth frame.</p> <pre><code>anim = flyvision.animations.activations.StimulusResponse(\n    movie_input[None], responses[cell_type][:, 0, :, None]\n)\n# these are now just the first 5 models for illustration\nmodel_index = [0, 1, 2, 3, 4]\nanim.animate_in_notebook(\n    samples=model_index,  \n    frames=np.arange(anim.frames)[::10]\n)\n</code></pre> <p></p> <p>Or look at responses in multiple models jointly.  Disclaimer: including more axes slows down the animation.</p> <pre><code>cell_type_responses = responses[cell_type]\nmodel_idx = [0, 1, 2, 3, 4]\nanim = flyvision.animations.activations.StimulusResponse(\n    movie_input[None],\n    [cell_type_responses[i][None, 0, :, None] for i in model_idx]\n)\nanim.animate_in_notebook(frames=np.arange(anim.frames)[::10])\n</code></pre> <p></p> <p>Let\u2019s look at how the whole ensemble characterizes the central cell responses.</p> <pre><code>central_responses = responses.central\n</code></pre> <pre><code>n_frames = movie_input.shape[0]\ntime = np.arange(0, n_frames * data.dt, data.dt)\n</code></pre> <pre><code>colors = ensemble.task_error().colors\n</code></pre> <pre><code>fig, ax = flyvision.plots.plt_utils.init_plot([2, 2], fontsize=5)\nfor model_id, response in enumerate(central_responses[cell_type]):\n    ax.plot(time, response.squeeze(), c=colors[model_id], zorder=len(ensemble) - model_id)\nax.set_xlabel(\"time in s\", fontsize=5)\nax.set_ylabel(\"response (a.u.)\", fontsize=5)\nax.set_title(f\"{cell_type} responses across the ensemble\", fontsize=5)\n</code></pre> <pre><code>Text(0.5, 1.0, 'T4c responses across the ensemble')\n</code></pre> <p></p> <p>From the above plot it seems like different models generate different predictions for the cell type function and its hard to tell them apart. Therefore, we clustered the models such that we can separate the above responses by functional cluster for a specific cell type. Note, clusters are stored as dictionaries in which the key is the cluster identity and their values are the indices to the corresponding models.</p> <pre><code>cluster_indices = ensemble.cluster_indices(cell_type)\n</code></pre> <pre><code>[2024-09-28 03:50:59] clustering:640 Loaded T4c embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n</code></pre> <pre><code>for cluster_id, model_idx in cluster_indices.items():\n    fig, ax = flyvision.plots.plt_utils.init_plot([2, 2], fontsize=5)\n    for model_id in model_idx:\n        response = responses.central[cell_type][model_id]\n        ax.plot(time, response.squeeze(), c=colors[model_id], zorder=len(ensemble) - model_id)\n    ax.set_xlabel(\"time in s\", fontsize=5)\n    ax.set_ylabel(\"response (a.u.)\", fontsize=5)\n    ax.set_title(f\"{cell_type} responses across cluster {cluster_id+1}\", fontsize=5)\n    plt.show()\n</code></pre> <p></p> <p></p> <p></p> <p>For T4c, we know that the first set of models is upwards tuning and the second is downwards tuning (Fig.4c) \u2013 lets try to observe differences in their responses.</p> <p>We choose the best upwards tuning model and the best downwards tuning model to compare.</p> <p>We can notice that the spatial location of hyperpolarization and depolarization is switched vertically between both models. </p> <pre><code>cell_type = \"T4c\"\n</code></pre> <pre><code>cluster_indices = ensemble.cluster_indices(cell_type)\n</code></pre> <pre><code>anim = flyvision.animations.activations.StimulusResponse(\n    movie_input[None],\n    [responses[cell_type][[cluster_indices[0][0]], 0][:, :, None], \n     responses[cell_type][[cluster_indices[1][0]], 0][:, :, None]]\n)\nanim.animate_in_notebook(frames = np.arange(anim.frames)[::5])\n</code></pre> <p></p>"},{"location":"examples/Untitled/","title":"Untitled","text":"<pre><code>from datamate import Namespace\n\nimport flyvision\n\nfrom flyvision import Network\n\nfrom flyvision.utils.tensor_utils import AutoDeref\n\n%load_ext autoreload\n%autoreload 2\n</code></pre> <pre><code>1\n</code></pre> <pre><code>1\n</code></pre> <pre><code>network = Network()\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\nInput In [1], in &lt;cell line: 1&gt;()\n----&gt; 1 network = Network()\n\n\nNameError: name 'Network' is not defined\n</code></pre> <pre><code>steady_state = network.steady_state(1, 1/50, 2, 0.5, None, False)\n\nassert isinstance(steady_state, AutoDeref)\n\nassert list(steady_state.keys()) == [\"nodes\", \"edges\", \"sources\", \"targets\"]\n\nassert steady_state[\"nodes\"][\"activity\"].shape == (2, network.n_nodes)\n\nassert steady_state[\"sources\"][\"activity\"].shape == (2, network.n_edges)\n\nassert steady_state[\"targets\"][\"activity\"].shape == (2, network.n_edges)\n</code></pre> <pre><code>import torch\n</code></pre> <pre><code>initial_frames = torch.Tensor(2, 1, 721).uniform_()\n\nnetwork.fade_in_state(1, 1/20, initial_frames, None, False)\n</code></pre> <pre><code>len(slice(0, 10, 1))\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nTypeError                                 Traceback (most recent call last)\n\nInput In [44], in &lt;cell line: 1&gt;()\n----&gt; 1 len(slice(0, 10, 1))\n\n\nTypeError: object of type 'slice' has no len()\n</code></pre> <pre><code>type(slice(None))\n</code></pre> <pre><code>slice\n</code></pre> <pre><code>x = torch.zeros((4, 40, 1, 45000))\n</code></pre> <pre><code>%%timeit\nx = torch.zeros((4, 40, 1, 45000))\n</code></pre> <pre><code>4.01 ms \u00b1 108 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n</code></pre> <pre><code>%%timeit\nx.zero_()\n</code></pre> <pre><code>1.54 ms \u00b1 81.1 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\n</code></pre> <pre><code>shape = x.shape\n</code></pre> <pre><code>torch.Size([4, 40, 1, 45000])\n</code></pre> <pre><code>%time x *= 0\n</code></pre> <pre><code>CPU times: user 13.9 ms, sys: 1.73 ms, total: 15.6 ms\nWall time: 2.09 ms\n</code></pre> <pre><code>%%timeit\nx.any()\n</code></pre> <pre><code>3.27 ms \u00b1 203 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n</code></pre> <pre><code>x = torch.arange(10)\n</code></pre> <pre><code>x.ndim\n</code></pre> <pre><code>1\n</code></pre> <pre><code>from flyvision.ensemble import EnsembleView\n</code></pre> <pre><code>ensemble = EnsembleView(flyvision.results_dir / \"opticflow/000\")\n</code></pre> <pre><code>cluster = ensemble.cluster_indices(\"T4a\")\n</code></pre> <pre><code>ensemble[cluster[0]]\n</code></pre> <pre><code>{'opticflow/000/0000': &lt;flyvision.network.NetworkView at 0x121e90b50&gt;,\n 'opticflow/000/0001': &lt;flyvision.network.NetworkView at 0x121e51f10&gt;,\n 'opticflow/000/0002': &lt;flyvision.network.NetworkView at 0x121e57520&gt;,\n 'opticflow/000/0003': &lt;flyvision.network.NetworkView at 0x121e902b0&gt;,\n 'opticflow/000/0006': &lt;flyvision.network.NetworkView at 0x1215670a0&gt;,\n 'opticflow/000/0008': &lt;flyvision.network.NetworkView at 0x121439640&gt;,\n 'opticflow/000/0009': &lt;flyvision.network.NetworkView at 0x121e57910&gt;,\n 'opticflow/000/0010': &lt;flyvision.network.NetworkView at 0x121f800a0&gt;,\n 'opticflow/000/0011': &lt;flyvision.network.NetworkView at 0x1220190a0&gt;,\n 'opticflow/000/0012': &lt;flyvision.network.NetworkView at 0x121f42430&gt;,\n 'opticflow/000/0014': &lt;flyvision.network.NetworkView at 0x121f80190&gt;,\n 'opticflow/000/0021': &lt;flyvision.network.NetworkView at 0x121e57040&gt;,\n 'opticflow/000/0022': &lt;flyvision.network.NetworkView at 0x121e51c70&gt;,\n 'opticflow/000/0023': &lt;flyvision.network.NetworkView at 0x121f42100&gt;,\n 'opticflow/000/0024': &lt;flyvision.network.NetworkView at 0x121f428b0&gt;,\n 'opticflow/000/0034': &lt;flyvision.network.NetworkView at 0x121f808b0&gt;}\n</code></pre> <pre><code>ensemble.validation_losses()\n</code></pre> <pre><code>[autoreload of flyvision.network failed: Traceback (most recent call last):\n  File \"/Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n    superreload(m, reload, self.old_objects)\n  File \"/Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n    module = reload(module)\n  File \"/Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/importlib/__init__.py\", line 169, in reload\n    _bootstrap._exec(spec, module)\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 613, in _exec\n  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 846, in exec_module\n  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 983, in get_code\n  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 913, in source_to_code\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 228, in _call_with_frames_removed\n  File \"/Users/lappalainenj/projects/flyvision/flyvision/network.py\", line 930\n    raise NotImplementedError(\"Decoder initialization not implemented yet.\"\")\n                                                                             ^\nSyntaxError: EOL while scanning string literal\n]\n\n\n\n\n\n[5.136557112137477,\n 5.1910432005922,\n 5.220126719938384,\n 5.247156371672948,\n 5.251272610492176,\n 5.259885032143858,\n 5.260432395670149,\n 5.262506494919459,\n 5.26999799741639,\n 5.270350070463286,\n 5.271915781829092,\n 5.277487408783701,\n 5.277920800778601,\n 5.281195688578817,\n 5.283142616351445,\n 5.285234338707394,\n 5.289696128831969,\n 5.291882056328985,\n 5.292151802115971,\n 5.295515714420213,\n 5.295636435349782,\n 5.296880326337284,\n 5.298010385698742,\n 5.2988701777325735,\n 5.299407997065121,\n 5.300875236590703,\n 5.303517184323734,\n 5.306977924373415,\n 5.308157583077748,\n 5.318766646915012,\n 5.319535469015439,\n 5.319623884227541,\n 5.324388653039932,\n 5.328959693511327,\n 5.330954361293051,\n 5.331605119837655,\n 5.33213666246997,\n 5.332739176021682,\n 5.335818343692356,\n 5.355444823702176,\n 5.3596575657526655,\n 5.359666532940334,\n 5.36637066801389,\n 5.371573102143076,\n 5.378605955176884,\n 5.383891744746102,\n 5.417977929115295,\n 5.418262870775329,\n 5.427841289175881,\n 5.677851686875026]\n</code></pre> <pre><code>import numpy as np\nfrom flyvision import results_dir\nfrom flyvision import Ensemble\n</code></pre> <pre><code>models = [results_dir / \"opticflow/000\" / f\"{i:04}\" for i in np.random.choice(np.arange(50), replace=False, size=50)]\nensemble = Ensemble(models)\n</code></pre> <pre><code>np.random.shuffle(ensemble.names)\n</code></pre> <pre><code>ensemble.names\n</code></pre> <pre><code>['opticflow/000/0036',\n 'opticflow/000/0029',\n 'opticflow/000/0047',\n 'opticflow/000/0015',\n 'opticflow/000/0000',\n 'opticflow/000/0019',\n 'opticflow/000/0003',\n 'opticflow/000/0008',\n 'opticflow/000/0014',\n 'opticflow/000/0013',\n 'opticflow/000/0004',\n 'opticflow/000/0045',\n 'opticflow/000/0010',\n 'opticflow/000/0042',\n 'opticflow/000/0017',\n 'opticflow/000/0046',\n 'opticflow/000/0041',\n 'opticflow/000/0023',\n 'opticflow/000/0026',\n 'opticflow/000/0011',\n 'opticflow/000/0031',\n 'opticflow/000/0044',\n 'opticflow/000/0030',\n 'opticflow/000/0035',\n 'opticflow/000/0001',\n 'opticflow/000/0018',\n 'opticflow/000/0020',\n 'opticflow/000/0016',\n 'opticflow/000/0012',\n 'opticflow/000/0021',\n 'opticflow/000/0006',\n 'opticflow/000/0034',\n 'opticflow/000/0007',\n 'opticflow/000/0038',\n 'opticflow/000/0009',\n 'opticflow/000/0039',\n 'opticflow/000/0022',\n 'opticflow/000/0040',\n 'opticflow/000/0033',\n 'opticflow/000/0028',\n 'opticflow/000/0043',\n 'opticflow/000/0037',\n 'opticflow/000/0002',\n 'opticflow/000/0027',\n 'opticflow/000/0048',\n 'opticflow/000/0024',\n 'opticflow/000/0025',\n 'opticflow/000/0005',\n 'opticflow/000/0032',\n 'opticflow/000/0049']\n</code></pre> <pre><code>sorted(ensemble.names)\n</code></pre> <pre><code>['opticflow/000/0000',\n 'opticflow/000/0001',\n 'opticflow/000/0002',\n 'opticflow/000/0003',\n 'opticflow/000/0004',\n 'opticflow/000/0005',\n 'opticflow/000/0006',\n 'opticflow/000/0007',\n 'opticflow/000/0008',\n 'opticflow/000/0009',\n 'opticflow/000/0010',\n 'opticflow/000/0011',\n 'opticflow/000/0012',\n 'opticflow/000/0013',\n 'opticflow/000/0014',\n 'opticflow/000/0015',\n 'opticflow/000/0016',\n 'opticflow/000/0017',\n 'opticflow/000/0018',\n 'opticflow/000/0019',\n 'opticflow/000/0020',\n 'opticflow/000/0021',\n 'opticflow/000/0022',\n 'opticflow/000/0023',\n 'opticflow/000/0024',\n 'opticflow/000/0025',\n 'opticflow/000/0026',\n 'opticflow/000/0027',\n 'opticflow/000/0028',\n 'opticflow/000/0029',\n 'opticflow/000/0030',\n 'opticflow/000/0031',\n 'opticflow/000/0032',\n 'opticflow/000/0033',\n 'opticflow/000/0034',\n 'opticflow/000/0035',\n 'opticflow/000/0036',\n 'opticflow/000/0037',\n 'opticflow/000/0038',\n 'opticflow/000/0039',\n 'opticflow/000/0040',\n 'opticflow/000/0041',\n 'opticflow/000/0042',\n 'opticflow/000/0043',\n 'opticflow/000/0044',\n 'opticflow/000/0045',\n 'opticflow/000/0046',\n 'opticflow/000/0047',\n 'opticflow/000/0048',\n 'opticflow/000/0049']\n</code></pre> <pre><code>type(ensemble[45:49])\n</code></pre> <pre><code>flyvision.ensemble.Ensemble\n</code></pre> <pre><code>ensemble[45:49]\n</code></pre> <pre><code>Ensemble(/Users/lappalainenj/projects/flyvision/data/results/opticflow/000)\n</code></pre> <pre><code>ensemble.viewitems()\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nAttributeError                            Traceback (most recent call last)\n\nInput In [40], in &lt;cell line: 1&gt;()\n----&gt; 1 ensemble.viewitems()\n\n\nAttributeError: 'Ensemble' object has no attribute 'viewitems'\n</code></pre> <pre><code>list(ensemble.dir.clustering.keys())\n</code></pre> <pre><code>['Lawf2',\n 'Tm5a',\n 'T4b',\n 'Am',\n 'TmY3',\n 'TmY4',\n 'TmY5a',\n 'T2a',\n 'T4c',\n 'CT1(Lo1)',\n 'T4d',\n 'TmY18',\n 'L3',\n 'Tm28',\n 'L4',\n 'T5a',\n 'TmY10',\n 'Tm20',\n 'Tm16',\n 'L5',\n 'L2',\n 'R7',\n 'Mi10',\n 'T2',\n 'Mi3',\n 'Tm1',\n 'Mi4',\n 'R8',\n 'R1',\n 'R6',\n 'Mi2',\n 'Tm9',\n 'T3',\n 'Mi11',\n 'Lawf1',\n 'T4a',\n 'TmY9',\n 'Tm5Y',\n 'Tm5b',\n 'Tm30',\n 'Tm5c',\n 'C3',\n 'TmY15',\n 'T5c',\n 'T5d',\n 'TmY14',\n 'TmY13',\n 'L1',\n 'C2',\n 'T5b',\n 'CT1(M10)',\n 'Mi14',\n 'T1',\n 'Mi9',\n 'Mi13',\n 'Tm2',\n 'R3',\n 'R4',\n 'Mi1',\n 'Tm3',\n 'Tm4',\n 'Mi12',\n 'Mi15',\n 'R5',\n 'R2']\n</code></pre> <pre><code>a = {1: [1.2, 2.3], 2: [2.3, 4.3]}\n</code></pre> <pre><code>from typing import Dict, List\n</code></pre> <pre><code>type(a)\n</code></pre> <pre><code>dict\n</code></pre> <pre><code>isinstance(a, Dict[int, List[float]])\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nTypeError                                 Traceback (most recent call last)\n\nInput In [48], in &lt;cell line: 1&gt;()\n----&gt; 1 isinstance(a, Dict[int, List[float]])\n\n\nFile ~/mambaforge-pypy3/envs/flyvision/lib/python3.9/typing.py:720, in _BaseGenericAlias.__instancecheck__(self, obj)\n    719 def __instancecheck__(self, obj):\n--&gt; 720     return self.__subclasscheck__(type(obj))\n\n\nFile ~/mambaforge-pypy3/envs/flyvision/lib/python3.9/typing.py:723, in _BaseGenericAlias.__subclasscheck__(self, cls)\n    722 def __subclasscheck__(self, cls):\n--&gt; 723     raise TypeError(\"Subscripted generics cannot be used with\"\n    724                     \" class and instance checks\")\n\n\nTypeError: Subscripted generics cannot be used with class and instance checks\n</code></pre> <pre><code>cluster_indices\n</code></pre> <pre><code>[autoreload of flyvision.network failed: Traceback (most recent call last):\n  File \"/Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n    superreload(m, reload, self.old_objects)\n  File \"/Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n    module = reload(module)\n  File \"/Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/importlib/__init__.py\", line 169, in reload\n    _bootstrap._exec(spec, module)\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 613, in _exec\n  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 846, in exec_module\n  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 983, in get_code\n  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 913, in source_to_code\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 228, in _call_with_frames_removed\n  File \"/Users/lappalainenj/projects/flyvision/flyvision/network.py\", line 930\n    raise NotImplementedError(\"Decoder initialization not implemented yet.\"\")\n                                                                             ^\nSyntaxError: EOL while scanning string literal\n]\n\n\n\n---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\nInput In [49], in &lt;cell line: 1&gt;()\n----&gt; 1 cluster_indices\n\n\nNameError: name 'cluster_indices' is not defined\n</code></pre> <pre><code>x = set((ensemble.dir.clustering.T4c / \"0\")[:])\n</code></pre> <pre><code>y = set(list(range(50)))\n</code></pre> <pre><code>y.issubset(y)\n</code></pre> <pre><code>True\n</code></pre> <pre><code>from matplotlib import colormaps as cm\n</code></pre> <pre><code>cm.get_cmap(\"binary\")\n</code></pre> binary  underbad over  <pre><code>from matplotlib.cm import ScalarMappable\n</code></pre> <pre><code>x = np.arange(6)\n</code></pre> <pre><code>x[:2]\n</code></pre>         array([0, 1])     <pre><code>[*x[:2], *x[len(x) - 2:]]\n</code></pre>         [0, 1, 4, 5]     <pre><code>x\n</code></pre>         array([0, 1, 2, 3, 4, 5])     <pre><code>models = [results_dir / f\"opticflow/000/{i:04}\" for i in range(6)]\nensemble = Ensemble(models)\n</code></pre> <pre><code>from copy import deepcopy\n</code></pre> <pre><code>names = deepcopy(ensemble.names)\n</code></pre> <pre><code>with ensemble.ratio(best=1 / 3, worst=1 / 3):\n    assert len(ensemble) == int(2 / 3 * len(names))\n    print(ensemble.names)\n    assert ensemble.names == [\n        *names[: int(len(names) * 1 / 3)],\n        *names[len(names) - int(len(names) * 1 / 3) :],\n    ]\n</code></pre>      ['opticflow/000/0000', 'opticflow/000/0001', 'opticflow/000/0004', 'opticflow/000/0005']    <pre><code>names\n</code></pre>         ['opticflow/000/0000',      'opticflow/000/0001',      'opticflow/000/0002',      'opticflow/000/0003',      'opticflow/000/0004',      'opticflow/000/0005']     <pre><code>[\n        *names[: int(len(ensemble) * 1 / 3)],\n        *names[len(ensemble) - int(len(ensemble) * 1 / 3) :],\n    ]\n</code></pre>         ['opticflow/000/0000',      'opticflow/000/0001',      'opticflow/000/0004',      'opticflow/000/0005']     <pre><code>ensemble.cluster_indices(\"T4c\")\n</code></pre>         {0: array([ 0,  1,  2,  3,  6,  9, 23, 24, 13, 12, 21, 22, 37, 19, 35, 30, 27,             17, 29, 16, 36, 14, 20,  7, 18, 31, 42, 11, 47, 44, 48]),      1: array([ 5, 26,  4, 33, 38, 40, 43]),      2: array([ 8, 25, 10, 32, 34, 28, 45, 15, 39, 41, 46, 49])}     <pre><code>ensemble = Ensemble(ensemble.dir)\n</code></pre> <pre><code>network = next(ensemble.yield_networks())\n</code></pre> <pre><code>x = set(np.arange(len(ensemble)))\n</code></pre> <pre><code>for cell_type in network.cell_types:\n    _dir = ensemble.dir.clustering[cell_type]\n    mask = _dir.masked[()]\n    print(mask)\n    _dir.masked = mask.astype(int)\n#     clustering = np.concatenate(list(ensemble.dir.clustering[cell_type].to_dict().values()))\n#     mask = np.array(list(x.difference(clustering)), dtype=np.int)\n#     _dir.masked = mask\n#     print(_dir)\n#     print(mask)\n</code></pre>      []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     [16]     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []     []    <pre><code>ensemble.dir.clustering[cell_type].to_dict()\n</code></pre>         {'2': array([ 0,  5, 26, 25,  4, 16,  7, 32, 42, 45, 15, 44, 48, 49]),      '1': array([ 2,  6,  8,  9, 23, 24, 10, 13, 12, 21, 22, 37, 33, 35, 30, 27, 17,             38, 14, 20, 18, 31, 34, 28, 40, 39, 47, 43, 46]),      '0': array([ 1,  3, 19, 29, 36, 11, 41]),      'masked': array([], dtype=int64)}     <pre><code>np.array(list(set(clustering)), dt)\n</code></pre>         array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])     <pre><code>np.concatenate(list(ensemble.dir.clustering[cell_type].to_dict().values()))\n</code></pre>         array([ 0,  5, 26, 25,  4, 16,  7, 32, 42, 45, 15, 44, 48, 49,  2,  6,  8,             9, 23, 24, 10, 13, 12, 21, 22, 37, 33, 35, 30, 27, 17, 38, 14, 20,            18, 31, 34, 28, 40, 39, 47, 43, 46,  1,  3, 19, 29, 36, 11, 41])     <pre><code>ensemble = Ensemble(ensemble.dir)\n</code></pre> <pre><code>ensemble\n</code></pre>         Ensemble(/Users/lappalainenj/projects/flyvision/data/results/opticflow/000)     <pre><code>ensemble.cluster_indices(\"C3\")\n</code></pre>         {0: array([ 1,  6,  5,  9, 23, 12, 37, 33, 29, 14, 32, 42, 45, 11, 15, 39, 48]),      1: array([24, 10, 22,  4, 35, 30, 27, 16, 38, 20,  7, 18, 31, 34, 28, 47, 44,             43]),      2: array([ 0,  2,  3,  8, 26, 25, 13, 21, 19, 17, 36, 40, 41, 46, 49])}     <pre><code>from flyvision.plots.plots import hex_scatter\n</code></pre> <pre><code>import flyvision\n\nu, v = flyvision.utils.hex_utils.get_hex_coords(15)\nvalues = np.random.normal(size=len(u))\n</code></pre> <pre><code>import matplotlib as mpl\n</code></pre> <pre><code>mpl.rcParams['figure.dpi'] = 300\n</code></pre> <pre><code>fig, ax, _ = hex_scatter(u, v, values, figsize=[5, 5], midpoint=0)\n</code></pre>    ![png](Untitled_files/Untitled_66_0.png)     <pre><code>import torch\ntorch.Tensor\n</code></pre>         torch.Tensor     <pre><code>torch.Tensor == torch.FloatTensor\n</code></pre>         False     <pre><code>from dataclasses import dataclass\n</code></pre>      [autoreload of flyvision.utils.df_utils failed: Traceback (most recent call last):       File \"/Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 257, in check         superreload(m, reload, self.old_objects)       File \"/Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload         module = reload(module)       File \"/Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/importlib/__init__.py\", line 169, in reload         _bootstrap._exec(spec, module)       File \"\", line 613, in _exec       File \"\", line 846, in exec_module       File \"\", line 983, in get_code       File \"\", line 913, in source_to_code       File \"\", line 228, in _call_with_frames_removed       File \"/Users/lappalainenj/projects/flyvision/flyvision/utils/df_utils.py\", line 8         ) -&gt; DataFrame:         ^     SyntaxError: non-default argument follows default argument     ]     [autoreload of flyvision.connectome failed: Traceback (most recent call last):       File \"/Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 257, in check         superreload(m, reload, self.old_objects)       File \"/Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload         module = reload(module)       File \"/Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/importlib/__init__.py\", line 169, in reload         _bootstrap._exec(spec, module)       File \"\", line 613, in _exec       File \"\", line 846, in exec_module       File \"\", line 983, in get_code       File \"\", line 913, in source_to_code       File \"\", line 228, in _call_with_frames_removed       File \"/Users/lappalainenj/projects/flyvision/flyvision/connectome.py\", line 506         df_utils.filter_df_by_list(edges, column=\"source_type\", cell_types),                                                                           ^     SyntaxError: positional argument follows keyword argument     ]    <pre><code>@dataclass\nclass D:\n    a: int\n    b: int\n</code></pre> <pre><code>d= D(2, 1)\n</code></pre> <pre><code>d\n</code></pre>         D(a=2, b=1)     <pre><code>flyvision.utils.nodes_edges_utils.layout\n</code></pre> <pre><code>\"1\" &gt; 1\n</code></pre>       ---------------------------------------------------------------------------      TypeError                                 Traceback (most recent call last)      Input In [10], in ()     ----&gt; 1 \"1\" &gt; 1       TypeError: '&gt;' not supported between instances of 'str' and 'int'    <pre><code>from numpy.typing import NDArray\nimport numpy as np\n</code></pre> <pre><code>img = np.arange(10)\n</code></pre> <pre><code>type(img) == NDArray\n</code></pre>         False     <pre><code>isinstance(img, np.ndarray)\n</code></pre>         True     <pre><code>import flyvision\nimport numpy as np\n</code></pre> <pre><code>\n</code></pre>         'module://matplotlib_inline.backend_inline'     <pre><code>\n</code></pre> <pre><code>%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.get_backend()\n</code></pre>         'module://matplotlib_inline.backend_inline'     <pre><code>%matplotlib --list\n</code></pre>      Available matplotlib backends: ['tk', 'gtk', 'gtk3', 'gtk4', 'wx', 'qt4', 'qt5', 'qt6', 'qt', 'osx', 'nbagg', 'notebook', 'agg', 'svg', 'pdf', 'ps', 'inline', 'ipympl', 'widget']    <pre><code>matplotlib.pyplot.switch_backend(\"nbagg\")\n</code></pre> <pre><code>def wrapper(f):\n\n    def wrap(*args, **kwargs):\n        current_backend = matplotlib.get_backend()\n        matplotlib.pyplot.switch_backend('nbagg')\n        f(*args, **kwargs)\n</code></pre> <pre><code>from contextlib import contextmanager\nfrom time import sleep\n</code></pre> <pre><code>@contextmanager\ndef matplotlib_backend(backend='nbagg'):\n    try:\n        current_backend = matplotlib.get_backend()\n        matplotlib.pyplot.switch_backend(backend)\n        yield\n    except:\n        yield\n    finally:\n        plt.gcf().canvas.draw()\n        sleep(0.1)\n        matplotlib.pyplot.switch_backend(current_backend)\n</code></pre> <pre><code>import numpy as np\ndef plot():\n    plt.plot(np.arange(10))\n    plt.show()\n</code></pre> <pre><code>matplotlib.pyplot.switch_backend(\"abc\")\n</code></pre>       ---------------------------------------------------------------------------      ModuleNotFoundError                       Traceback (most recent call last)      Input In [2], in ()     ----&gt; 1 matplotlib.pyplot.switch_backend(\"abc\")       File ~/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages/matplotlib/pyplot.py:271, in switch_backend(newbackend)         268 # have to escape the switch on access logic         269 old_backend = dict.__getitem__(rcParams, 'backend')     --&gt; 271 backend_mod = importlib.import_module(         272     cbook._backend_module_name(newbackend))         274 required_framework = _get_required_interactive_framework(backend_mod)         275 if required_framework is not None:       File ~/mambaforge-pypy3/envs/flyvision/lib/python3.9/importlib/__init__.py:127, in import_module(name, package)         125             break         126         level += 1     --&gt; 127 return _bootstrap._gcd_import(name[level:], package, level)       File :1030, in _gcd_import(name, package, level)       File :1007, in _find_and_load(name, import_)       File :984, in _find_and_load_unlocked(name, import_)       ModuleNotFoundError: No module named 'matplotlib.backends.backend_abc'    <pre><code>with matplotlib_backend('nbagg'):\n    plot()\n</code></pre> <pre><code>matplotlib.get_backend()\n</code></pre> <pre><code>matplotlib.pyplot.switch_backend('module://matplotlib_inline.backend_inline')\n</code></pre> <pre><code>import numpy as np\n</code></pre> <pre><code>matplotlib.set_logle()\n</code></pre> <pre><code>plt.plot(np.arange(100))\n</code></pre> <pre><code>%matplotlib widget\n</code></pre> <pre><code>anim = flyvision.animations.HexScatter(np.random.normal(size=[2, 10, 1, 721]))\nanim.animate_in_notebook()\n</code></pre> <pre><code>!pip install --upgrade ipympl\n</code></pre>      Requirement already satisfied: ipympl in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (0.9.3)     Requirement already satisfied: matplotlib&lt;4,&gt;=3.4.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (3.7.1)     Requirement already satisfied: ipython&lt;9 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (8.4.0)     Requirement already satisfied: traitlets&lt;6 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (5.9.0)     Requirement already satisfied: pillow in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (9.4.0)     Requirement already satisfied: ipython-genutils in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (0.2.0)     Requirement already satisfied: ipywidgets&lt;9,&gt;=7.6.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (8.0.5)     Requirement already satisfied: numpy in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (1.24.2)     Requirement already satisfied: pygments&gt;=2.4.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (2.14.0)     Requirement already satisfied: pickleshare in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (0.7.5)     Requirement already satisfied: backcall in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (0.2.0)     Requirement already satisfied: decorator in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (5.1.1)     Requirement already satisfied: jedi&gt;=0.16 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (0.18.2)     Requirement already satisfied: appnope in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (0.1.3)     Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (3.0.38)     Requirement already satisfied: pexpect&gt;4.3 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (4.8.0)     Requirement already satisfied: stack-data in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (0.6.2)     Requirement already satisfied: matplotlib-inline in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (0.1.6)     Requirement already satisfied: setuptools&gt;=18.5 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (67.6.0)     Requirement already satisfied: jupyterlab-widgets~=3.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipywidgets&lt;9,&gt;=7.6.0-&gt;ipympl) (3.0.6)     Requirement already satisfied: widgetsnbextension~=4.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipywidgets&lt;9,&gt;=7.6.0-&gt;ipympl) (4.0.6)     Requirement already satisfied: python-dateutil&gt;=2.7 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (2.8.2)     Requirement already satisfied: cycler&gt;=0.10 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (0.11.0)     Requirement already satisfied: fonttools&gt;=4.22.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (4.39.2)     Requirement already satisfied: kiwisolver&gt;=1.0.1 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (1.4.4)     Requirement already satisfied: importlib-resources&gt;=3.2.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (5.12.0)     Requirement already satisfied: pyparsing&gt;=2.3.1 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (3.0.9)     Requirement already satisfied: packaging&gt;=20.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (23.0)     Requirement already satisfied: contourpy&gt;=1.0.1 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (1.0.7)     Requirement already satisfied: zipp&gt;=3.1.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from importlib-resources&gt;=3.2.0-&gt;matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (3.15.0)     Requirement already satisfied: parso&lt;0.9.0,&gt;=0.8.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from jedi&gt;=0.16-&gt;ipython&lt;9-&gt;ipympl) (0.8.3)     Requirement already satisfied: ptyprocess&gt;=0.5 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from pexpect&gt;4.3-&gt;ipython&lt;9-&gt;ipympl) (0.7.0)     Requirement already satisfied: wcwidth in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython&lt;9-&gt;ipympl) (0.2.6)     Requirement already satisfied: six&gt;=1.5 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (1.16.0)     Requirement already satisfied: asttokens&gt;=2.1.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from stack-data-&gt;ipython&lt;9-&gt;ipympl) (2.2.1)     Requirement already satisfied: pure-eval in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from stack-data-&gt;ipython&lt;9-&gt;ipympl) (0.2.2)     Requirement already satisfied: executing&gt;=1.2.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from stack-data-&gt;ipython&lt;9-&gt;ipympl) (1.2.0)    <pre><code>!pip install ipympl\n</code></pre>      Collecting ipympl       Downloading ipympl-0.9.3-py2.py3-none-any.whl (511 kB)     \u001b[2K     \u001b[38;2;114;156;31m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m663.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m     \u001b[?25hRequirement already satisfied: ipywidgets&lt;9,&gt;=7.6.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (8.0.5)     Requirement already satisfied: numpy in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (1.24.2)     Requirement already satisfied: pillow in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (9.4.0)     Requirement already satisfied: matplotlib&lt;4,&gt;=3.4.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (3.7.1)     Requirement already satisfied: traitlets&lt;6 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (5.9.0)     Requirement already satisfied: ipython&lt;9 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (8.4.0)     Requirement already satisfied: ipython-genutils in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipympl) (0.2.0)     Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (3.0.38)     Requirement already satisfied: stack-data in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (0.6.2)     Requirement already satisfied: setuptools&gt;=18.5 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (67.6.0)     Requirement already satisfied: appnope in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (0.1.3)     Requirement already satisfied: pickleshare in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (0.7.5)     Requirement already satisfied: matplotlib-inline in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (0.1.6)     Requirement already satisfied: decorator in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (5.1.1)     Requirement already satisfied: pexpect&gt;4.3 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (4.8.0)     Requirement already satisfied: backcall in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (0.2.0)     Requirement already satisfied: pygments&gt;=2.4.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (2.14.0)     Requirement already satisfied: jedi&gt;=0.16 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipython&lt;9-&gt;ipympl) (0.18.2)     Requirement already satisfied: jupyterlab-widgets~=3.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipywidgets&lt;9,&gt;=7.6.0-&gt;ipympl) (3.0.6)     Requirement already satisfied: widgetsnbextension~=4.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from ipywidgets&lt;9,&gt;=7.6.0-&gt;ipympl) (4.0.6)     Requirement already satisfied: pyparsing&gt;=2.3.1 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (3.0.9)     Requirement already satisfied: contourpy&gt;=1.0.1 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (1.0.7)     Requirement already satisfied: packaging&gt;=20.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (23.0)     Requirement already satisfied: importlib-resources&gt;=3.2.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (5.12.0)     Requirement already satisfied: kiwisolver&gt;=1.0.1 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (1.4.4)     Requirement already satisfied: cycler&gt;=0.10 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (0.11.0)     Requirement already satisfied: fonttools&gt;=4.22.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (4.39.2)     Requirement already satisfied: python-dateutil&gt;=2.7 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (2.8.2)     Requirement already satisfied: zipp&gt;=3.1.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from importlib-resources&gt;=3.2.0-&gt;matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (3.15.0)     Requirement already satisfied: parso&lt;0.9.0,&gt;=0.8.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from jedi&gt;=0.16-&gt;ipython&lt;9-&gt;ipympl) (0.8.3)     Requirement already satisfied: ptyprocess&gt;=0.5 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from pexpect&gt;4.3-&gt;ipython&lt;9-&gt;ipympl) (0.7.0)     Requirement already satisfied: wcwidth in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython&lt;9-&gt;ipympl) (0.2.6)     Requirement already satisfied: six&gt;=1.5 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib&lt;4,&gt;=3.4.0-&gt;ipympl) (1.16.0)     Requirement already satisfied: asttokens&gt;=2.1.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from stack-data-&gt;ipython&lt;9-&gt;ipympl) (2.2.1)     Requirement already satisfied: executing&gt;=1.2.0 in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from stack-data-&gt;ipython&lt;9-&gt;ipympl) (1.2.0)     Requirement already satisfied: pure-eval in /Users/lappalainenj/mambaforge-pypy3/envs/flyvision/lib/python3.9/site-packages (from stack-data-&gt;ipython&lt;9-&gt;ipympl) (0.2.2)     Installing collected packages: ipympl     Successfully installed ipympl-0.9.3   # explicit groupby init   <pre><code>from datamate import Namespace\n\nfrom flyvision.initialization import Parameter\nfrom flyvision.connectome import ConnectomeDir\nfrom flyvision import connectome_file\n\n%load_ext autoreload\n%autoreload 2\n</code></pre> <pre><code>edge_config = Namespace(\n            sign=Namespace(\n                type=\"SynapseSign\",\n                initial_dist=\"Value\",\n                requires_grad=False,\n                groupby=[\"source_type\", \"target_type\"],\n            ),\n            syn_count=Namespace(\n                type=\"SynapseCount\",\n                initial_dist=\"Lognormal\",\n                mode=\"mean\",\n                requires_grad=False,\n                std=1.0,\n                groupby=[\"source_type\", \"target_type\", \"dv\", \"du\"],\n            ),\n            syn_strength=Namespace(\n                type=\"SynapseCountScaling\",\n                initial_dist=\"Value\",\n                requires_grad=True,\n                scale_elec=0.01,\n                scale_chem=0.01,\n                clamp=\"non_negative\",\n                groupby=[\"source_type\", \"target_type\"],\n            ),\n        )\n</code></pre> <pre><code>connectome = ConnectomeDir(Namespace(file=connectome_file, extent=15, n_syn_fill=1))\n</code></pre> <pre><code>param = Parameter(edge_config.sign, connectome)\n</code></pre> <pre><code>param.indices\n</code></pre>         tensor([  0,   0,   0,  ..., 603, 603, 603])     <pre><code>import flyvision\nfrom datamate import Directory\n</code></pre> <pre><code>gather_indices_dir = Directory(flyvision.root_dir).gather_indices\n</code></pre> <pre><code>for name, config in edge_config.items():\n    param = Parameter(config, connectome)\n\nedge_config\n</code></pre>         Namespace(       sign = Namespace(         type = 'SynapseSign',         initial_dist = 'Value',         requires_grad = False,         groupby = ['source_type', 'target_type']       ),       syn_count = Namespace(         type = 'SynapseCount',         initial_dist = 'Lognormal',         mode = 'mean',         requires_grad = False,         std = 1.0,         groupby = ['source_type', 'target_type', 'dv', 'du']       ),       syn_strength = Namespace(         type = 'SynapseCountScaling',         initial_dist = 'Value',         requires_grad = True,         scale_elec = 0.01,         scale_chem = 0.01,         clamp = 'non_negative',         groupby = ['source_type', 'target_type']       )     )     <pre><code>gather_indices_dir\n</code></pre>         gather_indices/ - Last modified: April 04, 2023 15:12:47     \u251c\u2500\u2500 sign/     \u2502   \u251c\u2500\u2500 indices.h5     \u2502   \u2514\u2500\u2500 raw_values.h5     \u251c\u2500\u2500 syn_count/     \u2502   \u251c\u2500\u2500 indices.h5     \u2502   \u2514\u2500\u2500 raw_values.h5     \u2514\u2500\u2500 syn_strength/         \u251c\u2500\u2500 indices.h5         \u2514\u2500\u2500 raw_values.h5      displaying: 4 directories, 6 files     <pre><code>node_config = Namespace(\n            bias=Namespace(\n                type=\"RestingPotential\",\n                groupby=[\"type\"],\n                initial_dist=\"Normal\",\n                mode=\"sample\",\n                requires_grad=True,\n                mean=0.5,\n                std=0.05,\n                penalize=Namespace(activity=True),\n                seed=0,\n            ),\n            time_const=Namespace(\n                type=\"TimeConstant\",\n                groupby=[\"type\"],\n                initial_dist=\"Value\",\n                value=0.05,\n                requires_grad=True,\n            ),\n        )\n\nnccopy = node_config.deepcopy()\n</code></pre> <pre><code>node_config\n</code></pre>         Namespace(       bias = Namespace(         type = 'RestingPotential',         groupby = ['type'],         initial_dist = 'Normal',         mode = 'sample',         requires_grad = True,         mean = 0.5,         std = 0.05,         penalize = Namespace(activity=True),         seed = 0       ),       time_const = Namespace(         type = 'TimeConstant',         groupby = ['type'],         initial_dist = 'Value',         value = 0.05,         requires_grad = True       )     )     <pre><code>for name, config in node_config.items():\n    param = Parameter(config, connectome)\n\nnode_config\n</code></pre>         Namespace(       bias = Namespace(         type = 'RestingPotential',         groupby = ['type'],         initial_dist = 'Normal',         mode = 'sample',         requires_grad = True,         mean = 0.5,         std = 0.05,         penalize = Namespace(activity=True),         seed = 0       ),       time_const = Namespace(         type = 'TimeConstant',         groupby = ['type'],         initial_dist = 'Value',         value = 0.05,         requires_grad = True       )     )     <pre><code>import numpy as np\n</code></pre> <pre><code>ncc = node_config.deepcopy()\n</code></pre> <pre><code>ncc.bias.type = np.arange(1, 101)\n</code></pre> <pre><code>node_config.bias.type=np.arange(100)\n</code></pre> <pre><code>ncc\n</code></pre>         Namespace(       bias = Namespace(         type = array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,             14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,             27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,             40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,             53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,             66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,             79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,             92,  93,  94,  95,  96,  97,  98,  99, 100]),         groupby = ['type'],         initial_dist = 'Normal',         mode = 'sample',         requires_grad = True,         mean = 0.5,         std = 0.05,         penalize = Namespace(activity=True),         seed = 0       ),       time_const = Namespace(         type = 'TimeConstant',         groupby = ['type'],         initial_dist = 'Value',         value = 0.05,         requires_grad = True       )     )     <pre><code>node_config.bias.type == ncc.bias.type\n</code></pre>         array([False, False, False, False, False, False, False, False, False,            False, False, False, False, False, False, False, False, False,            False, False, False, False, False, False, False, False, False,            False, False, False, False, False, False, False, False, False,            False, False, False, False, False, False, False, False, False,            False, False, False, False, False, False, False, False, False,            False, False, False, False, False, False, False, False, False,            False, False, False, False, False, False, False, False, False,            False, False, False, False, False, False, False, False, False,            False, False, False, False, False, False, False, False, False,            False, False, False, False, False, False, False, False, False,            False])     <pre><code>from datamate.namespaces import compare\n</code></pre> <pre><code>compare(node_config, ncc)\n</code></pre>         Namespace(       bias = Namespace(         type = False,         groupby = True,         initial_dist = True,         mode = True,         requires_grad = True,         mean = True,         std = True,         penalize = Namespace(activity=True),         seed = True       ),       time_const = Namespace(         type = True,         groupby = True,         initial_dist = True,         value = True,         requires_grad = True       )     )     <pre><code>from typing import Mapping\nfrom pathlib import Path\nfrom numpy import ndarray\n</code></pre> <pre><code>all??\n</code></pre> <pre><code>def all_true(obj: object) -&gt; bool:\n    \"\"\"\n\n    \"\"\"\n    if isinstance(obj, (type(None), bool, int, float, str, type, bytes)):\n        return bool(obj)\n    elif isinstance(obj, Path):\n        return bool(obj)\n    elif isinstance(obj, (list, tuple)):\n        return all([all_true(v) for v in obj])\n    elif isinstance(obj, (ndarray)):\n        return all([all_true(v.item()) for v in obj])\n    elif isinstance(obj, Mapping):\n        return all([all_true(obj[k]) for k in obj])\n    else:\n        try:\n            return all_true(vars(obj))\n        except TypeError as e:\n            raise TypeError(f\"all {obj} of type {type(obj)}: {e}.\") from e\n</code></pre> <pre><code>all_true(node_config)\n</code></pre>         True     <pre><code>node_config.bias.type[0] = 10\n</code></pre> <pre><code>node_config.bias.seed = 1\n</code></pre> <pre><code>gather_indices_dir\n</code></pre>         gather_indices/ - Last modified: April 04, 2023 15:13:22     \u251c\u2500\u2500 bias/     \u2502   \u251c\u2500\u2500 indices.h5     \u2502   \u2514\u2500\u2500 raw_values.h5     \u251c\u2500\u2500 sign/     \u2502   \u251c\u2500\u2500 indices.h5     \u2502   \u2514\u2500\u2500 raw_values.h5     \u251c\u2500\u2500 syn_count/     \u2502   \u251c\u2500\u2500 indices.h5     \u2502   \u2514\u2500\u2500 raw_values.h5     \u251c\u2500\u2500 syn_strength/     \u2502   \u251c\u2500\u2500 indices.h5     \u2502   \u2514\u2500\u2500 raw_values.h5     \u2514\u2500\u2500 time_const/         \u251c\u2500\u2500 indices.h5         \u2514\u2500\u2500 raw_values.h5      displaying: 6 directories, 10 files     <pre><code>import pandas as pd\n</code></pre> <pre><code>attributes = [\"type\", \"u\", \"v\"]\ngroupby = [\"type\", \"u\"]\n</code></pre> <pre><code>def cast(x):\n    if np.issubdtype(x.dtype, np.dtype(\"S\")):\n        return x.astype(\"U\")\n    return x\n</code></pre> <pre><code>df = pd.DataFrame({k: cast(connectome.nodes[k][:]) for k in attributes})\n</code></pre> <pre><code>gb = df.groupby(groupby, as_index=False, sort=False)\n</code></pre> <pre><code>gb.first??\n</code></pre> <pre><code>df.iloc[np.concatenate(list(gb.groups.values()))]\n</code></pre> type u 9619 Am -15 9620 Am -15 9621 Am -15 9622 Am -15 9623 Am -15 ... ... ... 42059 TmY9 15 42060 TmY9 15 42061 TmY9 15 42062 TmY9 15 42063 TmY9 15 <p>45669 rows \u00d7 2 columns</p> <pre><code>gb.index\n</code></pre>         MultiIndex([(   b'R1', -15),                 (   b'R1', -14),                 (   b'R1', -13),                 (   b'R1', -12),                 (   b'R1', -11),                 (   b'R1', -10),                 (   b'R1',  -9),                 (   b'R1',  -8),                 (   b'R1',  -7),                 (   b'R1',  -6),                 ...                 (b'TmY18',   6),                 (b'TmY18',   7),                 (b'TmY18',   8),                 (b'TmY18',   9),                 (b'TmY18',  10),                 (b'TmY18',  11),                 (b'TmY18',  12),                 (b'TmY18',  13),                 (b'TmY18',  14),                 (b'TmY18',  15)],                names=['type', 'u'], length=1975)     <pre><code>param.raw_values\n</code></pre>         Parameter containing:     tensor([0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,             0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,             0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,             0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,             0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,             0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,             0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,             0.0500, 0.0500], requires_grad=True)     <pre><code>from flyvision.initialization_2 import Parameter\n</code></pre> <pre><code>for name, config in edge_config.items():\n    param = Parameter(config, connectome)\n    assert (gather_indices_dir[f\"{name}\"].raw_values[:] == param.raw_values.detach().numpy()).all()\n    assert (gather_indices_dir[f\"{name}\"].indices[:] == param.indices.detach().numpy()).all()\n</code></pre> <pre><code>for name, config in node_config.items():\n    param = Parameter(config, connectome)\n    assert (gather_indices_dir[f\"{name}\"].raw_values[:] == param.raw_values.detach().numpy()).all()\n    assert (gather_indices_dir[f\"{name}\"].indices[:] == param.indices.detach().numpy()).all()\n</code></pre> <pre><code>\n</code></pre> <pre><code>class RestingPotential2(Parameter):\n    \"\"\"Initialize resting potentials a.k.a. biases for cell types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeDir):\n        nodes_dir = connectome.nodes\n\n        # equals order in connectome.unique_cell_types\n        nodes = pd.DataFrame(dict(type=nodes_dir.type[:].astype(str))).drop_duplicates()\n\n        param_config[\"type\"] = nodes[\"type\"].values\n        param_config[\"mean\"] = np.repeat(param_config[\"mean\"], len(nodes))\n        param_config[\"std\"] = np.repeat(param_config[\"std\"], len(nodes))\n\n        self.symmetry_masks = symmetry_mask_for_nodes(\n            param_config.get(\"symmetric\", []), nodes\n        )\n\n        self.indices = get_scatter_indices(param_config, nodes_dir)\n        self.parameter = InitialDistribution(param_config)\n        self.keys = param_config[\"type\"].tolist()\n</code></pre>"},{"location":"examples/Untitled1/","title":"Untitled1","text":"<pre><code>from typing import List\nfrom tqdm import tqdm\nimport torch\nimport numpy as np\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.dpi'] = 200\n\nfrom pathlib import Path\nfrom datamate import root, Directory\n\nimport flyvision\nfrom flyvision import NetworkView, results_dir\nfrom flyvision.datasets.sintel import MultiTaskSintel\nfrom flyvision.utils.activity_utils import LayerActivity\n\n%load_ext autoreload\n%autoreload 2\n</code></pre> <pre><code>nnview = NetworkView(flyvision.results_dir / \"opticflow/000/0000\")\n</code></pre> <pre><code>flynet = nnview.init_network()\n</code></pre> <pre><code>decoder = nnview.init_decoder()\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nNotImplementedError                       Traceback (most recent call last)\n\nInput In [4], in &lt;cell line: 1&gt;()\n----&gt; 1 decoder = nnview.init_decoder()\n\n\nFile ~/projects/flyvision/flyvision/network.py:898, in NetworkView.init_decoder(self, chkpt, decoder)\n    888 def init_decoder(self, chkpt=\"best_chkpt\", decoder=None):\n    889     \"\"\"Initialize the decoder.\n    890 \n    891     Args:\n   (...)\n    896         decoder instance.\n    897     \"\"\"\n--&gt; 898     raise NotImplementedError(\"Decoder initialization not implemented yet.\")\n    899     if self._initialized[\"decoder\"] and decoder is None:\n    900         return self.decoder\n\n\nNotImplementedError: Decoder initialization not implemented yet.\n</code></pre> <pre><code>dataset = MultiTaskSintel()\n</code></pre> <pre><code>dataset.augment = False\n</code></pre> <pre><code>dataset.dt = 1/50\n</code></pre> <pre><code>state = flynet.fade_in_state(1.0, 1/50, dataset[0][\"lum\"][0])\n</code></pre> <pre><code>flynet.stimulus.add_input(dataset[0][\"lum\"][None])\n</code></pre> <pre><code>activity = flynet(flynet.stimulus(), dataset.dt, state=state)\n</code></pre> <pre><code>flow = decoder(activity)\n</code></pre> <pre><code>flow.shape\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\nInput In [10], in &lt;cell line: 1&gt;()\n----&gt; 1 flow.shape\n\n\nNameError: name 'flow' is not defined\n</code></pre> <pre><code>anim = flyvision.animations.sintel.SintelSample(dataset[0][\"lum\"][None], dataset[0][\"flow\"][None], flow)\nanim.animate_in_notebook()\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nAttributeError                            Traceback (most recent call last)\n\nInput In [13], in &lt;cell line: 1&gt;()\n----&gt; 1 anim = flyvision.animations.sintel.SintelSample(dataset[0][\"lum\"][None], dataset[0][\"flow\"][None], flow)\n      2 anim.animate_in_notebook()\n\n\nAttributeError: module 'flyvision.animations' has no attribute 'sintel'\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/__main__/","title":"main","text":"<p>Main notebook containing relevant diagnostics and important figures for the manuscript. </p> <p>It is automatically copied from __main__.ipynb and executed for newly trained ensembles using papermill.</p> <p>This can also be updated and then triggered again by using the script `execute_ensemble_notebook.py\u2019.</p> <pre><code>from pathlib import Path\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as nnf\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom flyvision import results_dir\nfrom flyvision import EnsembleView\n\nimport logging\nfrom flyvision.analysis.moving_bar_responses import plot_angular_tuning\nfrom flyvision.plots.plt_utils import add_cluster_marker, get_marker\nlogging.disable(100)\n\n\nmpl.rcParams[\"figure.dpi\"] = 300\n\n%load_ext autoreload\n%autoreload 2\n</code></pre> <pre><code>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</code></pre> <pre><code>ensemble_name = \"flow/9997\"  # type: str\n</code></pre> <pre><code>validation_subdir = \"validation\"\nloss_file_name = \"loss\"  \n</code></pre> <pre><code>ensemble = EnsembleView(ensemble_name, \n                        best_checkpoint_fn_kwargs=\n                        { \n                                                   \"validation_subdir\": validation_subdir,\n                                                   \"loss_file_name\": loss_file_name \n                                                   }\n                        )\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n</code></pre> <pre><code>print(f\"Description of experiment: {ensemble[0].dir.config.description}\")\n</code></pre> <pre><code>Description of experiment: test\n</code></pre>"},{"location":"examples/__main__/#task-performance","title":"Task performance","text":""},{"location":"examples/__main__/#training-and-validation-losses","title":"Training and validation losses","text":"<pre><code>fig, ax = ensemble.training_loss()\n</code></pre> <pre><code>fig, ax = ensemble.validation_loss()\n</code></pre> <pre><code>fig, ax = ensemble.task_error_histogram()\n</code></pre>"},{"location":"examples/__main__/#learned-parameter-marginals","title":"Learned parameter marginals","text":"<pre><code>fig, axes = ensemble.node_parameters(\"bias\")\n</code></pre> <pre><code>fig, axes = ensemble.node_parameters(\"time_const\")\n</code></pre> <pre><code>fig, axes = ensemble.edge_parameters(\"syn_strength\")\n</code></pre>"},{"location":"examples/__main__/#dead-or-alive","title":"Dead or alive","text":"<pre><code>fig, ax, cbar, matrix = ensemble.dead_or_alive()\n</code></pre> <pre><code>___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n</code></pre>"},{"location":"examples/__main__/#contrast-selectivity-and-flash-response-indices-fri","title":"Contrast selectivity and flash response indices (FRI)","text":""},{"location":"examples/__main__/#20-best-task-performing-models","title":"20% best task-performing models","text":"<pre><code>with ensemble.ratio(best=0.2):\n    ensemble.flash_response_index()\n</code></pre> <pre><code>___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n</code></pre>"},{"location":"examples/__main__/#100-models","title":"100% models","text":"<pre><code>fig, ax = ensemble.flash_response_index()\n</code></pre> <pre><code>___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n</code></pre>"},{"location":"examples/__main__/#motion-selectivity-and-direction-selectivity-index-dsi","title":"Motion selectivity and direction selectivity index (DSI)","text":""},{"location":"examples/__main__/#20-best-task-performing-models_1","title":"20% best task-performing models","text":"<pre><code>with ensemble.ratio(best=0.2):\n    ensemble.direction_selectivity_index()\n</code></pre> <pre><code>___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n</code></pre>"},{"location":"examples/__main__/#100-models_1","title":"100% models","text":"<pre><code>ensemble.direction_selectivity_index()\n</code></pre> <pre><code>___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n\n\n\n(&lt;Figure size 3000x360 with 2 Axes&gt;, (&lt;Axes: &gt;, &lt;Axes: &gt;))\n</code></pre>"},{"location":"examples/__main__/#clustering-of-models-based-on-responses-to-naturalistic-stimuli","title":"Clustering of models based on responses to naturalistic stimuli","text":""},{"location":"examples/__main__/#t4c","title":"T4c","text":"<pre><code>task_error = ensemble.task_error()\nembeddingplot = ensemble.clustering(\"T4c\").plot(task_error=task_error.values, \n                                                colors=task_error.colors)\n</code></pre> <pre><code>___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n/home/lappalainenj@hhmi.org/miniconda3/envs/flyvision/lib/python3.9/site-packages/umap/umap_.py:1356: RuntimeWarning: divide by zero encountered in power\n  return 1.0 / (1.0 + a * x ** (2 * b))\n</code></pre> <pre><code>r = ensemble.movingedge_responses()\n</code></pre> <pre><code>cluster_indices = ensemble.cluster_indices(\"T4c\")\n</code></pre> <pre><code>colors = ensemble.task_error().colors\n</code></pre> <pre><code>fig, axes = plt.subplots(\n    1, len(cluster_indices), subplot_kw={\"projection\": \"polar\"}, figsize=[2, 1]\n)\nfor cluster_id, indices in cluster_indices.items():\n    plot_angular_tuning(\n        r.sel(network_id=indices),\n        \"T4c\",\n        intensity=1,\n        colors=colors[indices],\n        zorder=ensemble.zorder()[indices],\n        groundtruth=True if cluster_id == 0 else False,\n        fig=fig,\n        ax=axes[cluster_id],\n    )\n    add_cluster_marker(fig, axes[cluster_id], marker=get_marker(cluster_id))\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/figure_01_fly_visual_system/","title":"Figure 1","text":""},{"location":"examples/figure_01_fly_visual_system/#a","title":"a","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n\nfrom flyvision import EnsembleView\n</code></pre> <pre><code>ensemble = EnsembleView(\"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-09-28 04:06:51] ensemble:138 Loaded 50 networks.\n</code></pre> <pre><code>fig, ax, cbar, matrix = ensemble[0].connectivity_matrix()\n</code></pre>"},{"location":"examples/figure_01_fly_visual_system/#e","title":"e","text":"<pre><code>fig = ensemble[0].receptive_field(source=\"Mi9\", target=\"T4d\", annotate=True,\n                    annotate_coords=False, trained=False,\n                    n_syn=True, cbar=False, fontsize=6, vmax=14,\n                    figsize=[2, 2], title=\"\", max_extent=2, edgewidth=0.2)\n</code></pre>"},{"location":"examples/figure_01_fly_visual_system/#g","title":"g","text":"<pre><code>import matplotlib.pyplot as plt\n\nfrom flyvision.datasets.sintel import MultiTaskSintel\nfrom flyvision.plots.plots import hex_scatter, quick_hex_scatter\nfrom flyvision.plots.plt_utils import rm_spines\n</code></pre> <pre><code>dataset = MultiTaskSintel(dt=1/24)\nsequence = dataset.cartesian_sequence(0, outwidth=436)\n</code></pre> <p>sintel movie</p> <pre><code>for frame in [0, 1, 18]:\n    fig, ax = plt.subplots(figsize=[1, 1])\n    ax.imshow(sequence[1, frame], cmap=plt.cm.binary_r)\n    rm_spines(ax)\n</code></pre> <p></p> <p></p> <p></p> <pre><code>dataset.augment=False\n</code></pre> <pre><code>sequence = dataset[1]\n</code></pre> <p>fly eye rendering</p> <pre><code>for frame in [0, 1, -1]:\n    quick_hex_scatter(sequence[\"lum\"][frame, 0], cbar=False)\n    rm_spines(ax)\n</code></pre> <p></p> <p></p> <p></p> <p>activations</p> <pre><code>from flyvision.connectome import ConnectomeDir\nfrom flyvision.plots import plt_utils\nfrom flyvision.plots.network import WholeNetworkFigure\nfrom flyvision.utils.color_utils import cell_type_colors\n</code></pre> <pre><code>sequence = dataset[1]\n</code></pre> <pre><code>ctome = ConnectomeDir()\n</code></pre> <pre><code>nodes = ctome.nodes.to_df()\n</code></pre> <pre><code>responses = ensemble[0].init_network().simulate(sequence[\"lum\"][None], dt=1/50, as_layer_activity=True)\n</code></pre> <pre><code>[2024-09-28 04:15:47] chkpt_utils:72 Recovered network state.\n</code></pre> <pre><code>frame = -1\nwnf = WholeNetworkFigure(ctome)\nwnf.init_figure(\n    figsize=(5.250, 1.3125),\n    decoder_box=False,\n    cell_type_labels=False,\n    fontsize=5,\n    add_graph_kwargs={\n        \"constant_edge_width\": 0.2,\n        \"edge_width\": 0.15, # this scales edges relative to each other\n        \"constant_edge_color\": \"k\",\n        \"edge_alpha\": 0.1,\n        \"nx_kwargs\": {\"min_source_margin\": 0,\n                      \"min_target_margin\": 5,\n                      \"selfloop_x0\": 0,\n                      \"selfloop_y0\": 0,\n                      \"selfloop_h_shift\": 0.025,\n                      \"selfloop_v_shift\": 0.1275},\n    },\n    network_layout_axes_kwargs={\n        \"types_per_column\": 4,\n        \"region_spacing\": 1.25,\n        \"wspace\": 0.0,\n    },\n)\n\nfor i, cell_type in enumerate(wnf.layout.keys()):\n    ax = wnf.axes[i]\n    u = nodes[nodes.type == cell_type].u.values\n    v = nodes[nodes.type == cell_type].v.values\n    hex_scatter(\n        u,\n        v,\n        responses[cell_type][0, frame],\n        fig=wnf.fig,\n        ax=ax,\n        label=f\"{cell_type}\",\n        label_color=cell_type_colors[cell_type],\n        cmap=plt.cm.binary_r,\n        cbar=False,\n        fontsize=5,\n        fill=True,\n        labelxy=\"auto\"\n    )\n    (xmin, ymin, xmax, ymax) = ax.dataLim.extents\n    ax.set_xlim(plt_utils.get_lims((xmin, xmax), 0.01))\n    ax.set_ylim(plt_utils.get_lims((ymin, ymax), 0.02))\n</code></pre> <p></p> <p>optic flow</p> <pre><code>from flyvision.plots.plots import quick_hex_flow\n</code></pre> <pre><code>sequence = dataset[1]\n</code></pre> <pre><code>for frame in [0, 1, -1]:\n   quick_hex_flow(\n        sequence[\"flow\"][frame],\n        cwheel=False,\n        cwheelradius=0.2,\n        cwheelpos=\"southeast\",\n        cwheellabelpad=-3,\n    )\n</code></pre> <p></p> <p></p> <p></p>"},{"location":"examples/figure_02_simple_stimuli_responses/","title":"Figure 2","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n\nfrom matplotlib.patches import Rectangle\n\n\nfrom flyvision import EnsembleView\nfrom flyvision.utils import color_utils\n</code></pre> <pre><code>ensemble = EnsembleView(\"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-09-28 04:18:31] ensemble:138 Loaded 50 networks.\n</code></pre>"},{"location":"examples/figure_02_simple_stimuli_responses/#b","title":"b","text":"<pre><code>with ensemble.ratio(best=0.2):\n    fig, ax = ensemble.flash_response_index()\n\nymin, ymax= 0, 1\n# to get locations of left most and right most T4 subtype ticks\nxmin, xmax = [p.get_position()[0] for p in ax.get_xticklabels() if p.get_text() in [\"R1\", \"Tm3\"]]\n# to place in between ticks\nxmin -= 1/2\nxmax += 1/2\nxy = (xmin, ymin)\nwidth = xmax - xmin\nheight = ymax\nrect = Rectangle(xy, width, height, facecolor=color_utils.ON_FR, alpha=0.1)\nax.add_patch(rect)\n\nymin, ymax= 0, -1\n# to get locations of left most and right most T4 subtype ticks\nxmin, xmax = [p.get_position()[0] for p in ax.get_xticklabels() if p.get_text() in [\"L1\", \"Tm9\"]]\n# to place in between ticks\nxmin -= 1/2\nxmax += 1/2\nxy = (xmin, ymin)\nwidth = xmax - xmin\nheight = ymax\nrect = Rectangle(xy, width, height, facecolor=color_utils.OFF_FR, alpha=0.1)\nax.add_patch(rect)\n\nax.set_title(\"Flash response indices\")\n</code></pre> <pre><code>[2024-09-28 04:18:32] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/000', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 102bbcd0dbfd7bfa6847ec1a64bd245a)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:32] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses/102bbcd0dbfd7bfa6847ec1a64bd245a/output.h5\n[2024-09-28 04:18:33] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/001', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 01bc24ee52f66d92df6dda7a54fbb512)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:33] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses/01bc24ee52f66d92df6dda7a54fbb512/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.1s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:18:33] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/002', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 1be5fe2784c35f3799f9c52e4c1f4ab1)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:33] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__/flyvision/analysis/stimulus_responses/compute_responses/1be5fe2784c35f3799f9c52e4c1f4ab1/output.h5\n[2024-09-28 04:18:33] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/003', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 3a32cdc078ada6ec77ef312d81a5a3d3)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:33] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__/flyvision/analysis/stimulus_responses/compute_responses/3a32cdc078ada6ec77ef312d81a5a3d3/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:18:33] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/004', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 73395eed18b129d61ea168228b6dcbce)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:33] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__/flyvision/analysis/stimulus_responses/compute_responses/73395eed18b129d61ea168228b6dcbce/output.h5\n[2024-09-28 04:18:33] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/005', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 78e98f930ff18637efa20e1d548d3a8c)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:33] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__/flyvision/analysis/stimulus_responses/compute_responses/78e98f930ff18637efa20e1d548d3a8c/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:18:33] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/006', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 22e55668eb1321c0343e492d14827f15)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:33] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__/flyvision/analysis/stimulus_responses/compute_responses/22e55668eb1321c0343e492d14827f15/output.h5\n[2024-09-28 04:18:33] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/007', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 37749baa331d7b1fe7d6cb50f19136e2)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:34] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__/flyvision/analysis/stimulus_responses/compute_responses/37749baa331d7b1fe7d6cb50f19136e2/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:18:34] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/008', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 23d0249da454f978d09c5205e8b0136e)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:34] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__/flyvision/analysis/stimulus_responses/compute_responses/23d0249da454f978d09c5205e8b0136e/output.h5\n[2024-09-28 04:18:34] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/009', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash bb93e66c28a9572b3f9a66ec21c1a8fb)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:34] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__/flyvision/analysis/stimulus_responses/compute_responses/bb93e66c28a9572b3f9a66ec21c1a8fb/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n\n\n\nText(0.5, 1.0, 'Flash response indices')\n</code></pre>"},{"location":"examples/figure_02_simple_stimuli_responses/#c","title":"c","text":"<pre><code>with ensemble.ratio(best=0.2):\n    fig, axes = ensemble.direction_selectivity_index()\n\nymin, ymax = 0, 1\n# to get locations of left most and right most T4 subtype ticks\nxmin, xmax = [\n    p.get_position()[0]\n    for p in axes[1].get_xticklabels()\n    if p.get_text() in [\"T4a\", \"T4d\"]\n]\n# to place in between ticks\nxmin -= 1 / 2\nxmax += 1 / 2\nxy = (xmin, ymin)\nwidth = xmax - xmin\nheight = ymax\nrect = Rectangle(xy, width, height, facecolor=color_utils.ON, alpha=0.1)\naxes[0].add_patch(rect)\n\n# to get locations of left most and right most T4 subtype ticks\nxmin, xmax = [\n    p.get_position()[0]\n    for p in axes[1].get_xticklabels()\n    if p.get_text() in [\"T5a\", \"T5d\"]\n]\n# to place in between ticks\nxmin -= 1 / 2\nxmax += 1 / 2\nxy = (xmin, ymin)\nwidth = xmax - xmin\nheight = ymax\nrect = Rectangle(xy, width, height, facecolor=color_utils.OFF, alpha=0.1)\naxes[1].add_patch(rect)\n\nax.set_title(\"Direction selectivity indices\")\n</code></pre> <pre><code>[2024-09-28 04:18:37] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/000', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 77be693699aefc8a65b21a471879e324)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n\n\n[2024-09-28 04:18:37] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses/77be693699aefc8a65b21a471879e324/output.h5\n[2024-09-28 04:18:37] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/001', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 1d2c73d297130e58bf05418b7385227e)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:37] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses/1d2c73d297130e58bf05418b7385227e/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:18:37] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/002', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash a492cccda41a28f65f6051985f0cd6fc)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:37] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__/flyvision/analysis/stimulus_responses/compute_responses/a492cccda41a28f65f6051985f0cd6fc/output.h5\n[2024-09-28 04:18:37] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/003', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 86e7a776a281aa3c6274211ff33649db)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:37] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__/flyvision/analysis/stimulus_responses/compute_responses/86e7a776a281aa3c6274211ff33649db/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:18:37] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/004', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash cbb23a582ff5ce0c06961764a957f0d0)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:37] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__/flyvision/analysis/stimulus_responses/compute_responses/cbb23a582ff5ce0c06961764a957f0d0/output.h5\n[2024-09-28 04:18:37] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/005', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash ef1adddb6ce7d96ba6e3dba901c05dd7)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:37] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__/flyvision/analysis/stimulus_responses/compute_responses/ef1adddb6ce7d96ba6e3dba901c05dd7/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:18:37] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/006', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 17643fb00254698b3a84bd93a2e0903d)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:37] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__/flyvision/analysis/stimulus_responses/compute_responses/17643fb00254698b3a84bd93a2e0903d/output.h5\n[2024-09-28 04:18:38] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/007', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash c6e2af646c29f24a4c697b4c066d8916)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:38] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__/flyvision/analysis/stimulus_responses/compute_responses/c6e2af646c29f24a4c697b4c066d8916/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:18:38] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/008', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 88dff80cbdda9c384ba9384e600e62a6)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:38] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__/flyvision/analysis/stimulus_responses/compute_responses/88dff80cbdda9c384ba9384e600e62a6/output.h5\n[2024-09-28 04:18:38] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7feb0ba51dc0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/009', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7feb02a7ca60&gt;, network=None), \n&lt;class 'flyvision.datasets.moving_bar.MovingEdge'&gt;, { 'device': 'cuda',\n  'dt': 0.005,\n  'height': 80,\n  'intensities': [0, 1],\n  'offsets': (-10, 11),\n  'post_pad_mode': 'continue',\n  'speeds': (2.4, 4.8, 9.7, 13, 19, 25),\n  't_post': 1.0,\n  't_pre': 1.0}, \n4, 1.0, 0.0).\n\n                        (argument hash 395a0cfb766f550893c991f34a74ce3d)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:18:38] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__/flyvision/analysis/stimulus_responses/compute_responses/395a0cfb766f550893c991f34a74ce3d/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n\n\n\nText(0.5, 1.0, 'Direction selectivity indices')\n</code></pre>"},{"location":"examples/figure_02_simple_stimuli_responses/#d","title":"d","text":"<pre><code>from flyvision.analysis.flash_responses import (\n    flash_response_index,\n    fri_correlation_to_known,\n)\nfrom flyvision.analysis.moving_bar_responses import (\n    direction_selectivity_index,\n    dsi_correlation_to_known,\n    correlation_to_known_tuning_curves,\n    preferred_direction,\n    angular_distance_to_known,\n)\n</code></pre> <pre><code>with ensemble.ratio(best=0.2):\n    print(ensemble.names)\n    fris = flash_response_index(ensemble.flash_responses(), radius=6)\n    fri_corr = fri_correlation_to_known(fris)\n</code></pre> <pre><code>['flow/0000/000', 'flow/0000/001', 'flow/0000/002', 'flow/0000/003', 'flow/0000/004', 'flow/0000/005', 'flow/0000/006', 'flow/0000/007', 'flow/0000/008', 'flow/0000/009']\n</code></pre> <pre><code>with ensemble.ratio(best=0.2):\n    stims_and_resps_moving_edges = ensemble.movingedge_responses()\n\n    # TODO: fix this, does not come out as expected\n    dsi_corr = dsi_correlation_to_known(\n        direction_selectivity_index(stims_and_resps_moving_edges)\n    ).median(\"intensity\")\n\n    tuning_corrs = correlation_to_known_tuning_curves(stims_and_resps_moving_edges)\n    t4_corrs = tuning_corrs.custom.where(cell_type=[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], intensity=1).median(\"neuron\").squeeze()\n    t5_corrs = tuning_corrs.custom.where(cell_type=[\"T5a\", \"T5b\", \"T5c\", \"T5d\"], intensity=0).median(\"neuron\").squeeze()\n</code></pre> <pre><code># TODO: fix this, does not come out as expected\npds = preferred_direction(stims_and_resps_moving_edges)\npd_distances = angular_distance_to_known(pds)\n</code></pre> <pre><code>from flyvision.plots.plots import violin_groups\n\nfig, ax, *_ = violin_groups(\n    np.stack([fri_corr.squeeze(), t4_corrs.values, t5_corrs.values,  dsi_corr.values, ], axis=0)[:, None, :],\n    [\"FRI\", \"T4 tuning\", \"T5 tuning\", \"DSI\"],\n    ylabel=\"correlation\",\n    figsize=(1.8, 1.5),\n    ylim=(-1, 1),\n    colors=[\n        plt.get_cmap(\"Dark2\")(0.125),\n        plt.get_cmap(\"Dark2\")(0),\n        plt.get_cmap(\"Dark2\")(0.25),\n        plt.get_cmap(\"Dark2\")(0.375),\n    ],\n    color_by=\"experiments\",\n    scatter_edge_color=\"gray\",\n    scatter_radius=5,\n    violin_alpha=0.8,\n)\n</code></pre> <pre><code>fig, ax, *_ = violin_groups(\n    pd_distances.values.flatten()[None, None, :],\n    [\"PD distance\"],\n    ylabel=\"angular distance\",\n    figsize=(1.8, 1.5),\n    ylim=(-1, 1),\n    colors=[\n        plt.get_cmap(\"Dark2\")(0.5),\n    ],\n    color_by=\"experiments\",\n    scatter_edge_color=\"gray\",\n    scatter_radius=5,\n    violin_alpha=0.8,\n)\nax.set_ylim(-0.1, np.pi + 0.1)\n</code></pre> <pre><code>(-0.1, 3.241592653589793)\n</code></pre>"},{"location":"examples/figure_03_naturalistic_stimuli_responses/","title":"Figure 3","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n\nfrom flyvision import EnsembleView\n</code></pre> <pre><code>ensemble = EnsembleView(\"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-09-28 04:19:39] ensemble:138 Loaded 50 networks.\n</code></pre>"},{"location":"examples/figure_03_naturalistic_stimuli_responses/#a","title":"a","text":"<pre><code>task_error = ensemble.task_error()\n</code></pre> <pre><code>embedding_and_clustering = ensemble.clustering(\"T4c\")\n</code></pre> <pre><code>[2024-09-28 04:19:42] clustering:640 Loaded T4c embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n</code></pre> <pre><code>embeddingplot = embedding_and_clustering.plot(task_error=task_error.values, colors=task_error.colors)\n</code></pre>"},{"location":"examples/figure_03_naturalistic_stimuli_responses/#b","title":"b","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom flyvision.analysis.clustering import check_markers\nfrom flyvision.utils.activity_utils import CellTypeArray\nfrom flyvision.plots import plt_utils \nfrom flyvision.plots.plt_utils import get_marker, add_cluster_marker\nfrom flyvision.plots import plots\nfrom flyvision.datasets import MovingEdge\nfrom flyvision.analysis.moving_bar_responses import MovingEdgeResponseView, plot_angular_tuning\nfrom flyvision.utils.groundtruth_utils import tuning_curves\n</code></pre> <pre><code>cluster_indices = ensemble.cluster_indices(\"T4c\")\n</code></pre> <pre><code>r = ensemble.movingedge_responses()\nr['responses'] /= np.abs(r['responses']).max(dim=('frame', 'sample'))\n</code></pre> <pre><code>cluster_indices = ensemble.cluster_indices(\"T4c\")\n</code></pre> <pre><code>colors = ensemble.task_error().colors\n</code></pre> <pre><code>fig, axes = plt.subplots(\n    1, len(cluster_indices), subplot_kw={\"projection\": \"polar\"}, figsize=[2, 1]\n)\nfor cluster_id, indices in cluster_indices.items():\n    plot_angular_tuning(\n        r.sel(network_id=indices),\n        \"T4c\",\n        intensity=1,\n        colors=colors[indices],\n        zorder=ensemble.zorder()[indices],\n        groundtruth=True if cluster_id == 0 else False,\n        fig=fig,\n        ax=axes[cluster_id],\n    )\n    add_cluster_marker(fig, axes[cluster_id], marker=get_marker(cluster_id))\n</code></pre>"},{"location":"examples/figure_03_naturalistic_stimuli_responses/#e","title":"e","text":"<pre><code>for cluster_id, indices in cluster_indices.items():\n    with ensemble.select_items(indices):\n        fig, ax = ensemble.flash_response_index(cell_types=[\"Mi1\", \"Tm3\", \"Mi4\", \"Mi9\", \"CT1(M10)\"],\n                                                figsize=[1, 1])\n</code></pre> <pre><code>[2024-09-28 04:29:58] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/000', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 102bbcd0dbfd7bfa6847ec1a64bd245a)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:29:58] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses/102bbcd0dbfd7bfa6847ec1a64bd245a/output.h5\n[2024-09-28 04:29:58] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/001', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 01bc24ee52f66d92df6dda7a54fbb512)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:29:58] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses/01bc24ee52f66d92df6dda7a54fbb512/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:29:59] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/002', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 1be5fe2784c35f3799f9c52e4c1f4ab1)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:29:59] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/002/__cache__/flyvision/analysis/stimulus_responses/compute_responses/1be5fe2784c35f3799f9c52e4c1f4ab1/output.h5\n[2024-09-28 04:29:59] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/003', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 3a32cdc078ada6ec77ef312d81a5a3d3)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:29:59] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/003/__cache__/flyvision/analysis/stimulus_responses/compute_responses/3a32cdc078ada6ec77ef312d81a5a3d3/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:29:59] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/006', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 22e55668eb1321c0343e492d14827f15)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:29:59] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/006/__cache__/flyvision/analysis/stimulus_responses/compute_responses/22e55668eb1321c0343e492d14827f15/output.h5\n[2024-09-28 04:29:59] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/007', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 37749baa331d7b1fe7d6cb50f19136e2)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:29:59] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/007/__cache__/flyvision/analysis/stimulus_responses/compute_responses/37749baa331d7b1fe7d6cb50f19136e2/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:29:59] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/009', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash bb93e66c28a9572b3f9a66ec21c1a8fb)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:29:59] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/009/__cache__/flyvision/analysis/stimulus_responses/compute_responses/bb93e66c28a9572b3f9a66ec21c1a8fb/output.h5\n[2024-09-28 04:29:59] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/011/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/011', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/011/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 9a6457c1d9d4757b5c8d72581fe2c4a6)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/011/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:29:59] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/011/__cache__/flyvision/analysis/stimulus_responses/compute_responses/9a6457c1d9d4757b5c8d72581fe2c4a6/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:29:59] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/012/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/012', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/012/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 2b81eec90842579ef5cf5fc368ee5fef)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/012/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:29:59] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/012/__cache__/flyvision/analysis/stimulus_responses/compute_responses/2b81eec90842579ef5cf5fc368ee5fef/output.h5\n[2024-09-28 04:30:00] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/013/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/013', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/013/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 0be4cfd5ec972f5ecb5e3d5c1fc3fef8)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/013/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:00] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/013/__cache__/flyvision/analysis/stimulus_responses/compute_responses/0be4cfd5ec972f5ecb5e3d5c1fc3fef8/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:00] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/014/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/014', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/014/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 78f41007e53b1d6503476220d9dd4db9)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/014/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:00] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/014/__cache__/flyvision/analysis/stimulus_responses/compute_responses/78f41007e53b1d6503476220d9dd4db9/output.h5\n[2024-09-28 04:30:00] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/016/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/016', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/016/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 55046ad197d2c798dff879afc6a8dc2f)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/016/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:00] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/016/__cache__/flyvision/analysis/stimulus_responses/compute_responses/55046ad197d2c798dff879afc6a8dc2f/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:00] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/017/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/017', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/017/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 1ed79aec45a0a6fbdb1f2916e5b3ab37)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/017/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:00] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/017/__cache__/flyvision/analysis/stimulus_responses/compute_responses/1ed79aec45a0a6fbdb1f2916e5b3ab37/output.h5\n[2024-09-28 04:30:00] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/018/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/018', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/018/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash fdfe90bb92c33852b686cc05968bc0ee)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/018/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:00] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/018/__cache__/flyvision/analysis/stimulus_responses/compute_responses/fdfe90bb92c33852b686cc05968bc0ee/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:00] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/019/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/019', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/019/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 2ecb8848e11c25e962824a63b4845af0)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/019/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:00] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/019/__cache__/flyvision/analysis/stimulus_responses/compute_responses/2ecb8848e11c25e962824a63b4845af0/output.h5\n[2024-09-28 04:30:00] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/020/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/020', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/020/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash f20b34d2152c35a3d4a89cf78e990ed5)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/020/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:00] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/020/__cache__/flyvision/analysis/stimulus_responses/compute_responses/f20b34d2152c35a3d4a89cf78e990ed5/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:00] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/021/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/021', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/021/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 360d0bc7deb1d81f2ab3f5356583f315)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/021/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:00] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/021/__cache__/flyvision/analysis/stimulus_responses/compute_responses/360d0bc7deb1d81f2ab3f5356583f315/output.h5\n[2024-09-28 04:30:01] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/022/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/022', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/022/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash ae08c1dba87ee4799be3030b4c5aad27)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/022/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:01] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/022/__cache__/flyvision/analysis/stimulus_responses/compute_responses/ae08c1dba87ee4799be3030b4c5aad27/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:01] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/023/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/023', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/023/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 27dc64e2a8b3b41db36b500aa5e52a96)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/023/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:01] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/023/__cache__/flyvision/analysis/stimulus_responses/compute_responses/27dc64e2a8b3b41db36b500aa5e52a96/output.h5\n[2024-09-28 04:30:01] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/024/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/024', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/024/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 6d8f016a87d7e080d3edfd7bb0a7898f)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/024/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:01] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/024/__cache__/flyvision/analysis/stimulus_responses/compute_responses/6d8f016a87d7e080d3edfd7bb0a7898f/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:01] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/027/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/027', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/027/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash fb032b83a94391508f0254a2f2f872c2)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/027/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:01] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/027/__cache__/flyvision/analysis/stimulus_responses/compute_responses/fb032b83a94391508f0254a2f2f872c2/output.h5\n[2024-09-28 04:30:01] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/029/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/029', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/029/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash e84bb56decd6a3f09a23bd2cae2f5506)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/029/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:01] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/029/__cache__/flyvision/analysis/stimulus_responses/compute_responses/e84bb56decd6a3f09a23bd2cae2f5506/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:01] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/030/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/030', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/030/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash c4e18ac3fee1bd1be999fb76dce2de5b)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/030/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:01] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/030/__cache__/flyvision/analysis/stimulus_responses/compute_responses/c4e18ac3fee1bd1be999fb76dce2de5b/output.h5\n[2024-09-28 04:30:01] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/031/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/031', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/031/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash e45ab1c2f5e3e64ddce642cf3e497ee2)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/031/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:01] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/031/__cache__/flyvision/analysis/stimulus_responses/compute_responses/e45ab1c2f5e3e64ddce642cf3e497ee2/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:02] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/035/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/035', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/035/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash b7a4bfa4d3087222643fab31b62f51fe)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/035/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:02] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/035/__cache__/flyvision/analysis/stimulus_responses/compute_responses/b7a4bfa4d3087222643fab31b62f51fe/output.h5\n[2024-09-28 04:30:02] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/036/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/036', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/036/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash de3691d1258fd5a1635a52271dec143b)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/036/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:02] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/036/__cache__/flyvision/analysis/stimulus_responses/compute_responses/de3691d1258fd5a1635a52271dec143b/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:02] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/037/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/037', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/037/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash f6d87334dddf4b5055f783c1bd4a918f)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/037/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:02] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/037/__cache__/flyvision/analysis/stimulus_responses/compute_responses/f6d87334dddf4b5055f783c1bd4a918f/output.h5\n[2024-09-28 04:30:02] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/042/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/042', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/042/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 57d59f63bb56aa8899f2a0c061c04b8d)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/042/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:02] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/042/__cache__/flyvision/analysis/stimulus_responses/compute_responses/57d59f63bb56aa8899f2a0c061c04b8d/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:02] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/044/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/044', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/044/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 8ec6a78ed981b7f3927a8b525b371192)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/044/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:02] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/044/__cache__/flyvision/analysis/stimulus_responses/compute_responses/8ec6a78ed981b7f3927a8b525b371192/output.h5\n[2024-09-28 04:30:02] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/047/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/047', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/047/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 100134dba58e8ff8df01b926651d8cc1)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/047/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:02] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/047/__cache__/flyvision/analysis/stimulus_responses/compute_responses/100134dba58e8ff8df01b926651d8cc1/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:02] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/048/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/048', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/048/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 969ef58fdb1292ee59fd0b9c97ed99c4)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/048/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:02] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/048/__cache__/flyvision/analysis/stimulus_responses/compute_responses/969ef58fdb1292ee59fd0b9c97ed99c4/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:04] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/004', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 73395eed18b129d61ea168228b6dcbce)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:04] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/004/__cache__/flyvision/analysis/stimulus_responses/compute_responses/73395eed18b129d61ea168228b6dcbce/output.h5\n[2024-09-28 04:30:04] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/005', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 78e98f930ff18637efa20e1d548d3a8c)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:04] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/005/__cache__/flyvision/analysis/stimulus_responses/compute_responses/78e98f930ff18637efa20e1d548d3a8c/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:04] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/026/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/026', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/026/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash c987788d6c25740a69e7ec1a679ff258)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/026/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:04] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/026/__cache__/flyvision/analysis/stimulus_responses/compute_responses/c987788d6c25740a69e7ec1a679ff258/output.h5\n[2024-09-28 04:30:05] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/033/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/033', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/033/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 26df16b1c43ef99adf6817123c0c8218)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/033/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:05] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/033/__cache__/flyvision/analysis/stimulus_responses/compute_responses/26df16b1c43ef99adf6817123c0c8218/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:05] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/038/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/038', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/038/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash c21fa6c75abbb1492269f408de9df256)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/038/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:05] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/038/__cache__/flyvision/analysis/stimulus_responses/compute_responses/c21fa6c75abbb1492269f408de9df256/output.h5\n[2024-09-28 04:30:05] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/040/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/040', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/040/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 0d3fcc066332bc7dd4678d04b6b4af61)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/040/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:05] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/040/__cache__/flyvision/analysis/stimulus_responses/compute_responses/0d3fcc066332bc7dd4678d04b6b4af61/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:05] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/043/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/043', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/043/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 4af2ad30b7fabf3fdb6ed9e1b9176480)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/043/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:05] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/043/__cache__/flyvision/analysis/stimulus_responses/compute_responses/4af2ad30b7fabf3fdb6ed9e1b9176480/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:06] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/008', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 23d0249da454f978d09c5205e8b0136e)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:06] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/008/__cache__/flyvision/analysis/stimulus_responses/compute_responses/23d0249da454f978d09c5205e8b0136e/output.h5\n[2024-09-28 04:30:06] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/010/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/010', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/010/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash a9576a365d53c7f625f018b285fdc5b6)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/010/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:06] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/010/__cache__/flyvision/analysis/stimulus_responses/compute_responses/a9576a365d53c7f625f018b285fdc5b6/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:06] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/015/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/015', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/015/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 47e8f5d6314ae3e74978ca0c4eb4ca3e)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/015/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:06] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/015/__cache__/flyvision/analysis/stimulus_responses/compute_responses/47e8f5d6314ae3e74978ca0c4eb4ca3e/output.h5\n[2024-09-28 04:30:06] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/025/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/025', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/025/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 1aadf43eef81276244c6817a58eacb4d)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/025/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:06] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/025/__cache__/flyvision/analysis/stimulus_responses/compute_responses/1aadf43eef81276244c6817a58eacb4d/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:06] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/028/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/028', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/028/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 03f1ffa516a4c51d7ac3ef725c377377)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/028/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:06] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/028/__cache__/flyvision/analysis/stimulus_responses/compute_responses/03f1ffa516a4c51d7ac3ef725c377377/output.h5\n[2024-09-28 04:30:06] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/032/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/032', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/032/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash b4d629a0b5686c66d2386c4805b2737b)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/032/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:06] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/032/__cache__/flyvision/analysis/stimulus_responses/compute_responses/b4d629a0b5686c66d2386c4805b2737b/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:07] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/034/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/034', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/034/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 7676dffb17edcbb69828b60827d4e4a1)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/034/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:07] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/034/__cache__/flyvision/analysis/stimulus_responses/compute_responses/7676dffb17edcbb69828b60827d4e4a1/output.h5\n[2024-09-28 04:30:07] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/039/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/039', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/039/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 70698f9b9a7eed88297f1d5d2a055e42)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/039/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:07] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/039/__cache__/flyvision/analysis/stimulus_responses/compute_responses/70698f9b9a7eed88297f1d5d2a055e42/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:07] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/041/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/041', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/041/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 17090a11c0b9256830b8b7d83cd153ef)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/041/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:07] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/041/__cache__/flyvision/analysis/stimulus_responses/compute_responses/17090a11c0b9256830b8b7d83cd153ef/output.h5\n[2024-09-28 04:30:07] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/045/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/045', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/045/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash c1804d08f4c39bdbc0db962817c1d1c0)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/045/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:07] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/045/__cache__/flyvision/analysis/stimulus_responses/compute_responses/c1804d08f4c39bdbc0db962817c1d1c0/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n\n\n[2024-09-28 04:30:07] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/046/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/046', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/046/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash 2a16de239bc0d1c84e0e34668cb060fa)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/046/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:07] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/046/__cache__/flyvision/analysis/stimulus_responses/compute_responses/2a16de239bc0d1c84e0e34668cb060fa/output.h5\n[2024-09-28 04:30:07] logger:83 [MemorizedFunc(func=&lt;function compute_responses at 0x7f521be851f0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/049/__cache__)]: \n                        Querying compute_responses with signature\n                        compute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}, name='flow/0000/049', checkpoint=PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/049/chkpts/chkpt_00000'), recover_fn=&lt;function recover_network at 0x7f5212dd2ee0&gt;, network=None), \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n4, 1.0, 0.0).\n\n                        (argument hash dfcaf12160e6417247e694d35b314425)\n\n                        The store location is /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/049/__cache__/flyvision/analysis/stimulus_responses/compute_responses.\n\n[2024-09-28 04:30:07] xarray_joblib_backend:582 Loading Dataset from NetCDF at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/049/__cache__/flyvision/analysis/stimulus_responses/compute_responses/dfcaf12160e6417247e694d35b314425/output.h5\n\n\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n___________________________________compute_responses cache loaded - 0.0s, 0.0min\n</code></pre>"},{"location":"examples/figure_04_mechanisms/","title":"Figure 4","text":""},{"location":"examples/figure_04_mechanisms/#a","title":"a","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom flyvision import EnsembleView\nfrom flyvision.analysis.clustering import check_markers\nfrom flyvision.analysis.moving_bar_responses import MovingEdgeResponseView\nfrom flyvision.datasets import MovingEdge\nfrom flyvision.plots import plots, plt_utils\nfrom flyvision.utils.activity_utils import CellTypeArray\nfrom flyvision.utils.groundtruth_utils import tuning_curves\n</code></pre> <pre><code>ensemble = EnsembleView(\"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-09-28 05:21:16] ensemble:138 Loaded 50 networks.\n</code></pre> <pre><code>stims_and_resps = ensemble.movingedge_responses()\n</code></pre> <pre><code>stims_and_resps['responses'] /= (norm := ensemble.responses_norm(rectified=True))\n</code></pre> <pre><code># retrieve cluster indices for averaging across best clusters\ncell_types = [\n    \"L1\",\n    \"L2\",\n    \"L3\",\n    \"L4\",\n    \"L5\",\n    \"Mi1\",\n    \"Tm3\",\n    \"Mi4\",\n    \"Mi9\",\n    \"CT1(M10)\",\n    \"T4a\",\n    \"T4b\",\n    \"T4c\",\n    \"T4d\",\n    \"T5a\",\n    \"T5b\",\n    \"T5c\",\n    \"T5d\",\n    \"Tm1\",\n    \"Tm2\",\n    \"Tm4\",\n    \"Tm9\",\n    \"CT1(Lo1)\",\n    \"TmY3\",\n]\ncluster_indices = {}\nfor cell_type in cell_types:\n    if cell_type not in cluster_indices:\n        cluster_indices[cell_type] = ensemble.cluster_indices(cell_type)\n</code></pre> <pre><code>[2024-09-28 05:21:39] clustering:640 Loaded L1 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n\n\n[2024-09-28 05:21:40] clustering:640 Loaded L2 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:40] clustering:640 Loaded L3 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:40] clustering:640 Loaded L4 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:42] clustering:640 Loaded L5 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:42] clustering:640 Loaded Mi1 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:42] clustering:640 Loaded Tm3 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:44] clustering:640 Loaded Mi4 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:44] clustering:640 Loaded Mi9 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:44] clustering:640 Loaded CT1(M10) embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:45] clustering:640 Loaded T4a embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:45] clustering:640 Loaded T4b embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:45] clustering:640 Loaded T4c embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:47] clustering:640 Loaded T4d embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:47] clustering:640 Loaded T5a embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:47] clustering:640 Loaded T5b embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:49] clustering:640 Loaded T5c embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:49] clustering:640 Loaded T5d embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:49] clustering:640 Loaded Tm1 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:50] clustering:640 Loaded Tm2 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:50] clustering:640 Loaded Tm4 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:50] clustering:640 Loaded Tm9 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:52] clustering:640 Loaded CT1(Lo1) embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n[2024-09-28 05:21:52] clustering:640 Loaded TmY3 embedding and clustering from /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/umap_and_clustering.\n</code></pre> <pre><code>from flyvision.analysis.moving_bar_responses import plot_angular_tuning\n</code></pre> <pre><code># plot the tuning across the best clusters\nfig, axes, _ = plots.plt_utils.get_axis_grid(\n    range(4),\n    projection=\"polar\",\n    aspect_ratio=4,\n    figsize=[2.95, 0.83],\n    wspace=0.25,\n)\nfor i, cell_type in enumerate([\"T4a\", \"T4b\", \"T4c\", \"T4d\"]):\n    plot_angular_tuning(\n        stims_and_resps.sel(network_id=cluster_indices[cell_type][0]),\n        cell_type=cell_type,\n        intensity=1,\n        fig=fig,\n        ax=axes[i],\n        groundtruth=True,\n        groundtruth_linewidth=1.0,\n        average_models=True,\n        model_dim=2,\n        zorder=100\n    )\n    axes[i].set_xlabel(cell_type)\n</code></pre> <pre><code>fig, axes, _ = plots.plt_utils.get_axis_grid(\n    range(4),\n    projection=\"polar\",\n    aspect_ratio=4,\n    figsize=[2.95, 0.83],\n    wspace=0.25,\n)\nfor i, cell_type in enumerate([\"T5a\", \"T5b\", \"T5c\", \"T5d\"]):\n    plot_angular_tuning(\n        stims_and_resps.sel(network_id=cluster_indices[cell_type][0]),\n        cell_type=cell_type,\n        intensity=0,\n        fig=fig,\n        ax=axes[i],\n        groundtruth=True,\n        groundtruth_linewidth=1.0,\n        average_models=True,\n        model_dim=2,\n        zorder=100\n    )\n    axes[i].set_xlabel(cell_type)\n</code></pre>"},{"location":"examples/figure_04_mechanisms/#b","title":"b","text":"<pre><code>from datamate import namespacify\n\nfrom flyvision.analysis.moving_edge_currents import CellTypeArray, MovingEdgeCurrentView\nfrom flyvision.datasets import MovingEdge\n</code></pre> <pre><code>target_types = [\"T4c\"]\n</code></pre> <pre><code>dataset = MovingEdge(\n        widths=[80],\n        offsets=[-10, 11],\n        intensities=[0, 1],\n        speeds=[19],\n        height=80,\n        bar_loc_horizontal=0.0,\n        shuffle_offsets=False,\n        post_pad_mode=\"continue\",\n        t_pre=1.0,\n        t_post=1.0,\n        dt=1 / 200,\n        angles=[0, 45, 90, 180, 225, 270],\n)\n</code></pre> <pre><code>cell_type = \"T4c\"\nsubdir = f\"movingedge_responses/{ensemble[0].checkpoints.current_chkpt_key}/currents\"\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nAttributeError                            Traceback (most recent call last)\n\nInput In [25], in &lt;cell line: 2&gt;()\n      1 cell_type = \"T4c\"\n----&gt; 2 subdir = f\"movingedge_responses/{ensemble[0].checkpoints.current_chkpt_key}/currents\"\n\n\nAttributeError: 'Checkpoints' object has no attribute 'current_chkpt_key'\n</code></pre> <pre><code>current_views = {}\n</code></pre> <pre><code>norm = CellTypeArray(ensemble.responses_norm(rectified=False), \n                     ensemble[0].connectome)\n</code></pre> <pre><code>for target_type in target_types:\n    if target_type not in current_views:\n        current_views[target_type] = MovingEdgeCurrentView(\n            ensemble, target_type, subdir, dataset.arg_df\n        )\n    view = current_views[target_type]\n</code></pre> <pre><code>view.shape\n</code></pre> <pre><code>(49, 12, 485, 2)\n</code></pre> <pre><code>current_views[target_type] = view.divide_by_given_norm(norm)\n</code></pre> <pre><code>current_views[target_type].shape\n</code></pre> <pre><code>(49, 12, 485, 2)\n</code></pre> <pre><code>hide_source_types=\"auto\"\nhide_source_types_bins=7\nhide_source_types_cut_off_edge=1\nhide_source_types_mode=\"below_cut_off\"\n</code></pre> <pre><code>view.shape\n</code></pre> <pre><code>(49, 12, 485, 2)\n</code></pre> <pre><code>inputs = namespacify(\n    {\n        cell_type: dict(majors={}, minors={})\n        for cell_type in target_types\n    }\n)\n\nfor cell_type in target_types:\n    if cell_type not in current_views:\n        current_views[cell_type] = MovingEdgeCurrentView(\n            ensemble, cell_type, subdir, dataset.arg_df\n        )\n    view = current_views[cell_type]\n\n    inputs[cell_type].majors = view.model_selection(\n        cluster_indices[cell_type][0]\n    ).filter_source_types(\n        hide_source_types,\n        hide_source_types_bins,\n        hide_source_types_cut_off_edge,\n        \"below_cut_off\",\n    )\n    inputs[cell_type].minors = view.model_selection(\n        cluster_indices[cell_type][0]\n    ).filter_source_types(\n        hide_source_types,\n        hide_source_types_bins,\n        hide_source_types_cut_off_edge,\n        \"above_cut_off\",\n    )\n</code></pre> <pre><code>current_view = current_views[\"T4c\"]\n</code></pre> <pre><code>fig, ax = current_view.model_selection(cluster_indices[cell_type][0]).plot_response(\n    1, 90, t_end=1.0\n)\nxlim_responses = ax.get_xlim()\nax.set_ylabel(\"voltage (a.u.)\", fontsize=5)\nax.set_xlabel(\"time (s)\", fontsize=5)\n</code></pre> <pre><code>Text(0.5, 0, 'time (s)')\n</code></pre> <pre><code>fig, ax, legend_fig, legend_ax = current_view.model_selection(\n    cluster_indices[cell_type][0]\n).plot_temporal_contributions(\n    1,\n    90,\n    t_start=0,\n    t_end=1,\n    model_average=True,\n    legend=False,\n    sum_exc_inh=False,\n    only_sum=False,\n    max_figure_height_cm=3.3941,\n    panel_height_cm=3.3941,\n    max_figure_width_cm=4.0513,\n    panel_width_cm=4.0513,\n    hide_source_types=[\"T4a\", \"T4b\", \"T5c\", \"Mi10\", \"C3\"]\n)\nylim = ax.get_ylim()\nax.set_ylabel(\"current (a.u.)\", fontsize=5)\n</code></pre> <pre><code>Text(0, 0.5, 'current (a.u.)')\n</code></pre> <pre><code>fig, ax, _ = current_view.model_selection(\n    cluster_indices[cell_type][0]\n).plot_spatial_contribution_grid(\n    t_start=0,\n    t_end=1,\n)\n</code></pre>"},{"location":"examples/figure_04_mechanisms/#d","title":"d","text":"<pre><code>from datamate import Namespace\n\nfrom flyvision import utils\nfrom flyvision.utils import hex_utils\nfrom flyvision.datasets.dots import SpatialImpulses\nfrom flyvision.plots import plt_utils\nfrom flyvision.utils.activity_utils import StimulusResponseIndexer\n\nfrom flyvision.analysis.views import plot_strf\n</code></pre> <pre><code>ensemble = EnsembleView(\"flow/0000\", \"best\", \"validation\", \"epe\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-09-12 15:01:16] Loaded 50 networks.\n</code></pre> <pre><code>dt = 1/200\nsubdir = f\"spatial_impulses_responses/{ensemble[0].checkpoints.current_chkpt_key}\"\n</code></pre> <pre><code>config = Namespace(\n    impulse_durations=[0.005, 0.02],\n    max_extent=4,\n    dot_column_radius=0,\n    bg_intensity=0.5,\n    t_stim=2,\n    dt=dt,\n    n_ommatidia=721,\n    t_pre=1.0,\n    t_post=0,\n    intensity=1.0,\n    mode=\"impulse\",\n    device=\"cuda\",\n)\ndataset = SpatialImpulses(**config)\n</code></pre> <pre><code>arg_df = dataset.arg_df\narg_df[\"uv\"] = list([list(v) for v in zip(arg_df.u, arg_df.v)])\ncell_types = ensemble[0].connectome.unique_cell_types[:].astype(str)\n</code></pre> <pre><code>strf_view = StimulusResponseIndexer(arg_df, \n                                    CellTypeArray(None, cell_types=cell_types), \n                                    dataset.dt, \n                                    0,\n                                    stim_sample_dim=1,\n                                    temporal_dim=2)\n</code></pre> <pre><code># relevant stimuli arguments\nintensity = 1\nstim_arg_index = StimulusResponseIndexer.where_stim_args_index_static(dataset.arg_df, intensity=intensity).to_numpy()\n</code></pre> <pre><code># relevant time window\nt_start = 0\nt_end = 0.250\ntime = (\n    np.arange(\n        0,\n        ensemble[0]\n        .dir[subdir]\n        .network_states.nodes.activity_central.shape[1],\n        1,\n    )\n    * dataset.dt\n    - dataset.t_pre\n)\ntemporal_index = np.arange(len(time))[(time &gt;= t_start) &amp; (time &lt;= t_end)]\nstart_index = temporal_index.min()\nstop_index = temporal_index.max()\n</code></pre> <pre><code>strf_responses  = ensemble.stored_responses(\"spatial_impulses_responses\", \n                                            central=True, \n                                            slice=(stim_arg_index, \n                                                   slice(start_index, \n                                                         stop_index)))\n</code></pre> <pre><code>arg_df = dataset.arg_df.iloc[stim_arg_index]\narg_df.reset_index(drop=True, inplace=True)\n</code></pre> <pre><code>norm = ensemble.responses_norm()\n</code></pre> <pre><code># update ir view\nstrf_view = StimulusResponseIndexer(arg_df, \n                                    CellTypeArray(strf_responses, cell_types=cell_types), \n                                    dataset.dt, \n                                    0,\n                                    stim_sample_dim=1,\n                                    temporal_dim=2,\n                                    time=time[start_index:stop_index])\nstrf_view = strf_view.divide_by_given_array(norm[:], dims=(0, -1))\n</code></pre> <pre><code>from flyvision.utils.color_utils import flash_response_color_labels, adapt_color_alpha\nfrom flyvision.plots.figsize_utils import fit_panel_size\nfrom scipy.signal import find_peaks\n</code></pre> <pre><code>srf_cell_types = [\n    \"Mi1\", \"Tm3\", \"Mi4\", \"Mi9\", \"CT1(M10)\",\n    \"Tm1\", \"Tm2\", \"Tm4\", \"Tm9\", \"CT1(Lo1)\"\n             ]\n</code></pre> <pre><code>def strf_to_srf(x):\n    extr_index = find_peaks(np.abs(x[:, x.shape[1]//2]))[0]\n    if extr_index.any():\n        extr_index = extr_index[0]\n    else:\n        extr_index = 0\n    return x[extr_index].squeeze()\n</code></pre> <pre><code>mean_srfs = {}\nfor cell_type in srf_cell_types:\n    strfs = strf_view.where_stim_args(t_impulse=0.02)[cell_type][cluster_indices[cell_type][0]]\n    x = strfs[:].mean(axis=0).squeeze().T\n\n    # subtracting the spatial average at timepoint 0 after averaging to center\n    x -= x[0].mean(axis=0)\n    mean_srfs[cell_type] = strf_to_srf(x)\n</code></pre> <pre><code>cell_type = \"Mi9\"\nstrfs = strf_view.where_stim_args(t_impulse=0.02)[cell_type][cluster_indices[cell_type][0]]\nx = strfs[:].mean(axis=0).squeeze().T\n\n# subtracting the spatial average at timepoint 0 after averaging to center\nx -= x[0].mean(axis=0)\n</code></pre> <pre><code>nodes = ensemble[0].connectome.nodes.to_df()\n</code></pre> <pre><code>from flyvision.utils.hex_utils import hex_rows\nfrom flyvision.plots.plt_utils import ax_scatter\nfrom flyvision.plots.plots import hex_scatter\n\nx, y = hex_rows(2, 5)\nfig, axes, pos = ax_scatter(\n    x, y, figsize=[3.5, 2], hpad=0, wpad=0.1, wspace=-0.5, hspace=-0.4\n)\n\naxes = np.array(axes).reshape(2, 5)\n\nfor i, row in enumerate(np.array(srf_cell_types).reshape(2, 5)):\n    for j, cell_type in enumerate(row):\n        crange = np.max(np.abs(mean_srfs[cell_type]))\n        u, v = nodes[nodes.type==cell_type][[\"u\", \"v\"]].values.T\n        fig, ax, _ = hex_scatter(\n            dataset.dots.u,\n            dataset.dots.v,\n            mean_srfs[cell_type],\n            cmap=plt.cm.coolwarm,\n            vmin=-crange,\n            vmax=crange,\n            figsize=[3, 3],\n            cbar=False,\n            fig=fig,\n            ax=axes[1 - i, j],\n        )\n        ax.set_xlabel(cell_type, fontsize=6, labelpad=-10)\n\nfor ax in axes.flatten():\n    flash_response_color_labels(ax)\n</code></pre>"},{"location":"examples/figure_04_mechanisms/#e","title":"e","text":"<pre><code>from flyvision.datasets.dots import CentralImpulses\n</code></pre> <pre><code>config = Namespace(intensity=1, \n                   impulse_durations=[5e-3, 20e-3, 50e-3, 100e-3, 200e-3, 300e-3], \n                   dt=1 / 200, \n                   dot_column_radius=0,\n                   t_stim=2,\n                   n_ommatidia=721,\n                     t_pre=1.0,\n                        t_post=0,\n                        mode=\"impulse\",\n                        device=\"cuda\",\n)\ndataset = CentralImpulses(**config)\ndt = config.dt\n</code></pre> <pre><code>central_impulse_responses = ensemble.stored_responses(\"central_impulses_responses\", central=True)\n</code></pre> <pre><code>cir_view = StimulusResponseIndexer(\n    dataset.arg_df,\n    CellTypeArray(central_impulse_responses, connectome=ensemble.connectome),\n    dataset.dt,\n    dataset.t_pre,\n    stim_sample_dim=1,\n    temporal_dim=2,\n)\n</code></pre> <pre><code>norm = ensemble.responses_norm(rectified=False)\n</code></pre> <pre><code>trf_cell_types = np.array(\n    [\n        \"Mi1\",\n        \"Tm3\",\n        \"Mi4\",\n        \"Mi9\",\n        \"CT1(M10)\",\n        \"Tm1\",\n        \"Tm2\",\n        \"Tm4\",\n        \"Tm9\",\n        \"CT1(Lo1)\",\n        \"L1\",\n        \"L2\",\n        \"L3\",\n        \"L4\",\n        \"L5\",\n    ]\n).reshape(5, 3, order=\"F\")\n</code></pre> <pre><code>cir_view = (cir_view\n                .divide_by_given_array(norm[:], dims=(0, -1))\n                .between_seconds(-cir_view.dt, 1.0)\n           )\n</code></pre> <pre><code>from flyvision.plots.plt_utils import truncate_colormap\n</code></pre> <pre><code>durations = [0.02, 0.05, 0.1, 0.2, 0.3]\non_cmap = truncate_colormap(plt.cm.Blues_r, minval=0., maxval=0.4).resampled(len(durations))\noff_cmap = truncate_colormap(plt.cm.Blues_r, minval=0.5, maxval=0.9).resampled(len(durations))\ncmaps = {\n    1.: [on_cmap(i) for i in range(on_cmap.N)][::-1],\n    0: [off_cmap(i) for i in range(off_cmap.N)][::-1]\n}\n</code></pre> <pre><code>fig, axes = fit_panel_size(\n    5,\n    3,\n    max_figure_height_cm=5.35,\n    max_figure_width_cm=8,\n    panel_width_cm=8 / 3,\n    panel_height_cm=5.35 / 10,\n).axis_grid(wspace=0.6, hspace=0.0, as_matrix=True)\nfor i, row in enumerate(trf_cell_types):\n    for j, cell_type in enumerate(row):\n        ax = axes[i, j]\n        for q, duration in enumerate(durations[::-1]):\n            for intensity in [0, 1]:\n                color = cmaps[intensity][q] #plt.cm.Blues(256) if intensity == 1 else plt.cm.Blues(128)\n#                 linestyle = \"solid\" if intensity == 1 else \"dashed\"\n                zorder = 1 if intensity == 1 else 0\n                r = (\n                    cir_view.where_stim_args(t_impulse=duration, intensity=intensity)\n                    .cell_type(cell_type)[cluster_indices[cell_type][0]]\n                )\n                trf = r[:].squeeze().T\n                mean = trf.mean(axis=1)\n                # subtract baseline after model averaging to plot it centered\n                mean = mean - mean[[0]]\n                #         ci = np.quantile(trf, [0.25, 0.75], axis=1)\n                ax.plot(r.time, mean, linewidth=0.5, color=color, zorder=zorder)\n        ax.hlines(\n            mean[0],\n            r.time.min(),\n            r.time.max(),\n            linewidth=0.5,\n            color=\"0.5\",\n            zorder=-1,\n        )\n\n        plt_utils.rm_spines(ax)\n        ax.yaxis.set_label_position(\"right\")\n        ax.set_ylabel(\n            cell_type,\n            fontsize=6,\n            rotation=0,\n            ha=\"left\",\n            va=\"center\",\n            labelpad=0.1,\n        )\n        #         ylim = np.array)\n        ylim = np.array(ax.get_ylim())\n        ylim = (-max(abs(ylim)), max(abs(ylim)))\n        ax.set_ylim(ylim)\n\nfor ax in axes.flatten():\n    flash_response_color_labels(ax)\n</code></pre> <p>stimulus</p> <pre><code>import torch\n</code></pre> <pre><code># relevant time window\nt_start = -dataset.dt\nt_end = 1.0\ntime = (\n    np.arange(\n        0,\n        ensemble[0]\n        .dir[subdir]\n        .network_states.nodes.activity_central.shape[1],\n        1,\n    )\n    * dataset.dt\n    - dataset.t_pre\n)\ntemporal_index = np.arange(len(time))[(time &gt;= t_start) &amp; (time &lt;= t_end)]\nstart_index = temporal_index.min()\nstop_index = temporal_index.max()\n</code></pre> <pre><code>fig, axes = fit_panel_size(\n    5,\n    3,\n    max_figure_height_cm=5.35,\n    max_figure_width_cm=8,\n    panel_width_cm=8 / 3,\n    panel_height_cm=5.35 / 10,\n).axis_grid(wspace=0.6, hspace=0.0, as_matrix=True, unmask_n=1)\nax = axes[0, 0]\n# fig, ax = plt.subplots(figsize=[4, 4])\neps = 0.005\nfor j, duration in enumerate(durations[::-1]):\n    for intensity in [0, 1]:\n        color = cmaps[intensity][j]\n        #                 linestyle = \"solid\" if intensity == 1 else \"dashed\"\n        zorder = 1 if intensity == 1 else 0\n\n        index = cir_view.where_stim_args_index_static(\n            dataset.arg_df, intensity=intensity, t_impulse=duration, u=0, v=0\n        )\n        stim = dataset[index][0][start_index - 1 : stop_index, 721 // 2].cpu()\n        indices = torch.nonzero(torch.diff(stim))[:, 0]\n        for i, index in enumerate(indices):\n            ax.vlines(\n                time[index],\n                stim[index]+ (eps if intensity == 1 else -eps),\n                stim[index + 1]+ (eps if intensity == 1 else -eps),\n                linewidth=0.5,\n                color=color,\n                zorder=zorder,\n            )\n            try:\n                ax.hlines(\n                    stim[index + 1] + (eps if intensity == 1 else -eps),\n                    time[index],\n                    time[indices[i + 1]],\n                    linewidth=0.5,\n                    color=color,\n                    zorder=zorder,\n                )\n            except IndexError:\n                ax.hlines(\n                    stim[index + 1] + (eps if intensity == 1 else -eps),\n                    time[index],\n                    time[-1],\n                    linewidth=0.5,\n                    color=color,\n                    zorder=zorder,\n                )\n\nplt_utils.rm_spines(ax)\n\nylim = np.array(ax.get_ylim())\nylim = (-max(abs(ylim)), max(abs(ylim)))\nax.set_ylim(ylim)\n</code></pre> <pre><code>(-1.0554999949876218, 1.0554999949876218)\n</code></pre> <p></p> <pre><code>fig, axes = fit_panel_size(\n    5,\n    3,\n    max_figure_height_cm=5.35,\n    max_figure_width_cm=8,\n    panel_width_cm=8 / 3,\n    panel_height_cm=5.35 / 10,\n).axis_grid(wspace=0.6, hspace=0.0, as_matrix=True, unmask_n=1)\nax = axes[0, 0]\nfor j, duration in enumerate(durations[::-1]):\n    for intensity in [0, 1]:\n        color = cmaps[intensity][j]\n        #                 linestyle = \"solid\" if intensity == 1 else \"dashed\"\n        zorder = 1 if intensity == 1 else 0\n        index = cir_view.where_stim_args_index_static(\n            dataset.arg_df, intensity=intensity, t_impulse=duration, u=0, v=0\n        )\n        stim = dataset[index][0][start_index-1:stop_index, 721//2].cpu()\n        ax.plot(stim, linewidth=0.5, color=color, zorder=zorder)\nax.hlines(\n    0,\n    time.min(),\n    time.max(),\n    linewidth=0.5,\n    color=\"0.5\",\n    zorder=-1,\n)\n\nplt_utils.rm_spines(ax)\n\nylim = np.array(ax.get_ylim())\nylim = (-max(abs(ylim)), max(abs(ylim)))\nax.set_ylim(ylim)\n</code></pre> <pre><code>(-1.05, 1.05)\n</code></pre> <p></p>"},{"location":"examples/figure_04_mechanisms/#extended-data-fig-9","title":"Extended Data Fig. 9","text":""},{"location":"examples/figure_04_mechanisms/#t4c","title":"T4c","text":"<pre><code>strfs = strf_view.where_stim_args(t_impulse=0.02)[\"T4c\"][cluster_indices[\"T4c\"][0]]\n</code></pre> <pre><code>x = strfs[:].mean(axis=0).squeeze().T\n\n#subtracting the spatio-temporal baseline after averaging\nx -= x[0].mean(axis=0)\n</code></pre> <pre><code>fig, axes = plot_strf(strfs.time, x)\n</code></pre>"},{"location":"examples/figure_04_mechanisms/#t5c","title":"T5c","text":"<pre><code>strfs = strf_view.where_stim_args(t_impulse=0.02)[\"T5c\"][cluster_indices[\"T5c\"][0]]\n</code></pre> <pre><code>x = strfs[:].mean(axis=0).squeeze().T\n\n#subtracting the spatio-temporal baseline after averaging\nx -= x[0].mean(axis=0)\n</code></pre> <pre><code>fig, axes = plot_strf(strfs.time, x)\n</code></pre>"},{"location":"examples/figure_04_mechanisms/#f","title":"f","text":"<pre><code>from flyvision import NetworkView\nfrom flyvision.analysis.optimal_stimuli import plot_stim_response, OptimalStimulus, RegularizedOptimalStimulus\n</code></pre> <pre><code>def load_optstim(network_view, cell_type):\n    subdir = (\n        f\"naturalistic_stimuli_responses/{ensemble[0].checkpoints.current_chkpt_key}\"\n    )\n    dir = network_view.dir[subdir][\"optstims\"][cell_type]\n    optstim = OptimalStimulus(dir.stimulus[:], dir.response[:])\n    dir = network_view.dir[subdir][\"regularized_optstims\"][cell_type]\n    return RegularizedOptimalStimulus(\n        optstim,\n        dir.stimulus[:],\n        dir.response[:],\n        dir.central_predicted_activity[:],\n        dir.central_target_activity[:],\n        dir.losses[:],\n    )\n</code></pre> <pre><code>network_view = ensemble[0]\n</code></pre> <pre><code>optstims = load_optstim(network_view, \"T4c\")\n</code></pre> <pre><code>stim_resp_plot = plot_stim_response(\n    optstims.regularized_stimulus,\n    optstims.response,\n    1 / 100,\n    *network_view.get_uv(\"T4c\"),\n    figsize=[5, 1.6],\n    ylabel=None,\n    label_peak_response=False,\n)\n</code></pre> <pre><code>optstims = load_optstim(network_view, \"T5c\")\n</code></pre> <pre><code>stim_resp_plot = plot_stim_response(\n    optstims.regularized_stimulus,\n    optstims.response,\n    1 / 100,\n    *network_view.get_uv(\"T5c\"),\n    figsize=[5, 1.6],\n    ylabel=None,\n    label_peak_response=False,\n)\n</code></pre> <pre><code>\n</code></pre> <pre><code>\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/init/","title":"Init","text":"<pre><code>from flyvision.initialization import (\n    Parameter,\n    deepcopy_config,\n    RestingPotential,\n    TimeConstant,\n    SynapseCount,\n    SynapseCountScaling,\n    SynapseSign,\n)\nfrom flyvision.connectome import ConnectomeDir\nfrom datamate import Namespace\n</code></pre> <pre><code>import pandas as pd\nimport torch\n</code></pre> <pre><code>from flyvision import connectome_file\nfrom flyvision.initialization import symmetry_mask_for_edges\n</code></pre> <pre><code>def cast(x):\n    if np.issubdtype(x.dtype, np.dtype(\"S\")):\n        return x.astype(\"U\")\n    return x\n</code></pre> <pre><code>def get_scatter_indices(\n    dataframe, grouped_dataframe, groupby\n):\n    \"\"\"Returns the grouped dataframe and the reference indices for shared parameters.\n\n    Args:\n        dataframe (pd.DataFrame): dataframe of nodes or edges, can also\n                contain synapse counts and signs.\n        groupby (list): list of columns to group the dataframe by.\n        group (method): groupby method, e.g. first, mean, sum.\n\n    Returns:\n        pd.DataFrame: first entries per group.\n        tensor: indices for parameter sharing\n    \"\"\"\n    ungrouped_elements = zip(*[dataframe[k][:] for k in groupby])\n    grouped_elements = zip(*[grouped_dataframe[k][:] for k in groupby])\n    to_index = {k: i for i, k in enumerate(grouped_elements)}\n    return torch.tensor([to_index[k] for k in ungrouped_elements])\n</code></pre> <pre><code>from numbers import Number\n</code></pre> <pre><code>def byte_to_str(obj):\n    if isinstance(obj, np.ndarray):\n        if np.issubdtype(obj.dtype, np.dtype(\"S\")):\n            return obj.astype(\"U\")\n        return obj\n    if isinstance(obj, list):\n        obj = [byte_to_str(item) for item in obj]\n        return obj\n    elif isinstance(obj, tuple):\n        obj = tuple([byte_to_str(item) for item in obj])\n        return obj\n    elif isinstance(obj, bytes):\n        return obj.decode()\n    elif isinstance(obj, (str, Number)):\n        return obj\n    else:\n        raise TypeError\n</code></pre> <pre><code>def compare_param(param1, param2):\n    print(f\"comparing {param1}, {param2}\")\n    raw_v = (param1.raw_values == param2.raw_values).all()\n    print(f\"raw values {raw_v}, {param2.raw_values.shape}\")\n    ind = (param1.indices == param2.indices).all()\n    print(f\"indices {ind}, {param2.indices}\")\n    keys = byte_to_str(param1.keys) == byte_to_str(param2.keys)\n    print(f\"keys {keys}, {np.array(param2.keys).shape}\")\n    masks = all([\n        all([a[b].all(), a.sum() == len(b)])\n        for a, b in zip(param1.symmetry_masks, param2.symmetry_masks)\n    ])\n    print(f\"masks {masks}, {len(param2.symmetry_masks)}\")\n    if all([raw_v, ind, keys, masks]):\n        print(\"all passed\")\n        return True\n    return False\n</code></pre> <pre><code>from flyvision.initialization import InitialDistribution, symmetry_mask_for_nodes\n</code></pre> <pre><code>import numpy as np\n</code></pre> <pre><code>connectome = ConnectomeDir(dict(file=connectome_file, extent=15, n_syn_fill=1))\n</code></pre> <pre><code>from typing import List\nfrom numpy.typing import NDArray\n</code></pre> <pre><code>np.random.normal(size=[4, 4]).astype('|S64')\n</code></pre> <pre><code>array([[b'-0.9409330618360031', b'1.0359303347565043',\n        b'0.7579351187895884', b'1.4303009058439506'],\n       [b'1.6960079452744552', b'0.36587744106980996',\n        b'0.36973241134944446', b'-0.4087418488265296'],\n       [b'0.1919436271958159', b'-0.7850875645753341',\n        b'-0.6310774064104027', b'0.5065377202272231'],\n       [b'1.1692414813317535', b'1.041828059256901',\n        b'1.2154525911366734', b'-1.1017525548382592']], dtype='|S64')\n</code></pre> <pre><code>def atleast_column_vector(array):\n    array = np.array(array)\n    if array.ndim == 1:\n        return array.reshape(-1, 1)\n    return array\n\n\ndef matrix_mask_by_sub(sub_matrix, matrix) -&gt; NDArray[bool]:\n    \"\"\"Mask of rows in matrix that are contained in sub_matrix.\n\n    Args:\n        sub_matrix (array): shape (#rows1, #columns)\n        matrix (array): shape (#rows2, #columns)\n\n    Returns:\n        array: 1D boolean array of length #rows2\n\n    Note: #rows1 !&lt;= #rows2\n\n    Example:\n        sub_matrix = np.array([[1, 2, 3],\n                                [4, 3, 1]])\n        matrix = np.array([[3, 4, 1],\n                            [4, 3, 1],\n                            [1, 2, 3]])\n        matrix_mask_by_sub(sub_matrix, matrix)\n        array([False, True, True])\n\n    Typically, indexing a tensor with indices instead of booleans is\n    faster. Therefore, see also where_equal_rows.\n    \"\"\"\n    from functools import reduce\n\n    n_rows, n_columns = sub_matrix.shape\n    n_rows2 = matrix.shape[0]\n    if not n_rows &lt;= n_rows2:\n        raise ValueError\n    row_mask = []\n    for i in range(n_rows):\n        column_mask = []\n        for j in range(n_columns):\n            column_mask.append(sub_matrix[i, j] == matrix[:, j])\n        row_mask.append(reduce(np.logical_and, column_mask))\n    return reduce(np.logical_or, row_mask)\n\n\ndef where_equal_rows(matrix1, matrix2, as_mask=False, astype='|S64') -&gt; NDArray[int]:\n    \"\"\"Indices where matrix1 rows are in matrix2.\n\n    Example:\n        matrix1 = np.array([[1, 2, 3],\n                            [4, 3, 1]])\n        matrix2 = np.array([[3, 4, 1],\n                            [4, 3, 1],\n                            [1, 2, 3],\n                            [0, 0, 0]])\n        where_equal_rows(matrix1, matrix2)\n        array([2, 1])\n        matrix2[where_equal_rows(matrix1, matrix2)]\n        array([[1, 2, 3],\n               [4, 3, 1]])\n\n    See also: matrix_mask_by_sub.\n    \"\"\"\n    matrix1 = atleast_column_vector(matrix1)\n    matrix2 = atleast_column_vector(matrix2)\n    matrix1 = matrix1.astype(astype)\n    matrix2 = matrix2.astype(astype)\n\n    if as_mask:\n        return matrix_mask_by_sub(matrix1, matrix2)\n\n    n_rows1, n_cols1 = matrix1.shape\n    n_rows2, n_cols2 = matrix2.shape\n\n    if not n_rows1 &lt;= n_rows2:\n        raise ValueError(\"matrix1 must have less or\" \" equal as many rows as matrix2\")\n    if not n_cols1 == n_cols2:\n        raise ValueError(\"cannot compare matrices with different number of columns\")\n\n    where = []\n    rows = np.arange(matrix2.shape[0])\n    for row in matrix1:\n        equal_rows = (row == matrix2).all(axis=1)\n        for index in rows[equal_rows]:\n            where.append(index)\n    return np.array(where)\n\n\ndef symmetry_masks(symmetric, keys, as_mask=False) -&gt; List[torch.Tensor]:\n    \"\"\"One additional way to constrain network elements to have the same\n    parameter values.\n\n    Note, this method stores one mask per shared tuple of the size of the\n    parameter and should thus be used sparsely because its not very memory\n    friendly. The bulk part of parameter sharing is achieved through scatter\n    and gather operations.\n\n    Args:\n        symmetric: list of tuples of cell types that share parameters.\n        nodes: DataFrame containing 'cell_type' column.\n\n    Returns:\n        list of masks List[torch.BoolTensor]\n\n    Example:\n        symmetric = [[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], [\"T5a\", \"T5b\", \"T5c\", \"T5d\"]]\n        would return two masks, one to constrain all T4 subtypes to the same\n        parameter and another to constrain all T5 subtypes to the same parameter.\n    \"\"\"\n    if not symmetric:\n        return []\n    symmetry_masks = []  # type: List[torch.Tensor]\n    keys = atleast_column_vector(keys)\n    for i, identifiers in enumerate(symmetric):\n        identifiers = atleast_column_vector(identifiers)\n        # to allow identifiers like [None, \"A\", None, 0]\n        # for parameters that have multi-keys\n        columns = np.arange(identifiers.shape[1] + 1)[\n            np.where((identifiers != None).all(axis=0))\n        ]\n        try:\n            symmetry_masks.append(\n                torch.tensor(\n                    where_equal_rows(identifiers[:, columns],\n                                     keys[:, columns], as_mask=as_mask)\n                )\n            )\n        except Exception as e:\n            raise ValueError(\n                f\"{identifiers} cannot be a symmetry constraint\"\n                f\" for parameter with keys {keys}: {e}\"\n            ) from e\n    return symmetry_masks\n</code></pre>"},{"location":"examples/init/#restingpotential","title":"RestingPotential","text":"<pre><code>config = Namespace(\n                type=\"RestingPotential\",\n                groupby=[\"type\"],\n                initial_dist=\"Normal\",\n                mode=\"sample\",\n                requires_grad=True,\n                mean=0.5,\n                std=0.05,\n                penalize=Namespace(activity=True),\n                seed=0,\n    symmetric = [[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], [\"T5a\", \"T5b\", \"T5c\", \"T5d\"]]\n            )\n</code></pre> <pre><code>from flyvision.initialization import Parameter\n</code></pre> <pre><code>class RestingPotentialv2(Parameter):\n    \"\"\"Initialize resting potentials a.k.a. biases for cell types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeDir):\n        nodes_dir = connectome.nodes\n\n        nodes = pd.DataFrame(\n            {k: byte_to_str(nodes_dir[k][:]) for k in param_config.groupby}\n        )\n        grouped_nodes = nodes.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).first()\n\n        param_config[\"type\"] = grouped_nodes[\"type\"].values\n        param_config[\"mean\"] = np.repeat(param_config[\"mean\"], len(grouped_nodes))\n        param_config[\"std\"] = np.repeat(param_config[\"std\"], len(grouped_nodes))\n\n        self.parameter = InitialDistribution(param_config)\n        self.indices = get_scatter_indices(nodes, grouped_nodes, param_config.groupby)\n        self.keys = param_config[\"type\"].tolist()\n        self.symmetry_masks = symmetry_masks(\n            param_config.get(\"symmetric\", []), self.keys\n        )\n</code></pre> <pre><code>param = Parameter(config, connectome)\n</code></pre> <pre><code>np.array(param.keys)[param.symmetry_masks[0].cpu().numpy()]\n</code></pre> <pre><code>array(['T4a', 'T4b', 'T4c', 'T4d'], dtype='&lt;U8')\n</code></pre> <pre><code>config2 = Namespace(\n                type=\"RestingPotentialv2\",\n                groupby=[\"type\"],\n                initial_dist=\"Normal\",\n                mode=\"sample\",\n                requires_grad=True,\n                mean=0.5,\n                std=0.05,\n                penalize=Namespace(activity=True),\n                seed=0,\n    symmetric = [[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], [\"T5a\", \"T5b\", \"T5c\", \"T5d\"]]\n            )\n</code></pre> <pre><code>nodes = connectome.nodes.to_df()\n</code></pre> <pre><code>param2 = Parameter(config2, connectome)\n</code></pre> <pre><code>param.keys[0]\n</code></pre> <pre><code>'R1'\n</code></pre> <pre><code>param2.symmetry_masks\n</code></pre> <pre><code>[tensor([35, 36, 37, 38]), tensor([39, 40, 41, 42])]\n</code></pre> <pre><code>compare_param(param, param2)\n</code></pre> <pre><code>comparing RestingPotential(Namespace(\n  type = 'RestingPotential',\n  groupby = ['type'],\n  initial_dist = 'Normal',\n  mode = 'sample',\n  requires_grad = True,\n  mean = 0.5,\n  std = 0.05,\n  penalize = Namespace(activity=True),\n  seed = 0,\n  symmetric = [['T4a', 'T4b', 'T4c', 'T4d'], ['T5a', 'T5b', 'T5c', 'T5d']]\n), ConnectomeDir), RestingPotentialv2(Namespace(\n  type = 'RestingPotentialv2',\n  groupby = ['type'],\n  initial_dist = 'Normal',\n  mode = 'sample',\n  requires_grad = True,\n  mean = 0.5,\n  std = 0.05,\n  penalize = Namespace(activity=True),\n  seed = 0,\n  symmetric = [['T4a', 'T4b', 'T4c', 'T4d'], ['T5a', 'T5b', 'T5c', 'T5d']]\n), ConnectomeDir)\nraw values True, torch.Size([65])\nindices True, tensor([ 0,  0,  0,  ..., 64, 64, 64])\nkeys True, (65,)\nmasks True, 2\nall passed\n\n\n\n\n\nTrue\n</code></pre>"},{"location":"examples/init/#time-constants","title":"Time constants","text":"<pre><code>from flyvision.initialization import Parameter\n</code></pre> <pre><code>class TimeConstantv2(Parameter):\n    \"\"\"Initialize time constants for cell types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeDir):\n        nodes_dir = connectome.nodes\n\n        nodes = pd.DataFrame({k: byte_to_str(nodes_dir[k][:]) for k in param_config.groupby})\n        grouped_nodes = nodes.groupby(param_config.groupby, as_index=False, sort=False).first()\n\n        param_config[\"type\"] = grouped_nodes[\"type\"].values\n        param_config[\"value\"] = np.repeat(param_config[\"value\"], len(grouped_nodes))\n\n        self.indices = get_scatter_indices(nodes, grouped_nodes, param_config.groupby)\n        self.parameter = InitialDistribution(param_config)\n        self.keys = param_config[\"type\"].tolist()\n        self.symmetry_masks = symmetry_masks(\n            param_config.get(\"symmetric\", []), self.keys\n        )\n</code></pre> <pre><code>config1 = Namespace(\n                type=\"TimeConstant\",\n                groupby=[\"type\"],\n                initial_dist=\"Value\",\n                value=0.05,\n                requires_grad=True,\n        symmetric = [[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], [\"T5a\", \"T5b\", \"T5c\", \"T5d\"]]\n\n            )\n\nconfig2 = Namespace(\n                type=\"TimeConstantv2\",\n                groupby=[\"type\"],\n                initial_dist=\"Value\",\n                value=0.05,\n                requires_grad=True,\n        symmetric = [[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], [\"T5a\", \"T5b\", \"T5c\", \"T5d\"]]\n\n            )\n</code></pre> <pre><code>param = Parameter(config1, connectome)\n</code></pre> <pre><code>param2 = Parameter(config2, connectome)\n</code></pre> <pre><code>param2.symmetry_masks\n</code></pre> <pre><code>[tensor([35, 36, 37, 38]), tensor([39, 40, 41, 42])]\n</code></pre> <pre><code>compare_param(param, param2)\n</code></pre> <pre><code>comparing TimeConstant(Namespace(\n  type = 'TimeConstant',\n  groupby = ['type'],\n  initial_dist = 'Value',\n  value = 0.05,\n  requires_grad = True,\n  symmetric = [['T4a', 'T4b', 'T4c', 'T4d'], ['T5a', 'T5b', 'T5c', 'T5d']]\n), ConnectomeDir), TimeConstantv2(Namespace(\n  type = 'TimeConstantv2',\n  groupby = ['type'],\n  initial_dist = 'Value',\n  value = 0.05,\n  requires_grad = True,\n  symmetric = [['T4a', 'T4b', 'T4c', 'T4d'], ['T5a', 'T5b', 'T5c', 'T5d']]\n), ConnectomeDir)\nraw values True, torch.Size([65])\nindices True, tensor([ 0,  0,  0,  ..., 64, 64, 64])\nkeys True, (65,)\nmasks True, 2\nall passed\n\n\n\n\n\nTrue\n</code></pre>"},{"location":"examples/init/#synapsesign","title":"SynapseSign","text":"<pre><code>class SynapseSignv2(Parameter):\n    \"\"\"Initialize synapse signs for edge types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeDir) -&gt; None:\n        edges_dir = connectome.edges\n\n        edges = pd.DataFrame(\n            {k: byte_to_str(edges_dir[k][:]) for k in [*param_config.groupby, \"sign\"]}\n        )\n        grouped_edges = edges.groupby(param_config.groupby, as_index=False, sort=False).first()\n\n        param_config.source_type = grouped_edges.source_type.values\n        param_config.target_type = grouped_edges.target_type.values\n        param_config.value = grouped_edges.sign.values\n\n        self.indices = get_scatter_indices(edges, grouped_edges, param_config.groupby)\n        self.parameter = InitialDistribution(param_config)\n        self.keys = list(\n            zip(\n                param_config.source_type.tolist(),\n                param_config.target_type.tolist(),\n            )\n        )\n        self.symmetry_masks = symmetry_masks(\n            param_config.get(\"symmetric\", []), self.keys\n        )\n</code></pre> <pre><code>config = Namespace(\n    type=\"SynapseSign\",\n    initial_dist=\"Value\",\n    requires_grad=False,\n    groupby=[\"source_type\", \"target_type\"],\n    attributes=[\"sign\"],\n    symmetric=[[(\"R1\", \"L1\"), (\"R4\", \"L1\")]],\n)\n</code></pre> <pre><code>param = Parameter(config, connectome)\n</code></pre> <pre><code>param.symmetry_masks\n</code></pre> <pre><code>[]\n</code></pre> <pre><code>config2 = Namespace(\n                type=\"SynapseSignv2\",\n                initial_dist=\"Value\",\n                requires_grad=False,\n                groupby=[\"source_type\", \"target_type\"],\n                attributes=[\"sign\"],\n    symmetric=[[(\"R1\", \"L1\"),\n                (\"R4\", \"L1\")],\n              [(\"Mi9\", \"T4a\"),\n              (\"Mi9\", \"T4b\")]],\n            )\n</code></pre> <pre><code>param2 = Parameter(config2, connectome)\n</code></pre> <pre><code>compare_param(param, param2)\n</code></pre> <pre><code>comparing SynapseSign(Namespace(\n  type = 'SynapseSign',\n  initial_dist = 'Value',\n  requires_grad = False,\n  groupby = ['source_type', 'target_type'],\n  attributes = ['sign'],\n  symmetric = [[('R1', 'L1'), ('R4', 'L1')]]\n), ConnectomeDir), SynapseSignv2(Namespace(\n  type = 'SynapseSignv2',\n  initial_dist = 'Value',\n  requires_grad = False,\n  groupby = ['source_type', 'target_type'],\n  attributes = ['sign'],\n  symmetric = [[('R1', 'L1'), ('R4', 'L1')], [('Mi9', 'T4a'), ('Mi9', 'T4b')]]\n), ConnectomeDir)\nraw values True, torch.Size([604])\nindices True, tensor([  0,   0,   0,  ..., 603, 603, 603])\nkeys True, (604, 2)\nmasks True, 2\nall passed\n\n\n\n\n\nTrue\n</code></pre>"},{"location":"examples/init/#synapsecount","title":"SynapseCount","text":"<pre><code>class SynapseCountv2(Parameter):\n    \"\"\"Initialize synapse counts for edge types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeDir) -&gt; None:\n        mode = param_config.get(\"mode\", \"\")\n        if mode != \"mean\":\n            raise NotImplementedError(\n                f\"SynapseCount does not implement {mode}. Implement \"\n                \"a custom Parameter subclass.\"\n            )\n\n        edges_dir = connectome.edges\n\n        edges = pd.DataFrame(\n            {k: byte_to_str(edges_dir[k][:]) for k in [*param_config.groupby, \"n_syn\"]}\n        )\n        grouped_edges = edges.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).mean()\n\n        param_config.source_type = grouped_edges.source_type.values\n        param_config.target_type = grouped_edges.target_type.values\n        param_config.du = grouped_edges.du.values\n        param_config.dv = grouped_edges.dv.values\n\n        param_config.mode = \"mean\"\n        param_config.mean = np.log(grouped_edges.n_syn.values)\n\n        self.indices = get_scatter_indices(edges, grouped_edges, param_config.groupby)\n        self.parameter = InitialDistribution(param_config)\n        self.keys = list(\n            zip(\n                param_config.source_type.tolist(),\n                param_config.target_type.tolist(),\n                param_config.du.tolist(),\n                param_config.dv.tolist(),\n            )\n        )\n        self.symmetry_masks = symmetry_masks(\n            param_config.get(\"symmetric\", []), self.keys\n        )\n\n    def symmetry(self):\n        keys = np.array(self.keys)\n        return [keys[mask.cpu()] for mask in self.symmetry_masks]\n</code></pre> <pre><code>config = Namespace(\n                type=\"SynapseCount\",\n                initial_dist=\"Lognormal\",\n                mode=\"mean\",\n                requires_grad=False,\n                std=1.0,\n                groupby=[\"source_type\", \"target_type\", \"dv\", \"du\"],\n#         symmetric=[[(\"R1\", \"L1\"),\n#                 (\"R4\", \"L1\")],\n#               [(\"Mi9\", \"T4a\"),\n#               (\"Mi9\", \"T4b\")]],\n            )\n</code></pre> <pre><code>param = Parameter(config, connectome)\n</code></pre> <pre><code>config2 = Namespace(\n    type=\"SynapseCountv2\",\n    initial_dist=\"Lognormal\",\n    mode=\"mean\",\n    requires_grad=False,\n    std=1.0,\n    groupby=[\"source_type\", \"target_type\", \"du\", \"dv\"],\n    attributes=[\"n_syn\"],\n#     symmetric=[[(\"R1\", \"L1\"),\n#                 (\"R4\", \"L1\")],\n#               [(\"Mi9\", \"T4a\"),\n#               (\"Mi9\", \"T4b\")], \n#               [(None, None, 0, 0),\n#               (None, None, 0, 0)]],\n)\n</code></pre> <pre><code>config2 = Namespace(\n    type=\"SynapseCountv2\",\n    initial_dist=\"Lognormal\",\n    mode=\"mean\",\n    requires_grad=False,\n    std=1.0,\n    groupby=[\"source_type\", \"target_type\", \"dv\", \"du\"],\n    attributes=[\"n_syn\"],\n    symmetric=[\n        [(\"R2\",), (\"R3\",)],\n        [(\"R1\", \"L1\", 0), (\"R4\", \"L1\", 0)],\n        [(\"Mi9\", \"T4a\", 0, 0), (\"Mi9\", \"T4b\", 0, 0)],\n        [(\"Mi9\", \"T4a\", 0, 0, 1), (\"Mi9\", \"T4b\", 0, 0, 1)],\n    ],\n)\n</code></pre> <pre><code>param2 = Parameter(config2, connectome)\n</code></pre> <pre><code>compare_param(param, param2)\n</code></pre> <pre><code>comparing SynapseCount(Namespace(\n  type = 'SynapseCount',\n  initial_dist = 'Lognormal',\n  mode = 'mean',\n  requires_grad = False,\n  std = 1.0,\n  groupby = ['source_type', 'target_type', 'dv', 'du']\n), ConnectomeDir), SynapseCountv2(Namespace(\n  type = 'SynapseCountv2',\n  initial_dist = 'Lognormal',\n  mode = 'mean',\n  requires_grad = False,\n  std = 1.0,\n  groupby = ['source_type', 'target_type', 'du', 'dv'],\n  attributes = ['n_syn']\n), ConnectomeDir)\nraw values True, torch.Size([2355])\nindices True, tensor([   0,    0,    0,  ..., 2354, 2354, 2354])\nkeys True, (2355, 4)\nmasks True, 0\nall passed\n\n\n\n\n\nTrue\n</code></pre> <pre><code>param2.symmetry()\n</code></pre> <pre><code>[array([['R1', 'L1', '0', '0'],\n        ['R4', 'L1', '0', '0']], dtype='&lt;U21'),\n array([['Mi9', 'T4a', '-1', '0'],\n        ['Mi9', 'T4a', '0', '1'],\n        ['Mi9', 'T4a', '-1', '1'],\n        ['Mi9', 'T4a', '-1', '-1'],\n        ['Mi9', 'T4a', '0', '-1'],\n        ['Mi9', 'T4a', '0', '-2'],\n        ['Mi9', 'T4a', '1', '-2'],\n        ['Mi9', 'T4a', '1', '-1'],\n        ['Mi9', 'T4a', '0', '0'],\n        ['Mi9', 'T4a', '2', '2'],\n        ['Mi9', 'T4a', '-4', '0'],\n        ['Mi9', 'T4a', '-3', '0'],\n        ['Mi9', 'T4a', '-2', '-1'],\n        ['Mi9', 'T4a', '-2', '0'],\n        ['Mi9', 'T4a', '1', '0'],\n        ['Mi9', 'T4a', '1', '1'],\n        ['Mi9', 'T4b', '0', '1'],\n        ['Mi9', 'T4b', '-1', '1'],\n        ['Mi9', 'T4b', '-1', '2'],\n        ['Mi9', 'T4b', '0', '-1'],\n        ['Mi9', 'T4b', '0', '0']], dtype='&lt;U21'),\n array([['R1', 'L1', '0', '0'],\n        ['R1', 'L2', '0', '0'],\n        ['R1', 'L3', '0', '0'],\n        ...,\n        ['TmY18', 'TmY5a', '0', '0'],\n        ['TmY18', 'TmY15', '0', '0'],\n        ['TmY18', 'TmY18', '0', '0']], dtype='&lt;U21')]\n</code></pre>"},{"location":"examples/init/#synapsecountscaling","title":"SynapseCountScaling","text":"<pre><code>class SynapseCountScalingv2(Parameter):\n    \"\"\"Initialize synapse count scaling for edge types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeDir) -&gt; None:\n        edges_dir = connectome.edges\n\n        edges = pd.DataFrame(\n            {\n                k: byte_to_str(edges_dir[k][:])\n                for k in [*param_config.groupby, \"n_syn\"]\n            }\n        )\n        grouped_edges = edges.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).mean()\n\n        # to initialize synapse strengths with 1/&lt;N&gt;_rf\n        syn_strength = 1 / grouped_edges.n_syn.values  # 1/&lt;N&gt;_rf\n\n        # scale synapse strengths of chemical and electrical synapses\n        # individually\n        syn_strength[grouped_edges[grouped_edges.edge_type == \"chem\"].index] *= getattr(\n            param_config, \"scale_chem\", 0.01\n        )\n        syn_strength[grouped_edges[grouped_edges.edge_type == \"elec\"].index] *= getattr(\n            param_config, \"scale_elec\", 0.01\n        )\n\n        param_config.target_type = grouped_edges.target_type.values\n        param_config.source_type = grouped_edges.source_type.values\n        param_config.value = syn_strength\n\n        self.indices = get_scatter_indices(edges, grouped_edges, param_config.groupby)\n        self.parameter = InitialDistribution(param_config)\n        self.keys = list(\n            zip(\n                param_config.source_type.tolist(),\n                param_config.target_type.tolist(),\n            )\n        )\n        self.symmetry_masks = symmetry_masks(\n            param_config.get(\"symmetric\", []), self.keys\n        )\n</code></pre> <pre><code>config = Namespace(\n                type=\"SynapseCountScaling\",\n                initial_dist=\"Value\",\n                requires_grad=True,\n                scale_elec=0.01,\n                scale_chem=0.01,\n                clamp=\"non_negative\",\n                groupby=[\"source_type\", \"target_type\"],\n                attributes=[\"edge_type\", \"n_syn\"],\n            symmetric=[[(\"R1\", \"L1\"),\n                (\"R4\", \"L1\")],\n              [(\"Mi9\", \"T4a\"),\n              (\"Mi9\", \"T4b\")]],\n            )\n</code></pre> <pre><code>param = Parameter(config, connectome)\n</code></pre> <pre><code>config2 = Namespace(\n                type=\"SynapseCountScalingv2\",\n                initial_dist=\"Value\",\n                requires_grad=True,\n                scale_elec=0.01,\n                scale_chem=0.01,\n                clamp=\"non_negative\",\n                groupby=[\"source_type\", \"target_type\", \"edge_type\"],\n                attributes=[\"n_syn\"],\n            symmetric=[[(\"R1\", \"L1\"),\n                (\"R4\", \"L1\")],\n              [(\"Mi9\", \"T4a\"),\n              (\"Mi9\", \"T4b\")]],\n            )\n</code></pre> <pre><code>compare_param(param, param2)\n</code></pre> <pre><code>comparing SynapseCountScaling(Namespace(\n  type = 'SynapseCountScaling',\n  initial_dist = 'Value',\n  requires_grad = True,\n  scale_elec = 0.01,\n  scale_chem = 0.01,\n  clamp = 'non_negative',\n  groupby = ['source_type', 'target_type'],\n  attributes = ['edge_type', 'n_syn'],\n  symmetric = [[('R1', 'L1'), ('R4', 'L1')], [('Mi9', 'T4a'), ('Mi9', 'T4b')]]\n), ConnectomeDir), SynapseCountScalingv2(Namespace(\n  type = 'SynapseCountScalingv2',\n  initial_dist = 'Value',\n  requires_grad = True,\n  scale_elec = 0.01,\n  scale_chem = 0.01,\n  clamp = 'non_negative',\n  groupby = ['source_type', 'target_type', 'edge_type'],\n  attributes = ['n_syn'],\n  symmetric = [[('R1', 'L1'), ('R4', 'L1')], [('Mi9', 'T4a'), ('Mi9', 'T4b')]]\n), ConnectomeDir)\nraw values True, torch.Size([604])\nindices True, tensor([  0,   0,   0,  ..., 603, 603, 603])\nkeys True, (604, 2)\nmasks False, 2\n\n\n\n\n\nFalse\n</code></pre> <pre><code>from typing import Mapping\n</code></pre> <pre><code>def byte_to_str(obj):\n    \"\"\"Cast byte elements to string types.\n\n    Note, this function is recursive and will cast all byte elements in a nested\n    list or tuple.\n    \"\"\"\n    if isinstance(obj, Mapping):\n        return type(obj)({k: byte_to_str(v) for k, v in obj.items()})\n    elif isinstance(obj, np.ndarray):\n        if np.issubdtype(obj.dtype, np.dtype(\"S\")):\n            return obj.astype(\"U\")\n        return obj\n    elif isinstance(obj, list):\n        obj = [byte_to_str(item) for item in obj]\n        return obj\n    elif isinstance(obj, tuple):\n        obj = tuple([byte_to_str(item) for item in obj])\n        return obj\n    elif isinstance(obj, bytes):\n        return obj.decode()\n    elif isinstance(obj, (str, Number)):\n        return obj\n    else:\n        raise TypeError(f\"can't cast {obj} of type {type(obj)} to str\")\n</code></pre> <pre><code>a = Namespace(a=Namespace(a=Namespace(a=b\"a\")))\n</code></pre> <pre><code>a\n</code></pre> <pre><code>Namespace(a=Namespace(a=Namespace(a=b'a')))\n</code></pre> <pre><code>byte_to_str([[[[[(b\"a\", b\"b\")]]]]])\n</code></pre> <pre><code>[[[[[('a', 'b')]]]]]\n</code></pre> <pre><code>edges = connectome.edges.to_df()\n</code></pre> <pre><code>edges.groupby([\"source_type\", \"target_type\"], as_index=False, sort=False).mean([\"n_syn\"])\n</code></pre> source_type target_type source_u target_u n_syn du source_index dv source_v target_index target_v sign n_syn_certainty 0 R1 L1 0.000000 0.000000 40.000000 0.000000 360.000000 0.000000 0.000000 6128.000000 0.000000 -1.0 5.859477 1 R1 L2 0.000000 0.000000 46.000000 0.000000 360.000000 0.000000 0.000000 6849.000000 0.000000 -1.0 5.859477 2 R1 L3 0.000000 0.000000 11.000000 0.000000 360.000000 0.000000 0.000000 7570.000000 0.000000 -1.0 5.859477 3 R1 Am 0.000000 0.000000 36.000000 0.000000 360.000000 0.000000 0.000000 9979.000000 0.000000 -1.0 5.859477 4 R1 T1 0.000000 0.000000 2.000000 0.000000 360.000000 0.000000 0.000000 21515.000000 0.000000 -1.0 5.859477 ... ... ... ... ... ... ... ... ... ... ... ... ... ... 599 TmY18 T2 0.244507 -0.244507 2.364281 -0.489015 45313.822112 0.489015 -0.244507 22230.177888 0.244507 1.0 1.587606 600 TmY18 TmY5a -0.244507 0.244507 1.656361 0.489015 45302.177888 -0.489015 0.244507 40987.822112 -0.244507 1.0 5.517218 601 TmY18 TmY9 1.500000 -1.500000 1.000000 -3.000000 45344.787302 2.000000 -1.000000 41666.212698 1.000000 1.0 2.782612 602 TmY18 TmY15 -0.220461 0.220461 2.230947 0.440922 45302.296781 0.426213 -0.213107 44592.703219 0.213107 1.0 0.864511 603 TmY18 TmY18 0.000000 0.000000 1.292609 0.000000 45308.099109 -0.198219 0.099109 45307.900891 -0.099109 1.0 2.239571 <p>604 rows \u00d7 13 columns</p> <pre><code>edges.columns\n</code></pre> <pre><code>Index(['source_u', 'target_u', 'n_syn', 'du', 'source_type', 'target_type',\n       'edge_type', 'source_index', 'dv', 'source_v', 'target_index',\n       'target_v', 'sign', 'n_syn_certainty'],\n      dtype='object')\n</code></pre> <pre><code>edges\n</code></pre> source_u target_u n_syn du source_type target_type edge_type source_index dv source_v target_index target_v sign n_syn_certainty 0 -15 -15 40.0 0 R1 L1 chem 0 0 0 5768 0 -1.0 5.859477 1 -15 -15 40.0 0 R1 L1 chem 1 0 1 5769 1 -1.0 5.859477 2 -15 -15 40.0 0 R1 L1 chem 2 0 2 5770 2 -1.0 5.859477 3 -15 -15 40.0 0 R1 L1 chem 3 0 3 5771 3 -1.0 5.859477 4 -15 -15 40.0 0 R1 L1 chem 4 0 4 5772 4 -1.0 5.859477 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1513226 15 15 1.0 0 TmY18 TmY18 chem 45664 0 -4 45664 -4 1.0 2.239571 1513227 15 15 1.0 0 TmY18 TmY18 chem 45665 0 -3 45665 -3 1.0 2.239571 1513228 15 15 1.0 0 TmY18 TmY18 chem 45666 0 -2 45666 -2 1.0 2.239571 1513229 15 15 1.0 0 TmY18 TmY18 chem 45667 0 -1 45667 -1 1.0 2.239571 1513230 15 15 1.0 0 TmY18 TmY18 chem 45668 0 0 45668 0 1.0 2.239571 <p>1513231 rows \u00d7 14 columns</p> <pre><code>elements = [\"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"D\", \"E\"]\ngroups = [\"A\", \"B\", \"C\", \"D\", \"E\"]\nparameter = [1, 2, 3, 4, 5]\n# get_scatter_indices would return\nscatter_indices = [0, 0, 0, 1, 1, 2, 3, 3, 4]\nscattered_parameters = [parameter[idx] for idx in scatter_indices] \n</code></pre> <pre><code>scattered_parameters\n</code></pre> <pre><code>[1, 1, 1, 2, 2, 3, 4, 4, 5]\n</code></pre> <pre><code>param2.keys\n</code></pre> <pre><code>[('R1', 'L1'),\n ('R1', 'L2'),\n ('R1', 'L3'),\n ('R1', 'Am'),\n ('R1', 'T1'),\n ('R2', 'L1'),\n ('R2', 'L2'),\n ('R2', 'L3'),\n ('R2', 'Am'),\n ('R2', 'T1'),\n ('R3', 'L1'),\n ('R3', 'L2'),\n ('R3', 'L3'),\n ('R3', 'Am'),\n ('R3', 'T1'),\n ('R4', 'L1'),\n ('R4', 'L2'),\n ('R4', 'L3'),\n ('R4', 'Am'),\n ('R4', 'T1'),\n ('R5', 'L1'),\n ('R5', 'L2'),\n ('R5', 'L3'),\n ('R5', 'Am'),\n ('R5', 'T1'),\n ('R6', 'L1'),\n ('R6', 'L2'),\n ('R6', 'L3'),\n ('R6', 'Am'),\n ('R6', 'T1'),\n ('R7', 'R8'),\n ('R7', 'Mi9'),\n ('R7', 'Mi15'),\n ('R7', 'Tm5a'),\n ('R7', 'Tm5b'),\n ('R8', 'R7'),\n ('R8', 'L1'),\n ('R8', 'L3'),\n ('R8', 'Mi1'),\n ('R8', 'Mi4'),\n ('R8', 'Mi9'),\n ('R8', 'Mi15'),\n ('R8', 'Tm5c'),\n ('R8', 'Tm20'),\n ('L1', 'L5'),\n ('L1', 'Lawf2'),\n ('L1', 'C2'),\n ('L1', 'C3'),\n ('L1', 'Mi1'),\n ('L1', 'Tm3'),\n ('L2', 'R1'),\n ('L2', 'R2'),\n ('L2', 'L1'),\n ('L2', 'L4'),\n ('L2', 'L5'),\n ('L2', 'Lawf2'),\n ('L2', 'C3'),\n ('L2', 'Mi1'),\n ('L2', 'Mi4'),\n ('L2', 'Mi9'),\n ('L2', 'T1'),\n ('L2', 'Tm1'),\n ('L2', 'Tm2'),\n ('L2', 'Tm4'),\n ('L2', 'Tm20'),\n ('L2', 'TmY3'),\n ('L3', 'Lawf1'),\n ('L3', 'C3'),\n ('L3', 'Mi1'),\n ('L3', 'Mi2'),\n ('L3', 'Mi9'),\n ('L3', 'Mi13'),\n ('L3', 'Mi15'),\n ('L3', 'Tm3'),\n ('L3', 'Tm5Y'),\n ('L3', 'Tm5a'),\n ('L3', 'Tm5c'),\n ('L3', 'Tm9'),\n ('L3', 'Tm20'),\n ('L3', 'Tm28'),\n ('L3', 'TmY9'),\n ('L3', 'TmY10'),\n ('L4', 'R1'),\n ('L4', 'R2'),\n ('L4', 'R3'),\n ('L4', 'R4'),\n ('L4', 'R5'),\n ('L4', 'R6'),\n ('L4', 'L2'),\n ('L4', 'L3'),\n ('L4', 'L4'),\n ('L4', 'L5'),\n ('L4', 'Am'),\n ('L4', 'Mi9'),\n ('L4', 'T2'),\n ('L4', 'Tm2'),\n ('L4', 'Tm4'),\n ('L4', 'Tm9'),\n ('L4', 'TmY3'),\n ('L4', 'TmY13'),\n ('L5', 'L1'),\n ('L5', 'L2'),\n ('L5', 'L5'),\n ('L5', 'C2'),\n ('L5', 'C3'),\n ('L5', 'Mi1'),\n ('L5', 'Mi2'),\n ('L5', 'Mi4'),\n ('L5', 'Mi15'),\n ('L5', 'T1'),\n ('L5', 'T2'),\n ('L5', 'Tm3'),\n ('L5', 'Tm20'),\n ('L5', 'TmY3'),\n ('L5', 'TmY13'),\n ('L5', 'TmY14'),\n ('L5', 'TmY18'),\n ('Lawf1', 'Tm3'),\n ('Lawf2', 'L3'),\n ('Lawf2', 'Lawf2'),\n ('Lawf2', 'Am'),\n ('Am', 'R1'),\n ('Am', 'R2'),\n ('Am', 'R4'),\n ('Am', 'R5'),\n ('Am', 'L1'),\n ('Am', 'L2'),\n ('Am', 'L3'),\n ('Am', 'L4'),\n ('Am', 'C2'),\n ('Am', 'C3'),\n ('Am', 'T1'),\n ('C2', 'L1'),\n ('C2', 'L2'),\n ('C2', 'L3'),\n ('C2', 'L4'),\n ('C2', 'L5'),\n ('C2', 'Lawf2'),\n ('C2', 'Am'),\n ('C2', 'Mi1'),\n ('C2', 'T1'),\n ('C2', 'T2'),\n ('C2', 'T4a'),\n ('C2', 'Tm1'),\n ('C2', 'Tm9'),\n ('C2', 'TmY14'),\n ('C3', 'R3'),\n ('C3', 'L1'),\n ('C3', 'L2'),\n ('C3', 'L3'),\n ('C3', 'L5'),\n ('C3', 'Lawf2'),\n ('C3', 'Am'),\n ('C3', 'CT1(M10)'),\n ('C3', 'Mi1'),\n ('C3', 'Mi4'),\n ('C3', 'Mi9'),\n ('C3', 'T1'),\n ('C3', 'T2'),\n ('C3', 'T4a'),\n ('C3', 'T4b'),\n ('C3', 'T4c'),\n ('C3', 'T4d'),\n ('C3', 'Tm1'),\n ('C3', 'Tm2'),\n ('C3', 'Tm4'),\n ('C3', 'Tm9'),\n ('C3', 'Tm20'),\n ('CT1(Lo1)', 'T5a'),\n ('CT1(Lo1)', 'T5b'),\n ('CT1(Lo1)', 'T5c'),\n ('CT1(Lo1)', 'T5d'),\n ('CT1(Lo1)', 'Tm1'),\n ('CT1(Lo1)', 'Tm9'),\n ('CT1(M10)', 'C3'),\n ('CT1(M10)', 'Mi1'),\n ('CT1(M10)', 'T4a'),\n ('CT1(M10)', 'T4b'),\n ('CT1(M10)', 'T4c'),\n ('CT1(M10)', 'T4d'),\n ('Mi1', 'L1'),\n ('Mi1', 'L5'),\n ('Mi1', 'C2'),\n ('Mi1', 'C3'),\n ('Mi1', 'CT1(M10)'),\n ('Mi1', 'Mi2'),\n ('Mi1', 'Mi4'),\n ('Mi1', 'Mi9'),\n ('Mi1', 'Mi10'),\n ('Mi1', 'Mi12'),\n ('Mi1', 'Mi13'),\n ('Mi1', 'Mi14'),\n ('Mi1', 'Mi15'),\n ('Mi1', 'T2'),\n ('Mi1', 'T2a'),\n ('Mi1', 'T3'),\n ('Mi1', 'T4a'),\n ('Mi1', 'T4b'),\n ('Mi1', 'T4c'),\n ('Mi1', 'T4d'),\n ('Mi1', 'Tm1'),\n ('Mi1', 'Tm3'),\n ('Mi1', 'Tm20'),\n ('Mi1', 'TmY3'),\n ('Mi1', 'TmY9'),\n ('Mi1', 'TmY13'),\n ('Mi1', 'TmY14'),\n ('Mi1', 'TmY15'),\n ('Mi1', 'TmY18'),\n ('Mi2', 'Mi1'),\n ('Mi2', 'T2'),\n ('Mi2', 'T2a'),\n ('Mi2', 'T3'),\n ('Mi2', 'Tm1'),\n ('Mi2', 'TmY18'),\n ('Mi3', 'T2'),\n ('Mi3', 'Tm5b'),\n ('Mi4', 'L2'),\n ('Mi4', 'C3'),\n ('Mi4', 'Mi1'),\n ('Mi4', 'Mi4'),\n ('Mi4', 'Mi9'),\n ('Mi4', 'T1'),\n ('Mi4', 'T4a'),\n ('Mi4', 'T4b'),\n ('Mi4', 'T4c'),\n ('Mi4', 'T4d'),\n ('Mi4', 'Tm1'),\n ('Mi4', 'Tm2'),\n ('Mi4', 'Tm5Y'),\n ('Mi4', 'Tm5a'),\n ('Mi4', 'Tm5b'),\n ('Mi4', 'Tm5c'),\n ('Mi4', 'Tm9'),\n ('Mi4', 'Tm16'),\n ('Mi4', 'Tm20'),\n ('Mi4', 'Tm28'),\n ('Mi4', 'TmY3'),\n ('Mi4', 'TmY4'),\n ('Mi4', 'TmY5a'),\n ('Mi4', 'TmY10'),\n ('Mi4', 'TmY13'),\n ('Mi4', 'TmY15'),\n ('Mi4', 'TmY18'),\n ('Mi9', 'L3'),\n ('Mi9', 'Lawf1'),\n ('Mi9', 'C3'),\n ('Mi9', 'CT1(M10)'),\n ('Mi9', 'Mi1'),\n ('Mi9', 'Mi4'),\n ('Mi9', 'Mi10'),\n ('Mi9', 'Mi15'),\n ('Mi9', 'T2'),\n ('Mi9', 'T2a'),\n ('Mi9', 'T4a'),\n ('Mi9', 'T4b'),\n ('Mi9', 'T4c'),\n ('Mi9', 'T4d'),\n ('Mi9', 'Tm1'),\n ('Mi9', 'Tm2'),\n ('Mi9', 'Tm4'),\n ('Mi9', 'Tm5a'),\n ('Mi9', 'Tm5b'),\n ('Mi9', 'Tm16'),\n ('Mi9', 'TmY3'),\n ('Mi9', 'TmY4'),\n ('Mi9', 'TmY5a'),\n ('Mi9', 'TmY13'),\n ('Mi9', 'TmY18'),\n ('Mi10', 'Lawf1'),\n ('Mi10', 'Mi9'),\n ('Mi10', 'Mi14'),\n ('Mi10', 'T4a'),\n ('Mi10', 'T4b'),\n ('Mi10', 'T4c'),\n ('Mi10', 'T4d'),\n ('Mi10', 'Tm5b'),\n ('Mi10', 'TmY3'),\n ('Mi10', 'TmY5a'),\n ('Mi10', 'TmY14'),\n ('Mi12', 'Mi1'),\n ('Mi12', 'Mi9'),\n ('Mi12', 'Tm1'),\n ('Mi12', 'Tm2'),\n ('Mi12', 'Tm3'),\n ('Mi12', 'Tm4'),\n ('Mi13', 'L5'),\n ('Mi13', 'Mi1'),\n ('Mi13', 'T2'),\n ('Mi13', 'Tm1'),\n ('Mi13', 'Tm2'),\n ('Mi13', 'Tm3'),\n ('Mi13', 'Tm4'),\n ('Mi13', 'Tm9'),\n ('Mi14', 'Tm1'),\n ('Mi14', 'Tm4'),\n ('Mi14', 'TmY3'),\n ('Mi15', 'C3'),\n ('Mi15', 'Mi4'),\n ('Mi15', 'Mi10'),\n ('Mi15', 'Mi15'),\n ('Mi15', 'Tm5c'),\n ('T1', 'L2'),\n ('T1', 'L5'),\n ('T1', 'Tm20'),\n ('T2', 'Lawf2'),\n ('T2', 'Mi1'),\n ('T2', 'T2'),\n ('T2', 'Tm5c'),\n ('T2', 'TmY5a'),\n ('T2', 'TmY15'),\n ('T2a', 'Mi1'),\n ('T2a', 'T3'),\n ('T2a', 'Tm3'),\n ('T2a', 'Tm5Y'),\n ('T2a', 'Tm5b'),\n ('T2a', 'Tm28'),\n ('T2a', 'TmY4'),\n ('T2a', 'TmY5a'),\n ('T2a', 'TmY9'),\n ('T3', 'T2'),\n ('T3', 'T2a'),\n ('T3', 'Tm3'),\n ('T4a', 'C3'),\n ('T4a', 'CT1(M10)'),\n ('T4a', 'Mi9'),\n ('T4a', 'Mi12'),\n ('T4a', 'T4a'),\n ('T4a', 'T4c'),\n ('T4a', 'T5a'),\n ('T4a', 'TmY14'),\n ('T4a', 'TmY18'),\n ('T4b', 'CT1(M10)'),\n ('T4b', 'Mi9'),\n ('T4b', 'T4b'),\n ('T4b', 'T4c'),\n ('T4b', 'T5b'),\n ('T4b', 'TmY15'),\n ('T4c', 'CT1(M10)'),\n ('T4c', 'Mi9'),\n ('T4c', 'T4c'),\n ('T4c', 'T5c'),\n ('T4c', 'TmY4'),\n ('T4c', 'TmY14'),\n ('T4c', 'TmY15'),\n ('T4d', 'CT1(M10)'),\n ('T4d', 'T4a'),\n ('T4d', 'T4d'),\n ('T4d', 'T5d'),\n ('T4d', 'TmY4'),\n ('T4d', 'TmY15'),\n ('T5a', 'CT1(Lo1)'),\n ('T5a', 'T4a'),\n ('T5a', 'T5a'),\n ('T5a', 'T5b'),\n ('T5a', 'TmY9'),\n ('T5a', 'TmY14'),\n ('T5a', 'TmY15'),\n ('T5b', 'CT1(Lo1)'),\n ('T5b', 'T2'),\n ('T5b', 'T4b'),\n ('T5b', 'T5b'),\n ('T5b', 'T5d'),\n ('T5b', 'Tm2'),\n ('T5b', 'TmY14'),\n ('T5b', 'TmY15'),\n ('T5c', 'CT1(Lo1)'),\n ('T5c', 'T4c'),\n ('T5c', 'T5c'),\n ('T5c', 'Tm2'),\n ('T5c', 'TmY4'),\n ('T5c', 'TmY14'),\n ('T5c', 'TmY15'),\n ('T5d', 'CT1(Lo1)'),\n ('T5d', 'T2'),\n ('T5d', 'T4d'),\n ('T5d', 'T5d'),\n ('T5d', 'TmY4'),\n ('T5d', 'TmY15'),\n ('Tm1', 'L2'),\n ('Tm1', 'L5'),\n ('Tm1', 'Lawf2'),\n ('Tm1', 'C3'),\n ('Tm1', 'CT1(Lo1)'),\n ('Tm1', 'Mi1'),\n ('Tm1', 'Mi2'),\n ('Tm1', 'Mi4'),\n ('Tm1', 'Mi9'),\n ('Tm1', 'Mi12'),\n ('Tm1', 'Mi13'),\n ('Tm1', 'T1'),\n ('Tm1', 'T2'),\n ('Tm1', 'T2a'),\n ('Tm1', 'T3'),\n ('Tm1', 'T5a'),\n ('Tm1', 'T5b'),\n ('Tm1', 'T5c'),\n ('Tm1', 'T5d'),\n ('Tm1', 'Tm2'),\n ('Tm1', 'Tm4'),\n ('Tm1', 'Tm5Y'),\n ('Tm1', 'Tm9'),\n ('Tm1', 'Tm20'),\n ('Tm1', 'Tm28'),\n ('Tm1', 'TmY4'),\n ('Tm1', 'TmY9'),\n ('Tm1', 'TmY15'),\n ('Tm2', 'L2'),\n ('Tm2', 'L5'),\n ('Tm2', 'Lawf1'),\n ('Tm2', 'C3'),\n ('Tm2', 'CT1(Lo1)'),\n ('Tm2', 'Mi4'),\n ('Tm2', 'Mi9'),\n ('Tm2', 'T2'),\n ('Tm2', 'T2a'),\n ('Tm2', 'T5a'),\n ('Tm2', 'T5b'),\n ('Tm2', 'T5c'),\n ('Tm2', 'T5d'),\n ('Tm2', 'Tm1'),\n ('Tm2', 'Tm4'),\n ('Tm2', 'Tm9'),\n ('Tm2', 'Tm28'),\n ('Tm2', 'TmY3'),\n ('Tm2', 'TmY4'),\n ('Tm2', 'TmY13'),\n ('Tm2', 'TmY15'),\n ('Tm2', 'TmY18'),\n ('Tm3', 'L1'),\n ('Tm3', 'Lawf1'),\n ('Tm3', 'Lawf2'),\n ('Tm3', 'Mi1'),\n ('Tm3', 'Mi11'),\n ('Tm3', 'Mi14'),\n ('Tm3', 'T2'),\n ('Tm3', 'T2a'),\n ('Tm3', 'T3'),\n ('Tm3', 'T4a'),\n ('Tm3', 'T4b'),\n ('Tm3', 'T4c'),\n ('Tm3', 'T4d'),\n ('Tm3', 'Tm3'),\n ('Tm3', 'Tm4'),\n ('Tm3', 'Tm30'),\n ('Tm3', 'TmY3'),\n ('Tm3', 'TmY5a'),\n ('Tm3', 'TmY13'),\n ('Tm3', 'TmY14'),\n ('Tm3', 'TmY15'),\n ('Tm3', 'TmY18'),\n ('Tm4', 'Lawf2'),\n ('Tm4', 'C3'),\n ('Tm4', 'Mi4'),\n ('Tm4', 'Mi10'),\n ('Tm4', 'Mi12'),\n ('Tm4', 'Mi13'),\n ('Tm4', 'Mi14'),\n ('Tm4', 'T2'),\n ('Tm4', 'T2a'),\n ('Tm4', 'T3'),\n ('Tm4', 'T5a'),\n ('Tm4', 'T5b'),\n ('Tm4', 'T5c'),\n ('Tm4', 'T5d'),\n ('Tm4', 'Tm3'),\n ('Tm4', 'Tm4'),\n ('Tm4', 'TmY3'),\n ('Tm4', 'TmY4'),\n ('Tm4', 'TmY5a'),\n ('Tm4', 'TmY13'),\n ('Tm4', 'TmY14'),\n ('Tm4', 'TmY15'),\n ('Tm5Y', 'Tm5a'),\n ('Tm5Y', 'Tm5b'),\n ('Tm5Y', 'Tm20'),\n ('Tm5Y', 'TmY5a'),\n ('Tm5Y', 'TmY10'),\n ('Tm5a', 'Tm5a'),\n ('Tm5a', 'Tm5b'),\n ('Tm5b', 'Mi3'),\n ('Tm5b', 'Mi10'),\n ('Tm5b', 'Tm5a'),\n ('Tm5b', 'Tm5b'),\n ('Tm5b', 'Tm5c'),\n ('Tm5c', 'Mi4'),\n ('Tm5c', 'Mi15'),\n ('Tm5c', 'Tm5Y'),\n ('Tm5c', 'Tm5b'),\n ('Tm5c', 'Tm16'),\n ('Tm9', 'CT1(Lo1)'),\n ('Tm9', 'Mi9'),\n ('Tm9', 'T5a'),\n ('Tm9', 'T5b'),\n ('Tm9', 'T5c'),\n ('Tm9', 'T5d'),\n ('Tm9', 'Tm1'),\n ('Tm9', 'Tm2'),\n ('Tm9', 'Tm5Y'),\n ('Tm9', 'Tm28'),\n ('Tm9', 'TmY4'),\n ('Tm9', 'TmY9'),\n ('Tm9', 'TmY15'),\n ('Tm16', 'Lawf1'),\n ('Tm16', 'Lawf2'),\n ('Tm16', 'Mi9'),\n ('Tm16', 'T2'),\n ('Tm16', 'Tm1'),\n ('Tm16', 'Tm2'),\n ('Tm16', 'Tm4'),\n ('Tm16', 'Tm5Y'),\n ('Tm16', 'Tm5c'),\n ('Tm16', 'Tm9'),\n ('Tm16', 'TmY3'),\n ('Tm16', 'TmY5a'),\n ('Tm16', 'TmY10'),\n ('Tm16', 'TmY13'),\n ('Tm16', 'TmY14'),\n ('Tm20', 'Mi2'),\n ('Tm20', 'Mi9'),\n ('Tm20', 'Tm5Y'),\n ('Tm20', 'Tm9'),\n ('Tm20', 'Tm20'),\n ('Tm28', 'Tm5Y'),\n ('Tm28', 'TmY4'),\n ('Tm28', 'TmY9'),\n ('TmY3', 'T2'),\n ('TmY3', 'Tm4'),\n ('TmY3', 'TmY3'),\n ('TmY3', 'TmY4'),\n ('TmY3', 'TmY5a'),\n ('TmY3', 'TmY13'),\n ('TmY3', 'TmY14'),\n ('TmY3', 'TmY15'),\n ('TmY4', 'Mi3'),\n ('TmY4', 'Mi4'),\n ('TmY4', 'Mi13'),\n ('TmY4', 'T2'),\n ('TmY4', 'T5d'),\n ('TmY4', 'TmY4'),\n ('TmY4', 'TmY5a'),\n ('TmY4', 'TmY9'),\n ('TmY4', 'TmY14'),\n ('TmY5a', 'Mi2'),\n ('TmY5a', 'Mi3'),\n ('TmY5a', 'T2'),\n ('TmY5a', 'T2a'),\n ('TmY5a', 'Tm16'),\n ('TmY5a', 'TmY3'),\n ('TmY5a', 'TmY4'),\n ('TmY5a', 'TmY14'),\n ('TmY5a', 'TmY15'),\n ('TmY5a', 'TmY18'),\n ('TmY9', 'Mi13'),\n ('TmY9', 'TmY4'),\n ('TmY9', 'TmY9'),\n ('TmY10', 'Mi4'),\n ('TmY10', 'T2a'),\n ('TmY10', 'Tm5b'),\n ('TmY10', 'Tm5c'),\n ('TmY10', 'Tm9'),\n ('TmY10', 'Tm16'),\n ('TmY10', 'Tm20'),\n ('TmY10', 'Tm28'),\n ('TmY10', 'TmY4'),\n ('TmY10', 'TmY9'),\n ('TmY13', 'Mi4'),\n ('TmY13', 'T2'),\n ('TmY13', 'Tm5b'),\n ('TmY13', 'Tm16'),\n ('TmY13', 'TmY5a'),\n ('TmY14', 'C3'),\n ('TmY14', 'Mi12'),\n ('TmY14', 'Mi13'),\n ('TmY14', 'Tm9'),\n ('TmY14', 'Tm16'),\n ('TmY14', 'TmY4'),\n ('TmY15', 'Mi4'),\n ('TmY15', 'Mi9'),\n ('TmY15', 'T2'),\n ('TmY15', 'T2a'),\n ('TmY15', 'T4a'),\n ('TmY15', 'T4b'),\n ('TmY15', 'T4c'),\n ('TmY15', 'T4d'),\n ('TmY15', 'T5a'),\n ('TmY15', 'T5b'),\n ('TmY15', 'T5c'),\n ('TmY15', 'T5d'),\n ('TmY15', 'Tm1'),\n ('TmY15', 'Tm2'),\n ('TmY15', 'Tm3'),\n ('TmY15', 'Tm4'),\n ('TmY15', 'Tm9'),\n ('TmY15', 'TmY3'),\n ('TmY15', 'TmY14'),\n ('TmY15', 'TmY18'),\n ('TmY18', 'Mi4'),\n ('TmY18', 'Mi10'),\n ('TmY18', 'T2'),\n ('TmY18', 'TmY5a'),\n ('TmY18', 'TmY9'),\n ('TmY18', 'TmY15'),\n ('TmY18', 'TmY18')]\n</code></pre> <pre><code>from flyvision.utils.tensor_utils import matrix_mask_by_sub, where_equal_rows\n</code></pre> <pre><code>keys = np.array(param2.keys)\n</code></pre> <pre><code>keys[matrix_mask_by_sub(np.array([(\"R4\", \"Am\"), (\"Mi9\", \"T4a\")]), np.array(param2.keys))]\n</code></pre> <pre><code>array([['R4', 'Am'],\n       ['Mi9', 'T4a']], dtype='&lt;U8')\n</code></pre> <pre><code>matrix_mask_by_sub(np.array([(\"R4\", \"Am\"), (\"Mi9\", \"T4a\")]), np.array(param2.keys))\n</code></pre> <pre><code>array([False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False])\n</code></pre> <pre><code>np.array([(\"R4\", \"Am\"), (\"Mi9\", \"T4a\")]).shape\n</code></pre> <pre><code>(2, 2)\n</code></pre> <pre><code>np.array(param2.keys).shape\n</code></pre> <pre><code>(65,)\n</code></pre> <pre><code>np.array(param2.keys)[where_equal_rows(np.array([(\"R4\", \"Am\"), (\"Mi9\", \"T4a\")]), np.array(param2.keys))]\n</code></pre> <pre><code>array([['R4', 'Am'],\n       ['Mi9', 'T4a']], dtype='&lt;U8')\n</code></pre> <pre><code>where_equal_rows??\n</code></pre> <pre><code>edges.groupby([\"source_type\", \"target_type\"], sort=False, as_index=False, group_keys=[\"source_type\", \"target_type\"], observed=[\"source_type\", \"target_type\", \"edge_type\"]).mean([\"n_syn\"])\n</code></pre> source_type target_type source_u target_u n_syn du source_index dv source_v target_index target_v sign n_syn_certainty 0 R1 L1 0.000000 0.000000 40.000000 0.000000 360.000000 0.000000 0.000000 6128.000000 0.000000 -1.0 5.859477 1 R1 L2 0.000000 0.000000 46.000000 0.000000 360.000000 0.000000 0.000000 6849.000000 0.000000 -1.0 5.859477 2 R1 L3 0.000000 0.000000 11.000000 0.000000 360.000000 0.000000 0.000000 7570.000000 0.000000 -1.0 5.859477 3 R1 Am 0.000000 0.000000 36.000000 0.000000 360.000000 0.000000 0.000000 9979.000000 0.000000 -1.0 5.859477 4 R1 T1 0.000000 0.000000 2.000000 0.000000 360.000000 0.000000 0.000000 21515.000000 0.000000 -1.0 5.859477 ... ... ... ... ... ... ... ... ... ... ... ... ... ... 599 TmY18 T2 0.244507 -0.244507 2.364281 -0.489015 45313.822112 0.489015 -0.244507 22230.177888 0.244507 1.0 1.587606 600 TmY18 TmY5a -0.244507 0.244507 1.656361 0.489015 45302.177888 -0.489015 0.244507 40987.822112 -0.244507 1.0 5.517218 601 TmY18 TmY9 1.500000 -1.500000 1.000000 -3.000000 45344.787302 2.000000 -1.000000 41666.212698 1.000000 1.0 2.782612 602 TmY18 TmY15 -0.220461 0.220461 2.230947 0.440922 45302.296781 0.426213 -0.213107 44592.703219 0.213107 1.0 0.864511 603 TmY18 TmY18 0.000000 0.000000 1.292609 0.000000 45308.099109 -0.198219 0.099109 45307.900891 -0.099109 1.0 2.239571 <p>604 rows \u00d7 13 columns</p> <pre><code>Parameter.__subclasses__()\n</code></pre> <pre><code>[flyvision.initialization.RestingPotential,\n flyvision.initialization.TimeConstant,\n flyvision.initialization.SynapseSign,\n flyvision.initialization.SynapseCount,\n flyvision.initialization.SynapseCountScaling,\n __main__.RestingPotentialv2,\n __main__.RestingPotentialv2,\n __main__.RestingPotentialv2,\n __main__.TimeConstantv2,\n __main__.TimeConstantv2,\n __main__.TimeConstantv2]\n</code></pre> <pre><code>class A:\n    pass\n</code></pre> <pre><code>class B(A):\n    pass\n</code></pre> <pre><code>for cls in Parameter.__subclasses__():\n    cls.__bases__ = (B,)\n</code></pre> <pre><code>Parameter.__subclasses__()\n</code></pre> <pre><code>[]\n</code></pre> <pre><code>from flyvision import results_dir\nfrom flyvision.ensemble import EnsembleView, EnsembleDir\n</code></pre> <pre><code>ensemble = EnsembleDir(results_dir / \"opticflow/000\")\n</code></pre> <pre><code>old_config = Namespace(\n  type = 'NetworkDir',\n  network = Namespace(\n    connectome = Namespace(\n      type = 'ConnectomeDir',\n      file = 'fib25-fib19_v2.2.json',\n      extent = 15,\n      n_syn_fill = 1\n    ),\n    dynamics = Namespace(\n      type = 'PPNeuronIGRSynapses',\n      activation = Namespace(type='relu')\n    ),\n    node_config = Namespace(\n      bias = Namespace(\n        type = 'RestingPotential',\n        keys = ['type'],\n        initial_dist = 'Normal',\n        mode = 'sample',\n        requires_grad = True,\n        mean = 0.5,\n        std = 0.05,\n        penalize = Namespace(activity=True),\n        seed = 0\n      ),\n      time_const = Namespace(\n        type = 'TimeConstant',\n        keys = ['type'],\n        initial_dist = 'Value',\n        value = 0.05,\n        requires_grad = True\n      )\n    ),\n    edge_config = Namespace(\n      sign = Namespace(\n        type = 'SynapseSign',\n        initial_dist = 'Value',\n        requires_grad = False\n      ),\n      syn_count = Namespace(\n        type = 'SynapseCount',\n        initial_dist = 'Lognormal',\n        mode = 'mean',\n        requires_grad = False,\n        std = 1.0\n      ),\n      syn_strength = Namespace(\n        type = 'SynapseCountScaling',\n        initial_dist = 'Value',\n        requires_grad = True,\n        scale_elec = 0.01,\n        scale_chem = 0.01,\n        clamp = 'non_negative'\n      )\n    )\n  ),\n  task_dataset = Namespace(\n    type = 'MultiTaskSintel',\n    tasks = ['flow'],\n    n_frames = 19,\n    dt_sampling = True,\n    interpolate = True,\n    boxfilter = Namespace(extent=15, kernel_size=13),\n    vertical_splits = 3,\n    p_flip = 0.5,\n    p_rot = 0.5,\n    contrast = 0.2,\n    brightness = 0.1,\n    noise = 0.08,\n    cache = 'gpu',\n    gamma = 1.0\n  ),\n  task_decoder = Namespace(\n    type = 'DecoderGAVP',\n    shape = [8, 2],\n    kernel_size = 5,\n    const_weight = 0.001,\n    n_out_features = None,\n    p_dropout = 0.5\n  ),\n  task_loss = Namespace(type='mean_root_norm')\n)\n</code></pre> <pre><code>new_config = Namespace(\n  type = 'NetworkDir',\n  network = Namespace(\n    connectome = Namespace(\n      type = 'ConnectomeDir',\n      file = 'fib25-fib19_v2.2.json',\n      extent = 15,\n      n_syn_fill = 1\n    ),\n    dynamics = Namespace(\n      type = 'PPNeuronIGRSynapses',\n      activation = Namespace(type='relu')\n    ),\n    node_config = Namespace(\n      bias = Namespace(\n        type = 'RestingPotential',\n        groupby=[\"type\"],\n        initial_dist = 'Normal',\n        mode = 'sample',\n        requires_grad = True,\n        mean = 0.5,\n        std = 0.05,\n        penalize = Namespace(activity=True),\n        seed = 0\n      ),\n      time_const = Namespace(\n        type = 'TimeConstant',\n        groupby=[\"type\"],\n        initial_dist = 'Value',\n        value = 0.05,\n        requires_grad = True\n      )\n    ),\n    edge_config = Namespace(\n      sign = Namespace(\n        type = 'SynapseSign',\n        initial_dist = 'Value',\n        requires_grad = False,\n        groupby=[\"source_type\", \"target_type\"],\n      ),\n      syn_count = Namespace(\n        type = 'SynapseCount',\n        initial_dist = 'Lognormal',\n        mode = 'mean',\n        requires_grad = False,\n        std = 1.0,\n        groupby=[\"source_type\", \"target_type\", \"du\", \"dv\"],\n      ),\n      syn_strength = Namespace(\n        type = 'SynapseCountScaling',\n        initial_dist = 'Value',\n        requires_grad = True,\n        scale_elec = 0.01,\n        scale_chem = 0.01,\n        clamp = 'non_negative',\n        groupby=[\"source_type\", \"target_type\", \"edge_type\"],\n      )\n    )\n  ),\n  task_dataset = Namespace(\n    type = 'MultiTaskSintel',\n    tasks = ['flow'],\n    n_frames = 19,\n    dt_sampling = True,\n    interpolate = True,\n    boxfilter = Namespace(extent=15, kernel_size=13),\n    vertical_splits = 3,\n    p_flip = 0.5,\n    p_rot = 0.5,\n    contrast = 0.2,\n    brightness = 0.1,\n    noise = 0.08,\n    cache = 'gpu',\n    gamma = 1.0\n  ),\n  task_decoder = Namespace(\n    type = 'DecoderGAVP',\n    shape = [8, 2],\n    kernel_size = 5,\n    const_weight = 0.001,\n    n_out_features = None,\n    p_dropout = 0.5\n  ),\n  task_loss = Namespace(type='norm')\n)\n</code></pre> <pre><code>config = None\nfor name, _dir in ensemble.items():\n    if name.isnumeric():\n        print(name)\n        if config is None:\n            config = _dir.config\n        assert _dir.config == config\n        _dir._override_config(new_config)\n</code></pre> <pre><code>0003\n0004\n0032\n0035\n0034\n0033\n0005\n0002\n0020\n0018\n0027\n0011\n0029\n0016\n0042\n0045\n0028\n0017\n0010\n0019\n0026\n0021\n0044\n0043\n0007\n0038\n0000\n0036\n0009\n0031\n0030\n0037\n0008\n0001\n0006\n0039\n0046\n0041\n0048\n0024\n0023\n0015\n0012\n0049\n0040\n0047\n0013\n0014\n0022\n0025\n\n\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n/var/folders/b1/s01d0fxj4r56mc22xx01vnd9c7405m/T/ipykernel_70259/2707961450.py:8: ConfigWarning: Overriding config. Diff is:Namespace(\n  passed = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type', 'edge_type']\"\n  ],\n  stored = [\n    \"\u2260network.edge_config.syn_strength.groupby: ['source_type', 'target_type']\"\n  ]\n)\n  _dir._override_config(new_config)\n</code></pre> <pre><code>_dir._override_config()\n</code></pre> <pre><code>0025/ - Last modified: March 23, 2023 11:22:29\n\u251c\u2500\u2500 _meta.yaml\n\u251c\u2500\u2500 best_chkpt\n\u2514\u2500\u2500 validation_loss.h5\n\ndisplaying: 1 directory, 3 files\n</code></pre> <pre><code>x = np.arange(10)\n</code></pre> <pre><code>x[slice(-1, -2, -1)]\n</code></pre> <pre><code>array([9])\n</code></pre> <pre><code>x.tolist()[slice(-1, -1, -1)]\n</code></pre> <pre><code>[]\n</code></pre> <pre><code>\n</code></pre> <pre><code>slice(-1, -2, -1)\n</code></pre> <pre><code>import wget\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nModuleNotFoundError                       Traceback (most recent call last)\n\nInput In [164], in &lt;cell line: 1&gt;()\n----&gt; 1 import wget\n\n\nModuleNotFoundError: No module named 'wget'\n</code></pre> <pre><code>import tqdm\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/xarrayjoblib/","title":"Xarrayjoblib","text":"<pre><code>import logging\nfrom pathlib import Path\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nimport xarray as xr\nfrom torch import nn\nfrom torch.nn import functional as nnf\n\nfrom flyvision import EnsembleView, NetworkView, results_dir\nfrom flyvision.analysis.stimulus_responses import (\n    central_impulses_responses,\n    flash_responses,\n    moving_bar_responses,\n    moving_edge_responses,\n    spatial_impulses_responses,\n)\nfrom flyvision.utils.cluster_utils import get_status\n\nmpl.rcParams[\"figure.dpi\"] = 300\n\n%load_ext autoreload\n%autoreload 2\n</code></pre> <pre><code>ensemble = EnsembleView(\"flow/9997\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-09-19 23:43:16] ensemble:133 Loaded 50 networks.\n</code></pre> <pre><code>cluster_indices = ensemble.cluster_indices(\"T4c\")\n</code></pre> <pre><code>[2024-09-19 23:43:25] network:251 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n[2024-09-19 23:43:25] chkpt_utils:72 Recovered network state.\n[2024-09-19 23:43:25] logger:80 [MemorizedFunc(func=&lt;function compute_responses at 0x7f2411e8f550&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/9997/000/__cache__)]: Clearing function cache identified by flyvision/analysis/stimulus_responses/compute_responses\n[2024-09-19 23:43:31] chkpt_utils:72 Recovered network state.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'form': 'value', 'requires_grad': False, 'initial_dist': 'Value', 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'dv', 'du'], 'penalize': {'function': 'weight_decay', 'kwargs': {'lambda': 0}}}, 'syn_strength': {'type': 'SynapseCountS..., \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['flow'],\n  'temporal_split': True}, \n4, 0.0, 2.0)\n\n\n[2024-09-19 23:43:36] network:748 Computing 2268 stimulus responses.\n\n\n\nBatch:   0%|          | 0/567 [00:00&lt;?, ?it/s]\n\n\nStore item /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/9997/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses/1b552fa7f56e5cec50d6641a98ee2d8e/output.zarr\n______________________________________________compute_responses - 263.9s, 4.4min\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'form': 'value', 'requires_grad': False, 'initial_dist': 'Value', 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'dv', 'du'], 'penalize': {'function': 'weight_decay', 'kwargs': {'lambda': 0}}}, 'syn_strength': {'type': 'SynapseCountS..., \n&lt;class 'flyvision.datasets.sintel.AugmentedSintel'&gt;, { 'boxfilter': {'extent': 15, 'kernel_size': 13},\n  'dt': 0.01,\n  'interpolate': False,\n  'tasks': ['flow'],\n  'temporal_split': True}, \n4, 0.0, 2.0)\n\n\n[2024-09-19 23:47:55] chkpt_utils:72 Recovered network state.\n[2024-09-19 23:47:59] network:748 Computing 2268 stimulus responses.\n\n\n\nBatch:   0%|          | 0/567 [00:00&lt;?, ?it/s]\n\n\n\n---------------------------------------------------------------------------\n\nKeyboardInterrupt                         Traceback (most recent call last)\n\nInput In [3], in &lt;cell line: 1&gt;()\n----&gt; 1 cluster_indices = ensemble.cluster_indices(\"T4c\")\n\n\nFile /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/ensemble.py:603, in Ensemble.cluster_indices(self, cell_type)\n    586 def cluster_indices(self, cell_type: str) -&gt; Dict[int, NDArray[int]]:\n    587     \"\"\"Clusters from responses to naturalistic stimuli of the given cell type.\n    588 \n    589      Args:\n   (...)\n    600          first_cluster = ensemble[cluster_indices[0]]\n    601     \"\"\"\n--&gt; 603     clustering = self.clustering(cell_type)\n    604     cluster_indices = get_cluster_to_indices(\n    605         clustering.embedding.mask, clustering.labels, task_error=self.task_error()\n    606     )\n    608     _models = sorted(np.concatenate(list(cluster_indices.values())))\n\n\nFile /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/ensemble.py:578, in Ensemble.clustering(self, cell_type)\n    572 \"\"\"Return the clustering of the ensemble for a given cell type.\"\"\"\n    574 if (\n    575     not self.dir.umap_and_clustering\n    576     or not self.dir.umap_and_clustering[cell_type]\n    577 ):\n--&gt; 578     return compute_umap_and_clustering(self, cell_type)\n    580 path = self.dir.umap_and_clustering[f\"{cell_type}.pickle\"]\n    581 with open(path, \"rb\") as file:\n\n\nFile /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/clustering.py:667, in compute_umap_and_clustering(ensemble, cell_type, embedding_kwargs, gm_kwargs, subdir)\n    664     ensemble.cache[\"ensemble_embedding_object\"] = embeddings\n    665     return embeddings\n--&gt; 667 responses = naturalistic_stimuli_responses(ensemble)\n    668 embeddings = create_embedding_object(responses)\n    670 embedding = embeddings.from_cell_type(cell_type, embedding_kwargs=embedding_kwargs)\n\n\nFile /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/stimulus_responses.py:348, in naturalistic_stimuli_responses(network_view_or_ensemble, dataset, dt, batch_size)\n    335 def naturalistic_stimuli_responses(\n    336     network_view_or_ensemble: Union[\"flyvision.NetworkView\", \"flyvision.EnsembleView\"],\n    337     dataset: Optional[AugmentedSintel] = None,\n    338     dt=1 / 100,\n    339     batch_size=4,\n    340 ) -&gt; xr.Dataset:\n    341     default_dataset_config = {\n    342         'tasks': [\"flow\"],\n    343         'interpolate': False,\n   (...)\n    346         'dt': dt,\n    347     }\n--&gt; 348     return generic_responses(\n    349         network_view_or_ensemble,\n    350         dataset,\n    351         default_dataset_config,\n    352         AugmentedSintel,\n    353         t_pre=0.0,\n    354         t_fade_in=2.0,\n    355         batch_size=batch_size,\n    356     )\n\n\nFile /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/stimulus_responses.py:192, in generic_responses(network_view_or_ensemble, dataset, dataset_config, default_dataset_cls, t_pre, t_fade_in, batch_size, cell_index)\n    189 network = handle_network(0, network_views[0], None)\n    191 for idx, network_view in enumerate(network_views[1:], 1):\n--&gt; 192     handle_network(idx, network_view, network)\n    194 # TODO: as long as the concatenation is not lazy, this pattern might not be\n    195 # the best way to handle the results. See also https://github.com/pydata/xarray/issues/4628.\n    196 result = xr.concat(results, dim='network_id', data_vars='minimal', coords='minimal')\n\n\nFile /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/stimulus_responses.py:177, in generic_responses.&lt;locals&gt;.handle_network(idx, network_view, network)\n    173     checkpointed_network.init()\n    175 # Call the cached compute_responses function\n    176 results.append(\n--&gt; 177     cached_compute_responses_fn(\n    178         checkpointed_network,\n    179         dataset_class,\n    180         dataset_config,\n    181         batch_size,\n    182         t_pre,\n    183         t_fade_in,\n    184     )  # type: xr.Dataset\n    185 )\n    186 checkpoints.append(checkpointed_network.checkpoint)\n    187 return checkpointed_network.network\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/memory.py:655, in MemorizedFunc.__call__(self, *args, **kwargs)\n    654 def __call__(self, *args, **kwargs):\n--&gt; 655     return self._cached_call(args, kwargs)[0]\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/memory.py:598, in MemorizedFunc._cached_call(self, args, kwargs, shelving)\n    595     must_call = True\n    597 if must_call:\n--&gt; 598     out, metadata = self.call(*args, **kwargs)\n    599     if self.mmap_mode is not None:\n    600         # Memmap the output at the first call to be consistent with\n    601         # later calls\n    602         if self._verbose:\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/memory.py:856, in MemorizedFunc.call(self, *args, **kwargs)\n    854 if self._verbose &gt; 0:\n    855     print(format_call(self.func, args, kwargs))\n--&gt; 856 output = self.func(*args, **kwargs)\n    857 self.store_backend.dump_item(\n    858     [func_id, args_id], output, verbose=self._verbose)\n    860 duration = time.time() - start_time\n\n\nFile /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/stimulus_responses.py:59, in compute_responses(network, dataset_class, dataset_config, batch_size, t_pre, t_fade_in, cell_index)\n     56 responses_array = []\n     58 # Compute responses\n---&gt; 59 for i, (stimulus, responses) in enumerate(\n     60     network.stimulus_response(\n     61         dataset,\n     62         dataset.dt,\n     63         t_pre=t_pre,\n     64         t_fade_in=t_fade_in,\n     65         batch_size=batch_size,\n     66     )\n     67 ):\n     68     if cell_index is not None:\n     69         responses = np.take(responses, cell_index, axis=-1)\n\n\nKeyboardInterrupt:\n</code></pre> <pre><code>from flyvision.analysis.stimulus_responses import moving_edge_responses\nfrom flyvision.analysis.moving_bar_responses import plot_angular_tuning\n</code></pre> <pre><code>responses = moving_edge_responses(ensemble)\n</code></pre> <pre><code>plot_angular_tuning(responses, \"T4c\", 1)\n</code></pre> <pre><code>ensemble = EnsembleView([\"flow/0000/000\", \"flow/0000/001\"])\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/2 [00:00&lt;?, ?it/s]\n\n\n[2024-09-19 16:27:29] ensemble:133 Loaded 2 networks.\n</code></pre> <pre><code>nv = ensemble[0]\n</code></pre> <pre><code>from flyvision.analysis.stimulus_responses import flash_responses\n</code></pre> <pre><code>flash_responses(nv, batch_size=4)\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\nInput In [1], in &lt;cell line: 1&gt;()\n----&gt; 1 flash_responses(nv, batch_size=4)\n\n\nNameError: name 'flash_responses' is not defined\n</code></pre> <pre><code>\n</code></pre> <pre><code>x(nv)\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nTypeError                                 Traceback (most recent call last)\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:140, in Hasher._batch_setitems(self, items)\n    135 try:\n    136     # Trying first to compare dict assuming the type of keys is\n    137     # consistent and orderable.\n    138     # This fails on python 3 when keys are unorderable\n    139     # but we keep it in a try as it's faster.\n--&gt; 140     Pickler._batch_setitems(self, iter(sorted(items)))\n    141 except TypeError:\n    142     # If keys are unorderable, sorting them using their hash. This is\n    143     # slower but works in any case.\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:997, in _Pickler._batch_setitems(self, items)\n    996     save(k)\n--&gt; 997     save(v)\n    998 write(SETITEMS)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:241, in NumpyHasher.save(self, obj)\n    240     return\n--&gt; 241 Hasher.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:89, in Hasher.save(self, obj)\n     88         obj = _MyHash(func_name, inst, cls)\n---&gt; 89 Pickler.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:603, in _Pickler.save(self, obj, save_persistent_id)\n    602 # Save the reduce() output and finally memoize the object\n--&gt; 603 self.save_reduce(obj=obj, *rv)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:692, in _Pickler.save_reduce(self, func, args, state, listitems, dictitems, state_setter, obj)\n    691 save(func)\n--&gt; 692 save(args)\n    693 write(REDUCE)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:241, in NumpyHasher.save(self, obj)\n    240     return\n--&gt; 241 Hasher.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:89, in Hasher.save(self, obj)\n     88         obj = _MyHash(func_name, inst, cls)\n---&gt; 89 Pickler.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:560, in _Pickler.save(self, obj, save_persistent_id)\n    559 if f is not None:\n--&gt; 560     f(self, obj)  # Call unbound method with explicit self\n    561     return\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:901, in _Pickler.save_tuple(self, obj)\n    900 for element in obj:\n--&gt; 901     save(element)\n    903 if id(obj) in memo:\n    904     # Subtle.  d was not in memo when we entered save_tuple(), so\n    905     # the process of saving the tuple's elements must have saved\n   (...)\n    909     # could have been done in the \"for element\" loop instead, but\n    910     # recursive tuples are a rare thing.\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:241, in NumpyHasher.save(self, obj)\n    240     return\n--&gt; 241 Hasher.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:89, in Hasher.save(self, obj)\n     88         obj = _MyHash(func_name, inst, cls)\n---&gt; 89 Pickler.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:578, in _Pickler.save(self, obj, save_persistent_id)\n    577 if reduce is not None:\n--&gt; 578     rv = reduce(self.proto)\n    579 else:\n\n\nTypeError: 'NoneType' object is not callable\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTypeError                                 Traceback (most recent call last)\n\nInput In [6], in &lt;cell line: 1&gt;()\n----&gt; 1 x(nv)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/memory.py:655, in MemorizedFunc.__call__(self, *args, **kwargs)\n    654 def __call__(self, *args, **kwargs):\n--&gt; 655     return self._cached_call(args, kwargs)[0]\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/memory.py:528, in MemorizedFunc._cached_call(self, args, kwargs, shelving)\n    500 def _cached_call(self, args, kwargs, shelving=False):\n    501     \"\"\"Call wrapped function and cache result, or read cache if available.\n    502 \n    503     This function returns the wrapped function output and some metadata.\n   (...)\n    526         Some metadata about wrapped function call (see _persist_input()).\n    527     \"\"\"\n--&gt; 528     func_id, args_id = self._get_output_identifiers(*args, **kwargs)\n    529     metadata = None\n    530     msg = None\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/memory.py:699, in MemorizedFunc._get_output_identifiers(self, *args, **kwargs)\n    697 \"\"\"Return the func identifier and input parameter hash of a result.\"\"\"\n    698 func_id = _build_func_identifier(self.func)\n--&gt; 699 argument_hash = self._get_argument_hash(*args, **kwargs)\n    700 return func_id, argument_hash\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/memory.py:693, in MemorizedFunc._get_argument_hash(self, *args, **kwargs)\n    692 def _get_argument_hash(self, *args, **kwargs):\n--&gt; 693     return hashing.hash(filter_args(self.func, self.ignore, args, kwargs),\n    694                         coerce_mmap=(self.mmap_mode is not None))\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:265, in hash(obj, hash_name, coerce_mmap)\n    263 else:\n    264     hasher = Hasher(hash_name=hash_name)\n--&gt; 265 return hasher.hash(obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:63, in Hasher.hash(self, obj, return_digest)\n     61 def hash(self, obj, return_digest=True):\n     62     try:\n---&gt; 63         self.dump(obj)\n     64     except pickle.PicklingError as e:\n     65         e.args += ('PicklingError while hashing %r: %r' % (obj, e),)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:487, in _Pickler.dump(self, obj)\n    485 if self.proto &gt;= 4:\n    486     self.framer.start_framing()\n--&gt; 487 self.save(obj)\n    488 self.write(STOP)\n    489 self.framer.end_framing()\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:241, in NumpyHasher.save(self, obj)\n    239     self._hash.update(pickle.dumps(obj))\n    240     return\n--&gt; 241 Hasher.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:89, in Hasher.save(self, obj)\n     87         cls = obj.__self__.__class__\n     88         obj = _MyHash(func_name, inst, cls)\n---&gt; 89 Pickler.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:560, in _Pickler.save(self, obj, save_persistent_id)\n    558 f = self.dispatch.get(t)\n    559 if f is not None:\n--&gt; 560     f(self, obj)  # Call unbound method with explicit self\n    561     return\n    563 # Check private dispatch table if any, or else\n    564 # copyreg.dispatch_table\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:971, in _Pickler.save_dict(self, obj)\n    968     self.write(MARK + DICT)\n    970 self.memoize(obj)\n--&gt; 971 self._batch_setitems(obj.items())\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:144, in Hasher._batch_setitems(self, items)\n    140     Pickler._batch_setitems(self, iter(sorted(items)))\n    141 except TypeError:\n    142     # If keys are unorderable, sorting them using their hash. This is\n    143     # slower but works in any case.\n--&gt; 144     Pickler._batch_setitems(self, iter(sorted((hash(k), v)\n    145                                               for k, v in items)))\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:997, in _Pickler._batch_setitems(self, items)\n    995     for k, v in tmp:\n    996         save(k)\n--&gt; 997         save(v)\n    998     write(SETITEMS)\n    999 elif n:\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:241, in NumpyHasher.save(self, obj)\n    239     self._hash.update(pickle.dumps(obj))\n    240     return\n--&gt; 241 Hasher.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:89, in Hasher.save(self, obj)\n     87         cls = obj.__self__.__class__\n     88         obj = _MyHash(func_name, inst, cls)\n---&gt; 89 Pickler.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:603, in _Pickler.save(self, obj, save_persistent_id)\n    599     raise PicklingError(\"Tuple returned by %s must have \"\n    600                         \"two to six elements\" % reduce)\n    602 # Save the reduce() output and finally memoize the object\n--&gt; 603 self.save_reduce(obj=obj, *rv)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:692, in _Pickler.save_reduce(self, func, args, state, listitems, dictitems, state_setter, obj)\n    690 else:\n    691     save(func)\n--&gt; 692     save(args)\n    693     write(REDUCE)\n    695 if obj is not None:\n    696     # If the object is already in the memo, this means it is\n    697     # recursive. In this case, throw away everything we put on the\n    698     # stack, and fetch the object back from the memo.\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:241, in NumpyHasher.save(self, obj)\n    239     self._hash.update(pickle.dumps(obj))\n    240     return\n--&gt; 241 Hasher.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:89, in Hasher.save(self, obj)\n     87         cls = obj.__self__.__class__\n     88         obj = _MyHash(func_name, inst, cls)\n---&gt; 89 Pickler.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:560, in _Pickler.save(self, obj, save_persistent_id)\n    558 f = self.dispatch.get(t)\n    559 if f is not None:\n--&gt; 560     f(self, obj)  # Call unbound method with explicit self\n    561     return\n    563 # Check private dispatch table if any, or else\n    564 # copyreg.dispatch_table\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:901, in _Pickler.save_tuple(self, obj)\n    899 write(MARK)\n    900 for element in obj:\n--&gt; 901     save(element)\n    903 if id(obj) in memo:\n    904     # Subtle.  d was not in memo when we entered save_tuple(), so\n    905     # the process of saving the tuple's elements must have saved\n   (...)\n    909     # could have been done in the \"for element\" loop instead, but\n    910     # recursive tuples are a rare thing.\n    911     get = self.get(memo[id(obj)][0])\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:241, in NumpyHasher.save(self, obj)\n    239     self._hash.update(pickle.dumps(obj))\n    240     return\n--&gt; 241 Hasher.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/joblib/hashing.py:89, in Hasher.save(self, obj)\n     87         cls = obj.__self__.__class__\n     88         obj = _MyHash(func_name, inst, cls)\n---&gt; 89 Pickler.save(self, obj)\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/pickle.py:578, in _Pickler.save(self, obj, save_persistent_id)\n    576 reduce = getattr(obj, \"__reduce_ex__\", None)\n    577 if reduce is not None:\n--&gt; 578     rv = reduce(self.proto)\n    579 else:\n    580     reduce = getattr(obj, \"__reduce__\", None)\n\n\nTypeError: 'NoneType' object is not callable\n</code></pre> <pre><code>r = flash_responses(ensemble)\n</code></pre> <pre><code>[2024-09-19 15:40:19] logger:80 [MemorizedFunc(func=&lt;function compute_responses at 0x7fb8953669d0&gt;, location=/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__)]: Clearing function cache identified by flyvision/analysis/stimulus_responses/compute_responses\n\n\ncall in cache\nZarr directory exists at /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/__cache__/flyvision/analysis/stimulus_responses/compute_responses/36cc2e714bcc32d4310f6c8f5a3b3a22/output.zarr\ncall in cache\n\n\n[2024-09-19 15:40:19] chkpt_utils:72 Recovered network state.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n[2024-09-19 15:40:19] network:747 Computing 4 stimulus responses.\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\nStore item /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/__cache__/flyvision/analysis/stimulus_responses/compute_responses/0c7c0da65596c80075f59c01e695a49c/output.zarr\n________________________________________________compute_responses - 3.2s, 0.1min\n</code></pre> <pre><code>r['responses'].data\n</code></pre> <pre><code>array([[[[ 1.26998270e+00,  1.14091361e+00,  8.79052460e-01, ...,\n          -6.65360272e-01,  4.84376013e-01,  1.56474614e+00],\n         [ 1.26998210e+00,  1.14091325e+00,  8.79052281e-01, ...,\n          -6.65285587e-01,  4.84358519e-01,  1.56486785e+00],\n         [ 1.26998150e+00,  1.14091289e+00,  8.79052103e-01, ...,\n          -6.65213525e-01,  4.84341621e-01,  1.56498337e+00],\n         ...,\n         [ 1.27000153e+00,  1.14092326e+00,  8.79057825e-01, ...,\n          -6.65505469e-01,  4.84511584e-01,  1.56172812e+00],\n         [ 1.27000058e+00,  1.14092278e+00,  8.79057527e-01, ...,\n          -6.65413439e-01,  4.84495133e-01,  1.56193316e+00],\n         [ 1.26999962e+00,  1.14092231e+00,  8.79057229e-01, ...,\n          -6.65324688e-01,  4.84478980e-01,  1.56213117e+00]],\n\n        [[ 1.26998270e+00,  1.14091361e+00,  8.79052460e-01, ...,\n          -6.65360272e-01,  4.84376013e-01,  1.56474614e+00],\n         [ 1.26998210e+00,  1.14091325e+00,  8.79052281e-01, ...,\n          -6.65285528e-01,  4.84358549e-01,  1.56486785e+00],\n         [ 1.26998150e+00,  1.14091289e+00,  8.79052103e-01, ...,\n          -6.65213525e-01,  4.84341681e-01,  1.56498337e+00],\n         ...,\n         [ 1.26999938e+00,  1.14092231e+00,  8.79057169e-01, ...,\n          -6.64689541e-01,  4.84426320e-01,  1.56245875e+00],\n         [ 1.26999855e+00,  1.14092183e+00,  8.79056931e-01, ...,\n          -6.64619029e-01,  4.84410375e-01,  1.56263471e+00],\n         [ 1.26999772e+00,  1.14092135e+00,  8.79056692e-01, ...,\n          -6.64551556e-01,  4.84394759e-01,  1.56280386e+00]],\n\n        [[ 1.26998270e+00,  1.14091361e+00,  8.79052460e-01, ...,\n          -6.65360272e-01,  4.84376013e-01,  1.56474614e+00],\n         [ 1.26998210e+00,  1.14091325e+00,  8.79052281e-01, ...,\n          -6.65285587e-01,  4.84358549e-01,  1.56486785e+00],\n         [ 1.26998150e+00,  1.14091289e+00,  8.79052103e-01, ...,\n          -6.65213466e-01,  4.84341681e-01,  1.56498337e+00],\n         ...,\n         [ 1.26996088e+00,  1.14090216e+00,  8.79046261e-01, ...,\n          -6.63660169e-01,  4.84010607e-01,  1.56863821e+00],\n         [ 1.26996136e+00,  1.14090240e+00,  8.79046381e-01, ...,\n          -6.63626075e-01,  4.84002650e-01,  1.56859958e+00],\n         [ 1.26996183e+00,  1.14090264e+00,  8.79046500e-01, ...,\n          -6.63593173e-01,  4.83994961e-01,  1.56855977e+00]],\n\n        [[ 1.26998270e+00,  1.14091361e+00,  8.79052460e-01, ...,\n          -6.65360272e-01,  4.84376013e-01,  1.56474614e+00],\n         [ 1.26998210e+00,  1.14091325e+00,  8.79052281e-01, ...,\n          -6.65285528e-01,  4.84358519e-01,  1.56486785e+00],\n         [ 1.26998150e+00,  1.14091289e+00,  8.79052103e-01, ...,\n          -6.65213466e-01,  4.84341651e-01,  1.56498337e+00],\n         ...,\n         [ 1.26996148e+00,  1.14090240e+00,  8.79046440e-01, ...,\n          -6.63580477e-01,  4.83976334e-01,  1.56881285e+00],\n         [ 1.26996207e+00,  1.14090264e+00,  8.79046559e-01, ...,\n          -6.63551450e-01,  4.83968198e-01,  1.56876075e+00],\n         [ 1.26996255e+00,  1.14090300e+00,  8.79046738e-01, ...,\n          -6.63523316e-01,  4.83960509e-01,  1.56870782e+00]]],\n\n\n       [[[ 2.26847947e-01,  1.73184633e+00,  3.66457075e-01, ...,\n           4.38959032e-01,  1.15676522e+00, -9.46795451e-04],\n         [ 2.26922005e-01,  1.73270357e+00,  3.66352379e-01, ...,\n           4.38438445e-01,  1.15802646e+00, -8.05967429e-04],\n         [ 2.26995245e-01,  1.73355222e+00,  3.66249621e-01, ...,\n           4.37931597e-01,  1.15926170e+00, -6.67890650e-04],\n         ...,\n         [ 2.32199892e-01,  1.79689252e+00,  3.60339612e-01, ...,\n           4.07203078e-01,  1.23493397e+00,  1.45732462e-02],\n         [ 2.32207999e-01,  1.79692674e+00,  3.60299319e-01, ...,\n           4.06869888e-01,  1.23555434e+00,  1.48489913e-02],\n         [ 2.32216313e-01,  1.79696441e+00,  3.60260069e-01, ...,\n           4.06542301e-01,  1.23616111e+00,  1.51194008e-02]],\n\n        [[ 2.26847947e-01,  1.73184633e+00,  3.66457075e-01, ...,\n           4.38959032e-01,  1.15676522e+00, -9.46825719e-04],\n         [ 2.26922005e-01,  1.73270357e+00,  3.66352379e-01, ...,\n           4.38438445e-01,  1.15802646e+00, -8.06012831e-04],\n         [ 2.26995245e-01,  1.73355222e+00,  3.66249621e-01, ...,\n           4.37931627e-01,  1.15926170e+00, -6.67920976e-04],\n         ...,\n         [ 2.32457072e-01,  1.79971373e+00,  3.59658748e-01, ...,\n           4.01285648e-01,  1.24299502e+00,  1.82700194e-02],\n         [ 2.32460201e-01,  1.79968691e+00,  3.59628052e-01, ...,\n           4.00977790e-01,  1.24349368e+00,  1.84929017e-02],\n         [ 2.32463762e-01,  1.79966605e+00,  3.59598309e-01, ...,\n           4.00675088e-01,  1.24398196e+00,  1.87107958e-02]],\n\n        [[ 2.26847947e-01,  1.73184633e+00,  3.66457075e-01, ...,\n           4.38959032e-01,  1.15676522e+00, -9.46795451e-04],\n         [ 2.26922005e-01,  1.73270357e+00,  3.66352379e-01, ...,\n           4.38438475e-01,  1.15802646e+00, -8.05967429e-04],\n         [ 2.26995245e-01,  1.73355222e+00,  3.66249621e-01, ...,\n           4.37931687e-01,  1.15926170e+00, -6.67920918e-04],\n         ...,\n         [ 2.34749660e-01,  1.82607627e+00,  3.56502026e-01, ...,\n           3.77276391e-01,  1.29048550e+00,  3.32663991e-02],\n         [ 2.34736368e-01,  1.82585859e+00,  3.56509507e-01, ...,\n           3.77202153e-01,  1.29056251e+00,  3.33554670e-02],\n         [ 2.34723553e-01,  1.82564819e+00,  3.56517464e-01, ...,\n           3.77132207e-01,  1.29063022e+00,  3.34387310e-02]],\n\n        [[ 2.26847947e-01,  1.73184633e+00,  3.66457075e-01, ...,\n           4.38959032e-01,  1.15676522e+00, -9.46825719e-04],\n         [ 2.26922005e-01,  1.73270357e+00,  3.66352379e-01, ...,\n           4.38438475e-01,  1.15802646e+00, -8.05997697e-04],\n         [ 2.26995245e-01,  1.73355222e+00,  3.66249621e-01, ...,\n           4.37931627e-01,  1.15926170e+00, -6.67875574e-04],\n         ...,\n         [ 2.34463289e-01,  1.82269490e+00,  3.57069880e-01, ...,\n           3.81346226e-01,  1.28545821e+00,  3.04317325e-02],\n         [ 2.34454304e-01,  1.82253230e+00,  3.57072860e-01, ...,\n           3.81256282e-01,  1.28554511e+00,  3.05252597e-02],\n         [ 2.34445736e-01,  1.82237637e+00,  3.57076257e-01, ...,\n           3.81170303e-01,  1.28562391e+00,  3.06138750e-02]]]])\n</code></pre> <pre><code>type(r['responses'].data)\n</code></pre> <pre><code>numpy.ndarray\n</code></pre> <pre><code>r.custom.where(cell_type=\"T4c\", time='&lt;0.5')\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nValueError                                Traceback (most recent call last)\n\nInput In [562], in &lt;cell line: 1&gt;()\n----&gt; 1 r.custom.where(cell_type=\"T4c\", time='&lt;0.5').plot()\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/xarray/plot/accessor.py:942, in DatasetPlotAccessor.__call__(self, *args, **kwargs)\n    941 def __call__(self, *args, **kwargs) -&gt; NoReturn:\n--&gt; 942     raise ValueError(\n    943         \"Dataset.plot cannot be called directly. Use \"\n    944         \"an explicit plot method, e.g. ds.plot.scatter(...)\"\n    945     )\n\n\nValueError: Dataset.plot cannot be called directly. Use an explicit plot method, e.g. ds.plot.scatter(...)\n</code></pre> <pre><code>from flyvision.analysis.simple_correlation import correlation\nfrom flyvision.utils import groundtruth_utils\n</code></pre> <pre><code>from flyvision.analysis.flash_responses import (\n    flash_response_index,\n    fri_correlation_to_known,\n)\n</code></pre> <pre><code>fris = flash_response_index(r, radius=6)\n</code></pre> <pre><code>fri_correlation_to_known(fris)\n</code></pre> <pre>&lt;xarray.DataArray (network_id: 2, sample: 1)&gt;\narray([[0.80960086],\n       [0.80693697]])\nCoordinates:\n  * network_id   (network_id) int64 0 1\n    baseline     (sample) float64 0.5\n    radius       (sample) int64 6\n    checkpoints  (network_id) object /groups/turaga/home/lappalainenj/FlyVis/...\nDimensions without coordinates: sample</pre>xarray.DataArray<ul><li>network_id: 2</li><li>sample: 1</li></ul><ul><li>0.8096 0.8069<pre>array([[0.80960086],\n       [0.80693697]])</pre></li><li>Coordinates: (4)<ul><li>network_id(network_id)int640 1<pre>array([0, 1])</pre></li><li>baseline(sample)float640.5<pre>array([0.5])</pre></li><li>radius(sample)int646<pre>array([6])</pre></li><li>checkpoints(network_id)object/groups/turaga/home/lappalainenj...<pre>array([PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'),\n       PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000')],\n      dtype=object)</pre></li></ul></li><li>Indexes: (1)<ul><li>network_idPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='network_id'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <pre><code>r = moving_edge_responses(ensemble, speeds=[19, 25], offsets=(-5, 5), batch_size=4)\n</code></pre> <pre><code>call in cache\ncall in cache\n</code></pre> <pre><code>from flyvision.analysis.moving_bar_responses import (\n    direction_selectivity_index,\n    get_time_masks,\n    peak_responses,\n    peak_responses_angular,\n    preferred_direction,\n)\n</code></pre> <pre><code>preferred_direction(r)\n</code></pre> <pre>&lt;xarray.DataArray 'responses' (network_id: 2, neuron: 65, intensity: 2)&gt;\narray([[[-1.45409812e-01,  1.14432681e+00],\n        [-9.62252107e-13,  5.99157085e-01],\n        [-4.08941150e-13,  1.13965543e+00],\n        [-2.22000780e-01,  1.14465379e+00],\n        [-4.32689046e-01,  1.18060851e+00],\n        [-2.09103564e+00,  1.14558450e+00],\n        [-2.23311971e-13,  3.14159265e+00],\n        [-2.23017858e-13, -3.08158205e-11],\n        [ 0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00],\n        [-1.10966079e+00,  5.87139353e-01],\n        [-1.03336630e+00,  1.57079633e+00],\n        [-2.05912039e+00,  7.17909389e-02],\n        [ 0.00000000e+00,  0.00000000e+00],\n        [-2.37817679e+00,  1.76616951e-01],\n        [ 0.00000000e+00,  0.00000000e+00],\n        [-1.78946527e+00, -1.64230814e+00],\n        [ 2.48722963e+00, -2.06809747e+00],\n        [ 3.79276538e-02,  7.96743874e-01],\n        [-2.57616066e+00,  8.71883716e-01],\n...\n        [ 1.04448801e+00, -1.20075429e-01],\n        [ 4.28249427e-01,  0.00000000e+00],\n        [ 3.59000058e-01,  2.97415837e+00],\n        [ 2.96230948e+00,  2.07275550e+00],\n        [ 1.25311650e+00,  1.57271571e+00],\n        [ 2.30960222e-01,  2.61799388e+00],\n        [ 2.52816532e-01,  0.00000000e+00],\n        [-1.09909854e+00, -3.10067051e+00],\n        [ 2.38115894e-01,  0.00000000e+00],\n        [ 9.33658938e-01,  2.94982890e+00],\n        [-1.26624535e+00,  2.46788810e+00],\n        [-7.07413398e-02, -3.10107988e+00],\n        [-2.56214694e+00, -2.31216017e+00],\n        [-2.52406902e+00, -2.50096814e+00],\n        [ 4.78682585e-01,  3.57782381e-01],\n        [-2.21087128e+00,  1.18826756e+00],\n        [-1.63206802e+00,  1.77147327e+00],\n        [ 1.60169098e+00, -7.08962709e-02],\n        [-5.76669296e-01, -7.29345144e-01],\n        [-3.08845703e+00,  9.30896627e-02]]])\nCoordinates:\n  * intensity    (intensity) int64 0 1\n  * network_id   (network_id) int64 0 1\n  * neuron       (neuron) int64 0 1 2 3 4 5 6 7 8 ... 56 57 58 59 60 61 62 63 64\n    cell_type    (neuron) &lt;U8 'R1' 'R2' 'R3' 'R4' ... 'TmY14' 'TmY15' 'TmY18'\n    u            (neuron) int32 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0\n    v            (neuron) int32 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0\n    checkpoints  (network_id) object /groups/turaga/home/lappalainenj/FlyVis/...</pre>xarray.DataArray'responses'<ul><li>network_id: 2</li><li>neuron: 65</li><li>intensity: 2</li></ul><ul><li>-0.1454 1.144 -9.623e-13 0.5992 ... -0.5767 -0.7293 -3.088 0.09309<pre>array([[[-1.45409812e-01,  1.14432681e+00],\n        [-9.62252107e-13,  5.99157085e-01],\n        [-4.08941150e-13,  1.13965543e+00],\n        [-2.22000780e-01,  1.14465379e+00],\n        [-4.32689046e-01,  1.18060851e+00],\n        [-2.09103564e+00,  1.14558450e+00],\n        [-2.23311971e-13,  3.14159265e+00],\n        [-2.23017858e-13, -3.08158205e-11],\n        [ 0.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00],\n        [-1.10966079e+00,  5.87139353e-01],\n        [-1.03336630e+00,  1.57079633e+00],\n        [-2.05912039e+00,  7.17909389e-02],\n        [ 0.00000000e+00,  0.00000000e+00],\n        [-2.37817679e+00,  1.76616951e-01],\n        [ 0.00000000e+00,  0.00000000e+00],\n        [-1.78946527e+00, -1.64230814e+00],\n        [ 2.48722963e+00, -2.06809747e+00],\n        [ 3.79276538e-02,  7.96743874e-01],\n        [-2.57616066e+00,  8.71883716e-01],\n...\n        [ 1.04448801e+00, -1.20075429e-01],\n        [ 4.28249427e-01,  0.00000000e+00],\n        [ 3.59000058e-01,  2.97415837e+00],\n        [ 2.96230948e+00,  2.07275550e+00],\n        [ 1.25311650e+00,  1.57271571e+00],\n        [ 2.30960222e-01,  2.61799388e+00],\n        [ 2.52816532e-01,  0.00000000e+00],\n        [-1.09909854e+00, -3.10067051e+00],\n        [ 2.38115894e-01,  0.00000000e+00],\n        [ 9.33658938e-01,  2.94982890e+00],\n        [-1.26624535e+00,  2.46788810e+00],\n        [-7.07413398e-02, -3.10107988e+00],\n        [-2.56214694e+00, -2.31216017e+00],\n        [-2.52406902e+00, -2.50096814e+00],\n        [ 4.78682585e-01,  3.57782381e-01],\n        [-2.21087128e+00,  1.18826756e+00],\n        [-1.63206802e+00,  1.77147327e+00],\n        [ 1.60169098e+00, -7.08962709e-02],\n        [-5.76669296e-01, -7.29345144e-01],\n        [-3.08845703e+00,  9.30896627e-02]]])</pre></li><li>Coordinates: (7)<ul><li>intensity(intensity)int640 1<pre>array([0, 1])</pre></li><li>network_id(network_id)int640 1<pre>array([0, 1])</pre></li><li>neuron(neuron)int640 1 2 3 4 5 6 ... 59 60 61 62 63 64<pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64])</pre></li><li>cell_type(neuron)&lt;U8'R1' 'R2' 'R3' ... 'TmY15' 'TmY18'<pre>array(['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'L1', 'L2', 'L3',\n       'L4', 'L5', 'Lawf1', 'Lawf2', 'Am', 'C2', 'C3', 'CT1(Lo1)',\n       'CT1(M10)', 'Mi1', 'Mi2', 'Mi3', 'Mi4', 'Mi9', 'Mi10', 'Mi11',\n       'Mi12', 'Mi13', 'Mi14', 'Mi15', 'T1', 'T2', 'T2a', 'T3', 'T4a',\n       'T4b', 'T4c', 'T4d', 'T5a', 'T5b', 'T5c', 'T5d', 'Tm1', 'Tm2',\n       'Tm3', 'Tm4', 'Tm5Y', 'Tm5a', 'Tm5b', 'Tm5c', 'Tm9', 'Tm16',\n       'Tm20', 'Tm28', 'Tm30', 'TmY3', 'TmY4', 'TmY5a', 'TmY9', 'TmY10',\n       'TmY13', 'TmY14', 'TmY15', 'TmY18'], dtype='&lt;U8')</pre></li><li>u(neuron)int320 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype=int32)</pre></li><li>v(neuron)int320 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype=int32)</pre></li><li>checkpoints(network_id)object/groups/turaga/home/lappalainenj...<pre>array([PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'),\n       PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000')],\n      dtype=object)</pre></li></ul></li><li>Indexes: (3)<ul><li>network_idPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='network_id'))</pre></li><li>neuronPandasIndex<pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64],\n      dtype='int64', name='neuron'))</pre></li><li>intensityPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='intensity'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <pre><code>r.custom.plot_traces(key='responses', x=\"time\", cell_type='T4c', u=0, v=0, speed=19)\n</code></pre> <pre><code>&lt;Axes: xlabel='time', ylabel='responses'&gt;\n</code></pre> <pre><code>from flyvision.analysis.moving_bar_responses import (\n    direction_selectivity_index,\n    peak_responses,\n    plot_T4_tuning,\n    plot_T5_tuning,\n)\n</code></pre> <pre><code>from typing import Dict, List, Optional, Union\n\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nfrom scipy.interpolate import interp1d\n\n\ndef tuning_curve_correlation_to_known(\n    tuning: xr.DataArray,\n    mode: str = \"independent\",\n    aggregate: Optional[str] = \"absmax\",\n    aggregate_dims: Optional[List[str]] = None,\n    select_stimuli_indices: Optional[List[int]] = None,\n    respect_contrast: bool = True,\n    concatenate: bool = False,\n    opposite_contrast: bool = False,\n    interpolate: bool = False,\n    fill_missing: float = 0.0,\n) -&gt; Union[Dict[str, xr.DataArray], xr.DataArray]:\n    \"\"\"\n    Computes the correlation between predicted tuning curves and known tuning curves.\n\n    Args:\n        tuning (xarray.DataArray): DataArray containing the responses,\n            with dimensions including 'network_id', 'sample', 'neuron',\n            and coordinates such as 'angle', 'intensity', 'cell_type'.\n        mode (str): 'independent' or 'joint' -- compute correlations independently or jointly.\n        aggregate (str): 'median', 'mean', 'max', 'absmax', 'select' -- method to aggregate over stimulus parameters.\n        aggregate_dims (list): Dimensions along which to aggregate the correlation values.\n        select_stimuli_indices (list): Indices to select specific stimuli for correlations.\n        respect_contrast (bool): If True, compute correlations for preferred contrast tunings.\n        concatenate (bool): If True, concatenate all cell types into one array.\n        opposite_contrast (bool): If True, compute correlations for opposite contrast.\n        interpolate (bool): If True, interpolate ground truth tuning curves to match predicted angles.\n        fill_missing (float): Value to fill missing values with.\n\n    Returns:\n        dict or xarray.DataArray: Dictionary of correlations per cell type,\n            or concatenated DataArray if concatenate=True.\n    \"\"\"\n    # Fill missing values and ensure required coordinates\n    tuning = tuning.fillna(fill_missing)\n    required_coords = {'angle', 'intensity', 'cell_type'}\n    if not required_coords.issubset(tuning.coords):\n        missing = required_coords - set(tuning.coords)\n        raise ValueError(f\"Missing required coordinates: {missing}\")\n\n    # Set default angles and intensities if not provided\n    gt_angles = np.arange(0, 360, 30)\n\n    angles = pd.unique(p.coords['angle'])\n    intensities = tuning.coords['intensity'].values.tolist()\n\n    # Prepare tuning data\n    tuning = tuning.set_index(sample=['angle', 'intensity', 'speed', 'width', 't_stim'])\n    tuning = tuning.unstack('sample')\n    tuning = tuning.swap_dims({'neuron': 'cell_type'})\n    tuning = tuning.sel(angle=angles, intensity=intensities)\n\n    # Retrieve ground truth tuning curves\n    cell_types = ['T4a', 'T4b', 'T4c', 'T4d', 'T5a', 'T5b', 'T5c', 'T5d']\n    gt_tuning_curves = {}\n    for cell_type in cell_types:\n        if cell_type in groundtruth_utils.tuning_curves:\n            gt_tuning = groundtruth_utils.tuning_curves[cell_type]\n            if interpolate and len(angles) != len(gt_angles):\n                interp_func = interp1d(gt_angles, gt_tuning, kind='cubic', fill_value=\"extrapolate\")\n                gt_tuning = interp_func(angles)\n            gt_tuning_curves[cell_type] = xr.DataArray(\n                gt_tuning,\n                dims=['angle'],\n                coords={'angle': angles}\n            )\n        else:\n            raise ValueError(f\"Ground truth tuning curve for {cell_type} not found.\")\n\n    # Compute correlations\n    correlations = {}\n    other_dims = [dim for dim in tuning.dims if dim not in ['angle', 'cell_type']]\n    for cell_type, gt_tuning_da in gt_tuning_curves.items():\n        if cell_type not in tuning['cell_type']:\n            continue\n        predicted_tuning = tuning.sel(cell_type=cell_type)\n\n        # Handle contrast preference\n        if respect_contrast or opposite_contrast:\n            intensity_value = 1 if 'T4' in cell_type else 0\n            if opposite_contrast:\n                intensity_value = 1 - intensity_value\n            predicted_tuning = predicted_tuning.sel(intensity=intensity_value)\n\n        # Stack dimensions for correlation computation\n        predicted_tuning = predicted_tuning.stack(stim_dims=other_dims)\n\n        # Compute correlation\n        corr = xr.corr(predicted_tuning, gt_tuning_da, dim='angle')\n        corr = corr.unstack('stim_dims')\n        correlations[cell_type] = corr\n\n    # Handle joint mode\n    if mode == 'joint':\n        combined_gt = xr.concat(list(gt_tuning_curves.values()), dim='cell_type').stack(flat_dim=('cell_type', 'angle'))\n        predicted_tuning = xr.concat(\n            [tuning.sel(cell_type=ct) for ct in gt_tuning_curves],\n            dim='cell_type'\n        ).stack(flat_dim=('cell_type', 'angle'))\n        corr = xr.corr(predicted_tuning, combined_gt, dim='flat_dim')\n        correlations = {'joint': corr}\n\n    # Aggregate correlations\n    if aggregate is not None:\n        agg_funcs = {\n            'median': xr.DataArray.median,\n            'mean': xr.DataArray.mean,\n            'max': xr.DataArray.max,\n            'absmax': lambda da, dim: da.isel({dim: da.argmax(dim=dim)}),\n            'select': None  # Handle 'select' separately\n        }\n        if aggregate not in agg_funcs and aggregate != 'select':\n            raise ValueError(f\"Invalid aggregation method: {aggregate}\")\n\n        for cell_type, corr in correlations.items():\n            if aggregate == 'select':\n                if select_stimuli_indices is None:\n                    raise ValueError(\"select_stimuli_indices must be provided when aggregate='select'\")\n                indexers = {dim: select_stimuli_indices for dim in aggregate_dims}\n                correlations[cell_type] = corr.isel(**indexers)\n            else:\n                func = agg_funcs[aggregate]\n                if aggregate == 'absmax':\n                    correlations[cell_type] = corr.reduce(\n                        func=np.abs, dim=aggregate_dims\n                    ).max(dim=aggregate_dims)\n                else:\n                    correlations[cell_type] = func(corr, dim=aggregate_dims)\n\n    # Concatenate if requested\n    if concatenate:\n        concatenated = xr.concat([corr.expand_dims('cell_type') for corr in correlations.values()], dim='cell_type')\n        concatenated['cell_type'] = list(correlations.keys())\n        return concatenated\n\n    return correlations\n</code></pre> <pre><code>def compute_independent_correlation(\n    tuning: xr.DataArray,\n    respect_contrast: bool = True,\n    opposite_contrast: bool = False,\n    interpolate: bool = False,\n    fill_missing: float = 0.0,\n) -&gt; Dict[str, xr.DataArray]:\n    \"\"\"\n    Computes the correlation between predicted tuning curves and known tuning curves independently for each cell type.\n\n    Args:\n        tuning (xarray.DataArray): DataArray containing the responses, with dimensions including 'network_id', 'sample', 'neuron',\n            and coordinates such as 'angle', 'intensity', 'cell_type'.\n        respect_contrast (bool): If True, compute correlations for preferred contrast tunings.\n        opposite_contrast (bool): If True, compute correlations for opposite contrast.\n        interpolate (bool): If True, interpolate ground truth tuning curves to match predicted angles.\n        fill_missing (float): Value to fill missing values with.\n\n    Returns:\n        Dict[str, xr.DataArray]: Dictionary of correlations per cell type.\n    \"\"\"\n    # Fill missing values and ensure required coordinates\n    tuning = tuning.fillna(fill_missing)\n    required_coords = {'angle', 'intensity', 'cell_type'}\n    missing_coords = required_coords - set(tuning.coords)\n    if missing_coords:\n        raise ValueError(f\"Missing required coordinates: {missing_coords}\")\n\n    # Extract angles and intensities from the dataset\n    angles = pd.unique(tuning.coords['angle'].values)\n    intensities = tuning.coords['intensity'].values\n\n    # Prepare tuning data\n    tuning = tuning.set_index(sample=['angle', 'intensity', 'speed', 'width', 't_stim'])\n    tuning = tuning.unstack('sample')\n    tuning = tuning.swap_dims({'neuron': 'cell_type'})\n\n    # Retrieve ground truth tuning curves\n    cell_types = ['T4a', 'T4b', 'T4c', 'T4d', 'T5a', 'T5b', 'T5c', 'T5d']\n    gt_angles = np.arange(0, 360, 30)\n    gt_tuning_curves = {}\n    for cell_type in cell_types:\n        if cell_type in groundtruth_utils.tuning_curves:\n            gt_tuning = groundtruth_utils.tuning_curves[cell_type]\n            if interpolate and not np.array_equal(angles, gt_angles):\n                interp_func = interp1d(\n                    gt_angles, gt_tuning, kind='cubic', fill_value=\"extrapolate\"\n                )\n                gt_tuning = interp_func(angles)\n            gt_tuning_curves[cell_type] = xr.DataArray(\n                gt_tuning,\n                dims=['angle'],\n                coords={'angle': angles}\n            )\n        else:\n            raise ValueError(f\"Ground truth tuning curve for {cell_type} not found.\")\n\n    # Compute correlations\n    correlations = {}\n    other_dims = [dim for dim in tuning.dims if dim not in ['angle', 'cell_type']]\n    for cell_type, gt_tuning_da in gt_tuning_curves.items():\n        if cell_type not in tuning['cell_type']:\n            continue\n        predicted_tuning = tuning.sel(cell_type=cell_type)\n\n        # Handle contrast preference\n        if respect_contrast or opposite_contrast:\n            intensity_value = 1 if 'T4' in cell_type else 0\n            if opposite_contrast:\n                intensity_value = 1 - intensity_value\n            predicted_tuning = predicted_tuning.sel(intensity=intensity_value)\n\n        # Stack dimensions for correlation computation\n        predicted_tuning = predicted_tuning.stack(stim_dims=other_dims)\n\n        # Compute correlation\n        corr = xr.corr(predicted_tuning, gt_tuning_da, dim='angle')\n        corr = corr.unstack('stim_dims')\n        correlations[cell_type] = corr\n\n    return correlations\n</code></pre> <pre><code>p = peak_responses(r)\n</code></pre> <pre><code>p\n</code></pre> <pre>&lt;xarray.DataArray 'responses' (network_id: 2, sample: 48, neuron: 65)&gt;\narray([[[1.2707839 , 1.1413251 , 0.87928057, ..., 0.        ,\n         0.5582776 , 1.5659437 ],\n        [1.2704179 , 1.1411365 , 0.8791765 , ..., 0.        ,\n         0.53905785, 1.5659436 ],\n        [1.7614158 , 1.6339452 , 1.3735752 , ..., 0.        ,\n         0.69133985, 2.3346248 ],\n        ...,\n        [1.2694845 , 1.1404232 , 0.8785498 , ..., 0.        ,\n         0.5668351 , 1.5659437 ],\n        [1.7603157 , 1.6335958 , 1.3731476 , ..., 0.        ,\n         0.82430005, 2.2795477 ],\n        [1.7545149 , 1.6271223 , 1.3670439 , ..., 0.        ,\n         0.7924563 , 2.2833645 ]],\n\n       [[0.2344091 , 1.8128183 , 0.35886836, ..., 0.40078512,\n         1.4728736 , 0.02466989],\n        [0.23360322, 1.807395  , 0.35886833, ..., 0.39070988,\n         1.4203595 , 0.02466989],\n        [0.75059944, 2.6100328 , 0.77915674, ..., 0.73170674,\n         3.045277  , 1.0024749 ],\n        ...,\n        [0.23270926, 1.8062077 , 0.35837454, ..., 0.39070982,\n         1.4639144 , 0.02466999],\n        [0.75134325, 2.6244059 , 0.7889573 , ..., 0.68094814,\n         3.3359861 , 0.9433924 ],\n        [0.7356812 , 2.4753177 , 0.7923856 , ..., 0.5576049 ,\n         3.2058313 , 0.9258229 ]]], dtype=float32)\nCoordinates:\n  * network_id   (network_id) int64 0 1\n  * sample       (sample) int64 0 1 2 3 4 5 6 7 8 ... 39 40 41 42 43 44 45 46 47\n  * neuron       (neuron) int64 0 1 2 3 4 5 6 7 8 ... 56 57 58 59 60 61 62 63 64\n    cell_type    (neuron) &lt;U8 'R1' 'R2' 'R3' 'R4' ... 'TmY14' 'TmY15' 'TmY18'\n    u            (neuron) int32 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0\n    v            (neuron) int32 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0\n    angle        (sample) int64 0 0 0 0 30 30 30 ... 300 300 300 330 330 330 330\n    width        (sample) int64 80 80 80 80 80 80 80 80 ... 80 80 80 80 80 80 80\n    intensity    (sample) int64 0 0 1 1 0 0 1 1 0 0 1 ... 0 1 1 0 0 1 1 0 0 1 1\n    t_stim       (sample) float64 0.2042 0.1552 0.2042 ... 0.1552 0.2042 0.1552\n    speed        (sample) int64 19 25 19 25 19 25 19 25 ... 25 19 25 19 25 19 25\n    checkpoints  (network_id) object /groups/turaga/home/lappalainenj/FlyVis/...</pre>xarray.DataArray'responses'<ul><li>network_id: 2</li><li>sample: 48</li><li>neuron: 65</li></ul><ul><li>1.271 1.141 0.8793 1.369 1.681 1.834 ... 1.188 0.0 0.5576 3.206 0.9258<pre>array([[[1.2707839 , 1.1413251 , 0.87928057, ..., 0.        ,\n         0.5582776 , 1.5659437 ],\n        [1.2704179 , 1.1411365 , 0.8791765 , ..., 0.        ,\n         0.53905785, 1.5659436 ],\n        [1.7614158 , 1.6339452 , 1.3735752 , ..., 0.        ,\n         0.69133985, 2.3346248 ],\n        ...,\n        [1.2694845 , 1.1404232 , 0.8785498 , ..., 0.        ,\n         0.5668351 , 1.5659437 ],\n        [1.7603157 , 1.6335958 , 1.3731476 , ..., 0.        ,\n         0.82430005, 2.2795477 ],\n        [1.7545149 , 1.6271223 , 1.3670439 , ..., 0.        ,\n         0.7924563 , 2.2833645 ]],\n\n       [[0.2344091 , 1.8128183 , 0.35886836, ..., 0.40078512,\n         1.4728736 , 0.02466989],\n        [0.23360322, 1.807395  , 0.35886833, ..., 0.39070988,\n         1.4203595 , 0.02466989],\n        [0.75059944, 2.6100328 , 0.77915674, ..., 0.73170674,\n         3.045277  , 1.0024749 ],\n        ...,\n        [0.23270926, 1.8062077 , 0.35837454, ..., 0.39070982,\n         1.4639144 , 0.02466999],\n        [0.75134325, 2.6244059 , 0.7889573 , ..., 0.68094814,\n         3.3359861 , 0.9433924 ],\n        [0.7356812 , 2.4753177 , 0.7923856 , ..., 0.5576049 ,\n         3.2058313 , 0.9258229 ]]], dtype=float32)</pre></li><li>Coordinates: (12)<ul><li>network_id(network_id)int640 1<pre>array([0, 1])</pre></li><li>sample(sample)int640 1 2 3 4 5 6 ... 42 43 44 45 46 47<pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])</pre></li><li>neuron(neuron)int640 1 2 3 4 5 6 ... 59 60 61 62 63 64<pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64])</pre></li><li>cell_type(neuron)&lt;U8'R1' 'R2' 'R3' ... 'TmY15' 'TmY18'<pre>array(['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'L1', 'L2', 'L3',\n       'L4', 'L5', 'Lawf1', 'Lawf2', 'Am', 'C2', 'C3', 'CT1(Lo1)',\n       'CT1(M10)', 'Mi1', 'Mi2', 'Mi3', 'Mi4', 'Mi9', 'Mi10', 'Mi11',\n       'Mi12', 'Mi13', 'Mi14', 'Mi15', 'T1', 'T2', 'T2a', 'T3', 'T4a',\n       'T4b', 'T4c', 'T4d', 'T5a', 'T5b', 'T5c', 'T5d', 'Tm1', 'Tm2',\n       'Tm3', 'Tm4', 'Tm5Y', 'Tm5a', 'Tm5b', 'Tm5c', 'Tm9', 'Tm16',\n       'Tm20', 'Tm28', 'Tm30', 'TmY3', 'TmY4', 'TmY5a', 'TmY9', 'TmY10',\n       'TmY13', 'TmY14', 'TmY15', 'TmY18'], dtype='&lt;U8')</pre></li><li>u(neuron)int320 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype=int32)</pre></li><li>v(neuron)int320 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype=int32)</pre></li><li>angle(sample)int640 0 0 0 30 ... 300 330 330 330 330<pre>array([  0,   0,   0,   0,  30,  30,  30,  30,  60,  60,  60,  60,  90,\n        90,  90,  90, 120, 120, 120, 120, 150, 150, 150, 150, 180, 180,\n       180, 180, 210, 210, 210, 210, 240, 240, 240, 240, 270, 270, 270,\n       270, 300, 300, 300, 300, 330, 330, 330, 330])</pre></li><li>width(sample)int6480 80 80 80 80 ... 80 80 80 80 80<pre>array([80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80])</pre></li><li>intensity(sample)int640 0 1 1 0 0 1 1 ... 0 0 1 1 0 0 1 1<pre>array([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n       0, 0, 1, 1])</pre></li><li>t_stim(sample)float640.2042 0.1552 ... 0.2042 0.1552<pre>array([0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241])</pre></li><li>speed(sample)int6419 25 19 25 19 ... 25 19 25 19 25<pre>array([19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19,\n       25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25,\n       19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25])</pre></li><li>checkpoints(network_id)object/groups/turaga/home/lappalainenj...<pre>array([PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'),\n       PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000')],\n      dtype=object)</pre></li></ul></li><li>Indexes: (3)<ul><li>network_idPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='network_id'))</pre></li><li>samplePandasIndex<pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],\n      dtype='int64', name='sample'))</pre></li><li>neuronPandasIndex<pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64],\n      dtype='int64', name='neuron'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <pre><code>def get_groundtruth_tuning_curves(cell_types, angles):\n    \"\"\"\n    Retrieves the ground truth tuning curves for the specified cell types.\n    Optionally interpolates the curves to match the provided angles.\n    \"\"\"\n    gt_angles = np.arange(0, 360, 30)\n    tuning_curves = []\n\n    for cell_type in cell_types:\n        gt_tuning = groundtruth_utils.tuning_curves[cell_type]\n        interp_func = interp1d(gt_angles, gt_tuning, kind='cubic', fill_value=\"extrapolate\")\n        gt_tuning = interp_func(angles)\n        tuning_curves.append(gt_tuning)\n\n    dataset = xr.DataArray(\n        np.array(tuning_curves), \n        dims=['neuron', 'angle'],\n        coords={'cell_type': (\"neuron\", cell_types), 'angle': angles}\n       )\n\n    return dataset\n</code></pre> <pre><code>def maisak_tuning_curve_correlation(dataset):\n    peak_responses = peak_responses(dataset)\n    gt_tuning = get_groundtruth_tuning_curves(\n        [\"T4a\", \"T4b\", \"T4c\", \"T4d\", \"T5a\", \"T5b\", \"T5c\", \"T5d\"], np.arange(0, 360, 30)\n    )\n\n    tuning = (\n        peak_responses.set_index(sample=[\"angle\", \"intensity\", \"width\", \"speed\"])\n        .unstack(\"sample\")\n        .fillna(0.0)\n        .custom.where(\n            cell_type=[\"T4a\", \"T4b\", \"T4c\", \"T4d\", \"T5a\", \"T5b\", \"T5c\", \"T5d\"]\n        )\n    )\n\n    # reset the neuron axis to make it compatible with the ground truth tuning curves\n    tuning[\"neuron\"] = np.arange(tuning.coords[\"neuron\"].size)\n\n    correlation = xr.corr(tuning, gt_tuning, dim=\"angle\")\n    correlation = correlation.isel(np.abs(correlation).argmax(dim=(\"speed\", \"width\")))\n    return correlation\n    # T4_correlation = correlation.custom.where(\n    #     cell_type=[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], intensity=1\n    # ).squeeze()\n    # T5_correlation = correlation.custom.where(\n    #     cell_type=[\"T5a\", \"T5b\", \"T5c\", \"T5d\"], intensity=0\n    # ).squeeze()\n    # return {\"T4\": T4_correlation, \"T5\": T5_correlation}\n</code></pre> <pre><code>maisak_tuning_curve_correlation(p)\n</code></pre> <pre>&lt;xarray.DataArray (network_id: 2, neuron: 8, intensity: 2)&gt;\narray([[[-0.52199455,  0.9361876 ],\n        [-0.23798394,  0.70642713],\n        [-0.38580189,  0.55304839],\n        [-0.67519017,  0.8633687 ],\n        [ 0.84585357, -0.38946799],\n        [ 0.90461177, -0.28886943],\n        [ 0.94923338, -0.40776379],\n        [ 0.88766108, -0.45659227]],\n\n       [[-0.46044535,  0.94221535],\n        [-0.17763585,  0.72580955],\n        [-0.29186963,  0.8033357 ],\n        [-0.36820605,  0.87244034],\n        [ 0.47247743,  0.67372036],\n        [ 0.86556892,  0.89139723],\n        [ 0.82270961,  0.75211954],\n        [ 0.91188945,  0.77480968]]])\nCoordinates:\n  * intensity    (intensity) int64 0 1\n    width        (network_id, neuron, intensity) int64 80 80 80 80 ... 80 80 80\n    speed        (network_id, neuron, intensity) int64 19 19 19 19 ... 19 25 25\n  * network_id   (network_id) int64 0 1\n  * neuron       (neuron) int64 0 1 2 3 4 5 6 7\n    cell_type    (neuron) &lt;U8 'T4a' 'T4b' 'T4c' 'T4d' 'T5a' 'T5b' 'T5c' 'T5d'\n    u            (neuron) int32 0 0 0 0 0 0 0 0\n    v            (neuron) int32 0 0 0 0 0 0 0 0\n    checkpoints  (network_id) object /groups/turaga/home/lappalainenj/FlyVis/...</pre>xarray.DataArray<ul><li>network_id: 2</li><li>neuron: 8</li><li>intensity: 2</li></ul><ul><li>-0.522 0.9362 -0.238 0.7064 -0.3858 ... 0.8227 0.7521 0.9119 0.7748<pre>array([[[-0.52199455,  0.9361876 ],\n        [-0.23798394,  0.70642713],\n        [-0.38580189,  0.55304839],\n        [-0.67519017,  0.8633687 ],\n        [ 0.84585357, -0.38946799],\n        [ 0.90461177, -0.28886943],\n        [ 0.94923338, -0.40776379],\n        [ 0.88766108, -0.45659227]],\n\n       [[-0.46044535,  0.94221535],\n        [-0.17763585,  0.72580955],\n        [-0.29186963,  0.8033357 ],\n        [-0.36820605,  0.87244034],\n        [ 0.47247743,  0.67372036],\n        [ 0.86556892,  0.89139723],\n        [ 0.82270961,  0.75211954],\n        [ 0.91188945,  0.77480968]]])</pre></li><li>Coordinates: (9)<ul><li>intensity(intensity)int640 1<pre>array([0, 1])</pre></li><li>width(network_id, neuron, intensity)int6480 80 80 80 80 ... 80 80 80 80 80<pre>array([[[80, 80],\n        [80, 80],\n        [80, 80],\n        [80, 80],\n        [80, 80],\n        [80, 80],\n        [80, 80],\n        [80, 80]],\n\n       [[80, 80],\n        [80, 80],\n        [80, 80],\n        [80, 80],\n        [80, 80],\n        [80, 80],\n        [80, 80],\n        [80, 80]]])</pre></li><li>speed(network_id, neuron, intensity)int6419 19 19 19 19 ... 19 25 19 25 25<pre>array([[[19, 19],\n        [19, 19],\n        [19, 19],\n        [19, 19],\n        [19, 19],\n        [19, 19],\n        [19, 19],\n        [19, 19]],\n\n       [[19, 19],\n        [19, 19],\n        [19, 19],\n        [25, 19],\n        [19, 19],\n        [25, 19],\n        [25, 19],\n        [25, 25]]])</pre></li><li>network_id(network_id)int640 1<pre>array([0, 1])</pre></li><li>neuron(neuron)int640 1 2 3 4 5 6 7<pre>array([0, 1, 2, 3, 4, 5, 6, 7])</pre></li><li>cell_type(neuron)&lt;U8'T4a' 'T4b' 'T4c' ... 'T5c' 'T5d'<pre>array(['T4a', 'T4b', 'T4c', 'T4d', 'T5a', 'T5b', 'T5c', 'T5d'],\n      dtype='&lt;U8')</pre></li><li>u(neuron)int320 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)</pre></li><li>v(neuron)int320 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)</pre></li><li>checkpoints(network_id)object/groups/turaga/home/lappalainenj...<pre>array([PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'),\n       PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000')],\n      dtype=object)</pre></li></ul></li><li>Indexes: (3)<ul><li>intensityPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='intensity'))</pre></li><li>network_idPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='network_id'))</pre></li><li>neuronPandasIndex<pre>PandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64', name='neuron'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <pre><code>np.abs(T5_correlation).reduce(np.max, dim=\"speed\")\n</code></pre> <pre>&lt;xarray.DataArray (network_id: 2, neuron: 4, intensity: 1, width: 1)&gt;\narray([[[[0.84585357]],\n\n        [[0.90461177]],\n\n        [[0.94923338]],\n\n        [[0.88766108]]],\n\n\n       [[[0.47247743]],\n\n        [[0.86556892]],\n\n        [[0.82270961]],\n\n        [[0.91188945]]]])\nCoordinates:\n  * intensity    (intensity) int64 0\n  * width        (width) int64 80\n  * network_id   (network_id) int64 0 1\n  * neuron       (neuron) int64 4 5 6 7\n    cell_type    (neuron) &lt;U8 'T5a' 'T5b' 'T5c' 'T5d'\n    u            (neuron) int32 0 0 0 0\n    v            (neuron) int32 0 0 0 0\n    checkpoints  (network_id) object /groups/turaga/home/lappalainenj/FlyVis/...</pre>xarray.DataArray<ul><li>network_id: 2</li><li>neuron: 4</li><li>intensity: 1</li><li>width: 1</li></ul><ul><li>0.8459 0.9046 0.9492 0.8877 0.4725 0.8656 0.8227 0.9119<pre>array([[[[0.84585357]],\n\n        [[0.90461177]],\n\n        [[0.94923338]],\n\n        [[0.88766108]]],\n\n\n       [[[0.47247743]],\n\n        [[0.86556892]],\n\n        [[0.82270961]],\n\n        [[0.91188945]]]])</pre></li><li>Coordinates: (8)<ul><li>intensity(intensity)int640<pre>array([0])</pre></li><li>width(width)int6480<pre>array([80])</pre></li><li>network_id(network_id)int640 1<pre>array([0, 1])</pre></li><li>neuron(neuron)int644 5 6 7<pre>array([4, 5, 6, 7])</pre></li><li>cell_type(neuron)&lt;U8'T5a' 'T5b' 'T5c' 'T5d'<pre>array(['T5a', 'T5b', 'T5c', 'T5d'], dtype='&lt;U8')</pre></li><li>u(neuron)int320 0 0 0<pre>array([0, 0, 0, 0], dtype=int32)</pre></li><li>v(neuron)int320 0 0 0<pre>array([0, 0, 0, 0], dtype=int32)</pre></li><li>checkpoints(network_id)object/groups/turaga/home/lappalainenj...<pre>array([PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'),\n       PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000')],\n      dtype=object)</pre></li></ul></li><li>Indexes: (4)<ul><li>intensityPandasIndex<pre>PandasIndex(Index([0], dtype='int64', name='intensity'))</pre></li><li>widthPandasIndex<pre>PandasIndex(Index([80], dtype='int64', name='width'))</pre></li><li>network_idPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='network_id'))</pre></li><li>neuronPandasIndex<pre>PandasIndex(Index([4, 5, 6, 7], dtype='int64', name='neuron'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <pre><code>angles = pd.unique(tuning.coords['angle'])\n</code></pre> <pre><code>get_groundtruth_tuning_curves(['T4a', 'T4b', 'T4c', 'T4d', 'T5a', 'T5b', 'T5c', 'T5d'], angles)\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nTypeError                                 Traceback (most recent call last)\n\nInput In [469], in &lt;cell line: 1&gt;()\n----&gt; 1 get_groundtruth_tuning_curves(['T4a', 'T4b', 'T4c', 'T4d', 'T5a', 'T5b', 'T5c', 'T5d'], angles)\n\n\nInput In [468], in get_groundtruth_tuning_curves(cell_types, angles)\n     14     gt_tuning = interp_func(angles)\n     15     tuning_curves.append(gt_tuning)\n---&gt; 17 dataset = xr.Dataset(tuning_curves, \n     18                      coords={'cell_type': cell_types, 'angle': angles}\n     19                      )\n     21 return dataset\n\n\nFile ~/miniconda3/envs/flyvision/lib/python3.9/site-packages/xarray/core/dataset.py:643, in Dataset.__init__(self, data_vars, coords, attrs)\n    640 if coords is None:\n    641     coords = {}\n--&gt; 643 both_data_and_coords = set(data_vars) &amp; set(coords)\n    644 if both_data_and_coords:\n    645     raise ValueError(\n    646         f\"variables {both_data_and_coords!r} are found in both data_vars and coords\"\n    647     )\n\n\nTypeError: unhashable type: 'numpy.ndarray'\n</code></pre> <pre><code>p\n</code></pre> <pre>&lt;xarray.DataArray 'responses' (network_id: 2, sample: 48, neuron: 65)&gt;\narray([[[1.2707839 , 1.1413251 , 0.87928057, ..., 0.        ,\n         0.5582776 , 1.5659437 ],\n        [1.2704179 , 1.1411365 , 0.8791765 , ..., 0.        ,\n         0.53905785, 1.5659436 ],\n        [1.7614158 , 1.6339452 , 1.3735752 , ..., 0.        ,\n         0.69133985, 2.3346248 ],\n        ...,\n        [1.2694845 , 1.1404232 , 0.8785498 , ..., 0.        ,\n         0.5668351 , 1.5659437 ],\n        [1.7603157 , 1.6335958 , 1.3731476 , ..., 0.        ,\n         0.82430005, 2.2795477 ],\n        [1.7545149 , 1.6271223 , 1.3670439 , ..., 0.        ,\n         0.7924563 , 2.2833645 ]],\n\n       [[0.2344091 , 1.8128183 , 0.35886836, ..., 0.40078512,\n         1.4728736 , 0.02466989],\n        [0.23360322, 1.807395  , 0.35886833, ..., 0.39070988,\n         1.4203595 , 0.02466989],\n        [0.75059944, 2.6100328 , 0.77915674, ..., 0.73170674,\n         3.045277  , 1.0024749 ],\n        ...,\n        [0.23270926, 1.8062077 , 0.35837454, ..., 0.39070982,\n         1.4639144 , 0.02466999],\n        [0.75134325, 2.6244059 , 0.7889573 , ..., 0.68094814,\n         3.3359861 , 0.9433924 ],\n        [0.7356812 , 2.4753177 , 0.7923856 , ..., 0.5576049 ,\n         3.2058313 , 0.9258229 ]]], dtype=float32)\nCoordinates:\n  * network_id   (network_id) int64 0 1\n  * sample       (sample) int64 0 1 2 3 4 5 6 7 8 ... 39 40 41 42 43 44 45 46 47\n  * neuron       (neuron) int64 0 1 2 3 4 5 6 7 8 ... 56 57 58 59 60 61 62 63 64\n    cell_type    (neuron) &lt;U8 'R1' 'R2' 'R3' 'R4' ... 'TmY14' 'TmY15' 'TmY18'\n    u            (neuron) int32 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0\n    v            (neuron) int32 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0\n    angle        (sample) int64 0 0 0 0 30 30 30 ... 300 300 300 330 330 330 330\n    width        (sample) int64 80 80 80 80 80 80 80 80 ... 80 80 80 80 80 80 80\n    intensity    (sample) int64 0 0 1 1 0 0 1 1 0 0 1 ... 0 1 1 0 0 1 1 0 0 1 1\n    t_stim       (sample) float64 0.2042 0.1552 0.2042 ... 0.1552 0.2042 0.1552\n    speed        (sample) int64 19 25 19 25 19 25 19 25 ... 25 19 25 19 25 19 25\n    checkpoints  (network_id) object /groups/turaga/home/lappalainenj/FlyVis/...</pre>xarray.DataArray'responses'<ul><li>network_id: 2</li><li>sample: 48</li><li>neuron: 65</li></ul><ul><li>1.271 1.141 0.8793 1.369 1.681 1.834 ... 1.188 0.0 0.5576 3.206 0.9258<pre>array([[[1.2707839 , 1.1413251 , 0.87928057, ..., 0.        ,\n         0.5582776 , 1.5659437 ],\n        [1.2704179 , 1.1411365 , 0.8791765 , ..., 0.        ,\n         0.53905785, 1.5659436 ],\n        [1.7614158 , 1.6339452 , 1.3735752 , ..., 0.        ,\n         0.69133985, 2.3346248 ],\n        ...,\n        [1.2694845 , 1.1404232 , 0.8785498 , ..., 0.        ,\n         0.5668351 , 1.5659437 ],\n        [1.7603157 , 1.6335958 , 1.3731476 , ..., 0.        ,\n         0.82430005, 2.2795477 ],\n        [1.7545149 , 1.6271223 , 1.3670439 , ..., 0.        ,\n         0.7924563 , 2.2833645 ]],\n\n       [[0.2344091 , 1.8128183 , 0.35886836, ..., 0.40078512,\n         1.4728736 , 0.02466989],\n        [0.23360322, 1.807395  , 0.35886833, ..., 0.39070988,\n         1.4203595 , 0.02466989],\n        [0.75059944, 2.6100328 , 0.77915674, ..., 0.73170674,\n         3.045277  , 1.0024749 ],\n        ...,\n        [0.23270926, 1.8062077 , 0.35837454, ..., 0.39070982,\n         1.4639144 , 0.02466999],\n        [0.75134325, 2.6244059 , 0.7889573 , ..., 0.68094814,\n         3.3359861 , 0.9433924 ],\n        [0.7356812 , 2.4753177 , 0.7923856 , ..., 0.5576049 ,\n         3.2058313 , 0.9258229 ]]], dtype=float32)</pre></li><li>Coordinates: (12)<ul><li>network_id(network_id)int640 1<pre>array([0, 1])</pre></li><li>sample(sample)int640 1 2 3 4 5 6 ... 42 43 44 45 46 47<pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])</pre></li><li>neuron(neuron)int640 1 2 3 4 5 6 ... 59 60 61 62 63 64<pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64])</pre></li><li>cell_type(neuron)&lt;U8'R1' 'R2' 'R3' ... 'TmY15' 'TmY18'<pre>array(['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'L1', 'L2', 'L3',\n       'L4', 'L5', 'Lawf1', 'Lawf2', 'Am', 'C2', 'C3', 'CT1(Lo1)',\n       'CT1(M10)', 'Mi1', 'Mi2', 'Mi3', 'Mi4', 'Mi9', 'Mi10', 'Mi11',\n       'Mi12', 'Mi13', 'Mi14', 'Mi15', 'T1', 'T2', 'T2a', 'T3', 'T4a',\n       'T4b', 'T4c', 'T4d', 'T5a', 'T5b', 'T5c', 'T5d', 'Tm1', 'Tm2',\n       'Tm3', 'Tm4', 'Tm5Y', 'Tm5a', 'Tm5b', 'Tm5c', 'Tm9', 'Tm16',\n       'Tm20', 'Tm28', 'Tm30', 'TmY3', 'TmY4', 'TmY5a', 'TmY9', 'TmY10',\n       'TmY13', 'TmY14', 'TmY15', 'TmY18'], dtype='&lt;U8')</pre></li><li>u(neuron)int320 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype=int32)</pre></li><li>v(neuron)int320 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype=int32)</pre></li><li>angle(sample)int640 0 0 0 30 ... 300 330 330 330 330<pre>array([  0,   0,   0,   0,  30,  30,  30,  30,  60,  60,  60,  60,  90,\n        90,  90,  90, 120, 120, 120, 120, 150, 150, 150, 150, 180, 180,\n       180, 180, 210, 210, 210, 210, 240, 240, 240, 240, 270, 270, 270,\n       270, 300, 300, 300, 300, 330, 330, 330, 330])</pre></li><li>width(sample)int6480 80 80 80 80 ... 80 80 80 80 80<pre>array([80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80])</pre></li><li>intensity(sample)int640 0 1 1 0 0 1 1 ... 0 0 1 1 0 0 1 1<pre>array([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n       0, 0, 1, 1])</pre></li><li>t_stim(sample)float640.2042 0.1552 ... 0.2042 0.1552<pre>array([0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241])</pre></li><li>speed(sample)int6419 25 19 25 19 ... 25 19 25 19 25<pre>array([19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19,\n       25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25,\n       19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25])</pre></li><li>checkpoints(network_id)object/groups/turaga/home/lappalainenj...<pre>array([PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'),\n       PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000')],\n      dtype=object)</pre></li></ul></li><li>Indexes: (3)<ul><li>network_idPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='network_id'))</pre></li><li>samplePandasIndex<pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],\n      dtype='int64', name='sample'))</pre></li><li>neuronPandasIndex<pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64],\n      dtype='int64', name='neuron'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <pre><code>dsi = direction_selectivity_index(r, average=False)\n</code></pre> <pre><code>a = dsi_correlation_to_known(dsi)\n</code></pre> <pre><code>a\n</code></pre> <pre>&lt;xarray.DataArray (network_id: 2, intensity: 2, speed: 2)&gt;\narray([[[0.65186982, 0.62478615],\n        [0.5719433 , 0.52512768]],\n\n       [[0.49935473, 0.40968303],\n        [0.57014632, 0.57931699]]])\nCoordinates:\n    width        int64 80\n  * intensity    (intensity) int64 0 1\n  * speed        (speed) int64 19 25\n  * network_id   (network_id) int64 0 1\n    checkpoints  (network_id) object /groups/turaga/home/lappalainenj/FlyVis/...</pre>xarray.DataArray<ul><li>network_id: 2</li><li>intensity: 2</li><li>speed: 2</li></ul><ul><li>0.6519 0.6248 0.5719 0.5251 0.4994 0.4097 0.5701 0.5793<pre>array([[[0.65186982, 0.62478615],\n        [0.5719433 , 0.52512768]],\n\n       [[0.49935473, 0.40968303],\n        [0.57014632, 0.57931699]]])</pre></li><li>Coordinates: (5)<ul><li>width()int6480<pre>array(80)</pre></li><li>intensity(intensity)int640 1<pre>array([0, 1])</pre></li><li>speed(speed)int6419 25<pre>array([19, 25])</pre></li><li>network_id(network_id)int640 1<pre>array([0, 1])</pre></li><li>checkpoints(network_id)object/groups/turaga/home/lappalainenj...<pre>array([PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'),\n       PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000')],\n      dtype=object)</pre></li></ul></li><li>Indexes: (3)<ul><li>intensityPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='intensity'))</pre></li><li>speedPandasIndex<pre>PandasIndex(Index([19, 25], dtype='int64', name='speed'))</pre></li><li>network_idPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='network_id'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <pre><code>peak_responses_angular(r)\n</code></pre> <pre>&lt;xarray.DataArray 'responses' (network_id: 2, sample: 48, neuron: 65)&gt;\narray([[[1.2707839 +0.j        , 1.14132512+0.j        ,\n         0.87928057+0.j        , ..., 0.        +0.j        ,\n         0.55827761+0.j        , 1.56594372+0.j        ],\n        [1.27041793+0.j        , 1.14113653+0.j        ,\n         0.8791765 +0.j        , ..., 0.        +0.j        ,\n         0.53905785+0.j        , 1.5659436 +0.j        ],\n        [1.76141584+0.j        , 1.63394523+0.j        ,\n         1.37357521+0.j        , ..., 0.        +0.j        ,\n         0.69133985+0.j        , 2.33462477+0.j        ],\n        ...,\n        [1.09940584-0.63474226j, 0.98763544-0.57021159j,\n         0.76084646-0.43927491j, ..., 0.        +0.j        ,\n         0.4908936 -0.28341755j, 1.35614704-0.78297186j],\n        [1.52447808-0.88015783j, 1.41473548-0.81679791j,\n         1.18918071-0.6865738j , ..., 0.        +0.j        ,\n         0.71386478-0.41215003j, 1.97414621-1.13977385j],\n        [1.5194545 -0.87725747j, 1.40912923-0.81356114j,\n         1.1838947 -0.68352193j, ..., 0.        +0.j        ,\n         0.68628731-0.39622816j, 1.97745169-1.14168227j]],\n\n       [[0.23440909+0.j        , 1.81281829+0.j        ,\n         0.35886836+0.j        , ..., 0.40078512+0.j        ,\n         1.47287357+0.j        , 0.02466989+0.j        ],\n        [0.23360322+0.j        , 1.80739498+0.j        ,\n         0.35886833+0.j        , ..., 0.39070988+0.j        ,\n         1.42035949+0.j        , 0.02466989+0.j        ],\n        [0.75059944+0.j        , 2.6100328 +0.j        ,\n         0.77915674+0.j        , ..., 0.73170674+0.j        ,\n         3.04527712+0.j        , 1.0024749 +0.j        ],\n        ...,\n        [0.20153213-0.11635463j, 1.56422172-0.90310383j,\n         0.31036145-0.17918727j, ..., 0.33836463-0.19535491j,\n         1.26778705-0.7319572j , 0.02136484-0.01233499j],\n        [0.65068234-0.37567163j, 2.27280215-1.31220293j,\n         0.68325706-0.39447865j, ..., 0.58971839-0.34047407j,\n         2.88904874-1.66799307j, 0.81700178-0.4716962j ],\n        [0.63711859-0.36784059j, 2.14368803-1.23765886j,\n         0.68622604-0.39619279j, ..., 0.48290002-0.27880245j,\n         2.77633134-1.60291564j, 0.80178616-0.46291146j]]])\nCoordinates:\n  * network_id   (network_id) int64 0 1\n  * sample       (sample) int64 0 1 2 3 4 5 6 7 8 ... 39 40 41 42 43 44 45 46 47\n  * neuron       (neuron) int64 0 1 2 3 4 5 6 7 8 ... 56 57 58 59 60 61 62 63 64\n    cell_type    (neuron) &lt;U8 'R1' 'R2' 'R3' 'R4' ... 'TmY14' 'TmY15' 'TmY18'\n    u            (neuron) int32 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0\n    v            (neuron) int32 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0\n    angle        (sample) int64 0 0 0 0 30 30 30 ... 300 300 300 330 330 330 330\n    width        (sample) int64 80 80 80 80 80 80 80 80 ... 80 80 80 80 80 80 80\n    intensity    (sample) int64 0 0 1 1 0 0 1 1 0 0 1 ... 0 1 1 0 0 1 1 0 0 1 1\n    t_stim       (sample) float64 0.2042 0.1552 0.2042 ... 0.1552 0.2042 0.1552\n    speed        (sample) int64 19 25 19 25 19 25 19 25 ... 25 19 25 19 25 19 25\n    checkpoints  (network_id) object /groups/turaga/home/lappalainenj/FlyVis/...</pre>xarray.DataArray'responses'<ul><li>network_id: 2</li><li>sample: 48</li><li>neuron: 65</li></ul><ul><li>(1.2707839012145996+0j) ... (0.8017861626237669-0.4629114568233494j)<pre>array([[[1.2707839 +0.j        , 1.14132512+0.j        ,\n         0.87928057+0.j        , ..., 0.        +0.j        ,\n         0.55827761+0.j        , 1.56594372+0.j        ],\n        [1.27041793+0.j        , 1.14113653+0.j        ,\n         0.8791765 +0.j        , ..., 0.        +0.j        ,\n         0.53905785+0.j        , 1.5659436 +0.j        ],\n        [1.76141584+0.j        , 1.63394523+0.j        ,\n         1.37357521+0.j        , ..., 0.        +0.j        ,\n         0.69133985+0.j        , 2.33462477+0.j        ],\n        ...,\n        [1.09940584-0.63474226j, 0.98763544-0.57021159j,\n         0.76084646-0.43927491j, ..., 0.        +0.j        ,\n         0.4908936 -0.28341755j, 1.35614704-0.78297186j],\n        [1.52447808-0.88015783j, 1.41473548-0.81679791j,\n         1.18918071-0.6865738j , ..., 0.        +0.j        ,\n         0.71386478-0.41215003j, 1.97414621-1.13977385j],\n        [1.5194545 -0.87725747j, 1.40912923-0.81356114j,\n         1.1838947 -0.68352193j, ..., 0.        +0.j        ,\n         0.68628731-0.39622816j, 1.97745169-1.14168227j]],\n\n       [[0.23440909+0.j        , 1.81281829+0.j        ,\n         0.35886836+0.j        , ..., 0.40078512+0.j        ,\n         1.47287357+0.j        , 0.02466989+0.j        ],\n        [0.23360322+0.j        , 1.80739498+0.j        ,\n         0.35886833+0.j        , ..., 0.39070988+0.j        ,\n         1.42035949+0.j        , 0.02466989+0.j        ],\n        [0.75059944+0.j        , 2.6100328 +0.j        ,\n         0.77915674+0.j        , ..., 0.73170674+0.j        ,\n         3.04527712+0.j        , 1.0024749 +0.j        ],\n        ...,\n        [0.20153213-0.11635463j, 1.56422172-0.90310383j,\n         0.31036145-0.17918727j, ..., 0.33836463-0.19535491j,\n         1.26778705-0.7319572j , 0.02136484-0.01233499j],\n        [0.65068234-0.37567163j, 2.27280215-1.31220293j,\n         0.68325706-0.39447865j, ..., 0.58971839-0.34047407j,\n         2.88904874-1.66799307j, 0.81700178-0.4716962j ],\n        [0.63711859-0.36784059j, 2.14368803-1.23765886j,\n         0.68622604-0.39619279j, ..., 0.48290002-0.27880245j,\n         2.77633134-1.60291564j, 0.80178616-0.46291146j]]])</pre></li><li>Coordinates: (12)<ul><li>network_id(network_id)int640 1<pre>array([0, 1])</pre></li><li>sample(sample)int640 1 2 3 4 5 6 ... 42 43 44 45 46 47<pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])</pre></li><li>neuron(neuron)int640 1 2 3 4 5 6 ... 59 60 61 62 63 64<pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64])</pre></li><li>cell_type(neuron)&lt;U8'R1' 'R2' 'R3' ... 'TmY15' 'TmY18'<pre>array(['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'L1', 'L2', 'L3',\n       'L4', 'L5', 'Lawf1', 'Lawf2', 'Am', 'C2', 'C3', 'CT1(Lo1)',\n       'CT1(M10)', 'Mi1', 'Mi2', 'Mi3', 'Mi4', 'Mi9', 'Mi10', 'Mi11',\n       'Mi12', 'Mi13', 'Mi14', 'Mi15', 'T1', 'T2', 'T2a', 'T3', 'T4a',\n       'T4b', 'T4c', 'T4d', 'T5a', 'T5b', 'T5c', 'T5d', 'Tm1', 'Tm2',\n       'Tm3', 'Tm4', 'Tm5Y', 'Tm5a', 'Tm5b', 'Tm5c', 'Tm9', 'Tm16',\n       'Tm20', 'Tm28', 'Tm30', 'TmY3', 'TmY4', 'TmY5a', 'TmY9', 'TmY10',\n       'TmY13', 'TmY14', 'TmY15', 'TmY18'], dtype='&lt;U8')</pre></li><li>u(neuron)int320 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype=int32)</pre></li><li>v(neuron)int320 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype=int32)</pre></li><li>angle(sample)int640 0 0 0 30 ... 300 330 330 330 330<pre>array([  0,   0,   0,   0,  30,  30,  30,  30,  60,  60,  60,  60,  90,\n        90,  90,  90, 120, 120, 120, 120, 150, 150, 150, 150, 180, 180,\n       180, 180, 210, 210, 210, 210, 240, 240, 240, 240, 270, 270, 270,\n       270, 300, 300, 300, 300, 330, 330, 330, 330])</pre></li><li>width(sample)int6480 80 80 80 80 ... 80 80 80 80 80<pre>array([80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80])</pre></li><li>intensity(sample)int640 0 1 1 0 0 1 1 ... 0 0 1 1 0 0 1 1<pre>array([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n       0, 0, 1, 1])</pre></li><li>t_stim(sample)float640.2042 0.1552 ... 0.2042 0.1552<pre>array([0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241])</pre></li><li>speed(sample)int6419 25 19 25 19 ... 25 19 25 19 25<pre>array([19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19,\n       25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25,\n       19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25])</pre></li><li>checkpoints(network_id)object/groups/turaga/home/lappalainenj...<pre>array([PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'),\n       PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000')],\n      dtype=object)</pre></li></ul></li><li>Indexes: (3)<ul><li>network_idPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='network_id'))</pre></li><li>samplePandasIndex<pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],\n      dtype='int64', name='sample'))</pre></li><li>neuronPandasIndex<pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64],\n      dtype='int64', name='neuron'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <pre><code>plot_T4_tuning(r)\n</code></pre> <pre><code>plot_T5_tuning(r)\n</code></pre> <pre><code>q = plot_angular_tuning(r, cell_type=\"T4c\", intensity=1,  average_models=False)\n</code></pre> <pre><code>r\n</code></pre> <pre>&lt;xarray.Dataset&gt;\nDimensions:      (sample: 48, frame: 440, channel: 1, hex_pixel: 721,\n                  network_id: 2, neuron: 65)\nCoordinates: (12/18)\n  * network_id   (network_id) int64 0 1\n  * sample       (sample) int64 0 1 2 3 4 5 6 7 8 ... 39 40 41 42 43 44 45 46 47\n  * frame        (frame) int64 0 1 2 3 4 5 6 7 ... 433 434 435 436 437 438 439\n    time         (frame) float64 -1.0 -0.995 -0.99 -0.985 ... 1.185 1.19 1.195\n  * channel      (channel) int64 0\n  * hex_pixel    (hex_pixel) int64 0 1 2 3 4 5 6 ... 714 715 716 717 718 719 720\n    ...           ...\n    angle        (sample) int64 0 0 0 0 30 30 30 ... 300 300 300 330 330 330 330\n    width        (sample) int64 80 80 80 80 80 80 80 80 ... 80 80 80 80 80 80 80\n    intensity    (sample) int64 0 0 1 1 0 0 1 1 0 0 1 ... 0 1 1 0 0 1 1 0 0 1 1\n    t_stim       (sample) float64 0.2042 0.1552 0.2042 ... 0.1552 0.2042 0.1552\n    speed        (sample) int64 19 25 19 25 19 25 19 25 ... 25 19 25 19 25 19 25\n    checkpoints  (network_id) object /groups/turaga/home/lappalainenj/FlyVis/...\nData variables:\n    stimulus     (sample, frame, channel, hex_pixel) float64 0.5 0.5 ... nan nan\n    responses    (network_id, sample, frame, neuron) float32 1.27 1.141 ... nan\nAttributes:\n    config:          {'offsets': (-5, 5), 'intensities': [0, 1], 'speeds': [1...\n    network_config:  {'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>sample: 48</li><li>frame: 440</li><li>channel: 1</li><li>hex_pixel: 721</li><li>network_id: 2</li><li>neuron: 65</li></ul></li><li>Coordinates: (18)<ul><li>network_id(network_id)int640 1<pre>array([0, 1])</pre></li><li>sample(sample)int640 1 2 3 4 5 6 ... 42 43 44 45 46 47<pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47])</pre></li><li>frame(frame)int640 1 2 3 4 5 ... 435 436 437 438 439<pre>array([  0,   1,   2, ..., 437, 438, 439])</pre></li><li>time(frame)float64-1.0 -0.995 -0.99 ... 1.19 1.195<pre>array([-1.   , -0.995, -0.99 , -0.985, -0.98 , -0.975, -0.97 , -0.965,\n       -0.96 , -0.955, -0.95 , -0.945, -0.94 , -0.935, -0.93 , -0.925,\n       -0.92 , -0.915, -0.91 , -0.905, -0.9  , -0.895, -0.89 , -0.885,\n       -0.88 , -0.875, -0.87 , -0.865, -0.86 , -0.855, -0.85 , -0.845,\n       -0.84 , -0.835, -0.83 , -0.825, -0.82 , -0.815, -0.81 , -0.805,\n       -0.8  , -0.795, -0.79 , -0.785, -0.78 , -0.775, -0.77 , -0.765,\n       -0.76 , -0.755, -0.75 , -0.745, -0.74 , -0.735, -0.73 , -0.725,\n       -0.72 , -0.715, -0.71 , -0.705, -0.7  , -0.695, -0.69 , -0.685,\n       -0.68 , -0.675, -0.67 , -0.665, -0.66 , -0.655, -0.65 , -0.645,\n       -0.64 , -0.635, -0.63 , -0.625, -0.62 , -0.615, -0.61 , -0.605,\n       -0.6  , -0.595, -0.59 , -0.585, -0.58 , -0.575, -0.57 , -0.565,\n       -0.56 , -0.555, -0.55 , -0.545, -0.54 , -0.535, -0.53 , -0.525,\n       -0.52 , -0.515, -0.51 , -0.505, -0.5  , -0.495, -0.49 , -0.485,\n       -0.48 , -0.475, -0.47 , -0.465, -0.46 , -0.455, -0.45 , -0.445,\n       -0.44 , -0.435, -0.43 , -0.425, -0.42 , -0.415, -0.41 , -0.405,\n       -0.4  , -0.395, -0.39 , -0.385, -0.38 , -0.375, -0.37 , -0.365,\n       -0.36 , -0.355, -0.35 , -0.345, -0.34 , -0.335, -0.33 , -0.325,\n       -0.32 , -0.315, -0.31 , -0.305, -0.3  , -0.295, -0.29 , -0.285,\n       -0.28 , -0.275, -0.27 , -0.265, -0.26 , -0.255, -0.25 , -0.245,\n       -0.24 , -0.235, -0.23 , -0.225, -0.22 , -0.215, -0.21 , -0.205,\n...\n        0.4  ,  0.405,  0.41 ,  0.415,  0.42 ,  0.425,  0.43 ,  0.435,\n        0.44 ,  0.445,  0.45 ,  0.455,  0.46 ,  0.465,  0.47 ,  0.475,\n        0.48 ,  0.485,  0.49 ,  0.495,  0.5  ,  0.505,  0.51 ,  0.515,\n        0.52 ,  0.525,  0.53 ,  0.535,  0.54 ,  0.545,  0.55 ,  0.555,\n        0.56 ,  0.565,  0.57 ,  0.575,  0.58 ,  0.585,  0.59 ,  0.595,\n        0.6  ,  0.605,  0.61 ,  0.615,  0.62 ,  0.625,  0.63 ,  0.635,\n        0.64 ,  0.645,  0.65 ,  0.655,  0.66 ,  0.665,  0.67 ,  0.675,\n        0.68 ,  0.685,  0.69 ,  0.695,  0.7  ,  0.705,  0.71 ,  0.715,\n        0.72 ,  0.725,  0.73 ,  0.735,  0.74 ,  0.745,  0.75 ,  0.755,\n        0.76 ,  0.765,  0.77 ,  0.775,  0.78 ,  0.785,  0.79 ,  0.795,\n        0.8  ,  0.805,  0.81 ,  0.815,  0.82 ,  0.825,  0.83 ,  0.835,\n        0.84 ,  0.845,  0.85 ,  0.855,  0.86 ,  0.865,  0.87 ,  0.875,\n        0.88 ,  0.885,  0.89 ,  0.895,  0.9  ,  0.905,  0.91 ,  0.915,\n        0.92 ,  0.925,  0.93 ,  0.935,  0.94 ,  0.945,  0.95 ,  0.955,\n        0.96 ,  0.965,  0.97 ,  0.975,  0.98 ,  0.985,  0.99 ,  0.995,\n        1.   ,  1.005,  1.01 ,  1.015,  1.02 ,  1.025,  1.03 ,  1.035,\n        1.04 ,  1.045,  1.05 ,  1.055,  1.06 ,  1.065,  1.07 ,  1.075,\n        1.08 ,  1.085,  1.09 ,  1.095,  1.1  ,  1.105,  1.11 ,  1.115,\n        1.12 ,  1.125,  1.13 ,  1.135,  1.14 ,  1.145,  1.15 ,  1.155,\n        1.16 ,  1.165,  1.17 ,  1.175,  1.18 ,  1.185,  1.19 ,  1.195])</pre></li><li>channel(channel)int640<pre>array([0])</pre></li><li>hex_pixel(hex_pixel)int640 1 2 3 4 5 ... 716 717 718 719 720<pre>array([  0,   1,   2, ..., 718, 719, 720])</pre></li><li>u_in(hex_pixel)int32-15 -15 -15 -15 -15 ... 15 15 15 15<pre>array([-15, -15, -15, -15, -15, -15, -15, -15, -15, -15, -15, -15, -15,\n       -15, -15, -15, -14, -14, -14, -14, -14, -14, -14, -14, -14, -14,\n       -14, -14, -14, -14, -14, -14, -14, -13, -13, -13, -13, -13, -13,\n       -13, -13, -13, -13, -13, -13, -13, -13, -13, -13, -13, -13, -12,\n       -12, -12, -12, -12, -12, -12, -12, -12, -12, -12, -12, -12, -12,\n       -12, -12, -12, -12, -12, -11, -11, -11, -11, -11, -11, -11, -11,\n       -11, -11, -11, -11, -11, -11, -11, -11, -11, -11, -11, -11, -10,\n       -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\n       -10, -10, -10, -10, -10, -10, -10,  -9,  -9,  -9,  -9,  -9,  -9,\n        -9,  -9,  -9,  -9,  -9,  -9,  -9,  -9,  -9,  -9,  -9,  -9,  -9,\n        -9,  -9,  -9,  -8,  -8,  -8,  -8,  -8,  -8,  -8,  -8,  -8,  -8,\n        -8,  -8,  -8,  -8,  -8,  -8,  -8,  -8,  -8,  -8,  -8,  -8,  -8,\n        -7,  -7,  -7,  -7,  -7,  -7,  -7,  -7,  -7,  -7,  -7,  -7,  -7,\n        -7,  -7,  -7,  -7,  -7,  -7,  -7,  -7,  -7,  -7,  -7,  -6,  -6,\n        -6,  -6,  -6,  -6,  -6,  -6,  -6,  -6,  -6,  -6,  -6,  -6,  -6,\n        -6,  -6,  -6,  -6,  -6,  -6,  -6,  -6,  -6,  -6,  -5,  -5,  -5,\n        -5,  -5,  -5,  -5,  -5,  -5,  -5,  -5,  -5,  -5,  -5,  -5,  -5,\n        -5,  -5,  -5,  -5,  -5,  -5,  -5,  -5,  -5,  -5,  -4,  -4,  -4,\n        -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,\n        -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -3,  -3,\n...\n         4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n         4,   4,   4,   4,   4,   4,   4,   4,   4,   5,   5,   5,   5,\n         5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n         5,   5,   5,   5,   5,   5,   5,   5,   5,   6,   6,   6,   6,\n         6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n         6,   6,   6,   6,   6,   6,   6,   6,   7,   7,   7,   7,   7,\n         7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n         7,   7,   7,   7,   7,   7,   8,   8,   8,   8,   8,   8,   8,\n         8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n         8,   8,   8,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,\n         9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,  10,\n        10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,\n        10,  10,  10,  10,  10,  10,  10,  11,  11,  11,  11,  11,  11,\n        11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,\n        11,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n        12,  12,  12,  12,  12,  12,  12,  13,  13,  13,  13,  13,  13,\n        13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  14,\n        14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,\n        14,  14,  14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,\n        15,  15,  15,  15,  15,  15], dtype=int32)</pre></li><li>v_in(hex_pixel)int320 1 2 3 4 5 6 ... -5 -4 -3 -2 -1 0<pre>array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n        13,  14,  15,  -1,   0,   1,   2,   3,   4,   5,   6,   7,   8,\n         9,  10,  11,  12,  13,  14,  15,  -2,  -1,   0,   1,   2,   3,\n         4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,  -3,\n        -2,  -1,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n        11,  12,  13,  14,  15,  -4,  -3,  -2,  -1,   0,   1,   2,   3,\n         4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,  -5,\n        -4,  -3,  -2,  -1,   0,   1,   2,   3,   4,   5,   6,   7,   8,\n         9,  10,  11,  12,  13,  14,  15,  -6,  -5,  -4,  -3,  -2,  -1,\n         0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n        13,  14,  15,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,\n         3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n        -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,   4,\n         5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,  -9,  -8,\n        -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,   4,   5,\n         6,   7,   8,   9,  10,  11,  12,  13,  14,  15, -10,  -9,  -8,\n        -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,   4,   5,\n         6,   7,   8,   9,  10,  11,  12,  13,  14,  15, -11, -10,  -9,\n        -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,   4,\n         5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15, -12, -11,\n...\n       -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,\n         3,   4,   5,   6,   7,   8,   9,  10,  11, -15, -14, -13, -12,\n       -11, -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,\n         2,   3,   4,   5,   6,   7,   8,   9,  10, -15, -14, -13, -12,\n       -11, -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,\n         2,   3,   4,   5,   6,   7,   8,   9, -15, -14, -13, -12, -11,\n       -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,\n         3,   4,   5,   6,   7,   8, -15, -14, -13, -12, -11, -10,  -9,\n        -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,   4,\n         5,   6,   7, -15, -14, -13, -12, -11, -10,  -9,  -8,  -7,  -6,\n        -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,   4,   5,   6, -15,\n       -14, -13, -12, -11, -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,\n        -1,   0,   1,   2,   3,   4,   5, -15, -14, -13, -12, -11, -10,\n        -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,\n         4, -15, -14, -13, -12, -11, -10,  -9,  -8,  -7,  -6,  -5,  -4,\n        -3,  -2,  -1,   0,   1,   2,   3, -15, -14, -13, -12, -11, -10,\n        -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2, -15,\n       -14, -13, -12, -11, -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,\n        -1,   0,   1, -15, -14, -13, -12, -11, -10,  -9,  -8,  -7,  -6,\n        -5,  -4,  -3,  -2,  -1,   0], dtype=int32)</pre></li><li>neuron(neuron)int640 1 2 3 4 5 6 ... 59 60 61 62 63 64<pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64])</pre></li><li>cell_type(neuron)&lt;U8'R1' 'R2' 'R3' ... 'TmY15' 'TmY18'<pre>array(['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'L1', 'L2', 'L3',\n       'L4', 'L5', 'Lawf1', 'Lawf2', 'Am', 'C2', 'C3', 'CT1(Lo1)',\n       'CT1(M10)', 'Mi1', 'Mi2', 'Mi3', 'Mi4', 'Mi9', 'Mi10', 'Mi11',\n       'Mi12', 'Mi13', 'Mi14', 'Mi15', 'T1', 'T2', 'T2a', 'T3', 'T4a',\n       'T4b', 'T4c', 'T4d', 'T5a', 'T5b', 'T5c', 'T5d', 'Tm1', 'Tm2',\n       'Tm3', 'Tm4', 'Tm5Y', 'Tm5a', 'Tm5b', 'Tm5c', 'Tm9', 'Tm16',\n       'Tm20', 'Tm28', 'Tm30', 'TmY3', 'TmY4', 'TmY5a', 'TmY9', 'TmY10',\n       'TmY13', 'TmY14', 'TmY15', 'TmY18'], dtype='&lt;U8')</pre></li><li>u(neuron)int320 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype=int32)</pre></li><li>v(neuron)int320 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype=int32)</pre></li><li>angle(sample)int640 0 0 0 30 ... 300 330 330 330 330<pre>array([  0,   0,   0,   0,  30,  30,  30,  30,  60,  60,  60,  60,  90,\n        90,  90,  90, 120, 120, 120, 120, 150, 150, 150, 150, 180, 180,\n       180, 180, 210, 210, 210, 210, 240, 240, 240, 240, 270, 270, 270,\n       270, 300, 300, 300, 300, 330, 330, 330, 330])</pre></li><li>width(sample)int6480 80 80 80 80 ... 80 80 80 80 80<pre>array([80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80])</pre></li><li>intensity(sample)int640 0 1 1 0 0 1 1 ... 0 0 1 1 0 0 1 1<pre>array([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n       0, 0, 1, 1])</pre></li><li>t_stim(sample)float640.2042 0.1552 ... 0.2042 0.1552<pre>array([0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241, 0.20417423, 0.15517241,\n       0.20417423, 0.15517241, 0.20417423, 0.15517241, 0.20417423,\n       0.15517241, 0.20417423, 0.15517241])</pre></li><li>speed(sample)int6419 25 19 25 19 ... 25 19 25 19 25<pre>array([19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19,\n       25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25,\n       19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25, 19, 25])</pre></li><li>checkpoints(network_id)object/groups/turaga/home/lappalainenj...<pre>array([PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'),\n       PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000')],\n      dtype=object)</pre></li></ul></li><li>Data variables: (2)<ul><li>stimulus(sample, frame, channel, hex_pixel)float640.5 0.5 0.5 0.5 ... nan nan nan nan<pre>array([[[[0.5       , 0.5       , 0.5       , ..., 0.5       ,\n          0.5       , 0.5       ]],\n\n        [[0.5       , 0.5       , 0.5       , ..., 0.5       ,\n          0.5       , 0.5       ]],\n\n        [[0.5       , 0.5       , 0.5       , ..., 0.5       ,\n          0.5       , 0.5       ]],\n\n        ...,\n\n        [[0.        , 0.        , 0.47431193, ..., 0.        ,\n          0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.47431193, ..., 0.        ,\n          0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.47431193, ..., 0.        ,\n          0.        , 0.        ]]],\n\n...\n\n       [[[0.5       , 0.5       , 0.5       , ..., 0.5       ,\n          0.5       , 0.5       ]],\n\n        [[0.5       , 0.5       , 0.5       , ..., 0.5       ,\n          0.5       , 0.5       ]],\n\n        [[0.5       , 0.5       , 0.5       , ..., 0.5       ,\n          0.5       , 0.5       ]],\n\n        ...,\n\n        [[       nan,        nan,        nan, ...,        nan,\n                 nan,        nan]],\n\n        [[       nan,        nan,        nan, ...,        nan,\n                 nan,        nan]],\n\n        [[       nan,        nan,        nan, ...,        nan,\n                 nan,        nan]]]])</pre></li><li>responses(network_id, sample, frame, neuron)float321.27 1.141 0.8791 ... nan nan nan<pre>array([[[[ 1.2699827e+00,  1.1409136e+00,  8.7905246e-01, ...,\n          -6.6536027e-01,  4.8437607e-01,  1.5647463e+00],\n         [ 1.2699821e+00,  1.1409132e+00,  8.7905228e-01, ...,\n          -6.6528553e-01,  4.8435861e-01,  1.5648680e+00],\n         [ 1.2699815e+00,  1.1409129e+00,  8.7905210e-01, ...,\n          -6.6521347e-01,  4.8434174e-01,  1.5649835e+00],\n         ...,\n         [ 7.7462441e-01,  6.4331424e-01,  3.8036552e-01, ...,\n          -5.7851070e-01,  5.2488267e-01,  1.2676799e+00],\n         [ 7.7462435e-01,  6.4331424e-01,  3.8036549e-01, ...,\n          -5.7848930e-01,  5.2487588e-01,  1.2676859e+00],\n         [ 7.7462429e-01,  6.4331424e-01,  3.8036549e-01, ...,\n          -5.7846826e-01,  5.2486914e-01,  1.2676917e+00]],\n\n        [[ 1.2699827e+00,  1.1409136e+00,  8.7905246e-01, ...,\n          -6.6536027e-01,  4.8437607e-01,  1.5647463e+00],\n         [ 1.2699821e+00,  1.1409132e+00,  8.7905228e-01, ...,\n          -6.6528553e-01,  4.8435861e-01,  1.5648680e+00],\n         [ 1.2699815e+00,  1.1409129e+00,  8.7905210e-01, ...,\n          -6.6521347e-01,  4.8434174e-01,  1.5649835e+00],\n...\n           1.3832799e+00,  3.3471973e+00, -8.2388854e-01],\n         [ 8.2881838e-01,  3.7831399e+00,  8.0427933e-01, ...,\n           1.3832707e+00,  3.3472531e+00, -8.2382894e-01],\n         [ 8.2882798e-01,  3.7832930e+00,  8.0428213e-01, ...,\n           1.3832619e+00,  3.3473077e+00, -8.2377064e-01]],\n\n        [[ 2.2684795e-01,  1.7318463e+00,  3.6645707e-01, ...,\n           4.3895900e-01,  1.1567652e+00, -9.4679988e-04],\n         [ 2.2692201e-01,  1.7327036e+00,  3.6635238e-01, ...,\n           4.3843845e-01,  1.1580265e+00, -8.0603233e-04],\n         [ 2.2699524e-01,  1.7335522e+00,  3.6624962e-01, ...,\n           4.3793163e-01,  1.1592617e+00, -6.6797069e-04],\n         ...,\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan]]]],\n      dtype=float32)</pre></li></ul></li><li>Indexes: (6)<ul><li>network_idPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='network_id'))</pre></li><li>samplePandasIndex<pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],\n      dtype='int64', name='sample'))</pre></li><li>framePandasIndex<pre>PandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       430, 431, 432, 433, 434, 435, 436, 437, 438, 439],\n      dtype='int64', name='frame', length=440))</pre></li><li>channelPandasIndex<pre>PandasIndex(Index([0], dtype='int64', name='channel'))</pre></li><li>hex_pixelPandasIndex<pre>PandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       711, 712, 713, 714, 715, 716, 717, 718, 719, 720],\n      dtype='int64', name='hex_pixel', length=721))</pre></li><li>neuronPandasIndex<pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64],\n      dtype='int64', name='neuron'))</pre></li></ul></li><li>Attributes: (2)config :{'offsets': (-5, 5), 'intensities': [0, 1], 'speeds': [19, 25], 'height': 80, 'post_pad_mode': 'continue', 'dt': 0.005, 'device': 'cuda', 't_pre': 1.0, 't_post': 1.0}network_config :{'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'groupby': ['source_type', 'target_type']}, 'syn_count': {'type': 'SynapseCount', 'initial_dist': 'Lognormal', 'mode': 'mean', 'requires_grad': False, 'std': 1.0, 'groupby': ['source_type', 'target_type', 'du', 'dv']}, 'syn_strength': {'type': 'SynapseCountScaling', 'initial_dist': 'Value', 'requires_grad': True, 'scale_elec': 0.01, 'scale_chem': 0.01, 'clamp': 'non_negative', 'groupby': ['source_type', 'target_type', 'edge_type']}}}</li></ul> <pre><code>q\n</code></pre> <pre>&lt;xarray.DataArray 'responses' (neuron: 1, angle: 12, width: 1, intensity: 1)&gt;\narray([[[[1.11791303]],\n\n        [[1.85500802]],\n\n        [[2.40902067]],\n\n        [[2.3863104 ]],\n\n        [[1.98378356]],\n\n        [[1.2498901 ]],\n\n        [[0.27551793]],\n\n        [[0.10736401]],\n\n        [[0.11013283]],\n\n        [[0.11038107]],\n\n        [[0.11502841]],\n\n        [[0.44682346]]]])\nCoordinates:\n  * angle      (angle) int64 0 30 60 90 120 150 180 210 240 270 300 330\n  * width      (width) int64 80\n  * intensity  (intensity) int64 1\n  * neuron     (neuron) int64 37\n    cell_type  (neuron) &lt;U8 'T4c'\n    u          (neuron) int32 0\n    v          (neuron) int32 0\n    quantile   float64 0.95</pre>xarray.DataArray'responses'<ul><li>neuron: 1</li><li>angle: 12</li><li>width: 1</li><li>intensity: 1</li></ul><ul><li>1.118 1.855 2.409 2.386 1.984 ... 0.1074 0.1101 0.1104 0.115 0.4468<pre>array([[[[1.11791303]],\n\n        [[1.85500802]],\n\n        [[2.40902067]],\n\n        [[2.3863104 ]],\n\n        [[1.98378356]],\n\n        [[1.2498901 ]],\n\n        [[0.27551793]],\n\n        [[0.10736401]],\n\n        [[0.11013283]],\n\n        [[0.11038107]],\n\n        [[0.11502841]],\n\n        [[0.44682346]]]])</pre></li><li>Coordinates: (8)<ul><li>angle(angle)int640 30 60 90 120 ... 240 270 300 330<pre>array([  0,  30,  60,  90, 120, 150, 180, 210, 240, 270, 300, 330])</pre></li><li>width(width)int6480<pre>array([80])</pre></li><li>intensity(intensity)int641<pre>array([1])</pre></li><li>neuron(neuron)int6437<pre>array([37])</pre></li><li>cell_type(neuron)&lt;U8'T4c'<pre>array(['T4c'], dtype='&lt;U8')</pre></li><li>u(neuron)int320<pre>array([0], dtype=int32)</pre></li><li>v(neuron)int320<pre>array([0], dtype=int32)</pre></li><li>quantile()float640.95<pre>array(0.95)</pre></li></ul></li><li>Indexes: (4)<ul><li>anglePandasIndex<pre>PandasIndex(Index([0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330], dtype='int64', name='angle'))</pre></li><li>widthPandasIndex<pre>PandasIndex(Index([80], dtype='int64', name='width'))</pre></li><li>intensityPandasIndex<pre>PandasIndex(Index([1], dtype='int64', name='intensity'))</pre></li><li>neuronPandasIndex<pre>PandasIndex(Index([37], dtype='int64', name='neuron'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <pre><code>f = q[1]\n</code></pre> <pre><code>f.data.squeeze()\n</code></pre> <pre><code>array([[0.8409317 , 1.0498772 , 1.153635  , 0.99954355, 0.725201  ,\n        0.35095292, 0.02448581, 0.02457634, 0.0248986 , 0.02675291,\n        0.03263285, 0.45294714],\n       [1.132491  , 1.8973833 , 2.4750936 , 2.4592981 , 2.0500247 ,\n        1.2972026 , 0.28873014, 0.11172125, 0.11461885, 0.11478255,\n        0.11936502, 0.33047357]], dtype=float32)\n</code></pre> <pre><code>theta.shape\n</code></pre> <pre><code>(48,)\n</code></pre> <pre><code>polar(theta, f.data.squeeze().T)\n</code></pre> <pre><code>(&lt;Figure size 1500x1500 with 1 Axes&gt;, &lt;PolarAxes: &gt;)\n</code></pre> <pre><code>r = flash_responses(ensemble[0:2])\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/2 [00:00&lt;?, ?it/s]\n\n\n[2024-09-15 00:45:39] Loaded 2 networks.\n[2024-09-15 00:45:47] Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n[2024-09-15 00:45:47] Recovered network state.\n</code></pre> <pre><code>flash_response_index(r, 6)\n</code></pre> <pre>&lt;xarray.DataArray 'responses' (network_id: 2, sample: 1, neuron: 65)&gt;\narray([[[ 1.07614057e-01,  1.22121731e-01,  1.65068723e-01,\n          9.90826539e-02,  7.81758936e-02,  7.06098243e-02,\n          2.54012198e-01,  1.06094743e-01, -3.33505716e-01,\n         -3.30759988e-01, -4.61144274e-02, -4.64987452e-03,\n          3.21964889e-01,  1.40345311e-01,  2.09036118e-01,\n         -3.31612651e-01,  2.33435375e-02, -1.73169247e-01,\n         -1.17779317e-01,  1.34492072e-01,  1.02727715e-01,\n         -1.76974075e-02, -7.66650601e-02,  1.16897822e-01,\n         -1.22651766e-01,  5.85589582e-02,  3.09883731e-03,\n          2.24795478e-02,  3.76868920e-02, -4.32464480e-02,\n          6.64255390e-03, -2.47358757e-01,  1.49016711e-01,\n          1.54813057e-01,  1.70755602e-01, -2.73465852e-02,\n         -4.46538091e-02, -4.55124657e-02, -3.11838756e-01,\n          7.00730195e-02,  1.99072636e-02, -2.85479567e-02,\n         -6.88058695e-02, -7.37968259e-02, -8.77654321e-02,\n          9.95634700e-02, -2.78928023e-02, -1.47159989e-01,\n         -2.15984130e-01, -2.41914828e-01,  6.56170456e-02,\n         -1.26004951e-01, -1.52371329e-01,  2.79308999e-03,\n         -4.09187021e-01,  2.35152115e-03, -2.35542726e-01,\n         -1.86430399e-01, -6.13986298e-02,  5.93723500e-02,\n...\n          2.60737780e-02,  1.49129525e-01, -3.83035052e-02,\n          2.58500827e-01, -1.08162738e-01, -6.37251487e-01,\n          3.58503263e-02,  6.35645611e-02,  3.32480699e-01,\n         -1.26485912e-02,  2.57151583e-01,  3.35483459e-02,\n         -5.59388863e-02, -9.38400425e-03,  1.28558197e-02,\n          2.54778123e-02,  3.70732946e-04,  8.87486053e-03,\n         -4.49437102e-02, -2.88796158e-02,  1.37185521e-02,\n         -6.92609680e-02,  7.50546404e-03,  4.91667330e-02,\n          4.50039610e-02, -2.37194587e-01,  9.91999831e-02,\n          6.38408455e-02,  1.23342521e-02, -3.86059987e-02,\n         -2.74846637e-02, -7.21865688e-03, -1.98470330e-02,\n         -3.73961642e-02, -1.51956316e-01,  2.61375302e-03,\n         -1.43572131e-01,  3.36000500e-02,  1.09999275e-01,\n          1.65108571e-01,  6.43148195e-02, -1.47615467e-01,\n         -1.72241060e-03,  4.94636868e-03, -1.58389569e-01,\n         -7.49176841e-02, -6.96112445e-02, -5.97895198e-02,\n          1.85007748e-03,  1.34547756e-04,  3.09411905e-02,\n         -6.61731191e-02, -2.40576061e-01,  1.92752325e-02,\n         -6.33063077e-02,  5.53334928e-02,  2.24329286e-01,\n          3.31206065e-02,  1.20604991e-02]]])\nCoordinates:\n  * network_id   (network_id) int64 0 1\n  * neuron       (neuron) int64 0 1 2 3 4 5 6 7 8 ... 56 57 58 59 60 61 62 63 64\n    cell_type    (neuron) &lt;U8 'R1' 'R2' 'R3' 'R4' ... 'TmY14' 'TmY15' 'TmY18'\n    u            (neuron) int32 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0\n    v            (neuron) int32 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0\n    baseline     (sample) float64 0.5\n    radius       (sample) int64 6\n    checkpoints  (network_id) object /groups/turaga/home/lappalainenj/FlyVis/...\nDimensions without coordinates: sample</pre>xarray.DataArray'responses'<ul><li>network_id: 2</li><li>sample: 1</li><li>neuron: 65</li></ul><ul><li>0.1076 0.1221 0.1651 0.09908 ... 0.05533 0.2243 0.03312 0.01206<pre>array([[[ 1.07614057e-01,  1.22121731e-01,  1.65068723e-01,\n          9.90826539e-02,  7.81758936e-02,  7.06098243e-02,\n          2.54012198e-01,  1.06094743e-01, -3.33505716e-01,\n         -3.30759988e-01, -4.61144274e-02, -4.64987452e-03,\n          3.21964889e-01,  1.40345311e-01,  2.09036118e-01,\n         -3.31612651e-01,  2.33435375e-02, -1.73169247e-01,\n         -1.17779317e-01,  1.34492072e-01,  1.02727715e-01,\n         -1.76974075e-02, -7.66650601e-02,  1.16897822e-01,\n         -1.22651766e-01,  5.85589582e-02,  3.09883731e-03,\n          2.24795478e-02,  3.76868920e-02, -4.32464480e-02,\n          6.64255390e-03, -2.47358757e-01,  1.49016711e-01,\n          1.54813057e-01,  1.70755602e-01, -2.73465852e-02,\n         -4.46538091e-02, -4.55124657e-02, -3.11838756e-01,\n          7.00730195e-02,  1.99072636e-02, -2.85479567e-02,\n         -6.88058695e-02, -7.37968259e-02, -8.77654321e-02,\n          9.95634700e-02, -2.78928023e-02, -1.47159989e-01,\n         -2.15984130e-01, -2.41914828e-01,  6.56170456e-02,\n         -1.26004951e-01, -1.52371329e-01,  2.79308999e-03,\n         -4.09187021e-01,  2.35152115e-03, -2.35542726e-01,\n         -1.86430399e-01, -6.13986298e-02,  5.93723500e-02,\n...\n          2.60737780e-02,  1.49129525e-01, -3.83035052e-02,\n          2.58500827e-01, -1.08162738e-01, -6.37251487e-01,\n          3.58503263e-02,  6.35645611e-02,  3.32480699e-01,\n         -1.26485912e-02,  2.57151583e-01,  3.35483459e-02,\n         -5.59388863e-02, -9.38400425e-03,  1.28558197e-02,\n          2.54778123e-02,  3.70732946e-04,  8.87486053e-03,\n         -4.49437102e-02, -2.88796158e-02,  1.37185521e-02,\n         -6.92609680e-02,  7.50546404e-03,  4.91667330e-02,\n          4.50039610e-02, -2.37194587e-01,  9.91999831e-02,\n          6.38408455e-02,  1.23342521e-02, -3.86059987e-02,\n         -2.74846637e-02, -7.21865688e-03, -1.98470330e-02,\n         -3.73961642e-02, -1.51956316e-01,  2.61375302e-03,\n         -1.43572131e-01,  3.36000500e-02,  1.09999275e-01,\n          1.65108571e-01,  6.43148195e-02, -1.47615467e-01,\n         -1.72241060e-03,  4.94636868e-03, -1.58389569e-01,\n         -7.49176841e-02, -6.96112445e-02, -5.97895198e-02,\n          1.85007748e-03,  1.34547756e-04,  3.09411905e-02,\n         -6.61731191e-02, -2.40576061e-01,  1.92752325e-02,\n         -6.33063077e-02,  5.53334928e-02,  2.24329286e-01,\n          3.31206065e-02,  1.20604991e-02]]])</pre></li><li>Coordinates: (8)<ul><li>network_id(network_id)int640 1<pre>array([0, 1])</pre></li><li>neuron(neuron)int640 1 2 3 4 5 6 ... 59 60 61 62 63 64<pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64])</pre></li><li>cell_type(neuron)&lt;U8'R1' 'R2' 'R3' ... 'TmY15' 'TmY18'<pre>array(['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'L1', 'L2', 'L3',\n       'L4', 'L5', 'Lawf1', 'Lawf2', 'Am', 'C2', 'C3', 'CT1(Lo1)',\n       'CT1(M10)', 'Mi1', 'Mi2', 'Mi3', 'Mi4', 'Mi9', 'Mi10', 'Mi11',\n       'Mi12', 'Mi13', 'Mi14', 'Mi15', 'T1', 'T2', 'T2a', 'T3', 'T4a',\n       'T4b', 'T4c', 'T4d', 'T5a', 'T5b', 'T5c', 'T5d', 'Tm1', 'Tm2',\n       'Tm3', 'Tm4', 'Tm5Y', 'Tm5a', 'Tm5b', 'Tm5c', 'Tm9', 'Tm16',\n       'Tm20', 'Tm28', 'Tm30', 'TmY3', 'TmY4', 'TmY5a', 'TmY9', 'TmY10',\n       'TmY13', 'TmY14', 'TmY15', 'TmY18'], dtype='&lt;U8')</pre></li><li>u(neuron)int320 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype=int32)</pre></li><li>v(neuron)int320 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0<pre>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype=int32)</pre></li><li>baseline(sample)float640.5<pre>array([0.5])</pre></li><li>radius(sample)int646<pre>array([6])</pre></li><li>checkpoints(network_id)object/groups/turaga/home/lappalainenj...<pre>array([PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000'),\n       PosixPath('/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/001/chkpts/chkpt_00000')],\n      dtype=object)</pre></li></ul></li><li>Indexes: (2)<ul><li>network_idPandasIndex<pre>PandasIndex(Index([0, 1], dtype='int64', name='network_id'))</pre></li><li>neuronPandasIndex<pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64],\n      dtype='int64', name='neuron'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <pre><code>ensemble = EnsembleView(\"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 21:59:00] Loaded 50 networks.\n</code></pre> <pre><code>\n</code></pre> <pre><code>responses\n</code></pre> <pre>&lt;xarray.Dataset&gt;\nDimensions:       (network_id: 50, sample: 4, frame: 600, channel: 1,\n                   hex_pixel: 721, neuron: 45669)\nCoordinates: (12/14)\n  * sample        (sample) int64 0 1 2 3\n  * frame         (frame) int64 0 1 2 3 4 5 6 7 ... 593 594 595 596 597 598 599\n    time          (frame) float64 -1.0 -0.995 -0.99 -0.985 ... 1.985 1.99 1.995\n  * channel       (channel) int64 0\n  * hex_pixel     (hex_pixel) int64 0 1 2 3 4 5 6 ... 715 716 717 718 719 720\n  * neuron        (neuron) int64 0 1 2 3 4 5 ... 45664 45665 45666 45667 45668\n    ...            ...\n    v             (neuron) int32 0 1 2 3 4 5 6 7 8 ... -8 -7 -6 -5 -4 -3 -2 -1 0\n    baseline      (sample) float64 0.5 0.5 0.5 0.5\n    intensity     (sample) int64 0 0 1 1\n    radius        (sample) int64 -1 6 -1 6\n    network_name  (network_id) &lt;U13 'flow/0000/000' ... 'flow/0000/049'\n  * network_id    (network_id) int64 0 1 2 3 4 5 6 7 ... 42 43 44 45 46 47 48 49\nData variables:\n    stimulus      (network_id, sample, frame, channel, hex_pixel) float32 0.5...\n    responses     (network_id, sample, frame, neuron) float32 1.065 ... -0.06967\nAttributes:\n    config:           {'type': 'RenderedFlashes', 'boxfilter': {'extent': 15,...\n    network_config:   Namespace(\\n  connectome = Namespace(\\n    type = 'Conn...\n    checkpoint_path:  /groups/turaga/home/lappalainenj/FlyVis/private/flyvisi...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>network_id: 50</li><li>sample: 4</li><li>frame: 600</li><li>channel: 1</li><li>hex_pixel: 721</li><li>neuron: 45669</li></ul></li><li>Coordinates: (14)<ul><li>sample(sample)int640 1 2 3<pre>array([0, 1, 2, 3])</pre></li><li>frame(frame)int640 1 2 3 4 5 ... 595 596 597 598 599<pre>array([  0,   1,   2, ..., 597, 598, 599])</pre></li><li>time(frame)float64-1.0 -0.995 -0.99 ... 1.99 1.995<pre>array([-1.   , -0.995, -0.99 , -0.985, -0.98 , -0.975, -0.97 , -0.965,\n       -0.96 , -0.955, -0.95 , -0.945, -0.94 , -0.935, -0.93 , -0.925,\n       -0.92 , -0.915, -0.91 , -0.905, -0.9  , -0.895, -0.89 , -0.885,\n       -0.88 , -0.875, -0.87 , -0.865, -0.86 , -0.855, -0.85 , -0.845,\n       -0.84 , -0.835, -0.83 , -0.825, -0.82 , -0.815, -0.81 , -0.805,\n       -0.8  , -0.795, -0.79 , -0.785, -0.78 , -0.775, -0.77 , -0.765,\n       -0.76 , -0.755, -0.75 , -0.745, -0.74 , -0.735, -0.73 , -0.725,\n       -0.72 , -0.715, -0.71 , -0.705, -0.7  , -0.695, -0.69 , -0.685,\n       -0.68 , -0.675, -0.67 , -0.665, -0.66 , -0.655, -0.65 , -0.645,\n       -0.64 , -0.635, -0.63 , -0.625, -0.62 , -0.615, -0.61 , -0.605,\n       -0.6  , -0.595, -0.59 , -0.585, -0.58 , -0.575, -0.57 , -0.565,\n       -0.56 , -0.555, -0.55 , -0.545, -0.54 , -0.535, -0.53 , -0.525,\n       -0.52 , -0.515, -0.51 , -0.505, -0.5  , -0.495, -0.49 , -0.485,\n       -0.48 , -0.475, -0.47 , -0.465, -0.46 , -0.455, -0.45 , -0.445,\n       -0.44 , -0.435, -0.43 , -0.425, -0.42 , -0.415, -0.41 , -0.405,\n       -0.4  , -0.395, -0.39 , -0.385, -0.38 , -0.375, -0.37 , -0.365,\n       -0.36 , -0.355, -0.35 , -0.345, -0.34 , -0.335, -0.33 , -0.325,\n       -0.32 , -0.315, -0.31 , -0.305, -0.3  , -0.295, -0.29 , -0.285,\n       -0.28 , -0.275, -0.27 , -0.265, -0.26 , -0.255, -0.25 , -0.245,\n       -0.24 , -0.235, -0.23 , -0.225, -0.22 , -0.215, -0.21 , -0.205,\n...\n        1.2  ,  1.205,  1.21 ,  1.215,  1.22 ,  1.225,  1.23 ,  1.235,\n        1.24 ,  1.245,  1.25 ,  1.255,  1.26 ,  1.265,  1.27 ,  1.275,\n        1.28 ,  1.285,  1.29 ,  1.295,  1.3  ,  1.305,  1.31 ,  1.315,\n        1.32 ,  1.325,  1.33 ,  1.335,  1.34 ,  1.345,  1.35 ,  1.355,\n        1.36 ,  1.365,  1.37 ,  1.375,  1.38 ,  1.385,  1.39 ,  1.395,\n        1.4  ,  1.405,  1.41 ,  1.415,  1.42 ,  1.425,  1.43 ,  1.435,\n        1.44 ,  1.445,  1.45 ,  1.455,  1.46 ,  1.465,  1.47 ,  1.475,\n        1.48 ,  1.485,  1.49 ,  1.495,  1.5  ,  1.505,  1.51 ,  1.515,\n        1.52 ,  1.525,  1.53 ,  1.535,  1.54 ,  1.545,  1.55 ,  1.555,\n        1.56 ,  1.565,  1.57 ,  1.575,  1.58 ,  1.585,  1.59 ,  1.595,\n        1.6  ,  1.605,  1.61 ,  1.615,  1.62 ,  1.625,  1.63 ,  1.635,\n        1.64 ,  1.645,  1.65 ,  1.655,  1.66 ,  1.665,  1.67 ,  1.675,\n        1.68 ,  1.685,  1.69 ,  1.695,  1.7  ,  1.705,  1.71 ,  1.715,\n        1.72 ,  1.725,  1.73 ,  1.735,  1.74 ,  1.745,  1.75 ,  1.755,\n        1.76 ,  1.765,  1.77 ,  1.775,  1.78 ,  1.785,  1.79 ,  1.795,\n        1.8  ,  1.805,  1.81 ,  1.815,  1.82 ,  1.825,  1.83 ,  1.835,\n        1.84 ,  1.845,  1.85 ,  1.855,  1.86 ,  1.865,  1.87 ,  1.875,\n        1.88 ,  1.885,  1.89 ,  1.895,  1.9  ,  1.905,  1.91 ,  1.915,\n        1.92 ,  1.925,  1.93 ,  1.935,  1.94 ,  1.945,  1.95 ,  1.955,\n        1.96 ,  1.965,  1.97 ,  1.975,  1.98 ,  1.985,  1.99 ,  1.995])</pre></li><li>channel(channel)int640<pre>array([0])</pre></li><li>hex_pixel(hex_pixel)int640 1 2 3 4 5 ... 716 717 718 719 720<pre>array([  0,   1,   2, ..., 718, 719, 720])</pre></li><li>neuron(neuron)int640 1 2 3 ... 45665 45666 45667 45668<pre>array([    0,     1,     2, ..., 45666, 45667, 45668])</pre></li><li>cell_type(neuron)&lt;U8'R1' 'R1' 'R1' ... 'TmY18' 'TmY18'<pre>array(['R1', 'R1', 'R1', ..., 'TmY18', 'TmY18', 'TmY18'], dtype='&lt;U8')</pre></li><li>u(neuron)int32-15 -15 -15 -15 -15 ... 15 15 15 15<pre>array([-15, -15, -15, ...,  15,  15,  15], dtype=int32)</pre></li><li>v(neuron)int320 1 2 3 4 5 6 ... -5 -4 -3 -2 -1 0<pre>array([ 0,  1,  2, ..., -2, -1,  0], dtype=int32)</pre></li><li>baseline(sample)float640.5 0.5 0.5 0.5<pre>array([0.5, 0.5, 0.5, 0.5])</pre></li><li>intensity(sample)int640 0 1 1<pre>array([0, 0, 1, 1])</pre></li><li>radius(sample)int64-1 6 -1 6<pre>array([-1,  6, -1,  6])</pre></li><li>network_name(network_id)&lt;U13'flow/0000/000' ... 'flow/0000/049'<pre>array(['flow/0000/000', 'flow/0000/001', 'flow/0000/002', 'flow/0000/003',\n       'flow/0000/004', 'flow/0000/005', 'flow/0000/006', 'flow/0000/007',\n       'flow/0000/008', 'flow/0000/009', 'flow/0000/010', 'flow/0000/011',\n       'flow/0000/012', 'flow/0000/013', 'flow/0000/014', 'flow/0000/015',\n       'flow/0000/016', 'flow/0000/017', 'flow/0000/018', 'flow/0000/019',\n       'flow/0000/020', 'flow/0000/021', 'flow/0000/022', 'flow/0000/023',\n       'flow/0000/024', 'flow/0000/025', 'flow/0000/026', 'flow/0000/027',\n       'flow/0000/028', 'flow/0000/029', 'flow/0000/030', 'flow/0000/031',\n       'flow/0000/032', 'flow/0000/033', 'flow/0000/034', 'flow/0000/035',\n       'flow/0000/036', 'flow/0000/037', 'flow/0000/038', 'flow/0000/039',\n       'flow/0000/040', 'flow/0000/041', 'flow/0000/042', 'flow/0000/043',\n       'flow/0000/044', 'flow/0000/045', 'flow/0000/046', 'flow/0000/047',\n       'flow/0000/048', 'flow/0000/049'], dtype='&lt;U13')</pre></li><li>network_id(network_id)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49<pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])</pre></li></ul></li><li>Data variables: (2)<ul><li>stimulus(network_id, sample, frame, channel, hex_pixel)float320.5 0.5 0.5 0.5 ... 0.5 0.5 0.5 0.5<pre>array([[[[[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         ...,\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]]],\n\n\n        [[[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n...\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]]],\n\n\n        [[[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         ...,\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n         [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]]]]], dtype=float32)</pre></li><li>responses(network_id, sample, frame, neuron)float321.065 1.064 ... -0.08417 -0.06967<pre>array([[[[ 1.0647585 ,  1.0643023 ,  1.064116  , ...,  1.0037799 ,\n           1.1802369 ,  1.1758567 ],\n         [ 1.0647585 ,  1.0643023 ,  1.064116  , ...,  1.0038444 ,\n           1.1802994 ,  1.1759069 ],\n         [ 1.0647585 ,  1.0643023 ,  1.064116  , ...,  1.0039065 ,\n           1.1803595 ,  1.1759552 ],\n         ...,\n         [ 1.0647607 ,  1.0643051 ,  1.0641189 , ...,  1.0035812 ,\n           1.180073  ,  1.1758418 ],\n         [ 1.0647606 ,  1.064305  ,  1.0641187 , ...,  1.0036479 ,\n           1.1801381 ,  1.1758913 ],\n         [ 1.0647606 ,  1.0643048 ,  1.0641186 , ...,  1.0037123 ,\n           1.1802008 ,  1.175939  ]],\n\n        [[ 1.0647585 ,  1.0643023 ,  1.064116  , ...,  1.0037799 ,\n           1.1802369 ,  1.1758567 ],\n         [ 1.0647585 ,  1.0643023 ,  1.064116  , ...,  1.0038444 ,\n           1.1802994 ,  1.1759069 ],\n         [ 1.0647585 ,  1.0643023 ,  1.064116  , ...,  1.0039065 ,\n           1.1803595 ,  1.1759552 ],\n...\n         [-0.48008505, -0.48008505, -0.48008505, ...,  0.31707653,\n           0.31497094,  0.33054996],\n         [-0.48008505, -0.48008505, -0.48008505, ...,  0.31687245,\n           0.31478694,  0.3304082 ],\n         [-0.48008505, -0.48008505, -0.48008505, ...,  0.31667095,\n           0.31460539,  0.33026838]],\n\n        [[-0.4800851 , -0.4800851 , -0.4800851 , ..., -0.39424074,\n          -0.30051097, -0.13593647],\n         [-0.4800851 , -0.4800851 , -0.4800851 , ..., -0.39432457,\n          -0.30055374, -0.13596988],\n         [-0.4800851 , -0.4800851 , -0.4800851 , ..., -0.39441872,\n          -0.30060574, -0.13601004],\n         ...,\n         [-0.4800851 , -0.4800851 , -0.4800851 , ..., -0.14209548,\n          -0.08404877, -0.06954683],\n         [-0.4800851 , -0.4800851 , -0.4800851 , ..., -0.14215337,\n          -0.08410751, -0.06960863],\n         [-0.4800851 , -0.4800851 , -0.4800851 , ..., -0.14221065,\n          -0.0841656 , -0.06966969]]]], dtype=float32)</pre></li></ul></li><li>Indexes: (6)<ul><li>samplePandasIndex<pre>PandasIndex(Index([0, 1, 2, 3], dtype='int64', name='sample'))</pre></li><li>framePandasIndex<pre>PandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       590, 591, 592, 593, 594, 595, 596, 597, 598, 599],\n      dtype='int64', name='frame', length=600))</pre></li><li>channelPandasIndex<pre>PandasIndex(Index([0], dtype='int64', name='channel'))</pre></li><li>hex_pixelPandasIndex<pre>PandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       711, 712, 713, 714, 715, 716, 717, 718, 719, 720],\n      dtype='int64', name='hex_pixel', length=721))</pre></li><li>neuronPandasIndex<pre>PandasIndex(Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n       ...\n       45659, 45660, 45661, 45662, 45663, 45664, 45665, 45666, 45667, 45668],\n      dtype='int64', name='neuron', length=45669))</pre></li><li>network_idPandasIndex<pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='network_id'))</pre></li></ul></li><li>Attributes: (3)config :{'type': 'RenderedFlashes', 'boxfilter': {'extent': 15, 'kernel_size': 13}, 'dynamic_range': [0, 1], 't_stim': 1.0, 't_pre': 1.0, 'dt': 0.005, 'radius': [-1, 6], 'alternations': [0, 1, 0]}network_config :Namespace(   connectome = Namespace(     type = 'ConnectomeDir',     file = 'fib25-fib19_v2.2.json',     extent = 15,     n_syn_fill = 1   ),   dynamics = Namespace(     type = 'PPNeuronIGRSynapses',     activation = Namespace(type='relu')   ),   node_config = Namespace(     bias = Namespace(       type = 'RestingPotential',       groupby = ['type'],       initial_dist = 'Normal',       mode = 'sample',       requires_grad = True,       mean = 0.5,       std = 0.05,       penalize = Namespace(activity=True),       seed = 0     ),     time_const = Namespace(       type = 'TimeConstant',       groupby = ['type'],       initial_dist = 'Value',       value = 0.05,       requires_grad = True     )   ),   edge_config = Namespace(     sign = Namespace(       type = 'SynapseSign',       initial_dist = 'Value',       requires_grad = False,       groupby = ['source_type', 'target_type']     ),     syn_count = Namespace(       type = 'SynapseCount',       initial_dist = 'Lognormal',       mode = 'mean',       requires_grad = False,       std = 1.0,       groupby = ['source_type', 'target_type', 'du', 'dv']     ),     syn_strength = Namespace(       type = 'SynapseCountScaling',       initial_dist = 'Value',       requires_grad = True,       scale_elec = 0.01,       scale_chem = 0.01,       clamp = 'non_negative',       groupby = ['source_type', 'target_type', 'edge_type']     )   ) )checkpoint_path :/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/data/results/flow/0000/000/chkpts/chkpt_00000</li></ul> <pre><code>responses = flash_responses(ensemble)\n</code></pre> <pre><code>[2024-09-14 22:06:52] Recovered network state.\n[2024-09-14 22:06:52] Recovered network state.\n[2024-09-14 22:06:53] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:07:00] Recovered network state.\n[2024-09-14 22:07:00] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:07:00] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:07:07] Recovered network state.\n[2024-09-14 22:07:07] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:07:08] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:07:14] Recovered network state.\n[2024-09-14 22:07:14] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:07:15] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:07:22] Recovered network state.\n[2024-09-14 22:07:22] Recovered network state.\n\n\n________________________________________________compute_responses - 6.4s, 0.1min\n\n\n[2024-09-14 22:07:22] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:07:29] Recovered network state.\n[2024-09-14 22:07:29] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:07:30] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:07:36] Recovered network state.\n[2024-09-14 22:07:36] Recovered network state.\n\n\n________________________________________________compute_responses - 6.4s, 0.1min\n\n\n[2024-09-14 22:07:37] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:07:44] Recovered network state.\n[2024-09-14 22:07:44] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:07:44] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:07:51] Recovered network state.\n[2024-09-14 22:07:51] Recovered network state.\n\n\n________________________________________________compute_responses - 6.4s, 0.1min\n\n\n[2024-09-14 22:07:52] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:07:58] Recovered network state.\n[2024-09-14 22:07:58] Recovered network state.\n\n\n________________________________________________compute_responses - 6.4s, 0.1min\n\n\n[2024-09-14 22:07:59] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:08:05] Recovered network state.\n[2024-09-14 22:08:05] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:08:06] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:08:13] Recovered network state.\n[2024-09-14 22:08:13] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:08:14] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/stimulus_responses.py:136: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.\n  ds = memory_cache(compute_responses)(\n[2024-09-14 22:08:20] Recovered network state.\n[2024-09-14 22:08:20] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:08:21] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:08:28] Recovered network state.\n[2024-09-14 22:08:28] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:08:29] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:08:35] Recovered network state.\n[2024-09-14 22:08:35] Recovered network state.\n\n\n________________________________________________compute_responses - 6.6s, 0.1min\n\n\n[2024-09-14 22:08:37] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:08:43] Recovered network state.\n[2024-09-14 22:08:43] Recovered network state.\n\n\n________________________________________________compute_responses - 6.7s, 0.1min\n\n\n[2024-09-14 22:08:44] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/stimulus_responses.py:136: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.\n  ds = memory_cache(compute_responses)(\n[2024-09-14 22:08:51] Recovered network state.\n[2024-09-14 22:08:51] Recovered network state.\n\n\n________________________________________________compute_responses - 6.7s, 0.1min\n\n\n[2024-09-14 22:08:52] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/stimulus_responses.py:136: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.\n  ds = memory_cache(compute_responses)(\n[2024-09-14 22:08:59] Recovered network state.\n[2024-09-14 22:08:59] Recovered network state.\n\n\n________________________________________________compute_responses - 6.7s, 0.1min\n\n\n[2024-09-14 22:09:00] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:09:07] Recovered network state.\n[2024-09-14 22:09:07] Recovered network state.\n\n\n________________________________________________compute_responses - 6.8s, 0.1min\n\n\n[2024-09-14 22:09:08] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:09:15] Recovered network state.\n[2024-09-14 22:09:15] Recovered network state.\n\n\n________________________________________________compute_responses - 6.7s, 0.1min\n\n\n[2024-09-14 22:09:16] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:09:23] Recovered network state.\n[2024-09-14 22:09:23] Recovered network state.\n\n\n________________________________________________compute_responses - 6.7s, 0.1min\n\n\n[2024-09-14 22:09:24] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:09:30] Recovered network state.\n[2024-09-14 22:09:30] Recovered network state.\n\n\n________________________________________________compute_responses - 6.7s, 0.1min\n\n\n[2024-09-14 22:09:32] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:09:38] Recovered network state.\n[2024-09-14 22:09:38] Recovered network state.\n\n\n________________________________________________compute_responses - 6.7s, 0.1min\n\n\n[2024-09-14 22:09:39] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:09:46] Recovered network state.\n[2024-09-14 22:09:46] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:09:47] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:09:53] Recovered network state.\n[2024-09-14 22:09:53] Recovered network state.\n\n\n________________________________________________compute_responses - 6.6s, 0.1min\n\n\n[2024-09-14 22:09:54] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:10:01] Recovered network state.\n[2024-09-14 22:10:01] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:10:01] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:10:08] Recovered network state.\n[2024-09-14 22:10:08] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:10:09] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:10:15] Recovered network state.\n[2024-09-14 22:10:15] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:10:16] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:10:23] Recovered network state.\n[2024-09-14 22:10:23] Recovered network state.\n\n\n________________________________________________compute_responses - 6.6s, 0.1min\n\n\n[2024-09-14 22:10:24] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:10:30] Recovered network state.\n[2024-09-14 22:10:30] Recovered network state.\n\n\n________________________________________________compute_responses - 6.6s, 0.1min\n\n\n[2024-09-14 22:10:31] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:10:38] Recovered network state.\n[2024-09-14 22:10:38] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:10:39] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:10:45] Recovered network state.\n[2024-09-14 22:10:45] Recovered network state.\n\n\n________________________________________________compute_responses - 6.5s, 0.1min\n\n\n[2024-09-14 22:10:46] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:10:53] Recovered network state.\n[2024-09-14 22:10:53] Recovered network state.\n\n\n________________________________________________compute_responses - 6.6s, 0.1min\n\n\n[2024-09-14 22:10:54] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:11:01] Recovered network state.\n[2024-09-14 22:11:01] Recovered network state.\n\n\n________________________________________________compute_responses - 6.7s, 0.1min\n\n\n[2024-09-14 22:11:02] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/stimulus_responses.py:136: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.\n  ds = memory_cache(compute_responses)(\n[2024-09-14 22:11:08] Recovered network state.\n[2024-09-14 22:11:08] Recovered network state.\n\n\n________________________________________________compute_responses - 6.8s, 0.1min\n\n\n[2024-09-14 22:11:10] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:11:16] Recovered network state.\n[2024-09-14 22:11:16] Recovered network state.\n\n\n________________________________________________compute_responses - 6.8s, 0.1min\n\n\n[2024-09-14 22:11:17] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:11:24] Recovered network state.\n[2024-09-14 22:11:24] Recovered network state.\n\n\n________________________________________________compute_responses - 6.7s, 0.1min\n\n\n[2024-09-14 22:11:25] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:11:32] Recovered network state.\n[2024-09-14 22:11:32] Recovered network state.\n\n\n________________________________________________compute_responses - 6.9s, 0.1min\n\n\n[2024-09-14 22:11:33] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:11:40] Recovered network state.\n[2024-09-14 22:11:40] Recovered network state.\n\n\n________________________________________________compute_responses - 7.1s, 0.1min\n\n\n[2024-09-14 22:11:42] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:11:49] Recovered network state.\n[2024-09-14 22:11:49] Recovered network state.\n\n\n________________________________________________compute_responses - 7.1s, 0.1min\n\n\n[2024-09-14 22:11:50] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:11:57] Recovered network state.\n[2024-09-14 22:11:57] Recovered network state.\n\n\n________________________________________________compute_responses - 7.1s, 0.1min\n\n\n[2024-09-14 22:11:58] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n________________________________________________compute_responses - 7.1s, 0.1min\n\n\n[2024-09-14 22:12:05] Recovered network state.\n[2024-09-14 22:12:05] Recovered network state.\n[2024-09-14 22:12:06] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:12:13] Recovered network state.\n[2024-09-14 22:12:13] Recovered network state.\n\n\n________________________________________________compute_responses - 7.1s, 0.1min\n\n\n[2024-09-14 22:12:15] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:12:22] Recovered network state.\n[2024-09-14 22:12:22] Recovered network state.\n\n\n________________________________________________compute_responses - 7.3s, 0.1min\n\n\n[2024-09-14 22:12:23] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/stimulus_responses.py:136: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.\n  ds = memory_cache(compute_responses)(\n[2024-09-14 22:12:30] Recovered network state.\n[2024-09-14 22:12:30] Recovered network state.\n\n\n________________________________________________compute_responses - 7.1s, 0.1min\n\n\n[2024-09-14 22:12:31] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/stimulus_responses.py:136: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.\n  ds = memory_cache(compute_responses)(\n[2024-09-14 22:12:39] Recovered network state.\n[2024-09-14 22:12:39] Recovered network state.\n\n\n________________________________________________compute_responses - 7.0s, 0.1min\n\n\n[2024-09-14 22:12:40] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/stimulus_responses.py:136: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.\n  ds = memory_cache(compute_responses)(\n[2024-09-14 22:12:47] Recovered network state.\n[2024-09-14 22:12:47] Recovered network state.\n\n\n________________________________________________compute_responses - 7.0s, 0.1min\n\n\n[2024-09-14 22:12:48] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:12:55] Recovered network state.\n[2024-09-14 22:12:55] Recovered network state.\n\n\n________________________________________________compute_responses - 7.2s, 0.1min\n\n\n[2024-09-14 22:12:56] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n[2024-09-14 22:13:04] Recovered network state.\n[2024-09-14 22:13:04] Recovered network state.\n\n\n________________________________________________compute_responses - 7.2s, 0.1min\n\n\n[2024-09-14 22:13:05] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n/groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvision/analysis/stimulus_responses.py:136: UserWarning: Persisting input arguments took 0.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.\n  ds = memory_cache(compute_responses)(\n[2024-09-14 22:13:12] Recovered network state.\n[2024-09-14 22:13:12] Recovered network state.\n\n\n________________________________________________compute_responses - 6.8s, 0.1min\n\n\n[2024-09-14 22:13:13] Computing 4 stimulus responses.\n\n\n________________________________________________________________________________\n[Memory] Calling flyvision.analysis.stimulus_responses.compute_responses...\ncompute_responses(CheckpointedNetwork(network_class=&lt;class 'flyvision.network.Network'&gt;, config={'connectome': {'type': 'ConnectomeDir', 'file': 'fib25-fib19_v2.2.json', 'extent': 15, 'n_syn_fill': 1}, 'dynamics': {'type': 'PPNeuronIGRSynapses', 'activation': {'type': 'relu'}}, 'node_config': {'bias': {'type': 'RestingPotential', 'groupby': ['type'], 'initial_dist': 'Normal', 'mode': 'sample', 'requires_grad': True, 'mean': 0.5, 'std': 0.05, 'penalize': {'activity': True}, 'seed': 0}, 'time_const': {'type': 'TimeConstant', 'groupby': ['type'], 'initial_dist': 'Value', 'value': 0.05, 'requires_grad': True}}, 'edge_config': {'sign': {'type': 'SynapseSign', 'initial_dist': 'Value', 'requires_grad': False, 'group..., \n&lt;class 'flyvision.datasets.flashes.Flashes'&gt;, { 'alternations': (0, 1, 0),\n  'dt': 0.005,\n  'dynamic_range': [0, 1],\n  'radius': (-1, 6),\n  't_pre': 1.0,\n  't_stim': 1}, \n1, 1.0, 0.0)\n\n\n\nBatch:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n\n\n________________________________________________compute_responses - 6.9s, 0.1min\n</code></pre> <pre><code>from __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, Optional\n\nimport torch\nimport xarray as xr\n</code></pre> <pre><code>from flyvision.utils.chkpt_utils import recover_network\n</code></pre> <pre><code>@dataclass(frozen=True)\nclass CheckpointedNetwork:\n    network_class: Any  # Network class (e.g., flyvision.Network)\n    config: Dict  # Configuration for the network\n    checkpoint: str  # Checkpoint path\n    recover_fn: Any = recover_network  # Function to recover the network\n    network: Any = None  # Network instance\n\n    def pre_init(self, eval: bool = True):\n        \"\"\"Pre-initialize the network.\"\"\"\n        if self.network is None:\n            self.network = self.network_class(**self.config)\n        if eval:\n            self.network.eval()\n        return self.network\n\n    def recover(self):\n        \"\"\"Recover the network from the checkpoint.\"\"\"\n        self.network = self.recover_fn(self.network, self.checkpoint)\n        return self.network\n\n    def __hash__(self):\n        \"\"\"Custom hash function that includes only hashable attributes.\"\"\"\n        return hash((self.network_class, frozenset(self.config.items()), self.checkpoint))\n</code></pre> <pre><code>def checkpoints(self):\n    config = self.dir.config.network.to_dict()\n    checkpoint = str(self.checkpoints.path)\n    return CheckpointedNetwork(\n        network_class=network_class,\n        config=config,\n        checkpoint=checkpoint,\n    )\n</code></pre>"},{"location":"reference/connectome/","title":"Connectome","text":""},{"location":"reference/connectome/#flyvision.connectome","title":"<code>connectome</code>","text":""},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir","title":"<code>ConnectomeDir</code>","text":"<p>               Bases: <code>Directory</code></p> <p>Compiles a connectome graph from average convolutional filters.</p> <p>The graph is cells (nodes) and synapse sets (edges).</p> <p>Attributes:</p> <pre><code>Files:\n    unique_cell_types (str): identified cell types\n    input_cell_types (str): input cell types\n    intermediate_cell_types (str): hidden cell types\n    output_cell_types (str): decoded cell types\n    central_cells_index (int): index of central cell in nodes table\n        for each cell type in unique_cell_types.\n    layout (str): input, hidden, output definitions for visualization.\n\nSubDirs:\n\n    nodes (NodeDir): table with a row for each individual node/cell and\n        columns/files describing their attributed.\n\n        Files:\n            type (str): cell type name\n            u (int): hex-coordinates #1 (oblique coordinates)\n            v (int): hex-coordinates #2 (oblique coordinates)\n            role (str): input, hidden, or output\n\n        SubDirs:\n\n            layer_index (Directory): all indices of a cell type in nodes.\n\n                Files:\n                    &lt;cell_type&gt; (int): all cell indices of cell_type in\n                        nodes.\n\n    edges (EdgeDir): A table with a row for each edge.\n\n        Files:\n            source_index (str): presynaptic cell\n            target_index (int): postsynaptic cell\n            sign (int): +1 (excitatory) or -1 (inhibitory)\n            n_syn (float): synapse count\n            other files for convenience\n</code></pre> Note <p>A connectome can be constructed from a JSON model file following this schema:.connectome import *</p> <pre><code>{\n    \"nodes\": [{\n        \"name\": string,\n        \"pattern\": (\n            [\"stride\", [&lt;u_stride:int&gt;, &lt;v_stride:int&gt;]]\n            | [\"tile\", &lt;stride:int&gt;]\n            | [\"single\", null]\n        )\n    }*],\n    \"edges\": [{\n        \"src\": string,\n        \"tar\": string,\n        \"alpha\": int,\n        \"offsets\": [[\n            [&lt;du:int&gt;, &lt;dv:int&gt;],\n            &lt;n_synapses:number&gt;\n        ]*],\n        \"edge_type\": \"chem\" | \"elec\"\n    }*]\n}\n</code></pre> <p>See \u201cdata/connectome/fib25-fib19_v2.2.json\u201d for an example.</p> Example <p>config = Namespace(file=\u2019fib25-fib19_v2.2.json\u2019,                        extent=15,                        n_syn_fill=1) connectome = Connectome(config)</p> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>@root(flyvision.root_dir / \"connectome\")\nclass ConnectomeDir(Directory):\n    \"\"\"Compiles a connectome graph from average convolutional filters.\n\n    The graph is cells (nodes) and synapse sets (edges).\n\n    Attributes:\n\n        Files:\n            unique_cell_types (str): identified cell types\n            input_cell_types (str): input cell types\n            intermediate_cell_types (str): hidden cell types\n            output_cell_types (str): decoded cell types\n            central_cells_index (int): index of central cell in nodes table\n                for each cell type in unique_cell_types.\n            layout (str): input, hidden, output definitions for visualization.\n\n        SubDirs:\n\n            nodes (NodeDir): table with a row for each individual node/cell and\n                columns/files describing their attributed.\n\n                Files:\n                    type (str): cell type name\n                    u (int): hex-coordinates #1 (oblique coordinates)\n                    v (int): hex-coordinates #2 (oblique coordinates)\n                    role (str): input, hidden, or output\n\n                SubDirs:\n\n                    layer_index (Directory): all indices of a cell type in nodes.\n\n                        Files:\n                            &lt;cell_type&gt; (int): all cell indices of cell_type in\n                                nodes.\n\n            edges (EdgeDir): A table with a row for each edge.\n\n                Files:\n                    source_index (str): presynaptic cell\n                    target_index (int): postsynaptic cell\n                    sign (int): +1 (excitatory) or -1 (inhibitory)\n                    n_syn (float): synapse count\n                    other files for convenience\n\n    Note:\n        A connectome can be constructed from a JSON model file following this\n        schema:.connectome import *\n\n            {\n                \"nodes\": [{\n                    \"name\": string,\n                    \"pattern\": (\n                        [\"stride\", [&lt;u_stride:int&gt;, &lt;v_stride:int&gt;]]\n                        | [\"tile\", &lt;stride:int&gt;]\n                        | [\"single\", null]\n                    )\n                }*],\n                \"edges\": [{\n                    \"src\": string,\n                    \"tar\": string,\n                    \"alpha\": int,\n                    \"offsets\": [[\n                        [&lt;du:int&gt;, &lt;dv:int&gt;],\n                        &lt;n_synapses:number&gt;\n                    ]*],\n                    \"edge_type\": \"chem\" | \"elec\"\n                }*]\n            }\n\n        See \"data/connectome/fib25-fib19_v2.2.json\" for an example.\n\n    Example:\n        &gt;&gt;&gt; config = Namespace(file='fib25-fib19_v2.2.json',\n                               extent=15,\n                               n_syn_fill=1)\n        &gt;&gt;&gt; connectome = Connectome(config)\n    \"\"\"\n\n    class Config:\n        file: str\n        \"The name of a JSON connectome file\"\n        extent: int\n        \"The array radius, in columns\"\n        n_syn_fill: int\n        \"The number of synapses to assume in data gaps\"\n\n    # -- Contents ------------------------------------------\n    unique_cell_types: ArrayFile\n    \"A list of all cell types\"\n    input_cell_types: ArrayFile\n    \"The cell types to use as inputs\"\n    intermediate_cell_types: ArrayFile\n    \"The hidden cell types\"\n    output_cell_types: ArrayFile\n    \"The cell types to use for task readout\"\n    central_cells_index: ArrayFile\n    \"Index of the central node of a unique cell type in the nodes table\"\n    layout: ArrayFile\n    \"Input, hidden, output layout for later circuit visualization\"\n    nodes: Directory\n    \"A table with a row for each node\"\n    edges: Directory\n    \"A table with a row for each edge\"\n    # ------------------------------------------------------\n\n    def __init__(self, file=flyvision.connectome_file, extent=15, n_syn_fill=1) -&gt; None:\n        # Load the connectome spec.\n        spec = json.loads(Path(self.path.parent / file).read_text())\n\n        # Store unique cell types and layout variables.\n        self.unique_cell_types = np.bytes_([n[\"name\"] for n in spec[\"nodes\"]])\n        self.input_cell_types = np.bytes_(spec[\"input_units\"])\n        self.output_cell_types = np.bytes_(spec[\"output_units\"])\n        intermediate_cell_types, _ = nodes_edges_utils.order_node_type_list(\n            np.array(\n                list(\n                    set(self.unique_cell_types)\n                    - set(self.input_cell_types)\n                    - set(self.output_cell_types)\n                )\n            ).astype(str)\n        )\n        self.intermediate_cell_types = np.array(intermediate_cell_types).astype(\"S\")\n\n        layout = []\n        layout.extend(\n            list(\n                zip(\n                    self.input_cell_types,\n                    [b\"retina\" for _ in range(len(self.input_cell_types))],\n                )\n            )\n        )\n        layout.extend(\n            list(\n                zip(\n                    self.intermediate_cell_types,\n                    [b\"intermediate\" for _ in range(len(self.intermediate_cell_types))],\n                )\n            )\n        )\n        layout.extend(\n            list(\n                zip(\n                    self.output_cell_types,\n                    [b\"output\" for _ in range(len(self.output_cell_types))],\n                )\n            )\n        )\n        self.layout = np.bytes_(layout)\n\n        # Construct nodes and edges.\n        nodes: List[Node] = []\n        edges: List[Edge] = []\n        add_nodes(nodes, spec[\"nodes\"], extent)\n        add_edges(edges, nodes, spec[\"edges\"], n_syn_fill)\n\n        # Define node roles (input, intermediate, output).\n        _role = {node: \"intermediate\" for node in set([n.type for n in nodes])}\n        _role.update({node: \"input\" for node in _role if node in spec[\"input_units\"]})\n        _role.update({node: \"output\" for node in _role if node in spec[\"output_units\"]})\n\n        # Store the graph.\n        self.nodes = dict(  # type: ignore\n            type=np.bytes_([n.type for n in nodes]),\n            u=np.int32([n.u for n in nodes]),\n            v=np.int32([n.v for n in nodes]),\n            role=np.bytes_([_role[n.type] for n in nodes]),\n        )\n\n        self.edges = dict(  # type: ignore\n            # [Essential fields]\n            source_index=np.int64([e.source.id for e in edges]),\n            target_index=np.int64([e.target.id for e in edges]),\n            sign=np.float32([e.sign for e in edges]),\n            n_syn=np.float32([e.n_syn for e in edges]),\n            # [Convenience fields]\n            source_type=np.bytes_([e.source.type for e in edges]),\n            target_type=np.bytes_([e.target.type for e in edges]),\n            source_u=np.int32([e.source.u for e in edges]),\n            target_u=np.int32([e.target.u for e in edges]),\n            source_v=np.int32([e.source.v for e in edges]),\n            target_v=np.int32([e.target.v for e in edges]),\n            du=np.int32([e.target.u - e.source.u for e in edges]),\n            dv=np.int32([e.target.v - e.source.v for e in edges]),\n            edge_type=np.bytes_([e.type for e in edges]),\n            n_syn_certainty=np.float32([e.n_syn_certainty for e in edges]),\n        )\n\n        # Store central indices.\n        self.central_cells_index = np.int64(\n            np.nonzero((self.nodes.u[:] == 0) &amp; (self.nodes.v[:] == 0))[0]\n        )\n\n        # Store layer indices.\n        layer_index = {}\n        for cell_type in self.unique_cell_types[:]:\n            node_indices = np.nonzero(self.nodes[\"type\"][:] == cell_type)[0]\n            layer_index[cell_type.decode()] = np.int64(node_indices)\n        self.nodes.layer_index = layer_index\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir.unique_cell_types","title":"<code>unique_cell_types: ArrayFile = np.bytes_([n['name'] for n in spec['nodes']])</code>  <code>instance-attribute</code>","text":"<p>A list of all cell types</p>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir.input_cell_types","title":"<code>input_cell_types: ArrayFile = np.bytes_(spec['input_units'])</code>  <code>instance-attribute</code>","text":"<p>The cell types to use as inputs</p>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir.intermediate_cell_types","title":"<code>intermediate_cell_types: ArrayFile = np.array(intermediate_cell_types).astype('S')</code>  <code>instance-attribute</code>","text":"<p>The hidden cell types</p>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir.output_cell_types","title":"<code>output_cell_types: ArrayFile = np.bytes_(spec['output_units'])</code>  <code>instance-attribute</code>","text":"<p>The cell types to use for task readout</p>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir.central_cells_index","title":"<code>central_cells_index: ArrayFile = np.int64(np.nonzero(self.nodes.u[:] == 0 &amp; self.nodes.v[:] == 0)[0])</code>  <code>instance-attribute</code>","text":"<p>Index of the central node of a unique cell type in the nodes table</p>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir.layout","title":"<code>layout: ArrayFile = np.bytes_(layout)</code>  <code>instance-attribute</code>","text":"<p>Input, hidden, output layout for later circuit visualization</p>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir.nodes","title":"<code>nodes: Directory = dict(type=np.bytes_([n.type for n in nodes]), u=np.int32([n.u for n in nodes]), v=np.int32([n.v for n in nodes]), role=np.bytes_([_role[n.type] for n in nodes]))</code>  <code>instance-attribute</code>","text":"<p>A table with a row for each node</p>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir.edges","title":"<code>edges: Directory = dict(source_index=np.int64([e.source.id for e in edges]), target_index=np.int64([e.target.id for e in edges]), sign=np.float32([e.sign for e in edges]), n_syn=np.float32([e.n_syn for e in edges]), source_type=np.bytes_([e.source.type for e in edges]), target_type=np.bytes_([e.target.type for e in edges]), source_u=np.int32([e.source.u for e in edges]), target_u=np.int32([e.target.u for e in edges]), source_v=np.int32([e.source.v for e in edges]), target_v=np.int32([e.target.v for e in edges]), du=np.int32([e.target.u - e.source.u for e in edges]), dv=np.int32([e.target.v - e.source.v for e in edges]), edge_type=np.bytes_([e.type for e in edges]), n_syn_certainty=np.float32([e.n_syn_certainty for e in edges]))</code>  <code>instance-attribute</code>","text":"<p>A table with a row for each edge</p>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir.Config","title":"<code>Config</code>","text":"Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>class Config:\n    file: str\n    \"The name of a JSON connectome file\"\n    extent: int\n    \"The array radius, in columns\"\n    n_syn_fill: int\n    \"The number of synapses to assume in data gaps\"\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir.Config.file","title":"<code>file: str</code>  <code>instance-attribute</code>","text":"<p>The name of a JSON connectome file</p>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir.Config.extent","title":"<code>extent: int</code>  <code>instance-attribute</code>","text":"<p>The array radius, in columns</p>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeDir.Config.n_syn_fill","title":"<code>n_syn_fill: int</code>  <code>instance-attribute</code>","text":"<p>The number of synapses to assume in data gaps</p>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeView","title":"<code>ConnectomeView</code>","text":"<p>Visualization of the connectome data.</p> <p>Parameters:</p> Name Type Description Default <code>connectome</code> <code>ConnectomeDir</code> <p>Directory of the connectome.</p> required <code>groups</code> <code>List[str]</code> <p>regular expressions to sort the nodes by.</p> <code>['R\\\\d', 'L\\\\d', 'Lawf\\\\d', 'A', 'C\\\\d', 'CT\\\\d.*', 'Mi\\\\d{1,2}', 'T\\\\d{1,2}.*', 'Tm.*\\\\d{1,2}.*']</code> <p>Attributes:</p> Name Type Description <code>connectome</code> <code>ConnectomeDir</code> <p>connectome of connectome.</p> <code>nodes</code> <code>Directory</code> <p>node table.</p> <code>edges</code> <code>Directory</code> <p>edge table.</p> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>class ConnectomeView:\n    \"\"\"Visualization of the connectome data.\n\n    Args:\n        connectome (ConnectomeDir): Directory of the connectome.\n        groups (List[str]): regular expressions to sort the nodes by.\n\n    Attributes:\n        connectome (ConnectomeDir): connectome of connectome.\n        nodes (Directory): node table.\n        edges (Directory): edge table.\n    \"\"\"\n\n    def __init__(\n        self,\n        connectome: ConnectomeDir,\n        groups=[\n            r\"R\\d\",\n            r\"L\\d\",\n            r\"Lawf\\d\",\n            r\"A\",\n            r\"C\\d\",\n            r\"CT\\d.*\",\n            r\"Mi\\d{1,2}\",\n            r\"T\\d{1,2}.*\",\n            r\"Tm.*\\d{1,2}.*\",\n        ],\n    ):\n        self.dir = connectome\n\n        assert \"nodes\" in self.dir and \"edges\" in self.dir\n\n        self.edges = self.dir.edges\n\n        self.nodes = self.dir.nodes\n\n        self.cell_types_unsorted = self.dir.unique_cell_types[:].astype(str)\n\n        (\n            self.cell_types_sorted,\n            self.cell_types_sort_index,\n        ) = nodes_edges_utils.order_node_type_list(\n            self.dir.unique_cell_types[:].astype(str), groups\n        )\n\n        self.layout = dict(self.dir.layout[:].astype(str))\n        self.node_indexer = nodes_edges_utils.NodeIndexer(self.dir)\n\n    # -- connectivity matrix -------------------------------------------------------\n\n    def connectivity_matrix(\n        self,\n        mode: str = \"n_syn\",\n        only_sign: Optional[str] = None,\n        cell_types: Optional[List[str]] = None,\n        no_symlog: Optional[bool] = False,\n        min_number: Optional[float] = None,\n        cmap: Optional[Colormap] = None,\n        size_scale: Optional[float] = None,\n        title: Optional[str] = None,\n        cbar_label: Optional[str] = None,\n        **kwargs,\n    ) -&gt; Figure:\n        \"\"\"Plots the connectivity matrix as counts or weights.\n\n        Args:\n            mode: 'n_syn' referring to number of input synapses,\n                    'count' referring to number of input neurons.\n            only_sign: '+' for displaying only excitatory projections,\n                    '-' for displaying only inhibitory projections.\n            cell_types: provide a subset of nodes to only display those.\n            no_symlog: disable symetric log scale.\n            size_scale: determines the size of the scattered squares.\n\n        Note, kwargs are passed to the heatmap plot function.\n        \"\"\"\n\n        _kwargs = dict(\n            n_syn=dict(\n                symlog=1e-5,\n                grid=True,\n                cmap=cmap or cm.get_cmap(\"seismic\"),\n                title=title or \"Connectivity between identified cell types\",\n                cbar_label=cbar_label or r\"$\\pm\\sum_{pre} N_\\mathrm{syn.}^{pre, post}$\",\n                size_scale=size_scale or 0.05,\n            ),\n            count=dict(\n                grid=True,\n                cmap=cmap or cm.get_cmap(\"seismic\"),\n                midpoint=0,\n                title=title or \"Number of Input Neurons\",\n                cbar_label=cbar_label or r\"$\\sum_{pre} 1$\",\n                size_scale=size_scale or 0.05,\n            ),\n        )\n\n        kwargs.update(_kwargs[mode])\n        if no_symlog:\n            kwargs.update(symlog=None)\n            kwargs.update(midpoint=0)\n\n        edges = self.edges.to_df()\n\n        # to take projections onto central nodes (home columns) into account\n        edges = edges[(edges.target_u == 0) &amp; (edges.target_v == 0)]\n\n        # filter edges to allow providing a subset of cell types\n        cell_types = cell_types or self.cell_types_sorted\n        edges = df_utils.filter_by_column_values(\n            df_utils.filter_by_column_values(\n                edges, column=\"source_type\", values=cell_types\n            ),\n            column=\"target_type\",\n            values=cell_types,\n        )\n        weights = self._weights()[edges.index]\n\n        # lookup table for key -&gt; (i, j)\n        type_index = {node_typ: i for i, node_typ in enumerate(cell_types)}\n        matrix = np.zeros([len(type_index), len(type_index)])\n\n        for srctyp, tgttyp, weight in zip(\n            edges.source_type.values, edges.target_type.values, weights\n        ):\n            if mode == \"count\":\n                # to simply count the number of projections\n                matrix[type_index[srctyp], type_index[tgttyp]] += 1\n            elif mode in [\"weight\", \"n_syn\"]:\n                # to sum the synapse counts\n                matrix[type_index[srctyp], type_index[tgttyp]] += weight\n            else:\n                raise ValueError\n\n        # to filter out all connections weaker than min_number\n        if min_number is not None:\n            matrix[np.abs(matrix) &lt;= min_number] = np.nan\n\n        # to display either only excitatory or inhibitory connections\n        if only_sign == \"+\":\n            matrix[matrix &lt; 0] = 0\n            kwargs.update(symlog=None, midpoint=0)\n        elif only_sign == \"-\":\n            matrix[matrix &gt; 0] = 0\n            kwargs.update(symlog=None, midpoint=0)\n        elif only_sign is None:\n            pass\n        else:\n            raise ValueError\n\n        return plots.heatmap(matrix, cell_types, **kwargs)\n\n    def _weights(self) -&gt; NDArray:\n        return self.edges.sign[:] * self.edges.n_syn[:]\n\n    # -- network graphs ------------------------------------------------------------\n\n    def network_layout(\n        self,\n        max_extent: int = 5,\n        **kwargs,\n    ) -&gt; Figure:\n        \"\"\"Retinotopic hexagonal lattice columnar organization of the network.\n\n        Args:\n            max_extent: integer column radius to visualize.\n        \"\"\"\n        backbone = WholeNetworkFigure(self.dir)\n        backbone.init_figure(figsize=[7, 3])\n        return self.hex_layout_all(\n            max_extent=max_extent, fig=backbone.fig, axes=backbone.axes, **kwargs\n        )\n\n    def hex_layout(\n        self,\n        cell_type: str,\n        max_extent: int = 5,\n        edgecolor=\"none\",\n        edgewidth=0.5,\n        alpha=1,\n        fill=False,\n        cmap=None,\n        fig=None,\n        ax=None,\n        **kwargs,\n    ):\n        \"\"\"Retinotopic hexagonal lattice columnar organization of the cell type.\"\"\"\n        nodes = self.nodes.to_df()\n        node_condition = nodes.type == cell_type\n        u, v = nodes.u[node_condition], nodes.v[node_condition]\n        max_extent = hex_utils.get_extent(u, v) if max_extent is None else max_extent\n        extent_condition = (\n            (-max_extent &lt;= u)\n            &amp; (u &lt;= max_extent)\n            &amp; (-max_extent &lt;= v)\n            &amp; (v &lt;= max_extent)\n            &amp; (-max_extent &lt;= u + v)\n            &amp; (u + v &lt;= max_extent)\n        )\n        u, v = u[extent_condition].values, v[extent_condition].values\n\n        label = cell_type\n        if ax is not None:\n            # prevent labeling twice\n            label = cell_type if cell_type not in [t.get_text() for t in ax.texts] else \"\"\n\n        fig, ax, _ = plots.hex_scatter(\n            u,\n            v,\n            color=1,\n            label=label,\n            fig=fig,\n            ax=ax,\n            edgecolor=edgecolor,\n            edgewidth=edgewidth,\n            alpha=alpha,\n            fill=fill,\n            cmap=cmap or plt_utils.get_alpha_colormap(\"#2f3541\", 1),\n            cbar=False,\n            **kwargs,\n        )\n        return fig\n\n    def hex_layout_all(\n        self,\n        cell_types: str = None,\n        max_extent: int = 5,\n        edgecolor=\"none\",\n        alpha=1,\n        fill=False,\n        cmap=None,\n        fig=None,\n        axes=None,\n        **kwargs,\n    ):\n        \"\"\"Retinotopic hexagonal lattice columnar organization of all cell types.\"\"\"\n        cell_types = self.cell_types_sorted if cell_types is None else cell_types\n        if fig is None or axes is None:\n            fig, axes, (gw, gh) = plt_utils.get_axis_grid(self.cell_types_sorted)\n\n        for i, cell_type in enumerate(cell_types):\n            self.hex_layout(\n                cell_type,\n                edgecolor=edgecolor,\n                edgewidth=0.1,\n                alpha=alpha,\n                fill=fill,\n                max_extent=max_extent,\n                cmap=cmap or plt_utils.get_alpha_colormap(\"#2f3541\", 1),\n                fig=fig,\n                ax=axes[i],\n                **kwargs,\n            )\n        return fig\n\n    def get_uv(self, cell_type) -&gt; Tuple[NDArray]:\n        \"\"\"Hex-coordinates of a particular cell type to pass to hex_scatter plot.\"\"\"\n        nodes = self.nodes.to_df()\n        nodes = nodes[nodes.type == cell_type]\n        u, v = nodes[[\"u\", \"v\"]].values.T\n        return u, v\n\n    # -- receptive fields ----------------------------------------------------------\n\n    def sources_list(self, cell_type: str) -&gt; NDArray:\n        \"\"\"Presynaptic cell types.\"\"\"\n        edges = self.edges.to_df()\n        return np.unique(edges[edges.target_type == cell_type].source_type.values)\n\n    def targets_list(self, cell_type: str) -&gt; NDArray:\n        \"\"\"Postsynaptic cell types.\"\"\"\n        edges = self.edges.to_df()\n        return np.unique(edges[edges.source_type == cell_type].target_type.values)\n\n    def receptive_field(\n        self,\n        source: str = \"Mi9\",\n        target: str = \"T4a\",\n        rfs: Optional[\"ReceptiveFields\"] = None,\n        max_extent: int = None,\n        vmin=None,\n        vmax=None,\n        title=\"{source} :\u2192 {target}\",\n        **kwargs,\n    ):\n        \"\"\"Receptive field of target from source.\"\"\"\n        if rfs is None:\n            rfs = ReceptiveFields(target, self.edges.to_df())\n            max_extent = max_extent or rfs.max_extent\n\n        weights = self._weights()\n\n        # to derive color range values taking all inputs into account\n        vmin = min(\n            0,\n            min(weights[rfs[source].index].min() for source in rfs.source_types),\n        )\n        vmax = max(\n            0,\n            max(weights[rfs[source].index].max() for source in rfs.source_types),\n        )\n\n        weights = weights[rfs[source].index]\n        label = \"\"\n\n        # requires to look from the target cell, ie mirror the coordinates\n        du_inv, dv_inv = -rfs[source].du.values, -rfs[source].dv.values\n        fig, ax, (label_text, scalarmapper) = plots.kernel(\n            du_inv,\n            dv_inv,\n            weights,\n            label=label,\n            max_extent=max_extent,\n            fill=True,\n            vmin=vmin,\n            vmax=vmax,\n            title=title.format(**locals()),\n            **kwargs,\n        )\n        return fig\n\n    def receptive_fields_grid(\n        self,\n        target: str,\n        sources: Iterable[str] = None,\n        sort_alphabetically=True,\n        ax_titles=\"{source} :\u2192 {target}\",\n        figsize=[20, 20],\n        max_extent=None,\n        fig=None,\n        axes=None,\n        ignore_sign_error=False,\n        max_figure_height_cm=22,\n        panel_height_cm=3,\n        max_figure_width_cm=18,\n        panel_width_cm=3.6,\n        **kwargs,\n    ):\n        \"\"\"Receptive fields of target inside a regular grid of axes.\"\"\"\n\n        rfs = ReceptiveFields(target, self.edges.to_df())\n        max_extent = max_extent or rfs.max_extent\n        weights = self._weights()\n\n        # to sort in descending order by sum of inputs\n        sorted_sum_of_inputs = dict(\n            sorted(\n                valmap(lambda v: weights[v.index].sum(), rfs).items(),\n                key=lambda item: item[1],\n                reverse=True,\n            )\n        )\n        # to sort alphabetically in case sources is specified\n        if sort_alphabetically:\n            sources, _ = nodes_edges_utils.order_node_type_list(sources)\n        sources = sources or list(sorted_sum_of_inputs.keys())\n\n        # to derive color range values taking all inputs into account\n        vmin = min(0, min(weights[rfs[source].index].min() for source in sources))\n        vmax = max(0, max(weights[rfs[source].index].max() for source in sources))\n\n        if fig is None or axes is None:\n            figsize = figsize_from_n_items(\n                len(rfs.source_types),\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=panel_height_cm,\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(\n                unmask_n=len(rfs.source_types), hspace=0.0, wspace=0\n            )\n\n        cbar = kwargs.get(\"cbar\", False)\n        for i, src in enumerate(sources):\n            if i == 0 and cbar:\n                cbar = True\n                kwargs.update(cbar=cbar)\n            else:\n                cbar = False\n                kwargs.update(cbar=cbar)\n            try:\n                self.receptive_field(\n                    target=target,\n                    source=src,\n                    fig=fig,\n                    ax=axes[i],\n                    title=ax_titles,\n                    vmin=vmin,\n                    vmax=vmax,\n                    rfs=rfs,\n                    max_extent=max_extent,\n                    annotate=False,\n                    annotate_coords=False,\n                    title_y=0.9,\n                    **kwargs,\n                )\n            except plots.SignError as e:\n                if ignore_sign_error:\n                    pass\n                else:\n                    raise e\n        return fig\n\n    # -- projective fields ---------------------------------------------------------\n\n    def projective_field(\n        self,\n        source: str = \"Mi9\",\n        target: str = \"T4a\",\n        title=\"{source} \u2192: {target}\",\n        prfs: Optional[\"ProjectiveFields\"] = None,\n        max_extent: int = None,\n        vmin=None,\n        vmax=None,\n        **kwargs,\n    ):\n        \"\"\"Projective field from source to target.\"\"\"\n        if prfs is None:\n            prfs = ProjectiveFields(source, self.edges.to_df())\n            max_extent = max_extent or prfs.max_extent\n        if max_extent is None:\n            return None\n        weights = self._weights()\n\n        # to derive color range values taking all inputs into account\n        vmin = min(\n            0,\n            min(weights[prfs[target].index].min() for target in prfs.target_types),\n        )\n\n        vmax = max(\n            0,\n            max(weights[prfs[target].index].max() for target in prfs.target_types),\n        )\n\n        weights = weights[prfs[target].index]\n        label = \"\"\n        du, dv = prfs[target].du.values, prfs[target].dv.values\n        fig, ax, (label_text, scalarmapper) = plots.kernel(\n            du,\n            dv,\n            weights,\n            label=label,\n            fill=True,\n            max_extent=max_extent,\n            vmin=vmin,\n            vmax=vmax,\n            title=title.format(**locals()),\n            **kwargs,\n        )\n        return fig\n\n    def projective_fields_grid(\n        self,\n        source: str,\n        targets: Iterable[str] = None,\n        fig=None,\n        axes=None,\n        figsize=[20, 20],\n        ax_titles=\"{source} \u2192: {target}\",\n        min_axes=-1,\n        max_figure_height_cm=22,\n        panel_height_cm=3,\n        max_figure_width_cm=18,\n        panel_width_cm=3.6,\n        max_extent=None,\n        sort_alphabetically=False,\n        ignore_sign_error=False,\n        **kwargs,\n    ):\n        \"\"\"Projective fields of source inside a regular grid of axes.\"\"\"\n        prfs = ProjectiveFields(source, self.edges.to_df())\n        max_extent = max_extent or prfs.max_extent\n        weights = self._weights()\n        sorted_sum_of_outputs = dict(\n            sorted(\n                valmap(lambda v: weights[v.index].sum(), prfs).items(),\n                key=lambda item: item[1],\n                reverse=True,\n            )\n        )\n\n        # to sort alphabetically in case sources is specified\n        if sort_alphabetically:\n            targets, _ = nodes_edges_utils.order_node_type_list(targets)\n\n        targets = targets or list(sorted_sum_of_outputs.keys())\n\n        vmin = min(0, min(weights[prfs[target].index].min() for target in targets))\n        vmax = max(0, max(weights[prfs[target].index].max() for target in targets))\n\n        if fig is None or axes is None:\n            figsize = figsize_from_n_items(\n                len(prfs.target_types),\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=panel_height_cm,\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(\n                unmask_n=len(prfs.target_types), hspace=0.0, wspace=0\n            )\n\n        cbar = kwargs.get(\"cbar\", False)\n        for i, target in enumerate(targets):\n            if i == 0 and cbar:\n                cbar = True\n                kwargs.update(cbar=cbar)\n            else:\n                cbar = False\n                kwargs.update(cbar=cbar)\n            try:\n                self.projective_field(\n                    source=source,\n                    target=target,\n                    fig=fig,\n                    ax=axes[i],\n                    title=ax_titles,\n                    prfs=prfs,\n                    max_extent=max_extent,\n                    vmin=vmin,\n                    vmax=vmax,\n                    annotate_coords=False,\n                    annotate=False,\n                    title_y=0.9,\n                    **kwargs,\n                )\n            except plots.SignError as e:\n                if ignore_sign_error:\n                    pass\n                else:\n                    raise e\n        return fig\n\n    def receptive_fields_df(self, target_type) -&gt; \"ReceptiveFields\":\n        return ReceptiveFields(target_type, self.edges.to_df())\n\n    def projective_fields_df(self, source_type) -&gt; \"ProjectiveFields\":\n        return ProjectiveFields(source_type, self.edges.to_df())\n\n    def receptive_fields_sum(self, target_type) -&gt; Dict[str, int]:\n        return ReceptiveFields(target_type, self.edges.to_df()).sum()\n\n    def projective_fields_sum(self, source_type) -&gt; Dict[str, int]:\n        return ProjectiveFields(source_type, self.edges.to_df()).sum()\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeView.connectivity_matrix","title":"<code>connectivity_matrix(mode='n_syn', only_sign=None, cell_types=None, no_symlog=False, min_number=None, cmap=None, size_scale=None, title=None, cbar_label=None, **kwargs)</code>","text":"<p>Plots the connectivity matrix as counts or weights.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>\u2018n_syn\u2019 referring to number of input synapses,     \u2018count\u2019 referring to number of input neurons.</p> <code>'n_syn'</code> <code>only_sign</code> <code>Optional[str]</code> <p>\u2019+\u2019 for displaying only excitatory projections,     \u2018-\u2019 for displaying only inhibitory projections.</p> <code>None</code> <code>cell_types</code> <code>Optional[List[str]]</code> <p>provide a subset of nodes to only display those.</p> <code>None</code> <code>no_symlog</code> <code>Optional[bool]</code> <p>disable symetric log scale.</p> <code>False</code> <code>size_scale</code> <code>Optional[float]</code> <p>determines the size of the scattered squares.</p> <code>None</code> <p>Note, kwargs are passed to the heatmap plot function.</p> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>def connectivity_matrix(\n    self,\n    mode: str = \"n_syn\",\n    only_sign: Optional[str] = None,\n    cell_types: Optional[List[str]] = None,\n    no_symlog: Optional[bool] = False,\n    min_number: Optional[float] = None,\n    cmap: Optional[Colormap] = None,\n    size_scale: Optional[float] = None,\n    title: Optional[str] = None,\n    cbar_label: Optional[str] = None,\n    **kwargs,\n) -&gt; Figure:\n    \"\"\"Plots the connectivity matrix as counts or weights.\n\n    Args:\n        mode: 'n_syn' referring to number of input synapses,\n                'count' referring to number of input neurons.\n        only_sign: '+' for displaying only excitatory projections,\n                '-' for displaying only inhibitory projections.\n        cell_types: provide a subset of nodes to only display those.\n        no_symlog: disable symetric log scale.\n        size_scale: determines the size of the scattered squares.\n\n    Note, kwargs are passed to the heatmap plot function.\n    \"\"\"\n\n    _kwargs = dict(\n        n_syn=dict(\n            symlog=1e-5,\n            grid=True,\n            cmap=cmap or cm.get_cmap(\"seismic\"),\n            title=title or \"Connectivity between identified cell types\",\n            cbar_label=cbar_label or r\"$\\pm\\sum_{pre} N_\\mathrm{syn.}^{pre, post}$\",\n            size_scale=size_scale or 0.05,\n        ),\n        count=dict(\n            grid=True,\n            cmap=cmap or cm.get_cmap(\"seismic\"),\n            midpoint=0,\n            title=title or \"Number of Input Neurons\",\n            cbar_label=cbar_label or r\"$\\sum_{pre} 1$\",\n            size_scale=size_scale or 0.05,\n        ),\n    )\n\n    kwargs.update(_kwargs[mode])\n    if no_symlog:\n        kwargs.update(symlog=None)\n        kwargs.update(midpoint=0)\n\n    edges = self.edges.to_df()\n\n    # to take projections onto central nodes (home columns) into account\n    edges = edges[(edges.target_u == 0) &amp; (edges.target_v == 0)]\n\n    # filter edges to allow providing a subset of cell types\n    cell_types = cell_types or self.cell_types_sorted\n    edges = df_utils.filter_by_column_values(\n        df_utils.filter_by_column_values(\n            edges, column=\"source_type\", values=cell_types\n        ),\n        column=\"target_type\",\n        values=cell_types,\n    )\n    weights = self._weights()[edges.index]\n\n    # lookup table for key -&gt; (i, j)\n    type_index = {node_typ: i for i, node_typ in enumerate(cell_types)}\n    matrix = np.zeros([len(type_index), len(type_index)])\n\n    for srctyp, tgttyp, weight in zip(\n        edges.source_type.values, edges.target_type.values, weights\n    ):\n        if mode == \"count\":\n            # to simply count the number of projections\n            matrix[type_index[srctyp], type_index[tgttyp]] += 1\n        elif mode in [\"weight\", \"n_syn\"]:\n            # to sum the synapse counts\n            matrix[type_index[srctyp], type_index[tgttyp]] += weight\n        else:\n            raise ValueError\n\n    # to filter out all connections weaker than min_number\n    if min_number is not None:\n        matrix[np.abs(matrix) &lt;= min_number] = np.nan\n\n    # to display either only excitatory or inhibitory connections\n    if only_sign == \"+\":\n        matrix[matrix &lt; 0] = 0\n        kwargs.update(symlog=None, midpoint=0)\n    elif only_sign == \"-\":\n        matrix[matrix &gt; 0] = 0\n        kwargs.update(symlog=None, midpoint=0)\n    elif only_sign is None:\n        pass\n    else:\n        raise ValueError\n\n    return plots.heatmap(matrix, cell_types, **kwargs)\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeView.network_layout","title":"<code>network_layout(max_extent=5, **kwargs)</code>","text":"<p>Retinotopic hexagonal lattice columnar organization of the network.</p> <p>Parameters:</p> Name Type Description Default <code>max_extent</code> <code>int</code> <p>integer column radius to visualize.</p> <code>5</code> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>def network_layout(\n    self,\n    max_extent: int = 5,\n    **kwargs,\n) -&gt; Figure:\n    \"\"\"Retinotopic hexagonal lattice columnar organization of the network.\n\n    Args:\n        max_extent: integer column radius to visualize.\n    \"\"\"\n    backbone = WholeNetworkFigure(self.dir)\n    backbone.init_figure(figsize=[7, 3])\n    return self.hex_layout_all(\n        max_extent=max_extent, fig=backbone.fig, axes=backbone.axes, **kwargs\n    )\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeView.hex_layout","title":"<code>hex_layout(cell_type, max_extent=5, edgecolor='none', edgewidth=0.5, alpha=1, fill=False, cmap=None, fig=None, ax=None, **kwargs)</code>","text":"<p>Retinotopic hexagonal lattice columnar organization of the cell type.</p> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>def hex_layout(\n    self,\n    cell_type: str,\n    max_extent: int = 5,\n    edgecolor=\"none\",\n    edgewidth=0.5,\n    alpha=1,\n    fill=False,\n    cmap=None,\n    fig=None,\n    ax=None,\n    **kwargs,\n):\n    \"\"\"Retinotopic hexagonal lattice columnar organization of the cell type.\"\"\"\n    nodes = self.nodes.to_df()\n    node_condition = nodes.type == cell_type\n    u, v = nodes.u[node_condition], nodes.v[node_condition]\n    max_extent = hex_utils.get_extent(u, v) if max_extent is None else max_extent\n    extent_condition = (\n        (-max_extent &lt;= u)\n        &amp; (u &lt;= max_extent)\n        &amp; (-max_extent &lt;= v)\n        &amp; (v &lt;= max_extent)\n        &amp; (-max_extent &lt;= u + v)\n        &amp; (u + v &lt;= max_extent)\n    )\n    u, v = u[extent_condition].values, v[extent_condition].values\n\n    label = cell_type\n    if ax is not None:\n        # prevent labeling twice\n        label = cell_type if cell_type not in [t.get_text() for t in ax.texts] else \"\"\n\n    fig, ax, _ = plots.hex_scatter(\n        u,\n        v,\n        color=1,\n        label=label,\n        fig=fig,\n        ax=ax,\n        edgecolor=edgecolor,\n        edgewidth=edgewidth,\n        alpha=alpha,\n        fill=fill,\n        cmap=cmap or plt_utils.get_alpha_colormap(\"#2f3541\", 1),\n        cbar=False,\n        **kwargs,\n    )\n    return fig\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeView.hex_layout_all","title":"<code>hex_layout_all(cell_types=None, max_extent=5, edgecolor='none', alpha=1, fill=False, cmap=None, fig=None, axes=None, **kwargs)</code>","text":"<p>Retinotopic hexagonal lattice columnar organization of all cell types.</p> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>def hex_layout_all(\n    self,\n    cell_types: str = None,\n    max_extent: int = 5,\n    edgecolor=\"none\",\n    alpha=1,\n    fill=False,\n    cmap=None,\n    fig=None,\n    axes=None,\n    **kwargs,\n):\n    \"\"\"Retinotopic hexagonal lattice columnar organization of all cell types.\"\"\"\n    cell_types = self.cell_types_sorted if cell_types is None else cell_types\n    if fig is None or axes is None:\n        fig, axes, (gw, gh) = plt_utils.get_axis_grid(self.cell_types_sorted)\n\n    for i, cell_type in enumerate(cell_types):\n        self.hex_layout(\n            cell_type,\n            edgecolor=edgecolor,\n            edgewidth=0.1,\n            alpha=alpha,\n            fill=fill,\n            max_extent=max_extent,\n            cmap=cmap or plt_utils.get_alpha_colormap(\"#2f3541\", 1),\n            fig=fig,\n            ax=axes[i],\n            **kwargs,\n        )\n    return fig\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeView.get_uv","title":"<code>get_uv(cell_type)</code>","text":"<p>Hex-coordinates of a particular cell type to pass to hex_scatter plot.</p> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>def get_uv(self, cell_type) -&gt; Tuple[NDArray]:\n    \"\"\"Hex-coordinates of a particular cell type to pass to hex_scatter plot.\"\"\"\n    nodes = self.nodes.to_df()\n    nodes = nodes[nodes.type == cell_type]\n    u, v = nodes[[\"u\", \"v\"]].values.T\n    return u, v\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeView.sources_list","title":"<code>sources_list(cell_type)</code>","text":"<p>Presynaptic cell types.</p> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>def sources_list(self, cell_type: str) -&gt; NDArray:\n    \"\"\"Presynaptic cell types.\"\"\"\n    edges = self.edges.to_df()\n    return np.unique(edges[edges.target_type == cell_type].source_type.values)\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeView.targets_list","title":"<code>targets_list(cell_type)</code>","text":"<p>Postsynaptic cell types.</p> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>def targets_list(self, cell_type: str) -&gt; NDArray:\n    \"\"\"Postsynaptic cell types.\"\"\"\n    edges = self.edges.to_df()\n    return np.unique(edges[edges.source_type == cell_type].target_type.values)\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeView.receptive_field","title":"<code>receptive_field(source='Mi9', target='T4a', rfs=None, max_extent=None, vmin=None, vmax=None, title='{source} :\u2192 {target}', **kwargs)</code>","text":"<p>Receptive field of target from source.</p> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>def receptive_field(\n    self,\n    source: str = \"Mi9\",\n    target: str = \"T4a\",\n    rfs: Optional[\"ReceptiveFields\"] = None,\n    max_extent: int = None,\n    vmin=None,\n    vmax=None,\n    title=\"{source} :\u2192 {target}\",\n    **kwargs,\n):\n    \"\"\"Receptive field of target from source.\"\"\"\n    if rfs is None:\n        rfs = ReceptiveFields(target, self.edges.to_df())\n        max_extent = max_extent or rfs.max_extent\n\n    weights = self._weights()\n\n    # to derive color range values taking all inputs into account\n    vmin = min(\n        0,\n        min(weights[rfs[source].index].min() for source in rfs.source_types),\n    )\n    vmax = max(\n        0,\n        max(weights[rfs[source].index].max() for source in rfs.source_types),\n    )\n\n    weights = weights[rfs[source].index]\n    label = \"\"\n\n    # requires to look from the target cell, ie mirror the coordinates\n    du_inv, dv_inv = -rfs[source].du.values, -rfs[source].dv.values\n    fig, ax, (label_text, scalarmapper) = plots.kernel(\n        du_inv,\n        dv_inv,\n        weights,\n        label=label,\n        max_extent=max_extent,\n        fill=True,\n        vmin=vmin,\n        vmax=vmax,\n        title=title.format(**locals()),\n        **kwargs,\n    )\n    return fig\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeView.receptive_fields_grid","title":"<code>receptive_fields_grid(target, sources=None, sort_alphabetically=True, ax_titles='{source} :\u2192 {target}', figsize=[20, 20], max_extent=None, fig=None, axes=None, ignore_sign_error=False, max_figure_height_cm=22, panel_height_cm=3, max_figure_width_cm=18, panel_width_cm=3.6, **kwargs)</code>","text":"<p>Receptive fields of target inside a regular grid of axes.</p> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>def receptive_fields_grid(\n    self,\n    target: str,\n    sources: Iterable[str] = None,\n    sort_alphabetically=True,\n    ax_titles=\"{source} :\u2192 {target}\",\n    figsize=[20, 20],\n    max_extent=None,\n    fig=None,\n    axes=None,\n    ignore_sign_error=False,\n    max_figure_height_cm=22,\n    panel_height_cm=3,\n    max_figure_width_cm=18,\n    panel_width_cm=3.6,\n    **kwargs,\n):\n    \"\"\"Receptive fields of target inside a regular grid of axes.\"\"\"\n\n    rfs = ReceptiveFields(target, self.edges.to_df())\n    max_extent = max_extent or rfs.max_extent\n    weights = self._weights()\n\n    # to sort in descending order by sum of inputs\n    sorted_sum_of_inputs = dict(\n        sorted(\n            valmap(lambda v: weights[v.index].sum(), rfs).items(),\n            key=lambda item: item[1],\n            reverse=True,\n        )\n    )\n    # to sort alphabetically in case sources is specified\n    if sort_alphabetically:\n        sources, _ = nodes_edges_utils.order_node_type_list(sources)\n    sources = sources or list(sorted_sum_of_inputs.keys())\n\n    # to derive color range values taking all inputs into account\n    vmin = min(0, min(weights[rfs[source].index].min() for source in sources))\n    vmax = max(0, max(weights[rfs[source].index].max() for source in sources))\n\n    if fig is None or axes is None:\n        figsize = figsize_from_n_items(\n            len(rfs.source_types),\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=panel_height_cm,\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n        fig, axes = figsize.axis_grid(\n            unmask_n=len(rfs.source_types), hspace=0.0, wspace=0\n        )\n\n    cbar = kwargs.get(\"cbar\", False)\n    for i, src in enumerate(sources):\n        if i == 0 and cbar:\n            cbar = True\n            kwargs.update(cbar=cbar)\n        else:\n            cbar = False\n            kwargs.update(cbar=cbar)\n        try:\n            self.receptive_field(\n                target=target,\n                source=src,\n                fig=fig,\n                ax=axes[i],\n                title=ax_titles,\n                vmin=vmin,\n                vmax=vmax,\n                rfs=rfs,\n                max_extent=max_extent,\n                annotate=False,\n                annotate_coords=False,\n                title_y=0.9,\n                **kwargs,\n            )\n        except plots.SignError as e:\n            if ignore_sign_error:\n                pass\n            else:\n                raise e\n    return fig\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeView.projective_field","title":"<code>projective_field(source='Mi9', target='T4a', title='{source} \u2192: {target}', prfs=None, max_extent=None, vmin=None, vmax=None, **kwargs)</code>","text":"<p>Projective field from source to target.</p> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>def projective_field(\n    self,\n    source: str = \"Mi9\",\n    target: str = \"T4a\",\n    title=\"{source} \u2192: {target}\",\n    prfs: Optional[\"ProjectiveFields\"] = None,\n    max_extent: int = None,\n    vmin=None,\n    vmax=None,\n    **kwargs,\n):\n    \"\"\"Projective field from source to target.\"\"\"\n    if prfs is None:\n        prfs = ProjectiveFields(source, self.edges.to_df())\n        max_extent = max_extent or prfs.max_extent\n    if max_extent is None:\n        return None\n    weights = self._weights()\n\n    # to derive color range values taking all inputs into account\n    vmin = min(\n        0,\n        min(weights[prfs[target].index].min() for target in prfs.target_types),\n    )\n\n    vmax = max(\n        0,\n        max(weights[prfs[target].index].max() for target in prfs.target_types),\n    )\n\n    weights = weights[prfs[target].index]\n    label = \"\"\n    du, dv = prfs[target].du.values, prfs[target].dv.values\n    fig, ax, (label_text, scalarmapper) = plots.kernel(\n        du,\n        dv,\n        weights,\n        label=label,\n        fill=True,\n        max_extent=max_extent,\n        vmin=vmin,\n        vmax=vmax,\n        title=title.format(**locals()),\n        **kwargs,\n    )\n    return fig\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ConnectomeView.projective_fields_grid","title":"<code>projective_fields_grid(source, targets=None, fig=None, axes=None, figsize=[20, 20], ax_titles='{source} \u2192: {target}', min_axes=-1, max_figure_height_cm=22, panel_height_cm=3, max_figure_width_cm=18, panel_width_cm=3.6, max_extent=None, sort_alphabetically=False, ignore_sign_error=False, **kwargs)</code>","text":"<p>Projective fields of source inside a regular grid of axes.</p> Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>def projective_fields_grid(\n    self,\n    source: str,\n    targets: Iterable[str] = None,\n    fig=None,\n    axes=None,\n    figsize=[20, 20],\n    ax_titles=\"{source} \u2192: {target}\",\n    min_axes=-1,\n    max_figure_height_cm=22,\n    panel_height_cm=3,\n    max_figure_width_cm=18,\n    panel_width_cm=3.6,\n    max_extent=None,\n    sort_alphabetically=False,\n    ignore_sign_error=False,\n    **kwargs,\n):\n    \"\"\"Projective fields of source inside a regular grid of axes.\"\"\"\n    prfs = ProjectiveFields(source, self.edges.to_df())\n    max_extent = max_extent or prfs.max_extent\n    weights = self._weights()\n    sorted_sum_of_outputs = dict(\n        sorted(\n            valmap(lambda v: weights[v.index].sum(), prfs).items(),\n            key=lambda item: item[1],\n            reverse=True,\n        )\n    )\n\n    # to sort alphabetically in case sources is specified\n    if sort_alphabetically:\n        targets, _ = nodes_edges_utils.order_node_type_list(targets)\n\n    targets = targets or list(sorted_sum_of_outputs.keys())\n\n    vmin = min(0, min(weights[prfs[target].index].min() for target in targets))\n    vmax = max(0, max(weights[prfs[target].index].max() for target in targets))\n\n    if fig is None or axes is None:\n        figsize = figsize_from_n_items(\n            len(prfs.target_types),\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=panel_height_cm,\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n        fig, axes = figsize.axis_grid(\n            unmask_n=len(prfs.target_types), hspace=0.0, wspace=0\n        )\n\n    cbar = kwargs.get(\"cbar\", False)\n    for i, target in enumerate(targets):\n        if i == 0 and cbar:\n            cbar = True\n            kwargs.update(cbar=cbar)\n        else:\n            cbar = False\n            kwargs.update(cbar=cbar)\n        try:\n            self.projective_field(\n                source=source,\n                target=target,\n                fig=fig,\n                ax=axes[i],\n                title=ax_titles,\n                prfs=prfs,\n                max_extent=max_extent,\n                vmin=vmin,\n                vmax=vmax,\n                annotate_coords=False,\n                annotate=False,\n                title_y=0.9,\n                **kwargs,\n            )\n        except plots.SignError as e:\n            if ignore_sign_error:\n                pass\n            else:\n                raise e\n    return fig\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ReceptiveFields","title":"<code>ReceptiveFields</code>","text":"<p>               Bases: <code>Namespace</code></p> <p>Dictionary of receptive field dataframes for a specific cell type.</p> <p>Parameters:</p> Name Type Description Default <code>target_type</code> <p>target cell type.</p> required <code>edges</code> <p>all edges of a Connectome.</p> required Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>class ReceptiveFields(Namespace):\n    \"\"\"Dictionary of receptive field dataframes for a specific cell type.\n\n    Args:\n        target_type: target cell type.\n        edges: all edges of a Connectome.\n\n    Attributes:\n        target_type str\n        source_types List[str]\n    \"\"\"\n\n    def __init__(self, target_type, edges, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        object.__setattr__(self, \"_extents\", [])\n        _receptive_fields_edge_dfs(self, target_type, edges)\n\n    @property\n    def extents(self):\n        return dict(zip(self.source_types, self._extents))\n\n    @property\n    def max_extent(self):\n        return max(self._extents) if self._extents else None\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__}({self.target_type})\"\n\n    def sum(self):\n        return {key: self[key].n_syn.sum() for key in self}\n</code></pre>"},{"location":"reference/connectome/#flyvision.connectome.ProjectiveFields","title":"<code>ProjectiveFields</code>","text":"<p>               Bases: <code>Namespace</code></p> <p>Dictionary of projective field dataframes for a specific cell type.</p> <p>Parameters:</p> Name Type Description Default <code>source_type</code> <code>str</code> <p>target cell type.</p> required <code>edges</code> <code>DataFrame</code> <p>all edges of a Connectome.</p> required Source code in <code>flyvision/connectome/connectome.py</code> <pre><code>class ProjectiveFields(Namespace):\n    \"\"\"Dictionary of projective field dataframes for a specific cell type.\n\n    Args:\n        source_type: target cell type.\n        edges: all edges of a Connectome.\n\n    Attributes:\n        source_type str\n        target_types List[str]\n    \"\"\"\n\n    def __init__(self, source_type: str, edges: DataFrame, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        object.__setattr__(self, \"_extents\", [])\n        _projective_fields_edge_dfs(self, source_type, edges)\n\n    @property\n    def extents(self):\n        return dict(zip(self.target_types, self._extents))\n\n    @property\n    def max_extent(self):\n        return max(self._extents) if self._extents else None\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__}({self.source_type})\"\n\n    def sum(self):\n        return {key: self[key].n_syn.sum() for key in self}\n</code></pre>"},{"location":"reference/ensemble_clustering/","title":"Ensemble Clustering","text":""},{"location":"reference/ensemble_clustering/#flyvision.analysis.clustering","title":"<code>clustering</code>","text":""},{"location":"reference/ensemble_clustering/#flyvision.analysis.clustering.compute_umap_and_clustering","title":"<code>compute_umap_and_clustering(ensemble, cell_type, embedding_kwargs=None, gm_kwargs=None, subdir='umap_and_clustering')</code>","text":"<p>Compute UMAP embedding and Gaussian Mixture clustering of the responses.</p> Source code in <code>flyvision/analysis/clustering.py</code> <pre><code>def compute_umap_and_clustering(\n    ensemble: \"flyvision.network.EnsembleView\",\n    cell_type: str,\n    embedding_kwargs=None,\n    gm_kwargs=None,\n    subdir=\"umap_and_clustering\",\n):\n    \"\"\"Compute UMAP embedding and Gaussian Mixture clustering of the responses.\"\"\"\n\n    if embedding_kwargs is None:\n        embedding_kwargs = {\n            \"min_dist\": 0.105,\n            \"spread\": 9.0,\n            \"n_neighbors\": 5,\n            \"random_state\": 42,\n            \"n_epochs\": 1500,\n        }\n    if gm_kwargs is None:\n        gm_kwargs = {\n            \"range_n_clusters\": [2, 3, 3, 4, 5],\n            \"n_init\": 100,\n            \"max_iter\": 1000,\n            \"random_state\": 42,\n            \"tol\": 0.001,\n        }\n\n    destination = ensemble.path / subdir\n\n    def load_from_disk():\n        with open((destination / cell_type).with_suffix(\".pickle\"), \"rb\") as f:\n            embedding_and_clustering = pickle.load(f)\n\n        logging.info(\n            \"Loaded %s embedding and clustering from %s.\", cell_type, destination\n        )\n        return embedding_and_clustering\n\n    # Load the embedding and clustering from disk if it exists\n    if (destination / cell_type).with_suffix(\".pickle\").exists():\n        return load_from_disk()\n\n    def create_embedding_object(responses):\n        \"\"\"Return embedding object from cache or create and write cache.\"\"\"\n        central_responses = CentralActivity(\n            responses['responses'].values, ensemble[0].connectome, keepref=True\n        )\n        embeddings = EnsembleEmbedding(central_responses)\n        return embeddings\n\n    responses = naturalistic_stimuli_responses(ensemble)\n    embeddings = create_embedding_object(responses)\n\n    embedding = embeddings.from_cell_type(cell_type, embedding_kwargs=embedding_kwargs)\n    embedding_and_clustering = embedding.cluster.gaussian_mixture(**gm_kwargs)\n    return embedding_and_clustering\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvision.analysis.clustering.umap_embedding","title":"<code>umap_embedding(X, n_neighbors=5, min_dist=0.12, spread=9.0, random_state=42, n_components=2, metric='correlation', n_epochs=1500, **kwargs)</code>","text":"<p>Embedding of X using UMAP.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Array</code> <p>(#samples, 2)</p> required <code>n_neighbors</code> <code>int</code> <p>number of neighbors</p> <code>5</code> <code>min_dist</code> <code>float</code> <p>minimum distance</p> <code>0.12</code> <code>spread</code> <code>float</code> <p>spread</p> <code>9.0</code> <code>random_state</code> <code>int</code> <p>random state</p> <code>42</code> <code>n_components</code> <code>int</code> <p>number of components</p> <code>2</code> <code>metric</code> <code>str</code> <p>metric</p> <code>'correlation'</code> <code>n_epochs</code> <code>int</code> <p>number of epochs</p> <code>1500</code> Source code in <code>flyvision/analysis/clustering.py</code> <pre><code>def umap_embedding(\n    X,\n    n_neighbors=5,\n    min_dist=0.12,\n    spread=9.0,\n    random_state=42,\n    n_components=2,\n    metric=\"correlation\",\n    n_epochs=1500,\n    **kwargs,\n):\n    \"\"\"Embedding of X using UMAP.\n\n    Args:\n        X (Array): (#samples, 2)\n        n_neighbors (int): number of neighbors\n        min_dist (float): minimum distance\n        spread (float): spread\n        random_state (int): random state\n        n_components (int): number of components\n        metric (str): metric\n        n_epochs (int): number of epochs\n    \"\"\"\n\n    if n_components &gt; X.shape[0] - 2:\n        raise ValueError(\n            \"number of components must be 2 smaller than sample size.\"\n            \" See: https://github.com/lmcinnes/umap/issues/201\"\n        )\n\n    if len(X.shape) &gt; 2:\n        shape = X.shape\n        X = X.reshape(X.shape[0], -1)\n        logging.info(f\"reshaped X from {shape} to {X.shape}\")\n\n    embedding = np.ones([X.shape[0], n_components]) * np.nan\n    # umap doesn't like contant rows\n    mask = ~np.isclose(X.std(axis=1), 0)\n    X = X[mask]\n    reducer = UMAP(\n        n_neighbors=n_neighbors,\n        min_dist=min_dist,\n        random_state=random_state,\n        n_components=n_components,\n        metric=metric,\n        spread=spread,\n        n_epochs=n_epochs,\n        **kwargs,\n    )\n    _embedding = reducer.fit_transform(X)\n\n    # gaussian mixture doesn't like nans through disconnected vertices in umap\n    connected_vertices_mask = ~disconnected_vertices(reducer)\n    mask[mask] = mask[mask] &amp; connected_vertices_mask\n    embedding[mask] = _embedding[connected_vertices_mask]\n    return embedding, mask, reducer\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvision.analysis.clustering.GaussianMixtureClustering","title":"<code>GaussianMixtureClustering</code>  <code>dataclass</code>","text":"<p>Gaussian Mixture Clustering of the embeddings.</p> Source code in <code>flyvision/analysis/clustering.py</code> <pre><code>@dataclass\nclass GaussianMixtureClustering:\n    \"\"\"Gaussian Mixture Clustering of the embeddings.\"\"\"\n\n    embedding: Embedding = None\n    range_n_clusters: Iterable[int] = None\n    n_init: int = 1\n    max_iter: int = 1000\n    random_state: int = 0\n    labels: npt.NDArray = None\n    gm: object = None\n    scores: list = None\n    n_clusters: list = None\n\n    def __call__(\n        self,\n        range_n_clusters=None,\n        n_init=1,\n        max_iter=1000,\n        random_state=0,\n        **kwargs,\n    ):\n        self.labels, self.gm, self.scores, self.n_clusters = gaussian_mixture(\n            self.embedding.embedding,\n            self.embedding.mask,\n            range_n_clusters=range_n_clusters,\n            n_init=n_init,\n            max_iter=max_iter,\n            random_state=random_state,\n            **kwargs,\n        )\n        self.range_n_clusters = range_n_clusters\n        self.n_init = n_init\n        self.max_iter = max_iter\n        self.random_state = random_state\n        self.kwargs = kwargs\n        return self\n\n    def task_error_sort_labels(self, task_error, mode=\"mean\"):\n        self.labels = task_error_sort_labels(task_error, self.labels, mode=mode)\n\n    def plot(\n        self,\n        task_error=None,\n        colors=None,\n        annotate=True,\n        annotate_scores=False,\n        fig=None,\n        ax=None,\n        figsize=None,\n        plot_mode=\"paper\",\n        fontsize=5,\n        **kwargs,\n    ):\n        if self.embedding.embedding.shape[1] != 2:\n            raise AssertionError\n        if figsize is None:\n            figsize = [0.94, 2.38]\n        fig, ax = plot_embedding(\n            self.embedding.embedding,\n            colors=colors,\n            task_error=task_error,\n            labels=self.labels,\n            gm=self.gm,\n            mask=self.embedding.mask,\n            fit_gaussians=True,\n            annotate=annotate,\n            title=\"\",\n            fig=fig,\n            ax=ax,\n            mode=plot_mode,\n            figsize=figsize,\n            fontsize=fontsize,\n            range_n_clusters=self.range_n_clusters,\n            n_init_gaussian_mixture=self.n_init,\n            gm_kwargs=self.kwargs,\n            **kwargs,\n        )\n        if annotate_scores:\n            ax.annotate(\n                \"BIC: {:.2f}\".format(np.min(self.scores)),\n                xy=(ax.get_xlim()[0], ax.get_ylim()[1]),\n                ha=\"left\",\n                va=\"top\",\n                fontsize=fontsize,\n            )\n        return EmbeddingPlot(fig, ax, None, None, self.gm.n_components, self)\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvision.analysis.clustering.EnsembleEmbedding","title":"<code>EnsembleEmbedding</code>","text":"<p>Embedding of the ensemble responses.</p> <p>Args: responses (CentralActivity): CentralActivity object</p> Source code in <code>flyvision/analysis/clustering.py</code> <pre><code>class EnsembleEmbedding:\n    \"\"\"Embedding of the ensemble responses.\n\n    Args: responses (CentralActivity): CentralActivity object\n    \"\"\"\n\n    def __init__(self, responses: CentralActivity):\n        self.responses = responses\n\n    def from_cell_type(\n        self,\n        cell_type,\n        embedding_kwargs=None,\n    ) -&gt; Embedding:\n        \"\"\"Umap Embedding of the responses of a specific cell type.\"\"\"\n\n        embedding_kwargs = embedding_kwargs or {}\n        return Embedding(*umap_embedding(self.responses[cell_type], **embedding_kwargs))\n\n    def __call__(\n        self,\n        arg: Union[str, Iterable],\n        embedding_kwargs=None,\n    ):\n        if isinstance(arg, str):\n            return self.from_cell_type(arg, embedding_kwargs)\n        else:\n            raise ValueError(\"arg\")\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvision.analysis.clustering.EnsembleEmbedding.from_cell_type","title":"<code>from_cell_type(cell_type, embedding_kwargs=None)</code>","text":"<p>Umap Embedding of the responses of a specific cell type.</p> Source code in <code>flyvision/analysis/clustering.py</code> <pre><code>def from_cell_type(\n    self,\n    cell_type,\n    embedding_kwargs=None,\n) -&gt; Embedding:\n    \"\"\"Umap Embedding of the responses of a specific cell type.\"\"\"\n\n    embedding_kwargs = embedding_kwargs or {}\n    return Embedding(*umap_embedding(self.responses[cell_type], **embedding_kwargs))\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvision.analysis.clustering.Embedding","title":"<code>Embedding</code>  <code>dataclass</code>","text":"<p>Embedding of the ensemble responses.</p> Source code in <code>flyvision/analysis/clustering.py</code> <pre><code>@dataclass\nclass Embedding:\n    \"\"\"Embedding of the ensemble responses.\"\"\"\n\n    embedding: npt.NDArray = None\n    mask: npt.NDArray = None\n    reducer: object = None\n\n    @property\n    def cluster(self) -&gt; \"Clustering\":\n        return Clustering(self)\n\n    @property\n    def embedding(self) -&gt; npt.NDArray:  # noqa: F811\n        return getattr(self, \"_embedding\", None)\n\n    @embedding.setter\n    def embedding(self, value):\n        self._embedding, self.minmaxscaler = scale_tensor(value)\n\n    def plot(\n        self,\n        fig=None,\n        ax=None,\n        figsize=None,\n        plot_mode=\"paper\",\n        fontsize=5,\n        colors=None,\n        **kwargs,\n    ):\n        \"\"\"Plot the embedding.\"\"\"\n\n        if self.embedding.shape[1] != 2:\n            raise AssertionError\n        if figsize is None:\n            figsize = [0.94, 2.38]\n        return plot_embedding(\n            self.embedding,\n            colors=colors,\n            task_error=None,\n            labels=None,\n            mask=self.mask,\n            fit_gaussians=False,\n            annotate=False,\n            title=\"\",\n            fig=fig,\n            ax=ax,\n            mode=plot_mode,\n            figsize=figsize,\n            fontsize=fontsize,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvision.analysis.clustering.Embedding.plot","title":"<code>plot(fig=None, ax=None, figsize=None, plot_mode='paper', fontsize=5, colors=None, **kwargs)</code>","text":"<p>Plot the embedding.</p> Source code in <code>flyvision/analysis/clustering.py</code> <pre><code>def plot(\n    self,\n    fig=None,\n    ax=None,\n    figsize=None,\n    plot_mode=\"paper\",\n    fontsize=5,\n    colors=None,\n    **kwargs,\n):\n    \"\"\"Plot the embedding.\"\"\"\n\n    if self.embedding.shape[1] != 2:\n        raise AssertionError\n    if figsize is None:\n        figsize = [0.94, 2.38]\n    return plot_embedding(\n        self.embedding,\n        colors=colors,\n        task_error=None,\n        labels=None,\n        mask=self.mask,\n        fit_gaussians=False,\n        annotate=False,\n        title=\"\",\n        fig=fig,\n        ax=ax,\n        mode=plot_mode,\n        figsize=figsize,\n        fontsize=fontsize,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/flash_responses/","title":"Flash responses","text":""},{"location":"reference/flash_responses/#datasets","title":"Datasets","text":""},{"location":"reference/flash_responses/#flyvision.datasets.flashes","title":"<code>flashes</code>","text":"<p>Rendering of circular flash sequences on a hexagonal lattice.</p>"},{"location":"reference/flash_responses/#flyvision.datasets.flashes.RenderedFlashes","title":"<code>RenderedFlashes</code>","text":"<p>               Bases: <code>Directory</code></p> <p>Render a directory with flashes for the Flashes dataset.</p> <p>Parameters:</p> Name Type Description Default <code>boxfilter</code> <code>dict</code> <p>parameters for the BoxEye filter.</p> <code>dict(extent=15, kernel_size=13)</code> <code>dynamic_range</code> <code>list</code> <p>range of intensities. E.g. [0, 1] renders flashes with decrement 0.5-&gt;0 and increment 0.5-&gt;1.</p> <code>[0, 1]</code> <code>t_stim</code> <p>duration of the stimulus.</p> <code>1.0</code> <code>t_pre</code> <p>duration of the grey stimulus.</p> <code>1.0</code> <code>dt</code> <p>timesteps.</p> <code>1 / 200</code> <code>radius</code> <code>list</code> <p>radius of the stimulus.</p> <code>[-1, 6]</code> <code>alternations</code> <p>sequence of alternations between lower or upper intensity and baseline of the dynamic range.</p> <code>(0, 1, 0)</code> Source code in <code>flyvision/datasets/flashes.py</code> <pre><code>@root(renderings_dir)\nclass RenderedFlashes(Directory):\n    \"\"\"Render a directory with flashes for the Flashes dataset.\n\n    Args:\n        boxfilter: parameters for the BoxEye filter.\n        dynamic_range: range of intensities. E.g. [0, 1] renders flashes\n            with decrement 0.5-&gt;0 and increment 0.5-&gt;1.\n        t_stim: duration of the stimulus.\n        t_pre: duration of the grey stimulus.\n        dt: timesteps.\n        radius: radius of the stimulus.\n        alternations: sequence of alternations between lower or upper intensity and\n            baseline of the dynamic range.\n    \"\"\"\n\n    def __init__(\n        self,\n        boxfilter: dict = dict(extent=15, kernel_size=13),\n        dynamic_range: list = [0, 1],\n        t_stim=1.0,\n        t_pre=1.0,\n        dt=1 / 200,\n        radius: list = [-1, 6],\n        alternations=(0, 1, 0),\n    ):\n        boxfilter = BoxEye(**boxfilter)\n        n_ommatidia = len(boxfilter.receptor_centers)\n        dynamic_range = np.array(dynamic_range)\n        baseline = 2 * (dynamic_range.sum() / 2,)\n\n        intensity = dynamic_range.copy()\n        values = np.array(list(zip(baseline, intensity)))\n        samples = dict(v=values, r=radius)\n        values = list(product(*(v for v in samples.values())))\n        sequence = []  # samples, #frames, width, height\n        for (baseline, intensity), rad in tqdm(values, desc=\"Flashes\"):\n            sequence.append(\n                render_flash(\n                    n_ommatidia,\n                    intensity,\n                    baseline,\n                    t_stim,\n                    t_pre,\n                    dt,\n                    alternations,\n                    rad,\n                )\n            )\n\n        self.flashes = np.array(sequence)\n</code></pre>"},{"location":"reference/flash_responses/#flyvision.datasets.flashes.Flashes","title":"<code>Flashes</code>","text":"<p>               Bases: <code>SequenceDataset</code></p> <p>Flashes dataset.</p> <p>Parameters:</p> Name Type Description Default <code>boxfilter</code> <p>parameters for the BoxEye filter.</p> <code>dict(extent=15, kernel_size=13)</code> <code>dynamic_range</code> <p>range of intensities. E.g. [0, 1] renders flashes with decrement 0.5-&gt;0 and increment 0.5-&gt;1.</p> <code>[0, 1]</code> <code>t_stim</code> <p>duration of the stimulus.</p> <code>1.0</code> <code>t_pre</code> <p>duration of the grey stimulus.</p> <code>1.0</code> <code>dt</code> <p>timesteps.</p> <code>1 / 200</code> <code>radius</code> <p>radius of the stimulus.</p> <code>[-1, 6]</code> <code>alternations</code> <p>sequence of alternations between lower or upper intensity and baseline of the dynamic range.</p> <code>(0, 1, 0)</code> Source code in <code>flyvision/datasets/flashes.py</code> <pre><code>class Flashes(SequenceDataset):\n    \"\"\"Flashes dataset.\n\n    Args:\n        boxfilter: parameters for the BoxEye filter.\n        dynamic_range: range of intensities. E.g. [0, 1] renders flashes\n            with decrement 0.5-&gt;0 and increment 0.5-&gt;1.\n        t_stim: duration of the stimulus.\n        t_pre: duration of the grey stimulus.\n        dt: timesteps.\n        radius: radius of the stimulus.\n        alternations: sequence of alternations between lower or upper intensity and\n            baseline of the dynamic range.\n    \"\"\"\n\n    augment = False\n    n_sequences = 0\n    dt = None\n    framerate = None\n    t_post = 0.0\n\n    def __init__(\n        self,\n        boxfilter=dict(extent=15, kernel_size=13),\n        dynamic_range=[0, 1],\n        t_stim=1.0,\n        t_pre=1.0,\n        dt=1 / 200,\n        radius=[-1, 6],\n        alternations=(0, 1, 0),\n    ):\n        assert alternations[0] == 0, \"First alternation must be 0.\"\n        self.flashes_dir = RenderedFlashes(\n            boxfilter=boxfilter,\n            dynamic_range=dynamic_range,\n            t_stim=t_stim,\n            t_pre=t_pre,\n            dt=dt,\n            radius=radius,\n            alternations=alternations,\n        )\n        self.config = self.flashes_dir.config\n        baseline = 2 * (sum(dynamic_range) / 2,)\n        intensity = dynamic_range.copy()\n\n        params = [\n            (p[0][0], p[0][1], p[1])\n            for p in list(product(zip(baseline, intensity), radius))\n        ]\n        self.baseline = baseline[0]\n        self.arg_df = pd.DataFrame(params, columns=[\"baseline\", \"intensity\", \"radius\"])\n\n        self.dt = dt\n\n    @property\n    def t_pre(self):\n        return self.config.t_pre\n\n    @property\n    def t_stim(self):\n        return self.config.t_stim\n\n    def __len__(self):\n        return len(self.arg_df)\n\n    def get_item(self, key):\n        \"\"\"Indexing the dataset.\"\"\"\n        return torch.Tensor(self.flashes_dir.flashes[key])\n\n    def __repr__(self):\n        return f\"Flashes dataset. Parametrization: \\n{self.arg_df}\"\n</code></pre>"},{"location":"reference/flash_responses/#flyvision.datasets.flashes.Flashes.get_item","title":"<code>get_item(key)</code>","text":"<p>Indexing the dataset.</p> Source code in <code>flyvision/datasets/flashes.py</code> <pre><code>def get_item(self, key):\n    \"\"\"Indexing the dataset.\"\"\"\n    return torch.Tensor(self.flashes_dir.flashes[key])\n</code></pre>"},{"location":"reference/flash_responses/#flyvision.datasets.flashes.render_flash","title":"<code>render_flash(n_ommatidia, intensity, baseline, t_stim, t_pre, dt, alternations, radius)</code>","text":"<p>Generate a sequence of flashes on a hexagonal lattice.</p> <p>Parameters:</p> Name Type Description Default <code>n_ommatidia</code> <code>int</code> <p>number of ommatidia.</p> required <code>intensity</code> <code>float</code> <p>intensity of the flash.</p> required <code>baseline</code> <code>float</code> <p>intensity of the baseline.</p> required <code>t_stim</code> <code>float</code> <p>duration of the stimulus.</p> required <code>t_pre</code> <code>float</code> <p>duration of the grey stimulus.</p> required <code>dt</code> <code>float</code> <p>timesteps.</p> required <code>alternations</code> <code>list</code> <p>sequence of alternations between lower or upper intensity and baseline of the dynamic range.</p> required <code>radius</code> <code>int</code> <p>radius of the stimulus.</p> required Source code in <code>flyvision/datasets/flashes.py</code> <pre><code>def render_flash(\n    n_ommatidia, intensity, baseline, t_stim, t_pre, dt, alternations, radius\n):\n    \"\"\"Generate a sequence of flashes on a hexagonal lattice.\n\n    Args:\n        n_ommatidia (int): number of ommatidia.\n        intensity (float): intensity of the flash.\n        baseline (float): intensity of the baseline.\n        t_stim (float): duration of the stimulus.\n        t_pre (float): duration of the grey stimulus.\n        dt (float): timesteps.\n        alternations (list): sequence of alternations between lower or upper intensity\n            and baseline of the dynamic range.\n        radius (int): radius of the stimulus.\n    \"\"\"\n    stimulus = torch.ones(n_ommatidia)[None] * baseline\n\n    if radius != -1:\n        ring = HexLattice.filled_circle(\n            radius=radius, center=Hexal(0, 0, 0), as_lattice=True\n        )\n        coordinate_index = ring.where(1)\n    else:\n        coordinate_index = np.arange(n_ommatidia)\n\n    stimulus[:, coordinate_index] = intensity\n\n    on = resample(stimulus, t_stim, dt)\n    off = resample(torch.ones(n_ommatidia)[None] * baseline, t_pre, dt)\n\n    whole_stimulus = []\n    for switch in alternations:\n        if switch == 0:\n            whole_stimulus.append(off)\n        elif switch == 1:\n            whole_stimulus.append(on)\n    return torch.cat(whole_stimulus, dim=0).cpu().numpy()\n</code></pre>"},{"location":"reference/flash_responses/#arg","title":"Arg","text":""},{"location":"reference/flash_responses/#flyvision.datasets.dots","title":"<code>dots</code>","text":""},{"location":"reference/flash_responses/#analysis","title":"Analysis","text":""},{"location":"reference/flash_responses/#flyvision.analysis.flash_responses","title":"<code>flash_responses</code>","text":""},{"location":"reference/flash_responses/#flyvision.analysis.flash_responses.flash_response_index","title":"<code>flash_response_index(self, radius, on_intensity=1.0, off_intensity=0.0, nonnegative=True)</code>","text":"<p>Compute the Flash Response Index (FRI) using xarray methods.</p> Source code in <code>flyvision/analysis/flash_responses.py</code> <pre><code>def flash_response_index(\n    self: xr.DataArray,\n    radius,\n    on_intensity=1.0,\n    off_intensity=0.0,\n    nonnegative=True,\n) -&gt; xr.DataArray:\n    \"\"\"Compute the Flash Response Index (FRI) using xarray methods.\"\"\"\n\n    # Ensure that the stimulus configuration is correct for FRI computation\n    assert tuple(self.attrs['config']['alternations']) == (0, 1, 0)\n\n    responses = self['responses']\n\n    # Select the time window for the stimulus response using query\n    time_query = (\n        f\"{-self.attrs['config']['dt']} &lt;= time &lt;= {self.attrs['config']['t_stim']}\"\n    )\n    stim_response = responses.query(frame=time_query)\n\n    # Select the data for the given radius\n    stim_response = stim_response.query(sample=f'radius=={radius}')\n\n    # Apply nonnegative constraint if required\n    if nonnegative:\n        minimum = stim_response.min(dim=['frame', 'sample'])\n        stim_response += np.abs(minimum)\n\n    # Select the response data for on and off intensities\n    r_on = stim_response.query(sample=f'intensity=={on_intensity}')\n    r_off = stim_response.query(sample=f'intensity=={off_intensity}')\n\n    # Compute the peak responses by finding the maximum along the 'frame' dimension\n    on_peak = r_on.max(dim='frame')\n    off_peak = r_off.max(dim='frame')\n\n    # Drop the 'sample' coordinate to avoid broadcasting issues\n    on_peak = on_peak.drop('sample')\n    off_peak = off_peak.drop('sample')\n\n    # Compute the Flash Response Index (FRI)\n    fri = on_peak - off_peak\n    fri /= on_peak + off_peak + np.array([1e-16])\n\n    # Optionally, you can drop NaN values after computation\n    return fri.dropna(dim='sample', how='any')\n</code></pre>"},{"location":"reference/flash_responses/#flyvision.analysis.flash_responses.fri_correlation_to_known","title":"<code>fri_correlation_to_known(fris)</code>","text":"<p>Compute the correlation of the FRI to known cell type tunings.</p> Source code in <code>flyvision/analysis/flash_responses.py</code> <pre><code>def fri_correlation_to_known(fris: xr.DataArray) -&gt; xr.DataArray:\n    \"\"\"Compute the correlation of the FRI to known cell type tunings.\"\"\"\n    known_preferred_contrasts = {\n        k: v for k, v in groundtruth_utils.polarity.items() if v != 0\n    }\n    known_cell_types = list(known_preferred_contrasts.keys())\n    groundtruth = list(known_preferred_contrasts.values())\n\n    index = np.array([\n        np.where(nt == fris.cell_type)[0].item() for i, nt in enumerate(known_cell_types)\n    ])\n    fris = fris.isel(neuron=index)\n    groundtruth = xr.DataArray(\n        data=groundtruth,\n        dims=[\"neuron\"],\n    )\n    return xr.corr(fris, groundtruth, dim=\"neuron\")\n</code></pre>"},{"location":"reference/flash_responses/#flyvision.analysis.flash_responses.plot_fris","title":"<code>plot_fris(fris, cell_types, scatter_best=False, scatter_all=True, bold_output_type_labels=True, output_cell_types=None, known_first=True, sorted_type_list=None, figsize=[10, 1], cmap=plt.cm.Greys_r, ylim=(-1, 1), color_known_types=True, fontsize=6, **kwargs)</code>","text":"<p>Plot flash response indices (FRIs) for the given cell types with violins.</p> Source code in <code>flyvision/analysis/flash_responses.py</code> <pre><code>def plot_fris(\n    fris,  # fris.responses[:]\n    cell_types,  # fris.responses.cell_types\n    scatter_best=False,\n    scatter_all=True,\n    bold_output_type_labels=True,\n    output_cell_types=None,\n    known_first=True,\n    sorted_type_list=None,\n    figsize=[10, 1],\n    cmap=plt.cm.Greys_r,\n    ylim=(-1, 1),\n    color_known_types=True,\n    fontsize=6,\n    **kwargs,\n):\n    \"\"\"Plot flash response indices (FRIs) for the given cell types with violins.\"\"\"\n    fig, ax, colors, fris = fri_violins(\n        fris=fris,\n        cell_types=cell_types,\n        cmap=cmap,\n        fontsize=fontsize,\n        sorted_type_list=sorted_type_list,\n        figsize=figsize,\n        scatter_best=scatter_best,\n        scatter_all=scatter_all,\n        known_first=known_first,\n        **kwargs,\n    )\n    ax.grid(False)\n\n    if bold_output_type_labels and output_cell_types is not None:\n        plt_utils.boldify_labels(output_cell_types, ax)\n\n    ax.set_ylim(*ylim)\n    plt_utils.trim_axis(ax)\n    plt_utils.set_spine_tick_params(\n        ax,\n        tickwidth=0.5,\n        ticklength=3,\n        ticklabelpad=2,\n        spinewidth=0.5,\n    )\n\n    if color_known_types:\n        ax = flash_response_color_labels(ax)\n\n    ax.hlines(\n        0,\n        min(ax.get_xticks()),\n        max(ax.get_xticks()),\n        linewidth=0.25,\n        # linestyles=\"dashed\",\n        color=\"k\",\n        zorder=0,\n    )\n    ax.set_yticks(np.arange(-1.0, 1.5, 0.5))\n\n    return fig, ax\n</code></pre>"},{"location":"reference/moving_stimulus_responses/","title":"Moving Stimulus Responses","text":""},{"location":"reference/moving_stimulus_responses/#datasets","title":"Datasets","text":""},{"location":"reference/moving_stimulus_responses/#flyvision.datasets.moving_bar","title":"<code>moving_bar</code>","text":""},{"location":"reference/moving_stimulus_responses/#flyvision.datasets.moving_bar.RenderedOffsets","title":"<code>RenderedOffsets</code>","text":"<p>               Bases: <code>Directory</code></p> <p>Rendered offsets for the moving bar stimulus.</p> <p>Note: This class is used to precompute the offsets for the moving bar (edge) stimuli and store them in a directory. At runtime, the offsets are resampled to allow for changing the time step and to save GB of storage.</p> Source code in <code>flyvision/datasets/moving_bar.py</code> <pre><code>@root(renderings_dir)\nclass RenderedOffsets(Directory):\n    \"\"\"Rendered offsets for the moving bar stimulus.\n\n    Note: This class is used to precompute the offsets for the moving bar (edge) stimuli\n    and store them in a directory. At runtime, the offsets are resampled to allow for\n    changing the time step and to save GB of storage.\n    \"\"\"\n\n    class Config(dict):\n        offsets: list = list(range(-10, 11))\n        angles: list = [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330]\n        widths: list = [1, 2, 4]\n        intensities: list = [0, 1]\n        led_width: float = np.radians(2.25)\n        height: float = np.radians(2.25) * 9\n        n_bars: int = 1\n        bg_intensity: float = 0.5\n        bar_loc_horizontal: float = np.radians(90)\n\n    def __init__(self, config: Config):\n        eye = HexEye(721, 25)\n\n        params = list(product(config.angles, config.widths, config.intensities))\n\n        sequences = {}\n        _tqdm = tqdm(total=len(params), desc=\"building stimuli\")\n        for angle in config.angles:\n            for width in config.widths:\n                for intensity in config.intensities:\n                    offset_bars = eye.offset_bars(\n                        bar_width_rad=width * config.led_width,\n                        bar_height_rad=config.height,\n                        n_bars=config.n_bars,\n                        offsets=np.array(config.offsets) * config.led_width,\n                        bar_intensity=intensity,\n                        bg_intensity=config.bg_intensity,\n                        moving_angle=angle,\n                        bar_loc_horizontal=config.bar_loc_horizontal,\n                    )\n                    sequences[(angle, width, intensity)] = offset_bars\n                    _tqdm.update()\n\n        _tqdm.close()\n        self.offsets = torch.stack([sequences[p] for p in params]).cpu().numpy()\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.datasets.moving_bar.MovingBar","title":"<code>MovingBar</code>","text":"<p>               Bases: <code>StimulusDataset</code></p> <p>Moving bar stimulus.</p> <p>Parameters:</p> Name Type Description Default <code>widths</code> <p>list of int, optional Width of the bar in half ommatidia.</p> <code>[1, 2, 4]</code> <code>offsets</code> <p>tuple of int, optional Tuple of the first and last offset to the central column in half ommatidia.</p> <code>(-10, 11)</code> <code>intensities</code> <p>list of int, optional Intensity of the bar.</p> <code>[0, 1]</code> <code>speeds</code> <p>list of float, optional Speed of the bar in half ommatidia per second.</p> <code>[2.4, 4.8, 9.7, 13, 19, 25]</code> <code>height</code> <p>int, optional Height of the bar in half ommatidia.</p> <code>9</code> <code>dt</code> <p>float, optional Time step in seconds.</p> <code>1 / 200</code> <code>subdir</code> <p>str, optional Subdirectory where the stimulus is stored.</p> <code>'movingbar'</code> <code>device</code> <p>str, optional Device to store the stimulus.</p> <code>device</code> <code>bar_loc_horizontal</code> <p>float, optional Horizontal location of the bar in radians from left to right of image plane. Radians(90) is the center.</p> <code>radians(90)</code> <code>post_pad_mode</code> <p>str, optional Padding mode after the stimulus. One of \u2018continue\u2019, \u2018value\u2019, \u2018reflect\u2019. If \u2018value\u2019 the padding is filled with the value of <code>bg_intensity</code>.</p> <code>'value'</code> <code>t_pre</code> <p>float, optional Time before the stimulus in seconds.</p> <code>1.0</code> <code>t_post</code> <p>float, optional Time after the stimulus in seconds.</p> <code>1.0</code> <code>build_stim_on_init</code> <p>bool, optional Build the stimulus on initialization.</p> <code>True</code> <code>shuffle_offsets</code> <p>bool, optional Shuffle the offsets to remove spatio-temporal correlation.</p> <code>False</code> <code>seed</code> <p>int, optional Seed for the random state.</p> <code>0</code> <code>angles</code> <p>list of int, optional List of angles in degrees.</p> <code>[0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330]</code> Source code in <code>flyvision/datasets/moving_bar.py</code> <pre><code>class MovingBar(StimulusDataset):\n    \"\"\"Moving bar stimulus.\n\n    Args:\n        widths: list of int, optional\n            Width of the bar in half ommatidia.\n        offsets: tuple of int, optional\n            Tuple of the first and last offset to the central column in half ommatidia.\n        intensities: list of int, optional\n            Intensity of the bar.\n        speeds: list of float, optional\n            Speed of the bar in half ommatidia per second.\n        height: int, optional\n            Height of the bar in half ommatidia.\n        dt: float, optional\n            Time step in seconds.\n        subdir: str, optional\n            Subdirectory where the stimulus is stored.\n        device: str, optional\n            Device to store the stimulus.\n        bar_loc_horizontal: float, optional\n            Horizontal location of the bar in radians from left to right of image plane.\n            Radians(90) is the center.\n        post_pad_mode: str, optional\n            Padding mode after the stimulus. One of 'continue', 'value', 'reflect'.\n            If 'value' the padding is filled with the value of `bg_intensity`.\n        t_pre: float, optional\n            Time before the stimulus in seconds.\n        t_post: float, optional\n            Time after the stimulus in seconds.\n        build_stim_on_init: bool, optional\n            Build the stimulus on initialization.\n        shuffle_offsets: bool, optional\n            Shuffle the offsets to remove spatio-temporal correlation.\n        seed: int, optional\n            Seed for the random state.\n        angles: list of int, optional\n            List of angles in degrees.\n    \"\"\"\n\n    augment = False\n    n_sequences = 0\n    framerate = None\n\n    arg_df: pd.DataFrame = None\n\n    def __init__(\n        self,\n        widths=[1, 2, 4],  # in 1 * radians(2.25) led size\n        offsets=(-10, 11),  # in 1 * radians(2.25) led size\n        intensities=[0, 1],\n        speeds=[2.4, 4.8, 9.7, 13, 19, 25],  # in 1 * radians(5.8) / s\n        height=9,  # in 1 * radians(2.25) led size\n        dt=1 / 200,\n        subdir=\"movingbar\",\n        device=flyvision.device,\n        bar_loc_horizontal=np.radians(90),\n        post_pad_mode=\"value\",\n        t_pre=1.0,\n        t_post=1.0,\n        build_stim_on_init=True,  # can speed up things downstream if only responses\n        # are needed\n        shuffle_offsets=False,  # shuffle offsets to remove spatio-temporal correlation\n        # -- can be used as stimulus to compute a baseline of motion selectivity\n        seed=0,  # only for shuffle_offsets\n        angles=[0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n    ):\n        super().__init__()\n        # HexEye parameter\n        self.omm_width = np.radians(5.8)  # radians(5.8 degree)\n\n        # Monitor parameter\n        self.led_width = np.radians(2.25)  # Gruntman et al. 2018\n\n        _locals = locals()\n        self.config = Namespace({\n            arg: _locals[arg]\n            for arg in [\n                \"widths\",\n                \"offsets\",\n                \"intensities\",\n                \"speeds\",\n                \"height\",\n                \"bar_loc_horizontal\",\n                \"shuffle_offsets\",\n                \"post_pad_mode\",\n                \"t_pre\",\n                \"t_post\",\n                \"dt\",\n                \"angles\",\n            ]\n        })\n\n        # Stim parameter\n        self.angles = np.array(angles)\n        self.widths = np.array(widths)  # half ommatidia\n        if len(offsets) == 2:\n            self.offsets = np.arange(*offsets)  # half ommatidia\n        else:\n            assert (\n                np.mean(offsets[1:] - offsets[:-1]) == 1\n            )  # t_stim assumes spacing of 1 corresponding to 2.25 deg\n            self.offsets = offsets\n        self.intensities = np.array(intensities)\n        self.speeds = np.array(speeds)\n        self.bg_intensity = 0.5\n        self.n_bars = 1\n        self.bar_loc_horizontal = bar_loc_horizontal\n\n        self.t_stim = (len(self.offsets) * self.led_width) / (\n            self.speeds * self.omm_width\n        )\n        self.t_stim_max = np.max(self.t_stim)\n\n        self._speed_to_t_stim = dict(zip(self.speeds, self.t_stim))\n\n        self.height = self.led_width * height\n\n        self.post_pad_mode = post_pad_mode\n        self._t_pre = t_pre\n        self._t_post = t_post\n\n        params = [\n            (*p[:-1], *p[-1])\n            for p in list(\n                product(\n                    self.angles,\n                    self.widths,\n                    self.intensities,\n                    zip(self.t_stim, self.speeds),\n                )\n            )\n        ]\n        self.arg_df = pd.DataFrame(\n            params, columns=[\"angle\", \"width\", \"intensity\", \"t_stim\", \"speed\"]\n        )\n\n        self.arg_group_df = self.arg_df.groupby(\n            [\"angle\", \"width\", \"intensity\"], sort=False, as_index=False\n        ).all()\n\n        self.subdir = subdir\n\n        self.device = device\n        self.shuffle_offsets = shuffle_offsets\n        self.randomstate = None\n        if self.shuffle_offsets:\n            self.randomstate = np.random.RandomState(seed=seed)\n\n        self._dt = dt\n\n        self._built = False\n        if build_stim_on_init:\n            self._build()\n            self._resample()\n            self._built = True\n\n    @property\n    def dt(self):\n        return getattr(self, \"_dt\", None)\n\n    @dt.setter\n    def dt(self, value):\n        if self._dt == value:\n            self._dt = value\n            if self._built:\n                self._resample()\n            return\n        logging.warning(\n            f\"Cannot override dt={value} because responses with dt={self._dt} are \"\n            \"initialized.\"\n            f\" Keeping dt={self._dt}.\"\n        )\n\n    def __len__(self):\n        return len(self.arg_df)\n\n    def __repr__(self):\n        return (\n            f\"{self.__class__.__name__}\\n\"\n            + \"Config:\\n\"\n            + repr(self.config)\n            + \"Stimulus parameter:\\n\"\n            + repr(self.arg_df)\n        )\n\n    @property\n    def t_pre(self):\n        return self._t_pre\n\n    @property\n    def t_post(self):\n        return self._t_post\n\n    def _build(self):\n        self.wrap = RenderedOffsets(\n            dict(\n                angles=self.angles,\n                widths=self.widths,\n                intensities=self.intensities,\n                offsets=self.offsets,\n                led_width=self.led_width,\n                height=self.height,\n                n_bars=self.n_bars,\n                bg_intensity=self.bg_intensity,\n                bar_loc_horizontal=self.bar_loc_horizontal,\n            )\n        )\n\n        self._offsets = torch.tensor(self.wrap.offsets[:], device=self.device)\n        self._built = True\n\n    def _resample(self):\n        # resampling at runtime to allow for changing dt and to save GB of\n        # storage.\n        self.sequences = {}\n        self.indices = {}\n        for t, speed in zip(self.t_stim, self.speeds):\n            sequence, indices = resample(\n                self._offsets,\n                t,\n                self.dt,\n                dim=1,\n                device=self.device,\n                return_indices=True,\n            )\n            if self.shuffle_offsets:\n                # breakpoint()\n                sequence = shuffle(sequence, self.randomstate)\n            sequence = pad(\n                sequence,\n                t + self.t_pre,\n                self.dt,\n                mode=\"start\",\n                fill=self.bg_intensity,\n            )\n            sequence = pad(\n                sequence,\n                t + self.t_pre + self.t_post,\n                self.dt,\n                mode=\"end\",\n                pad_mode=self.post_pad_mode,\n                fill=self.bg_intensity,\n            )\n            # Because we fix the distance that the bar moves but vary speeds we\n            # have different stimulation times. To make all sequences equal\n            # length for storing them in a single tensor, we pad them with nans\n            # based on the maximal stimulation time (slowest speed). The nans\n            # can later be removed before processing the traces.\n            sequence = pad(\n                sequence,\n                self.t_stim_max + self.t_pre + self.t_post,\n                self.dt,\n                mode=\"end\",\n                fill=np.nan,\n            )\n            self.sequences[speed] = sequence\n            self.indices[speed] = indices\n\n    def _key(self, angle, width, intensity, speed):\n        try:\n            return self.arg_df.query(\n                f\"angle=={angle}\"\n                f\" &amp; width=={width}\"\n                f\" &amp; intensity == {intensity}\"\n                f\" &amp; speed == {speed}\"\n            ).index.values.item()\n        except ValueError:\n            raise ValueError(\n                f\"angle: {angle}, width: {width}, intensity: {intensity}, \"\n                f\"speed: {speed} invalid.\"\n            ) from None\n\n    def get_sequence_id_from_arguments(self, angle, width, intensity, speed):\n        # generic of _key\n        return self._get_sequence_id_from_arguments(locals())\n\n    def _params(self, key):\n        return self.arg_df.iloc[key].values\n\n    def _group_key(self, angle, width, intensity):\n        return self.arg_group_df.query(\n            f\"angle=={angle}\" f\" &amp; width=={width}\" f\" &amp; intensity == {intensity}\"\n        ).index.values.item()\n\n    def _group_params(self, key):\n        return self.arg_group_df.iloc[key].values\n\n    def get(self, angle, width, intensity, speed):\n        key = self._key(angle, width, intensity, speed)\n        return self[key]\n\n    def get_item(self, key):\n        angle, width, intensity, _, speed = self._params(key)\n        return self.sequences[speed][self._group_key(angle, width, intensity)]\n\n    def mask(self, angle=None, width=None, intensity=None, speed=None, t_stim=None):\n        # 22x faster than df.query\n        values = self.arg_df.values\n\n        def iterparam(param, name, axis, and_condition):\n            condition = np.zeros(len(values)).astype(bool)\n            if isinstance(param, Iterable):\n                for p in param:\n                    _new = values.take(axis, axis=1) == p\n                    assert any(_new), f\"{name} {p} not in dataset.\"\n                    condition = np.logical_or(condition, _new)\n            else:\n                _new = values.take(axis, axis=1) == param\n                assert any(_new), f\"{name} {param} not in dataset.\"\n                condition = np.logical_or(condition, _new)\n            return condition &amp; and_condition\n\n        condition = np.ones(len(values)).astype(bool)\n        if angle is not None:\n            condition = iterparam(angle, \"angle\", 0, condition)\n        if width is not None:\n            condition = iterparam(width, \"width\", 1, condition)\n        if intensity is not None:\n            condition = iterparam(intensity, \"intensity\", 2, condition)\n        if t_stim is not None:\n            condition = iterparam(t_stim, \"t_stim\", 3, condition)\n        if speed is not None:\n            condition = iterparam(speed, \"speed\", 4, condition)\n        return condition\n\n    def time_window(\n        self,\n        speed,\n        from_column=-1,\n        to_column=2,  # , start=-10, end=11, t_pre=1\n    ):\n        return time_window(\n            speed, from_column, to_column, self.offsets[0], self.offsets[1]\n        )\n\n    def mask_between_seconds(self, t_start, t_end):\n        time = self.time\n        return (time &gt;= t_start) &amp; (time &lt;= t_end)\n\n    @property\n    def time(self):\n        return np.arange(-self.t_pre, self.t_stim_max + self.t_post - self.dt, self.dt)\n\n    def stimulus(\n        self,\n        angle=None,\n        width=None,\n        intensity=None,\n        speed=None,\n        pre_stim=True,\n        post_stim=True,\n    ):\n        \"\"\"\n        #TODO: docstring\n        \"\"\"\n        key = self._key(angle, width, intensity, speed)\n        stim = self[key][:, 360].cpu().numpy()\n        if not post_stim:\n            stim = filter_post([stim], self.t_post, self.dt).squeeze()\n        if not pre_stim:\n            stim = filter_pre(stim[None], self.t_pre, self.dt).squeeze()\n        return stim\n\n    def stimulus_parameters(self, angle=None, width=None, intensity=None, speed=None):\n        def _number_to_list(*args):\n            returns = tuple()\n            for arg in args:\n                if isinstance(arg, Number):\n                    returns += ([arg],)\n                else:\n                    returns += (arg,)\n            return returns\n\n        angle, width, speed, intensity = _number_to_list(angle, width, speed, intensity)\n        angle = angle or self.angles\n        width = width or self.widths\n        intensity = intensity or self.intensities\n        speed = speed or self.speeds\n        return angle, width, intensity, speed\n\n    def sample_shape(\n        self,\n        angle=None,\n        width=None,\n        intensity=None,\n        speed=None,\n    ):\n        if isinstance(angle, Number):\n            angle = [angle]\n        if isinstance(width, Number):\n            width = [width]\n        if isinstance(speed, Number):\n            speed = [speed]\n        if isinstance(intensity, Number):\n            intensity = [intensity]\n        angle = angle or self.angles\n        width = width or self.widths\n        intensity = intensity or self.intensities\n        speed = speed or self.speeds\n        return (\n            len(angle),\n            len(width),\n            len(intensity),\n            len(speed),\n        )\n\n    def time_to_center(self, speed: float) -&gt; float:\n        \"\"\"Returns the time in s at which the bar reaches the center.\n\n        Note: time = distance / velocity, i.e.\n            time = (n_leds * led_width) / (speed * omm_width)\n            with speed in ommatidia / s.\n        \"\"\"\n        return np.abs(self.config.offsets[0]) * self.led_width / (speed * self.omm_width)\n\n    def get_time_with_origin_at_onset(self):\n        \"\"\"Time with 0 at the onset of the stimulus.\"\"\"\n        return np.linspace(\n            -self.t_pre,\n            self.t_stim_max - self.t_pre + self.t_post,\n            int(self.t_stim_max / self.dt)\n            + int(self.t_post / self.dt)\n            + int(self.t_pre / self.dt),\n        )\n\n    def get_time_with_origin_at_center(self, speed: float):\n        \"\"\"Time with 0 where the bar reaches the central column.\"\"\"\n        time_to_center = self.time_to_center(speed)\n        n_steps = (\n            int(self.t_stim_max / self.dt)\n            + int(self.t_post / self.dt)\n            + int(self.t_pre / self.dt)\n        )\n        return np.linspace(\n            -(self.t_pre + time_to_center),\n            n_steps * self.dt - (self.t_pre + time_to_center),\n            n_steps,\n        )\n\n    def stimulus_cartoon(\n        self,\n        angle,\n        width,\n        intensity,\n        speed,\n        time_after_stimulus_onset=0.5,\n        fig=None,\n        ax=None,\n        facecolor=\"#000000\",\n        cmap=plt.cm.bone,\n        alpha=0.5,\n        vmin=0,\n        vmax=1,\n        edgecolor=\"none\",\n        central_hex_color=\"#2f7cb9\",\n        **kwargs,\n    ):\n        fig, ax = init_plot(fig=fig, ax=ax)\n\n        time = (\n            np.arange(\n                0,\n                self.t_pre + self.t_stim_max + self.t_post - self.dt,\n                self.dt,\n            )\n            - self.t_pre\n        )\n        index = np.argmin(np.abs(time - time_after_stimulus_onset))\n\n        fig, ax, _ = quick_hex_scatter(\n            self.get(angle=angle, width=width, speed=speed, intensity=intensity)\n            .cpu()\n            .numpy()[index],\n            vmin=vmin,\n            vmax=vmax,\n            cbar=False,\n            figsize=[1, 1],\n            max_extent=5,\n            fig=fig,\n            ax=ax,\n            cmap=cmap,\n            alpha=alpha,\n            edgecolor=edgecolor,\n            **kwargs,\n        )\n        rotation = np.array([\n            [\n                np.cos(np.radians(angle - 90)),\n                -np.sin(np.radians(angle - 90)),\n            ],\n            [\n                np.sin(np.radians(angle - 90)),\n                np.cos(np.radians(angle - 90)),\n            ],\n        ])\n        x = rotation @ np.array([0, -5])\n        dx = rotation @ np.array([0, 1])\n        ax.arrow(\n            *x,\n            *dx,\n            facecolor=facecolor,\n            width=0.75,\n            head_length=2.5,\n            edgecolor=\"k\",\n            linewidth=0.25,\n        )\n        _hex = RegularPolygon(\n            (0, 0),\n            numVertices=6,\n            radius=1,\n            linewidth=1,\n            orientation=np.radians(30),\n            edgecolor=central_hex_color,\n            facecolor=central_hex_color,\n            alpha=1,\n            ls=\"-\",\n        )\n        ax.add_patch(_hex)\n\n        return fig, ax\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.datasets.moving_bar.MovingBar.stimulus","title":"<code>stimulus(angle=None, width=None, intensity=None, speed=None, pre_stim=True, post_stim=True)</code>","text":""},{"location":"reference/moving_stimulus_responses/#flyvision.datasets.moving_bar.MovingBar.stimulus--todo-docstring","title":"TODO: docstring","text":"Source code in <code>flyvision/datasets/moving_bar.py</code> <pre><code>def stimulus(\n    self,\n    angle=None,\n    width=None,\n    intensity=None,\n    speed=None,\n    pre_stim=True,\n    post_stim=True,\n):\n    \"\"\"\n    #TODO: docstring\n    \"\"\"\n    key = self._key(angle, width, intensity, speed)\n    stim = self[key][:, 360].cpu().numpy()\n    if not post_stim:\n        stim = filter_post([stim], self.t_post, self.dt).squeeze()\n    if not pre_stim:\n        stim = filter_pre(stim[None], self.t_pre, self.dt).squeeze()\n    return stim\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.datasets.moving_bar.MovingBar.time_to_center","title":"<code>time_to_center(speed)</code>","text":"<p>Returns the time in s at which the bar reaches the center.</p> time = distance / velocity, i.e. <p>time = (n_leds * led_width) / (speed * omm_width) with speed in ommatidia / s.</p> Source code in <code>flyvision/datasets/moving_bar.py</code> <pre><code>def time_to_center(self, speed: float) -&gt; float:\n    \"\"\"Returns the time in s at which the bar reaches the center.\n\n    Note: time = distance / velocity, i.e.\n        time = (n_leds * led_width) / (speed * omm_width)\n        with speed in ommatidia / s.\n    \"\"\"\n    return np.abs(self.config.offsets[0]) * self.led_width / (speed * self.omm_width)\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.datasets.moving_bar.MovingBar.get_time_with_origin_at_onset","title":"<code>get_time_with_origin_at_onset()</code>","text":"<p>Time with 0 at the onset of the stimulus.</p> Source code in <code>flyvision/datasets/moving_bar.py</code> <pre><code>def get_time_with_origin_at_onset(self):\n    \"\"\"Time with 0 at the onset of the stimulus.\"\"\"\n    return np.linspace(\n        -self.t_pre,\n        self.t_stim_max - self.t_pre + self.t_post,\n        int(self.t_stim_max / self.dt)\n        + int(self.t_post / self.dt)\n        + int(self.t_pre / self.dt),\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.datasets.moving_bar.MovingBar.get_time_with_origin_at_center","title":"<code>get_time_with_origin_at_center(speed)</code>","text":"<p>Time with 0 where the bar reaches the central column.</p> Source code in <code>flyvision/datasets/moving_bar.py</code> <pre><code>def get_time_with_origin_at_center(self, speed: float):\n    \"\"\"Time with 0 where the bar reaches the central column.\"\"\"\n    time_to_center = self.time_to_center(speed)\n    n_steps = (\n        int(self.t_stim_max / self.dt)\n        + int(self.t_post / self.dt)\n        + int(self.t_pre / self.dt)\n    )\n    return np.linspace(\n        -(self.t_pre + time_to_center),\n        n_steps * self.dt - (self.t_pre + time_to_center),\n        n_steps,\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.datasets.moving_bar.MovingEdge","title":"<code>MovingEdge</code>","text":"<p>               Bases: <code>MovingBar</code></p> <p>Moving edge stimulus.</p> <p>Parameters:</p> Name Type Description Default <code>offsets</code> <p>tuple of int, optional Tuple of the first and last offset to the central column in half ommatidia.</p> <code>(-10, 11)</code> <code>intensities</code> <p>list of int, optional Intensity of the bar.</p> <code>[0, 1]</code> <code>speeds</code> <p>list of float, optional Speed of the bar in half ommatidia per second.</p> <code>[2.4, 4.8, 9.7, 13, 19, 25]</code> <code>height</code> <p>int, optional Height of the bar in half ommatidia.</p> <code>9</code> <code>dt</code> <p>float, optional Time step in seconds.</p> <code>1 / 200</code> <code>subdir</code> <p>str, optional Subdirectory where the stimulus is stored.</p> <code>'movingbar'</code> <code>device</code> <p>str, optional Device to store the stimulus.</p> <code>device</code> <code>post_pad_mode</code> <p>str, optional Padding mode after the stimulus. One of \u2018continue\u2019, \u2018value\u2019, \u2018reflect\u2019. If \u2018value\u2019 the padding is filled with the value of <code>bg_intensity</code>.</p> <code>'continue'</code> <code>t_pre</code> <p>float, optional Time before the stimulus in seconds.</p> <code>1.0</code> <code>t_post</code> <p>float, optional Time after the stimulus in seconds.</p> <code>1.0</code> <code>build_stim_on_init</code> <p>bool, optional Build the stimulus on initialization.</p> <code>True</code> <code>shuffle_offsets</code> <p>bool, optional Shuffle the offsets to remove spatio-temporal correlation.</p> <code>False</code> <code>seed</code> <p>int, optional Seed for the random state.</p> <code>0</code> <code>angles</code> <p>list of int, optional List of angles in degrees.</p> <code>[0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330]</code> Source code in <code>flyvision/datasets/moving_bar.py</code> <pre><code>class MovingEdge(MovingBar):\n    \"\"\"Moving edge stimulus.\n\n    Args:\n        offsets: tuple of int, optional\n            Tuple of the first and last offset to the central column in half ommatidia.\n        intensities: list of int, optional\n            Intensity of the bar.\n        speeds: list of float, optional\n            Speed of the bar in half ommatidia per second.\n        height: int, optional\n            Height of the bar in half ommatidia.\n        dt: float, optional\n            Time step in seconds.\n        subdir: str, optional\n            Subdirectory where the stimulus is stored.\n        device: str, optional\n            Device to store the stimulus.\n        post_pad_mode: str, optional\n            Padding mode after the stimulus. One of 'continue', 'value', 'reflect'.\n            If 'value' the padding is filled with the value of `bg_intensity`.\n        t_pre: float, optional\n            Time before the stimulus in seconds.\n        t_post: float, optional\n            Time after the stimulus in seconds.\n        build_stim_on_init: bool, optional\n            Build the stimulus on initialization.\n        shuffle_offsets: bool, optional\n            Shuffle the offsets to remove spatio-temporal correlation.\n        seed: int, optional\n            Seed for the random state.\n        angles: list of int, optional\n            List of angles in degrees.\n    \"\"\"\n\n    def __init__(\n        self,\n        offsets=(-10, 11),  # in 1 * radians(2.25) led size\n        intensities=[0, 1],\n        speeds=[2.4, 4.8, 9.7, 13, 19, 25],  # in 1 * radians(5.8) / s\n        height=9,  # in 1 * radians(2.25) led size\n        dt=1 / 200,\n        subdir=\"movingbar\",\n        device=flyvision.device,\n        post_pad_mode=\"continue\",\n        t_pre=1.0,\n        t_post=1.0,\n        build_stim_on_init=True,  # can speed up things downstream if only responses\n        # are needed\n        shuffle_offsets=False,  # shuffle offsets to remove spatio-temporal correlation\n        # -- can be used as stimulus to compute a baseline of motion selectivity\n        seed=0,  # only for shuffle_offsets\n        angles=[0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n        **kwargs,\n    ):\n        super().__init__(\n            # arbitrary large value to make the 'bar' wide enough to appear as an edge\n            widths=[80],\n            offsets=offsets,\n            intensities=intensities,\n            speeds=speeds,\n            height=height,\n            dt=dt,\n            subdir=subdir,\n            device=device,\n            # the center of the bar will start at the left edge of the screen\n            bar_loc_horizontal=np.radians(0),\n            post_pad_mode=post_pad_mode,\n            t_pre=t_pre,\n            t_post=t_post,\n            build_stim_on_init=build_stim_on_init,\n            shuffle_offsets=shuffle_offsets,\n            seed=seed,\n            angles=angles,\n        )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#response-analysis","title":"Response Analysis","text":""},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_bar_responses","title":"<code>moving_bar_responses</code>","text":""},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_bar_responses.dsi_correlation_to_known","title":"<code>dsi_correlation_to_known(dsis)</code>","text":"<p>Computes the correlation between predicted DSIs and known DSIs.</p> <p>Parameters:</p> Name Type Description Default <code>dsis</code> <code>DataArray</code> <p>DataArray containing the DSIs for ON and OFF intensities, with dimensions including \u2018intensity\u2019 and \u2018neuron\u2019, and a coordinate \u2018cell_type\u2019.</p> required <p>Note: known DSIs are binary, either 0 or 1, depending on whether the cell type is known to be motion-tuned or not.</p> Source code in <code>flyvision/analysis/moving_bar_responses.py</code> <pre><code>def dsi_correlation_to_known(dsis: xr.DataArray) -&gt; xr.DataArray:\n    \"\"\"\n    Computes the correlation between predicted DSIs and known DSIs.\n\n    Args:\n        dsis (xarray.DataArray): DataArray containing the DSIs for\n            ON and OFF intensities, with dimensions including 'intensity' and 'neuron',\n            and a coordinate 'cell_type'.\n\n    Note: known DSIs are binary, either 0 or 1, depending on whether the cell type\n    is known to be motion-tuned or not.\n    \"\"\"\n    # Ensure the 'intensity' dimension has length 2\n    assert dsis.sizes['intensity'] == 2, \"Dimension 'intensity' should have length 2\"\n\n    # Retrieve ground truth motion tuning information\n    motion_tuning = groundtruth_utils.motion_tuning\n    known_dsi_types = groundtruth_utils.known_dsi_types\n\n    # Select dsis for known cell types\n    dsis_for_known = dsis.where(dsis['cell_type'].isin(known_dsi_types), drop=True)\n\n    # Construct ground truth motion tuning array\n    groundtruth_mt = xr.DataArray(\n        [\n            1.0 if ct in motion_tuning else 0.0\n            for ct in dsis_for_known['cell_type'].values\n        ],\n        coords={'neuron': dsis_for_known['neuron']},\n        dims=['neuron'],\n    )\n\n    # Compute correlation along 'neuron' dimension\n    corr_dsi = xr.corr(dsis_for_known, groundtruth_mt, dim='neuron')\n\n    return corr_dsi\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_bar_responses.get_time_masks","title":"<code>get_time_masks(dataset, from_column=-1.5, to_column=1.5)</code>","text":"<p>Generate time masks for each sample based on speed and specified column range.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The input dataset containing \u2018speed\u2019 and \u2018time\u2019 coordinates.</p> required <code>from_column</code> <code>float</code> <p>Start of the column range.</p> <code>-1.5</code> <code>to_column</code> <code>float</code> <p>End of the column range.</p> <code>1.5</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>xr.DataArray: A boolean mask with dimensions (\u2018sample\u2019, \u2018frame\u2019).</p> Source code in <code>flyvision/analysis/moving_bar_responses.py</code> <pre><code>def get_time_masks(\n    dataset: xr.Dataset, from_column: float = -1.5, to_column: float = 1.5\n) -&gt; xr.DataArray:\n    \"\"\"\n    Generate time masks for each sample based on speed and specified column range.\n\n    Args:\n        dataset (xr.Dataset): The input dataset containing 'speed' and 'time' coordinates.\n        from_column (float): Start of the column range.\n        to_column (float): End of the column range.\n\n    Returns:\n        xr.DataArray: A boolean mask with dimensions ('sample', 'frame').\n    \"\"\"\n    speeds = dataset['speed'].values\n    unique_speeds = np.unique(speeds)\n    config = dataset.attrs['config']\n    start, end = config['offsets']\n    times = dataset['time'].values\n\n    # Precompute masks for unique speeds\n    mask_dict = {}\n    for speed in unique_speeds:\n        t_start, t_end = time_window(\n            speed, from_column=from_column, to_column=to_column, start=start, end=end\n        )\n        mask_dict[speed] = mask_between_seconds(t_start, t_end, times)\n\n    # Map masks to each sample based on its speed\n    masks = np.array([mask_dict[speed] for speed in speeds])\n\n    # Create a DataArray for the masks\n    mask_da = xr.DataArray(\n        data=masks,\n        dims=('sample', 'frame'),\n        coords={'sample': dataset['sample'], 'frame': dataset['frame']},\n    )\n\n    return mask_da\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_bar_responses.peak_responses","title":"<code>peak_responses(dataset, norm=None, from_degree=None, to_degree=None)</code>","text":"<p>Compute peak responses from rectified voltages, optionally normalized.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The input dataset containing \u2018responses\u2019 and necessary coordinates.</p> required <code>norm</code> <code>DataArray</code> <p>Normalization array. Defaults to None.</p> <code>None</code> <code>from_degree</code> <code>float</code> <p>Starting degree for masking. Defaults to None.</p> <code>None</code> <code>to_degree</code> <code>float</code> <p>Ending degree for masking. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>xr.DataArray: Peak responses with reshaped and transposed dimensions.</p> Source code in <code>flyvision/analysis/moving_bar_responses.py</code> <pre><code>def peak_responses(\n    dataset: xr.Dataset,\n    norm: xr.DataArray = None,\n    from_degree: float = None,\n    to_degree: float = None,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Compute peak responses from rectified voltages, optionally normalized.\n\n    Args:\n        dataset (xr.Dataset): The input dataset containing 'responses' and necessary\n            coordinates.\n        norm (xr.DataArray, optional): Normalization array. Defaults to None.\n        from_degree (float, optional): Starting degree for masking. Defaults to None.\n        to_degree (float, optional): Ending degree for masking. Defaults to None.\n\n    Returns:\n        xr.DataArray: Peak responses with reshaped and transposed dimensions.\n    \"\"\"\n    config = dataset.attrs['config']\n    from_degree = from_degree if from_degree is not None else config['offsets'][0] * 2.25\n    to_degree = to_degree if to_degree is not None else (config['offsets'][1] - 1) * 2.25\n\n    # Generate time masks\n    masks = get_time_masks(\n        dataset, from_column=from_degree / 5.8, to_column=to_degree / 5.8\n    )\n\n    # Apply masks to responses and rectify\n    responses = dataset['responses']\n    masked = responses.where(masks, other=0)\n    rectified = masked.clip(min=0)  # Rectify: max(0, response)\n\n    # Normalize if provided\n    if norm is not None:\n        rectified = rectified / norm\n\n    # Compute peak (maximum over 'frame')\n    peak = rectified.max(dim='frame')\n    return peak\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_bar_responses.get_groundtruth_tuning_curves","title":"<code>get_groundtruth_tuning_curves(cell_types, angles)</code>","text":"<p>Retrieves the ground truth tuning curves for the specified cell types. Optionally interpolates the curves to match the provided angles.</p> Source code in <code>flyvision/analysis/moving_bar_responses.py</code> <pre><code>def get_groundtruth_tuning_curves(cell_types: List[str], angles: np.ndarray):\n    \"\"\"\n    Retrieves the ground truth tuning curves for the specified cell types.\n    Optionally interpolates the curves to match the provided angles.\n    \"\"\"\n    gt_angles = np.arange(0, 360, 30)\n    tuning_curves = []\n\n    for cell_type in cell_types:\n        gt_tuning = groundtruth_utils.tuning_curves[cell_type]\n        interp_func = interp1d(\n            gt_angles, gt_tuning, kind='cubic', fill_value=\"extrapolate\"\n        )\n        gt_tuning = interp_func(angles)\n        tuning_curves.append(gt_tuning)\n\n    dataset = xr.DataArray(\n        np.array(tuning_curves),\n        dims=['neuron', 'angle'],\n        coords={'cell_type': (\"neuron\", cell_types), 'angle': angles},\n    )\n\n    return dataset\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_bar_responses.peak_responses_angular","title":"<code>peak_responses_angular(dataset, norm=None, from_degree=None, to_degree=None)</code>","text":"<p>Compute peak responses and make them complex over angles.</p> Source code in <code>flyvision/analysis/moving_bar_responses.py</code> <pre><code>def peak_responses_angular(\n    dataset: xr.Dataset,\n    norm: xr.DataArray = None,\n    from_degree: float = None,\n    to_degree: float = None,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Compute peak responses and make them complex over angles.\n    \"\"\"\n    peak = peak_responses(\n        dataset, norm=norm, from_degree=from_degree, to_degree=to_degree\n    )\n\n    # Make complex over angles\n    angles = peak['angle'].values\n    radians = np.deg2rad(angles)\n    # Expand dimensions to match broadcasting\n    radians = radians[np.newaxis, :, np.newaxis]\n    complex_peak = peak * np.exp(1j * radians)\n\n    return complex_peak\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_bar_responses.direction_selectivity_index","title":"<code>direction_selectivity_index(dataset, average=True, norm=None, from_degree=None, to_degree=None)</code>","text":"<p>Compute Direction Selectivity Index (DSI).</p> Source code in <code>flyvision/analysis/moving_bar_responses.py</code> <pre><code>def direction_selectivity_index(\n    dataset: xr.Dataset,\n    average: bool = True,\n    norm: xr.DataArray = None,\n    from_degree: float = None,\n    to_degree: float = None,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Compute Direction Selectivity Index (DSI).\n    \"\"\"\n    view = peak_responses_angular(\n        dataset, norm=norm, from_degree=from_degree, to_degree=to_degree\n    )\n    view = view.set_index(sample=[\"angle\", \"width\", \"intensity\", \"speed\"]).unstack(\n        \"sample\"\n    )\n\n    # Compute vector sum over 'angle'\n    vector_sum = view.sum(dim='angle')\n    vector_length = np.abs(vector_sum)\n\n    # Normalization: sum of absolute responses\n    normalization = np.abs(view).sum(dim='angle').max(dim='intensity')\n    dsi = vector_length / (normalization + 1e-15)\n\n    if average:\n        # Average over 'width' and 'speed'\n        dsi = dsi.mean(dim=['width', 'speed'])\n\n    return dsi.squeeze()\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_bar_responses.preferred_direction","title":"<code>preferred_direction(dataset, average=True, norm=None, from_degree=None, to_degree=None)</code>","text":"<p>Compute the preferred direction based on peak responses.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The input dataset.</p> required <code>average</code> <code>bool</code> <p>Whether to average over certain dimensions. Defaults to True.</p> <code>True</code> <code>norm</code> <code>DataArray</code> <p>Normalization array. Defaults to None.</p> <code>None</code> <code>from_degree</code> <code>float</code> <p>Starting degree for masking. Defaults to None.</p> <code>None</code> <code>to_degree</code> <code>float</code> <p>Ending degree for masking. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>xr.DataArray: Preferred direction angles in radians.</p> Source code in <code>flyvision/analysis/moving_bar_responses.py</code> <pre><code>def preferred_direction(\n    dataset: xr.Dataset,\n    average: bool = True,\n    norm: xr.DataArray = None,\n    from_degree: float = None,\n    to_degree: float = None,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Compute the preferred direction based on peak responses.\n\n    Args:\n        dataset (xr.Dataset): The input dataset.\n        average (bool, optional): Whether to average over certain dimensions. Defaults\n            to True.\n        norm (xr.DataArray, optional): Normalization array. Defaults to None.\n        from_degree (float, optional): Starting degree for masking. Defaults to None.\n        to_degree (float, optional): Ending degree for masking. Defaults to None.\n\n    Returns:\n        xr.DataArray: Preferred direction angles in radians.\n    \"\"\"\n    view = peak_responses_angular(\n        dataset, norm=norm, from_degree=from_degree, to_degree=to_degree\n    )\n    view = view.set_index(sample=[\"angle\", \"width\", \"intensity\", \"speed\"]).unstack(\n        \"sample\"\n    )\n\n    # Compute vector sum over 'angle'\n    vector_sum = view.sum(dim='angle')\n    theta_pref = np.angle(vector_sum)\n\n    if average:\n        # Sum over 'width' and 'speed' before computing angle\n        vector_sum = view.sum(dim=['width', 'speed', 'angle'])\n        theta_pref = np.angle(vector_sum)\n\n    vector_sum.data = theta_pref\n    return vector_sum\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_bar_responses.simple_angle_distance","title":"<code>simple_angle_distance(a, b, upper=np.pi)</code>","text":"<p>Element-wise angle distance between 0 and pi radians.</p> <p>Parameters:</p> Name Type Description Default <code>a,</code> <code>b</code> <p>angle in radians, same shape</p> required <p>Returns: distance between 0 and pi radians.</p> Source code in <code>flyvision/analysis/moving_bar_responses.py</code> <pre><code>def simple_angle_distance(a, b, upper=np.pi):\n    \"\"\"Element-wise angle distance between 0 and pi radians.\n\n    Args:\n        a, b: angle in radians, same shape\n\n    Returns: distance between 0 and pi radians.\n    \"\"\"\n    a = np.atleast_1d(a)\n    b = np.atleast_1d(b)\n    # a = np.radians(a)\n    # b = np.radians(b)\n    # make all angles positive between 0 and 2 * pi\n    a = a % 2 * np.pi\n    b = b % 2 * np.pi\n\n    y = np.zeros_like(a)\n    # subtract the smaller angle from the larger one\n    mask = a &gt;= b\n    y[mask] = a[mask] - b[mask]\n    y[~mask] = b[~mask] - a[~mask]\n\n    # map distances between pi and 2 pi to 0 and pi\n    y[y &gt; np.pi] = 2 * np.pi - y[y &gt; np.pi]\n\n    # map distances between 0 and pi to 0 and upper\n    return y / np.pi * upper\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_bar_responses.plot_angular_tuning","title":"<code>plot_angular_tuning(dataset, cell_type, intensity, figsize=(1, 1), fontsize=5, linewidth=1, anglepad=-7, xlabelpad=-1, groundtruth=True, groundtruth_linewidth=1.0, fig=None, ax=None, peak_responses_da=None, weighted_average=None, average_models=False, colors=None, zorder=0, **kwargs)</code>","text":"<p>Plot angular tuning for a specific cell type and intensity.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The input dataset.</p> required <code>cell_type</code> <code>int</code> <p>The neuron index to plot.</p> required <code>intensity</code> <code>int</code> <p>The intensity level (0 or 1).</p> required <code>figsize</code> <code>tuple</code> <p>Figure size. Defaults to (6, 6).</p> <code>(1, 1)</code> <code>fontsize</code> <code>int</code> <p>Font size. Defaults to 12.</p> <code>5</code> <code>linewidth</code> <code>float</code> <p>Line width. Defaults to 2.</p> <code>1</code> <code>anglepad</code> <code>float</code> <p>Angle padding. Defaults to -7.</p> <code>-7</code> <code>xlabelpad</code> <code>float</code> <p>X-label padding. Defaults to -1.</p> <code>-1</code> <code>groundtruth</code> <code>bool</code> <p>Whether to plot ground truth. Defaults to False.</p> <code>True</code> <code>groundtruth_linewidth</code> <code>float</code> <p>Line width for ground truth. Defaults to 1.0.</p> <code>1.0</code> <code>fig</code> <code>Figure</code> <p>Existing figure. Defaults to None.</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>Existing axes. Defaults to None.</p> <code>None</code> <code>peak_responses_da</code> <code>DataArray</code> <p>Precomputed peak responses. Defaults to None.</p> <code>None</code> <code>weighted_average</code> <code>DataArray</code> <p>Weights for averaging models. Defaults to None.</p> <code>None</code> <code>average_models</code> <code>bool</code> <p>Whether to average across models. Defaults to False.</p> <code>False</code> <code>colors</code> <code>str</code> <p>Color for the plot. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for plotting.</p> <code>{}</code> <p>Returns:</p> Type Description <p>matplotlib.figure.Figure, matplotlib.axes.Axes: The figure and axes objects.</p> Source code in <code>flyvision/analysis/moving_bar_responses.py</code> <pre><code>def plot_angular_tuning(\n    dataset: xr.Dataset,\n    cell_type: int,\n    intensity: int,\n    figsize=(1, 1),\n    fontsize: int = 5,\n    linewidth: float = 1,\n    anglepad: float = -7,\n    xlabelpad: float = -1,\n    groundtruth: bool = True,\n    groundtruth_linewidth: float = 1.0,\n    fig: plt.Figure = None,\n    ax: plt.Axes = None,\n    peak_responses_da: xr.DataArray = None,\n    weighted_average: xr.DataArray = None,\n    average_models: bool = False,\n    colors: str = None,\n    zorder: int | Iterable = 0,\n    **kwargs,\n):\n    \"\"\"\n    Plot angular tuning for a specific cell type and intensity.\n\n    Args:\n        dataset (xr.Dataset): The input dataset.\n        cell_type (int): The neuron index to plot.\n        intensity (int): The intensity level (0 or 1).\n        figsize (tuple, optional): Figure size. Defaults to (6, 6).\n        fontsize (int, optional): Font size. Defaults to 12.\n        linewidth (float, optional): Line width. Defaults to 2.\n        anglepad (float, optional): Angle padding. Defaults to -7.\n        xlabelpad (float, optional): X-label padding. Defaults to -1.\n        groundtruth (bool, optional): Whether to plot ground truth. Defaults to False.\n        groundtruth_linewidth (float, optional): Line width for ground truth.\n            Defaults to 1.0.\n        fig (plt.Figure, optional): Existing figure. Defaults to None.\n        ax (plt.Axes, optional): Existing axes. Defaults to None.\n        peak_responses_da (xr.DataArray, optional): Precomputed peak responses.\n            Defaults to None.\n        weighted_average (xr.DataArray, optional): Weights for averaging models.\n            Defaults to None.\n        average_models (bool, optional): Whether to average across models.\n            Defaults to False.\n        colors (str, optional): Color for the plot. Defaults to None.\n        **kwargs: Additional keyword arguments for plotting.\n\n    Returns:\n        matplotlib.figure.Figure, matplotlib.axes.Axes: The figure and axes objects.\n    \"\"\"\n    if peak_responses_da is None:\n        peak_responses_da = peak_responses(dataset)\n\n    peak_responses_da = peak_responses_da.set_index(\n        sample=[\"angle\", \"width\", \"intensity\", \"speed\"]\n    ).unstack(\"sample\")\n\n    # Select the specific cell type\n    peak = peak_responses_da.custom.where(cell_type=cell_type, intensity=intensity)\n\n    # Squeeze irrelevant dimensions\n    # peak = peak.squeeze(dim=['width', 'intensity', 'speed'], drop=True)\n\n    # Average over speeds\n    average_tuning = peak.mean(dim=('speed', 'width'))\n\n    # Average over models if specified\n    if average_models and weighted_average is not None:\n        average_tuning = average_tuning.weighted(weighted_average).mean(dim='network_id')\n    elif average_models:\n        average_tuning = average_tuning.mean(dim='network_id')\n\n    color = (ON if intensity == 1 else OFF) if colors is None else colors\n\n    average_tuning = average_tuning / average_tuning.max()\n\n    angles = average_tuning['angle'].values\n    fig, ax = polar(\n        angles,\n        average_tuning.data.squeeze().T,\n        figsize=figsize,\n        fontsize=fontsize,\n        linewidth=linewidth,\n        anglepad=anglepad,\n        xlabelpad=xlabelpad,\n        color=color,\n        fig=fig,\n        ax=ax,\n        zorder=zorder,\n        **kwargs,\n    )\n\n    if groundtruth and cell_type in groundtruth_utils.tuning_curves:\n        r_gt = np.array(groundtruth_utils.tuning_curves[cell_type])\n        r_gt = r_gt / np.max(np.abs(r_gt))\n        theta_gt = np.arange(0, 360, 360 / len(r_gt))\n        polar(\n            theta_gt,\n            r_gt,\n            figsize=figsize,\n            fontsize=fontsize,\n            linewidth=groundtruth_linewidth,\n            anglepad=anglepad,\n            xlabelpad=xlabelpad,\n            color=\"k\",\n            fig=fig,\n            ax=ax,\n            # **kwargs,\n        )\n\n    return fig, ax\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#current-analysis","title":"Current Analysis","text":""},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_edge_currents","title":"<code>moving_edge_currents</code>","text":""},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_edge_currents.MovingEdgeCurrentView","title":"<code>MovingEdgeCurrentView</code>","text":"Source code in <code>flyvision/analysis/moving_edge_currents.py</code> <pre><code>class MovingEdgeCurrentView:\n    def __init__(\n        self,\n        ensemble,\n        target_type,\n        current_dir,\n        arg_df,\n        currents=None,\n        rfs=None,\n        time=None,\n        responses=None,\n    ):\n        self.target_type = target_type\n        self.ensemble = ensemble\n        self.current_dir = current_dir\n        self.config = ensemble[0].dir[current_dir].config\n        self.arg_df = arg_df\n        self.rfs = rfs or reset_index(\n            ReceptiveFields(target_type, ensemble[0].connectome.edges.to_df())\n        )\n        self.source_types = self.rfs.source_types\n        self.time = time\n        self.init_currents(currents)\n        self.init_time(time)\n        self.init_responses(responses)\n\n    def init_currents(self, currents) -&gt; None:\n        if currents is not None:\n            self.currents = currents\n            return\n        self.currents = Namespace()\n        for source_type in self.rfs.source_types:\n            # (on/off, n_models, n_angles, n_timesteps, n_input_cells)\n            self.currents[source_type] = np.array(\n                [\n                    nnv.dir[self.current_dir][self.target_type][source_type][:]\n                    for nnv in self.ensemble.values()\n                ],\n            )\n\n    def init_responses(self, responses) -&gt; None:\n        if responses is not None:\n            self.responses = responses\n            return\n        # (on/off, n_models, n_angles, n_timesteps)\n        self.responses = np.array(\n            [\n                nnv.dir[self.current_dir][self.target_type][\"activity_central\"][:]\n                for nnv in self.ensemble.values()\n            ],\n        )\n\n    def init_time(self, time) -&gt; None:\n        if time is not None:\n            self.time = time\n            return\n        self.time = self.time or (\n            np.arange(0, next(iter(self.currents.values())).shape[-2]) * self.config.dt\n            - self.config.t_pre\n        )\n\n    @property\n    def on(self) -&gt; \"MovingEdgeCurrentView\":\n        on_index = get_stimulus_index(self.arg_df, intensity=0)\n        arg_df = self.arg_df.iloc[on_index]\n        return self.view(\n            Namespace({\n                cell_type: np.take(c, indices=on_index, axis=1)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=np.take(self.responses, indices=on_index, axis=1),\n            arg_df=arg_df,\n        )\n\n    @property\n    def off(self) -&gt; \"MovingEdgeCurrentView\":\n        off_index = get_stimulus_index(self.arg_df, intensity=0)\n        arg_df = self.arg_df.iloc[off_index]\n        return self.view(\n            Namespace({\n                cell_type: np.take(c, indices=off_index, axis=1)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=np.take(self.responses, indices=off_index, axis=1),\n            arg_df=arg_df,\n        )\n\n    def divide_by_given_norm(self, norm: CellTypeArray) -&gt; \"MovingEdgeCurrentView\":\n        if not isinstance(norm, CellTypeArray):\n            raise ValueError\n\n        response_dims = np.arange(len(self.responses.shape))\n        response_norm = np.expand_dims(\n            norm[self.target_type].squeeze(), list(set(response_dims) - set([0]))\n        )\n\n        # divide the responses by the norm\n        new_responses = self.responses[:] / response_norm\n\n        # note: we also divide by the norm of the target cell type\n\n        currents_dims = np.arange(len(next(iter(self.currents.values())).shape))\n\n        currents_norm = np.expand_dims(\n            norm[self.target_type].squeeze(), list(set(currents_dims) - set([0]))\n        )\n\n        # divide the currents by the norm\n        new_currents = Namespace({\n            cell_type: c / currents_norm for cell_type, c in self.currents.items()\n        })\n        return self.view(currents=new_currents, responses=new_responses)\n\n    def at_contrast(self, contrast) -&gt; \"MovingEdgeCurrentView\":\n        contrast_index = get_stimulus_index(self.arg_df, intensity=contrast)\n        arg_df = self.arg_df.iloc[contrast_index]\n        return self.view(\n            Namespace({\n                cell_type: np.take(c, indices=contrast_index, axis=1)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=np.take(self.responses, indices=contrast_index, axis=1),\n            arg_df=arg_df,\n        )\n\n    def at_angle(self, angle) -&gt; \"MovingEdgeCurrentView\":\n        angle_index = get_stimulus_index(self.arg_df, angle=angle)\n        arg_df = self.arg_df.iloc[angle_index]\n        return self.view(\n            Namespace({\n                cell_type: np.take(c, indices=angle_index, axis=1)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=np.take(self.responses, indices=angle_index, axis=1),\n            arg_df=arg_df,\n        )\n\n    def at_position(self, u=None, v=None, central=True) -&gt; \"MovingEdgeCurrentView\":\n        rfs = at_position(self.rfs, u, v, central)\n        currents = Namespace({\n            cell_type: c[:, :, :, :, rfs[cell_type].index]\n            for cell_type, c in self.currents.items()\n        })\n        return self.view(currents, rfs=rfs)\n\n    def between_seconds(self, t_start, t_end) -&gt; \"MovingEdgeCurrentView\":\n        slice = np.where((self.time &gt;= t_start) &amp; (self.time &lt; t_end))[0]\n        newview = self[:, :, slice, :]\n        newview.time = self.time[slice]\n        newview.responses = self.responses[:, :, slice]\n        return newview\n\n    def model_selection(self, mask) -&gt; \"MovingEdgeCurrentView\":\n        return self[mask, :, :, :]\n\n    def __getattr__(self, key):\n        return self.__getitem__(key)\n\n    def __getitem__(self, key) -&gt; Union[\"MovingEdgeCurrentView\", Any]:\n        # e.g. view.C3\n        if isinstance(key, str) and key in self.source_types:\n            return self.view(Namespace({key: self.currents[key]}))\n        # e.g. view[\"C3\", 0, 0, 0]\n        elif (\n            isinstance(key, Iterable)\n            and isinstance(key[0], str)\n            and key[0] in self.source_types\n            and len(key[1:]) == self.shape\n        ):\n            return self.view(self.currents[key[0]][key[1:]])\n        # e.g. view[index, :, :, :]\n        elif isinstance(key, Iterable) and len(key) == len(self.shape):\n            return self.view(\n                Namespace({cell_type: c[key] for cell_type, c in self.currents.items()}),\n                responses=self.responses[key[:-1]],\n            )\n        # view[:]\n        elif key == slice(None):\n            if len(self.currents) == 1:\n                return next(iter(self.currents.values()))\n            return self.currents\n        return object.__getattribute__(self, key)\n\n    def __repr__(self):\n        cv = {ct: v.shape for ct, v in self.currents.items()}\n        formatted_cv = \",\\n        \".join(\n            f\"'{ct}': Array(shape={v})\" for ct, v in cv.items()\n        )\n        return (\n            f\"{self.__class__.__name__}(\\n\"\n            f\"    ensemble={self.ensemble.name},\\n\"\n            f\"    target_type={self.target_type},\\n\"\n            f\"    current_dir={self.current_dir},\\n\"\n            f\"    currents={{\\n        {formatted_cv}\\n    }},\\n\"\n            f\"    rfs={self.rfs}\\n\"\n            f\")\"\n        )\n\n    @property\n    def shape(self):\n        return next(iter(self.currents.values())).shape\n\n    def sorting(self, average_over_models=True, mode=\"all\"):\n        summed = self if len(self.shape) == 4 else self.sum_over_cells()\n        signs = self.signs()\n        if average_over_models:\n            absmax = {\n                k: v * signs[k]\n                for k, v in valmap(\n                    lambda v: np.nanmax(\n                        np.abs(np.nanmean(v, axis=1, keepdims=True)),\n                        axis=(0, 2, 3),\n                    ),\n                    summed[:],\n                ).items()\n            }\n        else:\n            # summing over on/off, angles and time to sort -- results in n_models sortings\n            absmax = {\n                k: v * signs[k]\n                for k, v in valmap(\n                    lambda v: np.nanmax(np.abs(v), axis=(0, 2, 3)), summed[:]\n                ).items()\n            }\n        cell_types = np.array(list(absmax.keys()))\n        values = np.array(list(absmax.values()))\n        sorting = np.argsort(values, axis=0).T\n        #         if average_over_models:\n        #             # add extra dimension here for the next operation\n        #             sorting = sorting[None]\n        self.sorted_cell_types = cell_types[sorting[:, ::-1]]\n\n        # return all excitatory and inhibitory from most excitatory to most inhibitory\n        if mode == \"all\":\n            return self.sorted_cell_types\n        # from most excitatory to least excitatory\n        elif mode == \"excitatory\":\n            assert average_over_models\n            return np.array([\n                cell_type\n                for cell_type in self.sorted_cell_types[0]\n                if signs[cell_type] == 1\n            ])\n        # from most inhibitory to least inhibitory\n        elif mode == \"inhibitory\":\n            assert average_over_models\n            return np.array([\n                cell_type\n                for cell_type in self.sorted_cell_types[0][::-1]\n                if signs[cell_type] == -1\n            ])\n        else:\n            raise ValueError(f\"mode {mode}\")\n\n    def filter_cell_types_by_contribution(\n        self, bins=3, cut_off_edge=1, mode=\"above_cut_off\", statistic=np.max\n    ):\n        \"\"\"\n        Intuitively chunks the y-axis of the current plots into two parts:\n            - excitatory\n            - inhibitory\n        and each of these into bins. In case of 3 corresponding to low-contribution,\n        moderate-contribution, high-contribution. Then all cell types above or below the\n        bin edge specified by cut_off_edge are discarded.\n        \"\"\"\n        sorting = self.sorting()[0]\n        signs = self.signs()\n        currents = self.sum_over_cells().currents\n\n        filtered_cell_types = []\n        for sign in [1, -1]:\n            # compute the std over all inputs\n            values = {\n                cell_type: statistic(np.abs(currents[cell_type][:]))\n                for cell_type in sorting\n                if signs[cell_type] == sign\n            }\n            # bin into three bins\n            # ala (low contribution, medium contribution, high contribution)\n            counts, bins = np.histogram(list(values.values()), bins=bins)\n            cut_off_value = bins[cut_off_edge]\n            if mode == \"above_cut_off\":\n                filtered_cell_types.extend(\n                    list(valfilter(lambda v, cut_off=cut_off_value: v &gt;= cut_off, values))\n                )\n            elif mode == \"below_cut_off\":\n                filtered_cell_types.extend(\n                    list(valfilter(lambda v, cut_off=cut_off_value: v &lt; cut_off, values))\n                )\n            else:\n                raise ValueError(f\"mode {mode}\")\n        return np.array(filtered_cell_types)\n\n    def filter_source_types(self, hide_source_types, bins, edge, mode, statistic=np.max):\n        source_types = self.sorting()[0]\n        if isinstance(hide_source_types, str) and hide_source_types == \"auto\":\n            hide_source_types = self.filter_cell_types_by_contribution(\n                bins=bins, cut_off_edge=edge, mode=mode, statistic=statistic\n            )\n\n        if hide_source_types is not None:\n            source_types = np.array([\n                source_type\n                for source_type in source_types\n                if source_type not in hide_source_types\n            ])\n        return source_types\n\n    def signs(self):\n        return {ct: np.mean(self.rfs[ct].sign) for ct in self.rfs.source_types}\n\n    def sum_over_cells(self) -&gt; \"MovingEdgeCurrentView\":\n        return self.view(\n            Namespace({\n                cell_type: c.sum(axis=-1) for cell_type, c in self.currents.items()\n            }),\n        )\n\n    def plot_spatial_contribution(\n        self,\n        source_type,\n        #         contrast,\n        #         angle,\n        t_start,\n        t_end,\n        mode=\"peak\",\n        title=\"{source_type} :\u2192\",\n        fig=None,\n        ax=None,\n        max_extent=None,\n        **kwargs,\n    ):\n        current_view = kwargs.get(\"current_view\") or (\n            self.between_seconds(t_start, t_end)  # .at_contrast(contrast).at_angle(angle)\n        )\n\n        vmin = kwargs.get(\"vmin\") or (\n            np.floor(\n                min(\n                    0,\n                    min(\n                        current.mean(axis=(0, 1, 2)).min()\n                        for current in list(current_view[:].values())\n                    ),\n                )\n                * 100\n            )\n            / 100\n        )\n\n        vmax = kwargs.get(\"vmax\") or (\n            np.ceil(\n                max(\n                    0,\n                    max(\n                        current.mean(axis=(0, 1, 2)).max()\n                        for current in list(current_view[:].values())\n                    ),\n                )\n                * 100\n            )\n            / 100\n        )\n\n        u, v = current_view.rfs[source_type][[\"source_u\", \"source_v\"]].values.T\n        # average over models\n        # (1, n_models, 1, n_timesteps, n_models) -&gt; (n_timesteps, n_models)\n        # import pdb\n\n        # pdb.set_trace()\n        values = current_view[source_type][:].mean(axis=(0, 1))\n        if mode == \"peak\":\n            values = values[\n                np.argmax(np.abs(values), axis=0), np.arange(values.shape[-1])\n            ]\n        elif mode == \"mean\":\n            values = np.mean(values, axis=0)\n        elif mode == \"std\":\n            signs = self.signs()\n            values = signs[source_type] * np.std(values, axis=0)\n        fig, ax, _ = plots.kernel(\n            u,\n            v,\n            values,\n            fill=True,\n            max_extent=max_extent or current_view.rfs.max_extent,\n            label=title.format(source_type=source_type),\n            labelxy=\"auto\",\n            strict_sign=False,\n            fig=fig,\n            ax=ax,\n            **kwargs,\n        )\n        (xmin, ymin, xmax, ymax) = ax.dataLim.extents\n        ax.set_xlim(plt_utils.get_lims((xmin, xmax), 0.01))\n        ax.set_ylim(plt_utils.get_lims((ymin, ymax), 0.01))\n\n    def plot_spatial_contribution_grid(\n        self,\n        #         contrast,\n        #         angle,\n        t_start,\n        t_end,\n        max_extent=3,\n        mode=\"peak\",\n        title=\"{source_type} :\u2192\",\n        fig=None,\n        axes=None,\n        fontsize=5,\n        edgewidth=0.125,\n        title_y=0.8,\n        max_figure_height_cm=9.271,\n        panel_height_cm=\"auto\",\n        max_figure_width_cm=2.54,\n        panel_width_cm=2.54,\n        annotate=False,\n        cbar=False,\n        hide_source_types=\"auto\",\n        hide_source_types_bins=5,\n        hide_source_types_cut_off_edge=1,\n        hide_source_types_mode=\"below_cut_off\",\n        max_axes=None,\n        **kwargs,\n    ):\n        current_view = self.between_seconds(t_start, t_end)\n\n        vmin = (\n            np.floor(\n                min(\n                    0,\n                    min(\n                        current.mean(axis=(0, 1, 2)).min()\n                        for current in list(current_view[:].values())\n                    ),\n                )\n                * 10\n            )\n            / 10\n        )\n\n        vmax = (\n            np.ceil(\n                max(\n                    0,\n                    max(\n                        current.mean(axis=(0, 1, 2)).max()\n                        for current in list(current_view[:].values())\n                    ),\n                )\n                * 10\n            )\n            / 10\n        )\n\n        source_types = self.filter_source_types(\n            hide_source_types,\n            bins=hide_source_types_bins,\n            edge=hide_source_types_cut_off_edge,\n            mode=hide_source_types_mode,\n        )\n\n        if fig is None and axes is None:\n            figsize = figsize_from_n_items(\n                max_axes or len(source_types),\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=(\n                    max_figure_height_cm / (max_axes or len(source_types))\n                    if panel_height_cm == \"auto\"\n                    else panel_height_cm\n                ),\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(\n                unmask_n=max_axes or len(source_types), hspace=0.1, wspace=0\n            )\n            if max_axes is not None and len(source_types) &lt; max_axes:\n                for ax in np.array(axes).flatten():\n                    if isinstance(ax, Axes):\n                        ax.axis(\"off\")\n\n        for i, source_type in enumerate(source_types):\n            self.plot_spatial_contribution(\n                source_type,\n                #                 contrast,\n                #                 angle,\n                t_start,\n                t_end,\n                mode=mode,\n                title=title,\n                fontsize=fontsize,\n                edgewidth=edgewidth,\n                title_y=title_y,\n                fig=fig,\n                ax=axes[i],\n                current_view=current_view,\n                vmin=vmin,\n                vmax=vmax,\n                annotate=annotate,\n                cbar=False,\n                max_extent=max_extent or current_view.rfs.max_extent,\n                **kwargs,\n            )\n\n        cmap = plt.cm.seismic\n        norm = plt_utils.get_norm(vmin=vmin, vmax=vmax, midpoint=0)\n        if cbar:\n            cbar = plt_utils.add_colorbar_to_fig(\n                fig,\n                width=0.01,\n                height=0.25,\n                fontsize=fontsize,\n                cmap=cmap,\n                norm=norm,\n                label=f\"{mode} input currents\",\n                n_ticks=4,\n                n_decimals=1,\n            )\n        return fig, axes, (cbar, cmap, norm, vmin, vmax)\n\n    def plot_spatial_filter(\n        self,\n        source_type,\n        #         contrast,\n        #         angle,\n        title=\"{source_type} :\u2192\",\n        fig=None,\n        ax=None,\n        max_extent=None,\n        **kwargs,\n    ):\n        filter = self.rfs\n\n        def filter_values(rf):\n            return (rf.n_syn * rf.sign).values\n\n        vmin = kwargs.pop(\"vmin\", None) or (\n            np.floor(\n                min(\n                    0,\n                    min(\n                        min(filter_values(filter[source_type]))\n                        for source_type in self.source_types\n                    ),\n                )\n                * 100\n            )\n            / 100\n        )\n\n        vmax = kwargs.pop(\"vmax\", None) or (\n            np.ceil(\n                max(\n                    0,\n                    max(\n                        max(filter_values(filter[source_type]))\n                        for source_type in self.source_types\n                    ),\n                )\n                * 100\n            )\n            / 100\n        )\n\n        u, v = filter[source_type][[\"source_u\", \"source_v\"]].values.T\n        # average over models\n        # (1, n_models, 1, n_timesteps, n_models) -&gt; (n_timesteps, n_models)\n        values = filter_values(filter[source_type])\n\n        label = title.format(source_type=source_type)\n        fig, ax, _ = plt_utils.kernel(\n            u,\n            v,\n            values,\n            fill=True,\n            max_extent=max_extent or filter.max_extent,\n            label=label,\n            labelxy=\"auto\",\n            strict_sign=False,\n            fig=fig,\n            ax=ax,\n            vmin=vmin,\n            vmax=vmax,\n            **kwargs,\n        )\n        (xmin, ymin, xmax, ymax) = ax.dataLim.extents\n        ax.set_xlim(plt_utils.get_lims((xmin, xmax), 0.01))\n        ax.set_ylim(plt_utils.get_lims((ymin, ymax), 0.01))\n        return ax\n\n    def plot_spatial_filter_grid(\n        self,\n        title=\"{source_type} :\u2192\",\n        fig=None,\n        axes=None,\n        max_extent=None,\n        fontsize=5,\n        edgewidth=0.125,\n        title_y=0.8,\n        max_figure_height_cm=9.271,\n        panel_height_cm=\"auto\",\n        max_figure_width_cm=2.54,\n        panel_width_cm=2.54,\n        annotate=False,\n        cbar=False,\n        hide_source_types=\"auto\",\n        hide_source_types_bins=5,\n        hide_source_types_cut_off_edge=1,\n        hide_source_types_mode=\"below_cut_off\",\n        max_axes=None,\n        wspace=0.0,\n        hspace=0.1,\n        **kwargs,\n    ):\n        filter = self.rfs\n\n        def filter_values(rf):\n            return (rf.n_syn * rf.sign).values\n\n        vmin = kwargs.pop(\"vmin\", None) or (\n            np.floor(\n                min(\n                    0,\n                    min(\n                        min(filter_values(filter[source_type]))\n                        for source_type in self.source_types\n                    ),\n                )\n                * 100\n            )\n            / 100\n        )\n\n        vmax = kwargs.pop(\"vmax\", None) or (\n            np.ceil(\n                max(\n                    0,\n                    max(\n                        max(filter_values(filter[source_type]))\n                        for source_type in self.source_types\n                    ),\n                )\n                * 100\n            )\n            / 100\n        )\n\n        source_types = self.filter_source_types(\n            hide_source_types,\n            bins=hide_source_types_bins,\n            edge=hide_source_types_cut_off_edge,\n            mode=hide_source_types_mode,\n        )\n\n        if fig is None and axes is None:\n            figsize = figsize_from_n_items(\n                max_axes or len(source_types),\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=(\n                    max_figure_height_cm / (max_axes or len(source_types))\n                    if panel_height_cm == \"auto\"\n                    else panel_height_cm\n                ),\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(\n                unmask_n=max_axes or len(source_types), hspace=hspace, wspace=wspace\n            )\n            if max_axes is not None and len(source_types) &lt; max_axes:\n                for ax in np.array(axes).flatten():\n                    if isinstance(ax, Axes):\n                        ax.axis(\"off\")\n        # import pdb\n\n        # pdb.set_trace()\n        for i, source_type in enumerate(source_types):\n            self.plot_spatial_filter(\n                source_type,\n                title=title,\n                fontsize=fontsize,\n                edgewidth=edgewidth,\n                title_y=title_y,\n                fig=fig,\n                ax=axes[i],\n                vmin=vmin,\n                vmax=vmax,\n                annotate=annotate,\n                cbar=False,\n                max_extent=max_extent or filter.max_extent,\n                **kwargs,\n            )\n\n        cmap = plt.cm.seismic\n        norm = plt_utils.get_norm(vmin=vmin, vmax=vmax, midpoint=0)\n        if cbar:\n            cbar = plt_utils.add_colorbar_to_fig(\n                fig,\n                width=0.01,\n                height=0.25,\n                fontsize=fontsize,\n                cmap=cmap,\n                norm=norm,\n                label=\"spatial filters\",\n                n_ticks=4,\n                n_decimals=1,\n            )\n        return fig, axes, (cbar, cmap, norm, vmin, vmax)\n\n    def view(\n        self, currents, rfs=None, time=None, responses=None, arg_df=None\n    ) -&gt; \"MovingEdgeCurrentView\":\n        arg_df = arg_df.reset_index(drop=True) if arg_df is not None else self.arg_df\n        return MovingEdgeCurrentView(\n            self.ensemble,\n            self.target_type,\n            self.current_dir,\n            arg_df,\n            currents,\n            rfs if rfs is not None else self.rfs,\n            time if time is not None else self.time,\n            responses if responses is not None else self.responses,\n        )\n\n    def subtract_baseline(self) -&gt; \"MovingEdgeCurrentView\":\n        return self.view(\n            Namespace({\n                cell_type: c - np.take(c, [0], -2)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=self.responses - np.take(self.responses, [0], -1),\n        )\n\n    def subtract_mean(self) -&gt; \"MovingEdgeCurrentView\":\n        return self.view(\n            Namespace({\n                cell_type: c - np.mean(c, -2, keepdims=True)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=self.responses - np.mean(self.responses, -1, keepdims=True),\n        )\n\n    def standardize(self) -&gt; \"MovingEdgeCurrentView\":\n        return self.view(\n            Namespace({\n                cell_type: (c - np.mean(c, -2, keepdims=True))\n                / (np.std(c, -2, keepdims=True) + 1e-15)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=(self.responses - np.mean(self.responses, -1, keepdims=True))\n            / (np.std(self.responses, -1, keepdims=True) + 1e-15),\n        )\n\n    def standardize_over_time_and_pd_nd(\n        self, t_start, t_end, pd\n    ) -&gt; \"MovingEdgeCurrentView\":\n        temp = self.between_seconds(t_start, t_end).at_angle([pd, (pd - 180) % 360])\n        return self.view(\n            Namespace({\n                cell_type: (\n                    c - np.mean(temp.currents[cell_type], (-2, -3), keepdims=True)\n                )\n                / (np.std(temp.currents[cell_type], (-2, -3), keepdims=True) + 1e-15)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=(self.responses - np.mean(temp.responses, (-1, -2), keepdims=True))\n            / (np.std(temp.responses, (-1, -2), keepdims=True) + 1e-15),\n        )\n\n    def init_colors(self, source_types):\n        signs = self.signs()\n        signs = {cell_type: signs[cell_type] for cell_type in source_types}\n        signs_reversed = {cell_type: signs[cell_type] for cell_type in source_types[::-1]}\n        n_exc = len([v for v in signs.values() if v == 1])\n        n_inh = len([v for v in signs.values() if v == -1])\n        exc_colors_pd = cmap_iter(\n            truncate_colormap(plt.cm.RdBu, minval=0.05, maxval=0.45, n=n_exc)\n        )\n        inh_cmap_pd = cmap_iter(\n            truncate_colormap(plt.cm.RdBu_r, minval=0.05, maxval=0.45, n=n_inh)\n        )\n        exc_colors_nd = cmap_iter(\n            truncate_colormap(plt.cm.BrBG_r, minval=0.05, maxval=0.45, n=n_exc)\n        )\n        inh_cmap_nd = cmap_iter(\n            truncate_colormap(plt.cm.BrBG, minval=0.05, maxval=0.45, n=n_inh)\n        )\n        colors_pd = {}\n        colors_nd = {}\n        for _, (cell_type, sign) in enumerate(signs.items()):\n            if sign == 1:\n                # take the first half of the RdBu colormap, i.e. red\n                colors_pd[cell_type] = next(exc_colors_pd)\n                colors_nd[cell_type] = next(exc_colors_nd)\n\n        for _, (cell_type, sign) in enumerate(signs_reversed.items()):\n            if sign == -1:\n                # take the first half of the RdBu colormap, i.e. red\n                colors_pd[cell_type] = next(inh_cmap_pd)\n                colors_nd[cell_type] = next(inh_cmap_nd)\n        self.colors_pd = colors_pd\n        self.colors_nd = colors_nd\n\n    def color(self, source_type, pd=True):\n        if pd:\n            return self.colors_pd[source_type]\n        return self.colors_nd[source_type]\n\n    def zorder(self, source_types, source_type, start_exc=1000, start_inh=1000):\n        signs = self.signs()\n        signs_reversed = {cell_type: signs[cell_type] for cell_type in source_types[::-1]}\n\n        z_order = start_exc\n        for _, (cell_type, sign) in enumerate(signs.items()):\n            if sign == 1:\n                if cell_type == source_type:\n                    return z_order\n                z_order -= 10\n\n        z_order = start_inh\n        for _, (cell_type, sign) in enumerate(signs_reversed.items()):\n            if sign == -1:\n                if cell_type == source_type:\n                    return z_order\n                z_order -= 10\n\n    def ylims(self, source_types=None, offset=0.02):\n        \"Ylims for temporal contributions summed over cells.\"\n        if source_types is not None:\n            return {\n                cell_type: plt_utils.get_lims(c, offset)\n                for cell_type, c in self.sum_over_cells().currents.items()\n                if cell_type in source_types\n            }\n        return plt_utils.get_lims(list(self.sum_over_cells().currents.values()), offset)\n\n    def plot_response(\n        self,\n        contrast,\n        angle,\n        t_start=0,\n        t_end=1,\n        max_figure_height_cm=1.4477,\n        panel_height_cm=1.4477,\n        max_figure_width_cm=4.0513,\n        panel_width_cm=4.0513,\n        fontsize=5,\n        model_average=True,\n        color=(0, 0, 0),\n        legend=False,\n        hide_yaxis=True,\n        trim_axes=True,\n        quantile=None,\n        scale_position=None,  # \"lower left\",\n        scale_label=\"{:.0f} ms\",\n        scale_unit=1000,\n        hline=False,\n        fig=None,\n        ax=None,\n    ):\n        r_pd = (\n            self.at_angle(angle)\n            .at_contrast(contrast)\n            .between_seconds(t_start, t_end)\n            .responses.squeeze(axis=-2)\n        )\n        r_nd = (\n            self.at_angle((angle - 180) % 360)\n            .at_contrast(contrast)\n            .between_seconds(t_start, t_end)\n            .responses.squeeze(axis=-2)\n        )\n\n        if fig is None and ax is None:\n            figsize = figsize_from_n_items(\n                1,\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=panel_height_cm,\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(hspace=0.0, wspace=0, fontsize=fontsize)\n            ax = axes[0]\n\n        color = [hex2color(PD), hex2color(ND)] if color is None else [color, color]\n\n        if model_average:\n            fig, ax, _, _ = plots.traces(\n                [r_pd.mean(axis=0), r_nd.mean(axis=0)],\n                x=self.between_seconds(t_start, t_end).time,\n                color=color,\n                linewidth=1,\n                fontsize=fontsize,\n                null_line=False,\n                fig=fig,\n                ax=ax,\n                linestyle=[\"solid\", \"dashed\"],\n                legend=\"\" if not legend else [f\"{self.target_type}\", \"null direction\"],\n                scale_pos=scale_position,\n                scale_label=scale_label,\n                scale_unit=scale_unit,\n            )\n        else:\n            fig, ax, _, _ = plots.traces(\n                r_pd,\n                x=self.between_seconds(t_start, t_end).time,\n                mean_color=adapt_color_alpha(color[0], 1),\n                color=adapt_color_alpha(color[0], 0.5),\n                linewidth=0.25,\n                zorder_traces=0,\n                zorder_mean=10,\n                fontsize=fontsize,\n                null_line=False,\n                highlight_mean=True,\n                fig=fig,\n                ax=ax,\n            )\n            plots.traces(\n                r_nd,\n                x=self.between_seconds(t_start, t_end).time,\n                mean_color=adapt_color_alpha(color[1], 1),\n                color=adapt_color_alpha(color[1], 0.5),\n                linewidth=0.25,\n                zorder_traces=0,\n                zorder_mean=10,\n                fontsize=fontsize,\n                null_line=False,\n                highlight_mean=True,\n                fig=fig,\n                linestyle=\"dashed\",\n                ax=ax,\n            )\n        if quantile:\n            quantile_pd = np.quantile(r_pd, quantile, axis=0)\n            quantile_nd = np.quantile(r_nd, quantile, axis=0)\n            ax.fill_between(\n                self.between_seconds(t_start, t_end).time,\n                quantile_pd[0],\n                quantile_pd[1],\n                facecolor=adapt_color_alpha(color[0], 0.1),\n                edgecolor=adapt_color_alpha(color[0], 1),\n                linewidth=0.25,\n            )\n            ax.fill_between(\n                self.between_seconds(t_start, t_end).time,\n                quantile_nd[0],\n                quantile_nd[1],\n                facecolor=adapt_color_alpha(color[1], 0.1),\n                edgecolor=adapt_color_alpha(color[1], 1),\n                linewidth=0.25,\n                linestyle=\"dashed\",\n            )\n\n        if hline:\n            # horizontal line at 0\n            ax.axhline(0, color=(0, 0, 0, 1), linewidth=0.25, zorder=-10)\n\n        if hide_yaxis:\n            plt_utils.rm_spines(ax, (\"left\",))\n        if trim_axes:\n            plt_utils.trim_axis(ax)\n        if legend:\n            ax.legend(\n                fontsize=fontsize,\n                ncols=1,\n                bbox_to_anchor=(1.05, 1),\n                loc=\"upper left\",\n                borderaxespad=0.0,\n            )\n        return fig, ax\n\n    def plot_response_pc_nc(\n        self,\n        contrast,\n        angle,\n        t_start=0,\n        t_end=1,\n        max_figure_height_cm=1.4477,\n        panel_height_cm=1.4477,\n        max_figure_width_cm=4.0513,\n        panel_width_cm=4.0513,\n        fontsize=5,\n        model_average=True,\n        color=(0, 0, 0),\n        legend=False,\n        hide_yaxis=True,\n        trim_axes=True,\n        quantile=None,\n        scale_position=None,  # \"lower left\",\n        scale_label=\"{:.0f} ms\",\n        scale_unit=1000,\n        fig=None,\n        ax=None,\n        hline=False,\n    ):\n        r_pc = (\n            self.at_angle(angle)\n            .at_contrast(contrast)\n            .between_seconds(t_start, t_end)\n            .responses.squeeze(axis=-2)\n        )\n        r_nc = (\n            self.at_angle(angle)\n            .at_contrast(0 if contrast == 1 else 1)\n            .between_seconds(t_start, t_end)\n            .responses.squeeze(axis=-2)\n        )\n\n        if fig is None and ax is None:\n            figsize = figsize_from_n_items(\n                1,\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=panel_height_cm,\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(hspace=0.0, wspace=0, fontsize=fontsize)\n            ax = axes[0]\n\n        color = [hex2color(PD), hex2color(ND)] if color is None else [color, color]\n\n        if model_average:\n            fig, ax, _, _ = plots.traces(\n                [r_pc.mean(axis=0), r_nc.mean(axis=0)],\n                x=self.between_seconds(t_start, t_end).time,\n                color=color,\n                linewidth=1,\n                fontsize=fontsize,\n                null_line=False,\n                fig=fig,\n                ax=ax,\n                linestyle=[\"solid\", \"dotted\"],\n                legend=\"\" if not legend else [f\"{self.target_type}\", \"null contrast\"],\n                scale_pos=scale_position,\n                scale_label=scale_label,\n                scale_unit=scale_unit,\n            )\n        else:\n            fig, ax, _, _ = plots.traces(\n                r_pc,\n                x=self.between_seconds(t_start, t_end).time,\n                mean_color=adapt_color_alpha(color[0], 1),\n                color=adapt_color_alpha(color[0], 0.5),\n                linewidth=0.25,\n                zorder_traces=0,\n                zorder_mean=10,\n                fontsize=fontsize,\n                null_line=False,\n                highlight_mean=True,\n                fig=fig,\n                ax=ax,\n            )\n            plots.traces(\n                r_nc,\n                x=self.between_seconds(t_start, t_end).time,\n                mean_color=adapt_color_alpha(color[1], 1),\n                color=adapt_color_alpha(color[1], 0.5),\n                linewidth=0.25,\n                zorder_traces=0,\n                zorder_mean=10,\n                fontsize=fontsize,\n                null_line=False,\n                highlight_mean=True,\n                fig=fig,\n                linestyle=\"dashed\",\n                ax=ax,\n            )\n        if quantile:\n            quantile_pd = np.quantile(r_pc, quantile, axis=0)\n            quantile_nd = np.quantile(r_nc, quantile, axis=0)\n            ax.fill_between(\n                self.between_seconds(t_start, t_end).time,\n                quantile_pd[0],\n                quantile_pd[1],\n                facecolor=adapt_color_alpha(color[0], 0.1),\n                edgecolor=adapt_color_alpha(color[0], 1),\n                linewidth=0.25,\n            )\n            ax.fill_between(\n                self.between_seconds(t_start, t_end).time,\n                quantile_nd[0],\n                quantile_nd[1],\n                facecolor=adapt_color_alpha(color[1], 0.1),\n                edgecolor=adapt_color_alpha(color[1], 1),\n                linewidth=0.25,\n                linestyle=\"dashed\",\n            )\n\n        # horizontal line at 0\n        if hline:\n            ax.axhline(0, color=(0, 0, 0, 1), linewidth=0.25, zorder=-10)\n\n        if hide_yaxis:\n            plt_utils.rm_spines(ax, (\"left\",))\n        if trim_axes:\n            plt_utils.trim_axis(ax)\n        if legend:\n            ax.legend(\n                fontsize=fontsize,\n                ncols=1,\n                bbox_to_anchor=(1.05, 1),\n                loc=\"upper left\",\n                borderaxespad=0.0,\n            )\n        return fig, ax\n\n    def plot_temporal_contributions(\n        self,\n        contrast,\n        angle,\n        t_start=0,\n        t_end=1,\n        fontsize=5,\n        linewidth=0.25,\n        legend=False,\n        legend_standalone=True,\n        legend_figsize_cm=(4.0572, 1),\n        legend_n_rows=None,\n        # for supplementary\n        # max_figure_height_cm=1.4477,\n        # panel_height_cm=1.4477,\n        # max_figure_width_cm=4.0513,\n        # panel_width_cm=4.0513,\n        # for Fig 3\n        max_figure_height_cm=3.3941,\n        panel_height_cm=3.3941,\n        max_figure_width_cm=4.0572,\n        panel_width_cm=4.0572,\n        model_average=True,\n        highlight_mean=True,  # only applies if model_average is False\n        sum_exc_inh=False,\n        only_sum=False,\n        hide_source_types=\"auto\",\n        hide_source_types_bins=5,\n        hide_source_types_cut_off_edge=1,\n        hide_source_types_mode=\"below_cut_off\",\n        hide_yaxis=True,\n        trim_axes=True,\n        quantile=None,\n        fig=None,\n        ax=None,\n        legend_ax=None,\n        hline=True,\n        legend_n_cols=None,\n        baseline_color=None,\n        colors=None,\n    ):\n        if fig is None and ax is None:\n            figsize = figsize_from_n_items(\n                1,\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=panel_height_cm,\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(hspace=0.0, wspace=0, fontsize=fontsize)\n            ax = axes[0]\n        cv_pd = (\n            self.at_contrast(contrast)\n            .at_angle(angle)\n            .between_seconds(t_start, t_end)\n            .sum_over_cells()\n        )\n        cv_nd = (\n            self.at_contrast(contrast)\n            .at_angle((angle - 180) % 360)\n            .between_seconds(t_start, t_end)\n            .sum_over_cells()\n        )\n\n        source_types = (\n            self.at_contrast(contrast)\n            .at_angle([angle, (angle - 180) % 360])\n            .between_seconds(t_start, t_end)\n            .filter_source_types(\n                hide_source_types,\n                hide_source_types_bins,\n                hide_source_types_cut_off_edge,\n                hide_source_types_mode,\n            )\n        )\n\n        color_source_types = (\n            self.at_contrast(contrast)\n            .at_angle([angle, (angle - 180) % 360])\n            .between_seconds(t_start, t_end)\n            .filter_source_types(\n                None,\n                hide_source_types_bins,\n                hide_source_types_cut_off_edge,\n                hide_source_types_mode,\n            )\n        )\n        cv_pd.init_colors(color_source_types)\n        cv_nd.init_colors(color_source_types)\n\n        def plot_mean_trace(\n            time, trace, label, color, zorder, linestyle=\"solid\", ax=None, fig=None\n        ):\n            ax.plot(\n                time,\n                trace,\n                label=label,\n                color=color,\n                zorder=zorder,\n                linestyle=linestyle,\n            )\n\n        def plot_individual_traces(\n            traces, time, color, zorder, label, linestyle=\"solid\", legend=None\n        ):\n            if not only_sum and not model_average:\n                plots.traces(\n                    traces,\n                    time,\n                    mean_color=color,\n                    color=color,\n                    linewidth=linewidth,\n                    zorder_traces=0,\n                    zorder_mean=zorder,\n                    fontsize=fontsize,\n                    null_line=True,\n                    highlight_mean=highlight_mean,\n                    fig=fig,\n                    ax=ax,\n                    legend=legend or label,\n                    linestyle=linestyle,\n                )\n\n        def plot_quantile(traces, time, color, zorder, linestyle=\"solid\"):\n            if quantile:\n                Q = np.quantile(traces, quantile, axis=0)\n                ax.fill_between(\n                    time,\n                    Q[0],\n                    Q[1],\n                    facecolor=adapt_color_alpha(color, 0.1),\n                    edgecolor=color,\n                    linewidth=0.25,\n                    linestyle=linestyle,\n                    zorder=zorder - 1,\n                )\n\n        def plot_summed_trace(time, trace, label, color, zorder, linestyle=\"solid\"):\n            if np.any(trace):\n                ax.plot(\n                    time,\n                    trace,\n                    label=label,\n                    color=color,\n                    zorder=zorder,\n                    linestyle=linestyle,\n                )\n\n        def get_summed_traces(signs, source_types, cv_pd, cv_nd):\n            # sum over cell types then average over models\n            exc_pd = np.zeros(cv_pd.shape)\n            inh_pd = np.zeros(cv_pd.shape)\n            exc_nd = np.zeros(cv_nd.shape)\n            inh_nd = np.zeros(cv_nd.shape)\n            # sum over cell types\n            for source_type in source_types:\n                if signs[source_type] == 1:\n                    exc_pd += cv_pd[source_type][:]  # (1, n_models, 1, n_timesteps)\n                    exc_nd += cv_nd[source_type][:]\n                else:\n                    inh_pd += cv_pd[source_type][:]\n                    inh_nd += cv_nd[source_type][:]\n            # (n_models, n_timesteps)\n            return (\n                exc_pd.squeeze(),\n                inh_pd.squeeze(),\n                exc_nd.squeeze(),\n                inh_nd.squeeze(),\n            )\n\n        for source_type in source_types:\n            if model_average and not only_sum:\n                # mean traces solid for PD and dashed for ND\n                if baseline_color is not None:\n                    color = baseline_color\n                elif colors:\n                    color = colors[source_type]\n                else:\n                    color = cv_pd.color(source_type)\n\n                plot_mean_trace(\n                    cv_pd.time,\n                    cv_pd[source_type][:].squeeze(axis=-2).T.mean(axis=1),\n                    source_type,\n                    color,\n                    cv_pd.zorder(source_types, source_type),\n                    ax=ax,\n                    fig=fig,\n                )\n                plot_mean_trace(\n                    cv_nd.time,\n                    cv_nd[source_type][:].squeeze(axis=-2).T.mean(axis=1),\n                    source_type,\n                    color,\n                    linestyle=\"dashed\",\n                    zorder=cv_pd.zorder(source_types, source_type),\n                    ax=ax,\n                    fig=fig,\n                )\n\n            elif not model_average and not only_sum:\n                # individual traces\n                plot_individual_traces(\n                    cv_pd[source_type][:].squeeze(axis=-2),\n                    cv_pd.time,\n                    cv_pd.color(source_type),\n                    cv_pd.zorder(source_types, source_type),\n                    source_type,\n                )\n                plot_individual_traces(\n                    cv_nd[source_type][:].squeeze(axis=-2),\n                    cv_nd.time,\n                    cv_pd.color(source_type),\n                    cv_pd.zorder(source_types, source_type),\n                    source_type,\n                    linestyle=\"dashed\",\n                    legend=\"null direction\",\n                )\n\n            # quantiles\n            plot_quantile(\n                cv_pd[source_type][:].squeeze(axis=-2),\n                cv_pd.time,\n                cv_pd.color(source_type),\n                cv_pd.zorder(source_types, source_type),\n                linestyle=\"solid\",\n            )\n            plot_quantile(\n                cv_nd[source_type][:].squeeze(axis=-2),\n                cv_nd.time,\n                cv_pd.color(source_type),\n                cv_pd.zorder(source_types, source_type),\n                linestyle=\"dashed\",\n            )\n        if sum_exc_inh or only_sum:\n            # plot summed traces\n            signs = cv_pd.signs()\n            exc_pd, inh_pd, exc_nd, inh_nd = get_summed_traces(\n                signs, source_types, cv_pd, cv_nd\n            )\n            plot_summed_trace(\n                cv_pd.time,\n                exc_pd.mean(axis=0),\n                \"excitatory\",\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=2000,\n            )\n            plot_quantile(\n                exc_pd,\n                cv_pd.time,\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=0,\n                linestyle=\"solid\",\n            )\n            plot_summed_trace(\n                cv_nd.time,\n                exc_nd.mean(axis=0),\n                \"excitatory\",\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=2000,\n                linestyle=\"dashed\",\n            )\n            plot_quantile(\n                exc_nd,\n                cv_pd.time,\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=0,\n                linestyle=\"dashed\",\n            )\n            plot_summed_trace(\n                cv_pd.time,\n                inh_pd.mean(axis=0),\n                \"inhibitory\",\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=2000,\n            )\n            plot_quantile(\n                inh_pd,\n                cv_pd.time,\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=0,\n                linestyle=\"solid\",\n            )\n            plot_summed_trace(\n                cv_nd.time,\n                inh_nd.mean(axis=0),\n                \"inhibitory\",\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=2000,\n                linestyle=\"dashed\",\n            )\n            plot_quantile(\n                inh_nd,\n                cv_pd.time,\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=0,\n                linestyle=\"dashed\",\n            )\n\n        if hline:\n            ax.hlines(\n                0,\n                cv_pd.time.min(),\n                cv_pd.time.max(),\n                color=(0, 0, 0, 1),\n                linewidth=0.25,\n                zorder=-10,\n            )\n\n        if legend:\n            ax.legend(\n                fontsize=fontsize,\n                ncols=1,\n                bbox_to_anchor=(1.05, 1),\n                loc=\"upper left\",\n                borderaxespad=0.0,\n            )\n        else:\n            ax.legend().set_visible(False)\n\n        ax.set_xlabel(\"time (s)\", fontsize=fontsize)\n        #         ax.set_ylabel(\"current (a.u.)\", fontsize=fontsize)\n\n        if hide_yaxis:\n            plt_utils.rm_spines(ax, (\"left\",))\n\n        if trim_axes:\n            plt_utils.trim_axis(ax)\n\n        if legend_standalone:\n            handles, labels = ax.get_legend_handles_labels()\n            nd_handle = Line2D(\n                [0], [0], color=\"k\", lw=1, label=\"null direction\", ls=\"dashed\"\n            )\n            legend_n_rows = legend_n_rows or len(labels) + 1\n            # legend_n_cols = (len(labels) + 1) // legend_n_rows\n            legend_fig, legend_ax = plt_utils.standalone_legend(\n                [*labels[::2], \"null direction\"],\n                None,\n                [*handles[::2], nd_handle],\n                fontsize=fontsize,\n                n_cols=legend_n_cols,\n                handlelength=2,\n                columnspacing=0.8,\n                labelspacing=0.25,\n                figsize=cm_to_inch(legend_figsize_cm),\n                fig=fig if legend_ax is not None else None,\n                ax=legend_ax,\n            )\n            return fig, ax, legend_fig, legend_ax\n        return fig, ax\n\n    def plot_temporal_contributions_pc_nc(\n        self,\n        contrast,\n        angle,\n        t_start=0,\n        t_end=1,\n        fontsize=5,\n        linewidth=0.25,\n        legend=False,\n        legend_standalone=True,\n        legend_figsize_cm=(4.0572, 1),\n        legend_n_rows=None,\n        max_figure_height_cm=3.3941,\n        panel_height_cm=3.3941,\n        max_figure_width_cm=4.0572,\n        panel_width_cm=4.0572,\n        model_average=True,\n        highlight_mean=True,  # only applies if model_average is False\n        sum_exc_inh=False,\n        only_sum=False,\n        hide_source_types=\"auto\",\n        hide_source_types_bins=5,\n        hide_source_types_cut_off_edge=1,\n        hide_source_types_mode=\"below_cut_off\",\n        hide_yaxis=True,\n        trim_axes=True,\n        quantile=None,\n        fig=None,\n        ax=None,\n        legend_ax=None,\n        null_linestyle=\"dotted\",\n        legend_n_cols=None,\n    ):\n        if fig is None and ax is None:\n            figsize = figsize_from_n_items(\n                1,\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=panel_height_cm,\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(hspace=0.0, wspace=0, fontsize=fontsize)\n            ax = axes[0]\n        cv_pc = (\n            self.at_contrast(contrast)\n            .at_angle(angle)\n            .between_seconds(t_start, t_end)\n            .sum_over_cells()\n        )\n        cv_nc = (\n            self.at_contrast(0 if contrast == 1 else 1)\n            .at_angle(angle)\n            .between_seconds(t_start, t_end)\n            .sum_over_cells()\n        )\n\n        source_types = (\n            self.at_contrast(contrast)\n            .at_angle([angle, (angle - 180) % 360])\n            .between_seconds(t_start, t_end)\n            .filter_source_types(\n                hide_source_types,\n                hide_source_types_bins,\n                hide_source_types_cut_off_edge,\n                hide_source_types_mode,\n            )\n        )\n\n        color_source_types = (\n            self.at_contrast(contrast)\n            .at_angle([angle, (angle - 180) % 360])\n            .between_seconds(t_start, t_end)\n            .filter_source_types(\n                None,\n                hide_source_types_bins,\n                hide_source_types_cut_off_edge,\n                hide_source_types_mode,\n            )\n        )\n        cv_pc.init_colors(color_source_types)\n        cv_nc.init_colors(color_source_types)\n\n        def plot_mean_trace(time, trace, label, color, zorder, linestyle=\"solid\"):\n            ax.plot(\n                time,\n                trace,\n                label=label,\n                color=color,\n                zorder=zorder,\n                linestyle=linestyle,\n            )\n\n        def plot_individual_traces(\n            traces, time, color, zorder, label, linestyle=\"solid\", legend=None\n        ):\n            if not only_sum and not model_average:\n                plots.traces(\n                    traces,\n                    time,\n                    mean_color=color,\n                    color=color,\n                    linewidth=linewidth,\n                    zorder_traces=0,\n                    zorder_mean=zorder,\n                    fontsize=fontsize,\n                    null_line=True,\n                    highlight_mean=highlight_mean,\n                    fig=fig,\n                    ax=ax,\n                    legend=legend or label,\n                    linestyle=linestyle,\n                )\n\n        def plot_quantile(traces, time, color, zorder, linestyle=\"solid\"):\n            if quantile:\n                Q = np.quantile(traces, quantile, axis=0)\n                ax.fill_between(\n                    time,\n                    Q[0],\n                    Q[1],\n                    facecolor=adapt_color_alpha(color, 0.1),\n                    edgecolor=color,\n                    linewidth=0.25,\n                    linestyle=linestyle,\n                    zorder=zorder - 1,\n                )\n\n        def plot_summed_trace(time, trace, label, color, zorder, linestyle=\"solid\"):\n            if np.any(trace):\n                ax.plot(\n                    time,\n                    trace,\n                    label=label,\n                    color=color,\n                    zorder=zorder,\n                    linestyle=linestyle,\n                )\n\n        def get_summed_traces(signs, source_types, cv_pc, cv_nc):\n            # sum over cell types then average over models\n            exc_pd = np.zeros(cv_pc.shape)\n            inh_pd = np.zeros(cv_pc.shape)\n            exc_nd = np.zeros(cv_nc.shape)\n            inh_nd = np.zeros(cv_nc.shape)\n            # sum over cell types\n            for source_type in source_types:\n                if signs[source_type] == 1:\n                    exc_pd += cv_pc[source_type][:]  # (1, n_models, 1, n_timesteps)\n                    exc_nd += cv_nc[source_type][:]\n                else:\n                    inh_pd += cv_pc[source_type][:]\n                    inh_nd += cv_nc[source_type][:]\n            # (n_models, n_timesteps)\n            return (\n                exc_pd.squeeze(),\n                inh_pd.squeeze(),\n                exc_nd.squeeze(),\n                inh_nd.squeeze(),\n            )\n\n        for source_type in source_types:\n            if model_average and not only_sum:\n                # mean traces solid for PD and dashed for ND\n                plot_mean_trace(\n                    cv_pc.time,\n                    cv_pc[source_type][:].squeeze(axis=-2).T.mean(axis=1),\n                    source_type,\n                    cv_pc.color(source_type),\n                    cv_pc.zorder(source_types, source_type),\n                )\n                plot_mean_trace(\n                    cv_nc.time,\n                    cv_nc[source_type][:].squeeze(axis=-2).T.mean(axis=1),\n                    source_type,\n                    cv_pc.color(source_type),\n                    linestyle=null_linestyle,\n                    zorder=cv_pc.zorder(source_types, source_type),\n                )\n\n            elif not model_average and not only_sum:\n                # individual traces\n                plot_individual_traces(\n                    cv_pc[source_type][:].squeeze(axis=-2),\n                    cv_pc.time,\n                    cv_pc.color(source_type),\n                    cv_pc.zorder(source_types, source_type),\n                    source_type,\n                )\n                plot_individual_traces(\n                    cv_nc[source_type][:].squeeze(axis=-2),\n                    cv_nc.time,\n                    cv_pc.color(source_type),\n                    cv_pc.zorder(source_types, source_type),\n                    source_type,\n                    linestyle=null_linestyle,\n                    legend=\"null contrast\",\n                )\n\n            # quantiles\n            plot_quantile(\n                cv_pc[source_type][:].squeeze(axis=-2),\n                cv_pc.time,\n                cv_pc.color(source_type),\n                cv_pc.zorder(source_types, source_type),\n                linestyle=\"solid\",\n            )\n            plot_quantile(\n                cv_nc[source_type][:].squeeze(axis=-2),\n                cv_nc.time,\n                cv_pc.color(source_type),\n                cv_pc.zorder(source_types, source_type),\n                linestyle=null_linestyle,\n            )\n        if sum_exc_inh or only_sum:\n            # plot summed traces\n            signs = cv_pc.signs()\n            exc_pd, inh_pd, exc_nd, inh_nd = get_summed_traces(\n                signs, source_types, cv_pc, cv_nc\n            )\n            plot_summed_trace(\n                cv_pc.time,\n                exc_pd.mean(axis=0),\n                \"excitatory\",\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=2000,\n            )\n            plot_quantile(\n                exc_pd,\n                cv_pc.time,\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=0,\n                linestyle=\"solid\",\n            )\n            plot_summed_trace(\n                cv_nc.time,\n                exc_nd.mean(axis=0),\n                \"excitatory\",\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=2000,\n                linestyle=null_linestyle,\n            )\n            plot_quantile(\n                exc_nd,\n                cv_pc.time,\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=0,\n                linestyle=null_linestyle,\n            )\n            plot_summed_trace(\n                cv_pc.time,\n                inh_pd.mean(axis=0),\n                \"inhibitory\",\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=2000,\n            )\n            plot_quantile(\n                inh_pd,\n                cv_pc.time,\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=0,\n                linestyle=\"solid\",\n            )\n            plot_summed_trace(\n                cv_nc.time,\n                inh_nd.mean(axis=0),\n                \"inhibitory\",\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=2000,\n                linestyle=null_linestyle,\n            )\n            plot_quantile(\n                inh_nd,\n                cv_pc.time,\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=0,\n                linestyle=null_linestyle,\n            )\n        ax.axhline(0, color=(0, 0, 0, 1), linewidth=0.25, zorder=-10)\n\n        if legend:\n            ax.legend(\n                fontsize=fontsize,\n                ncols=1,\n                bbox_to_anchor=(1.05, 1),\n                loc=\"upper left\",\n                borderaxespad=0.0,\n            )\n        else:\n            ax.legend().set_visible(False)\n\n        ax.set_xlabel(\"time (s)\", fontsize=fontsize)\n        #         ax.set_ylabel(\"current (a.u.)\", fontsize=fontsize)\n\n        if hide_yaxis:\n            plt_utils.rm_spines(ax, (\"left\",))\n\n        if trim_axes:\n            plt_utils.trim_axis(ax)\n\n        if legend_standalone:\n            handles, labels = ax.get_legend_handles_labels()\n            nd_handle = Line2D(\n                [0],\n                [0],\n                color=\"k\",\n                lw=1,\n                label=\"null contrast\",\n                ls=null_linestyle,\n            )\n            legend_n_rows = legend_n_rows or len(labels) + 1\n            # legend_n_cols = (len(labels) + 1) // legend_n_rows\n            legend_fig, legend_ax = plt_utils.standalone_legend(\n                [*labels[::2], \"null contrast\"],\n                None,\n                [*handles[::2], nd_handle],\n                fontsize=fontsize,\n                n_cols=legend_n_cols,\n                handlelength=2,\n                columnspacing=0.8,\n                labelspacing=0.25,\n                figsize=cm_to_inch(legend_figsize_cm),\n                fig=fig if legend_ax is not None else None,\n                ax=legend_ax,\n            )\n            return fig, ax, legend_fig, legend_ax\n        return fig, ax\n\n    def get_temporal_contributions(\n        self,\n        contrast,\n        angle,\n        t_start=0,\n        t_end=1,\n        hide_source_types=\"auto\",\n        hide_source_types_bins=5,\n        hide_source_types_cut_off_edge=1,\n        hide_source_types_mode=\"below_cut_off\",\n        summed_traces=False,\n    ):\n        cv_pd = (\n            self.at_contrast(contrast)\n            .at_angle(angle)\n            .between_seconds(t_start, t_end)\n            .sum_over_cells()\n        )\n        cv_nd = (\n            self.at_contrast(contrast)\n            .at_angle((angle - 180) % 360)\n            .between_seconds(t_start, t_end)\n            .sum_over_cells()\n        )\n\n        source_types = (\n            self.at_contrast(contrast)\n            .at_angle([angle, (angle - 180) % 360])\n            .between_seconds(t_start, t_end)\n            .filter_source_types(\n                hide_source_types,\n                hide_source_types_bins,\n                hide_source_types_cut_off_edge,\n                hide_source_types_mode,\n            )\n        )\n\n        color_source_types = (\n            self.at_contrast(contrast)\n            .at_angle([angle, (angle - 180) % 360])\n            .between_seconds(t_start, t_end)\n            .filter_source_types(\n                None,\n                hide_source_types_bins,\n                hide_source_types_cut_off_edge,\n                hide_source_types_mode,\n            )\n        )\n        cv_pd.init_colors(color_source_types)\n        cv_nd.init_colors(color_source_types)\n\n        def get_summed_traces(signs, source_types, cv_pd, cv_nd):\n            # sum over cell types then average over models\n            exc_pd = np.zeros(cv_pd.shape)\n            inh_pd = np.zeros(cv_pd.shape)\n            exc_nd = np.zeros(cv_nd.shape)\n            inh_nd = np.zeros(cv_nd.shape)\n            # sum over cell types\n            for source_type in source_types:\n                if signs[source_type] == 1:\n                    exc_pd += cv_pd[source_type][:]  # (1, n_models, 1, n_timesteps)\n                    exc_nd += cv_nd[source_type][:]\n                else:\n                    inh_pd += cv_pd[source_type][:]\n                    inh_nd += cv_nd[source_type][:]\n            # (n_models, n_timesteps)\n            return (\n                exc_pd.squeeze(),\n                inh_pd.squeeze(),\n                exc_nd.squeeze(),\n                inh_nd.squeeze(),\n            )\n\n        if summed_traces:\n            exc_pd, inh_pd, exc_nd, inh_nd = get_summed_traces(\n                cv_pd.signs(), source_types, cv_pd, cv_nd\n            )\n            # return exc_pd, inh_pd, exc_nd, inh_nd, source_types, color_source_types\n            return exc_pd, inh_pd, exc_nd, inh_nd\n\n        return cv_pd, cv_nd, source_types, color_source_types\n\n    def get_response(\n        self,\n        contrast,\n        angle,\n        t_start=0,\n        t_end=1,\n        model_average=True,\n    ):\n        r_pd = (\n            self.at_angle(angle)\n            .at_contrast(contrast)\n            .between_seconds(t_start, t_end)\n            .responses.squeeze(axis=-2)\n        )\n        r_nd = (\n            self.at_angle((angle - 180) % 360)\n            .at_contrast(contrast)\n            .between_seconds(t_start, t_end)\n            .responses.squeeze(axis=-2)\n        )\n\n        if model_average:\n            return (\n                r_pd.mean(axis=0),\n                r_nd.mean(axis=0),\n                self.between_seconds(t_start, t_end).time,\n            )\n\n        return r_pd, r_nd, self.between_seconds(t_start, t_end).time\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_edge_currents.MovingEdgeCurrentView.filter_cell_types_by_contribution","title":"<code>filter_cell_types_by_contribution(bins=3, cut_off_edge=1, mode='above_cut_off', statistic=np.max)</code>","text":"Intuitively chunks the y-axis of the current plots into two parts <ul> <li>excitatory</li> <li>inhibitory</li> </ul> <p>and each of these into bins. In case of 3 corresponding to low-contribution, moderate-contribution, high-contribution. Then all cell types above or below the bin edge specified by cut_off_edge are discarded.</p> Source code in <code>flyvision/analysis/moving_edge_currents.py</code> <pre><code>def filter_cell_types_by_contribution(\n    self, bins=3, cut_off_edge=1, mode=\"above_cut_off\", statistic=np.max\n):\n    \"\"\"\n    Intuitively chunks the y-axis of the current plots into two parts:\n        - excitatory\n        - inhibitory\n    and each of these into bins. In case of 3 corresponding to low-contribution,\n    moderate-contribution, high-contribution. Then all cell types above or below the\n    bin edge specified by cut_off_edge are discarded.\n    \"\"\"\n    sorting = self.sorting()[0]\n    signs = self.signs()\n    currents = self.sum_over_cells().currents\n\n    filtered_cell_types = []\n    for sign in [1, -1]:\n        # compute the std over all inputs\n        values = {\n            cell_type: statistic(np.abs(currents[cell_type][:]))\n            for cell_type in sorting\n            if signs[cell_type] == sign\n        }\n        # bin into three bins\n        # ala (low contribution, medium contribution, high contribution)\n        counts, bins = np.histogram(list(values.values()), bins=bins)\n        cut_off_value = bins[cut_off_edge]\n        if mode == \"above_cut_off\":\n            filtered_cell_types.extend(\n                list(valfilter(lambda v, cut_off=cut_off_value: v &gt;= cut_off, values))\n            )\n        elif mode == \"below_cut_off\":\n            filtered_cell_types.extend(\n                list(valfilter(lambda v, cut_off=cut_off_value: v &lt; cut_off, values))\n            )\n        else:\n            raise ValueError(f\"mode {mode}\")\n    return np.array(filtered_cell_types)\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvision.analysis.moving_edge_currents.MovingEdgeCurrentView.ylims","title":"<code>ylims(source_types=None, offset=0.02)</code>","text":"<p>Ylims for temporal contributions summed over cells.</p> Source code in <code>flyvision/analysis/moving_edge_currents.py</code> <pre><code>def ylims(self, source_types=None, offset=0.02):\n    \"Ylims for temporal contributions summed over cells.\"\n    if source_types is not None:\n        return {\n            cell_type: plt_utils.get_lims(c, offset)\n            for cell_type, c in self.sum_over_cells().currents.items()\n            if cell_type in source_types\n        }\n    return plt_utils.get_lims(list(self.sum_over_cells().currents.values()), offset)\n</code></pre>"},{"location":"reference/network/","title":"Network","text":""},{"location":"reference/network/#differentiable-pytorch-module","title":"Differentiable Pytorch Module","text":""},{"location":"reference/network/#flyvision.network.Network","title":"<code>Network</code>","text":"<p>               Bases: <code>Module</code></p> <p>A connectome-constrained network with nodes, edges, and dynamics.</p> <p>Parameters:</p> Name Type Description Default <code>connectome</code> <code>Namespace</code> <p>Connectome config.</p> <code>Namespace(file='fib25-fib19_v2.2.json', extent=15, n_syn_fill=1)</code> <code>dynamics</code> <code>Namespace</code> <p>Dynamics config.</p> <code>Namespace(type='PPNeuronIGRSynapses', activation=Namespace(type='relu'))</code> <code>node_config</code> <code>Namespace</code> <p>Node config.</p> <code>Namespace(bias=Namespace(type='RestingPotential', groupby=['type'], initial_dist='Normal', mode='sample', requires_grad=True, mean=0.5, std=0.05, penalize=Namespace(activity=True), seed=0), time_const=Namespace(type='TimeConstant', groupby=['type'], initial_dist='Value', value=0.05, requires_grad=True))</code> <code>edge_config</code> <code>Namespace</code> <p>Edge config.</p> <code>Namespace(sign=Namespace(type='SynapseSign', initial_dist='Value', requires_grad=False, groupby=['source_type', 'target_type']), syn_count=Namespace(type='SynapseCount', initial_dist='Lognormal', mode='mean', requires_grad=False, std=1.0, groupby=['source_type', 'target_type', 'dv', 'du']), syn_strength=Namespace(type='SynapseCountScaling', initial_dist='Value', requires_grad=True, scale_elec=0.01, scale_chem=0.01, clamp='non_negative', groupby=['source_type', 'target_type', 'edge_type']))</code> <p>Attributes:</p> Name Type Description <code>connectome</code> <code>ConnectomeDir</code> <p>Connectome.</p> <code>dynamics</code> <code>NetworkDynamics</code> <p>Dynamics.</p> <code>node_params</code> <code>Dict[str, Parameter]</code> <p>Node parameters.</p> <code>edge_params</code> <code>Dict[str, Parameter]</code> <p>Edge parameters.</p> <code>n_nodes</code> <code>int</code> <p>Number of nodes.</p> <code>n_edges</code> <code>int</code> <p>Number of edges.</p> <code>num_parameters</code> <code>int</code> <p>Number of parameters.</p> <code>config</code> <code>Namespace</code> <p>Config namespace.</p> <code>input_indices</code> <code>ndarray</code> <p>Input indices.</p> <code>output_indices</code> <code>ndarray</code> <p>Output indices.</p> <code>_source_indices</code> <code>ndarray</code> <p>Source indices.</p> <code>_target_indices</code> <code>ndarray</code> <p>Target indices.</p> <code>symmetry_config</code> <code>Dict[str, Dict[str, Tensor]]</code> <p>Symmetry config.</p> <code>clamp_config</code> <code>Dict[str, Dict[str, Tensor]]</code> <p>Clamp config.</p> <code>stimulus</code> <code>Stimulus</code> <p>Stimulus.</p> <code>state_hooks</code> <code>Namespace</code> <p>State hook.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>class Network(nn.Module):\n    \"\"\"A connectome-constrained network with nodes, edges, and dynamics.\n\n    Args:\n        connectome: Connectome config.\n        dynamics: Dynamics config.\n        node_config: Node config.\n        edge_config: Edge config.\n\n    Attributes:\n        connectome (ConnectomeDir): Connectome.\n        dynamics (NetworkDynamics): Dynamics.\n        node_params (Dict[str, Parameter]): Node parameters.\n        edge_params (Dict[str, Parameter]): Edge parameters.\n        n_nodes (int): Number of nodes.\n        n_edges (int): Number of edges.\n        num_parameters (int): Number of parameters.\n        config (Namespace): Config namespace.\n        input_indices (np.ndarray): Input indices.\n        output_indices (np.ndarray): Output indices.\n        _source_indices (np.ndarray): Source indices.\n        _target_indices (np.ndarray): Target indices.\n        symmetry_config (Dict[str, Dict[str, Tensor]]): Symmetry config.\n        clamp_config (Dict[str, Dict[str, Tensor]]): Clamp config.\n        stimulus (Stimulus): Stimulus.\n        state_hooks (Namespace): State hook.\n    \"\"\"\n\n    def __init__(\n        self,\n        connectome: Namespace = Namespace(\n            file=\"fib25-fib19_v2.2.json\", extent=15, n_syn_fill=1\n        ),\n        dynamics: Namespace = Namespace(\n            type=\"PPNeuronIGRSynapses\", activation=Namespace(type=\"relu\")\n        ),\n        node_config: Namespace = Namespace(\n            bias=Namespace(\n                type=\"RestingPotential\",\n                groupby=[\"type\"],\n                initial_dist=\"Normal\",\n                mode=\"sample\",\n                requires_grad=True,\n                mean=0.5,\n                std=0.05,\n                penalize=Namespace(activity=True),\n                seed=0,\n            ),\n            time_const=Namespace(\n                type=\"TimeConstant\",\n                groupby=[\"type\"],\n                initial_dist=\"Value\",\n                value=0.05,\n                requires_grad=True,\n            ),\n        ),\n        edge_config: Namespace = Namespace(\n            sign=Namespace(\n                type=\"SynapseSign\",\n                initial_dist=\"Value\",\n                requires_grad=False,\n                groupby=[\"source_type\", \"target_type\"],\n            ),\n            syn_count=Namespace(\n                type=\"SynapseCount\",\n                initial_dist=\"Lognormal\",\n                mode=\"mean\",\n                requires_grad=False,\n                std=1.0,\n                groupby=[\"source_type\", \"target_type\", \"dv\", \"du\"],\n            ),\n            syn_strength=Namespace(\n                type=\"SynapseCountScaling\",\n                initial_dist=\"Value\",\n                requires_grad=True,\n                scale_elec=0.01,\n                scale_chem=0.01,\n                clamp=\"non_negative\",\n                groupby=[\"source_type\", \"target_type\", \"edge_type\"],\n            ),\n        ),\n    ):\n        super().__init__()\n\n        # Call deecopy to alter passed configs without upstream effects\n        connectome = namespacify(connectome).deepcopy()\n        dynamics = namespacify(dynamics).deepcopy()\n        node_config = namespacify(node_config).deepcopy()\n        edge_config = namespacify(edge_config).deepcopy()\n        self.config = namespacify(\n            dict(\n                connectome=connectome,\n                dynamics=dynamics,\n                node_config=node_config,\n                edge_config=edge_config,\n            )\n        ).deepcopy()\n\n        # Store the connectome, dynamics, and parameters.\n        self.connectome = ConnectomeDir(connectome)\n        self.cell_types = self.connectome.unique_cell_types[:].astype(str)\n        self.dynamics = forward_subclass(NetworkDynamics, dynamics)\n\n        # Load constant indices into memory.\n        # Store source/target indices.\n        self._source_indices = torch.tensor(self.connectome.edges.source_index[:])\n        self._target_indices = torch.tensor(self.connectome.edges.target_index[:])\n\n        self.n_nodes = len(self.connectome.nodes.type)\n        self.n_edges = len(self.connectome.edges.edge_type)\n\n        # Optional way of parameter sharing is averaging at every call across\n        # precomputed masks. This can be useful for e.g. symmetric electrical\n        # compartments.\n        # Theses masks are collected from Parameters into this namespace.\n        self.symmetry_config = Namespace()  # type: Dict[str, List[torch.Tensor]]\n        # Clamp configuration is collected from Parameter into this Namespace\n        # for projected gradient descent.\n        self.clamp_config = Namespace()\n\n        # Construct node parameter sets.\n        self.node_params = Namespace()\n        for param_name, param_config in node_config.items():\n            param = forward_subclass(\n                Parameter,\n                config={\n                    \"type\": param_config.type,\n                    \"param_config\": param_config,\n                    \"connectome\": self.connectome,\n                },\n            )\n\n            # register parameter to module\n            self.register_parameter(f\"nodes_{param_name}\", param.raw_values)\n\n            # creating index to map shared parameters onto all nodes,\n            # sources, or targets\n            param.readers = dict(\n                nodes=param.indices,\n                sources=param.indices[self._source_indices],\n                targets=param.indices[self._target_indices],\n            )\n            self.node_params[param_name] = param\n\n            # additional map to optional boolean masks to constrain\n            # parameters (called in self.clamp)\n            self.symmetry_config[f\"nodes_{param_name}\"] = getattr(\n                param, \"symmetry_masks\", []\n            )\n\n            # additional map to optional clamp configuration to constrain\n            # parameters (called in self.clamp)\n            self.clamp_config[f\"nodes_{param_name}\"] = getattr(\n                param_config, \"clamp\", None\n            )\n\n        # Construct edge parameter sets.\n        self.edge_params = Namespace()\n        for param_name, param_config in edge_config.items():\n            param = forward_subclass(\n                Parameter,\n                config={\n                    \"type\": param_config.type,\n                    \"param_config\": param_config,\n                    \"connectome\": self.connectome,\n                },\n            )\n\n            self.register_parameter(f\"edges_{param_name}\", param.raw_values)\n\n            # creating index to map shared parameters onto all edges\n            param.readers = dict(edges=param.indices)\n\n            self.edge_params[param_name] = param\n\n            self.symmetry_config[f\"edges_{param_name}\"] = getattr(\n                param, \"symmetry_masks\", []\n            )\n\n            self.clamp_config[f\"edges_{param_name}\"] = getattr(\n                param_config, \"clamp\", None\n            )\n\n        # Store chem/elec indices for electrical compartments specified by\n        # the connectome.\n        self._elec_indices = torch.tensor(\n            np.nonzero(self.connectome.edges.edge_type[:] == b\"elec\")[0]\n        ).long()\n        self._chem_indices = torch.tensor(\n            np.nonzero(self.connectome.edges.edge_type[:] == b\"chem\")[0]\n        ).long()\n\n        self.num_parameters = n_params(self)\n        self._state_hooks = tuple()\n\n        self.stimulus = Stimulus(self.connectome, _init=False)\n\n        logging.info(f\"Initialized network with {self.num_parameters} parameters.\")\n\n    def __repr__(self):\n        return self.config.__repr__().replace(\"Namespace\", \"Network\", 1)\n\n    def param_api(self) -&gt; Dict[str, Dict[str, Tensor]]:\n        \"\"\"Param api for inspection.\n\n        Note, that this is not the same as the parameter api passed to the\n        dynamics. This is a convenience function to inspect the parameters,\n        but does not write derived parameters or sources and targets states.\n        \"\"\"\n        # Construct the base parameter namespace.\n        params = Namespace(\n            nodes=Namespace(),\n            edges=Namespace(),\n            sources=Namespace(),\n            targets=Namespace(),\n        )\n        for param_name, parameter in {\n            **self.node_params,\n            **self.edge_params,\n        }.items():\n            values = parameter.semantic_values\n            for route, indices in parameter.readers.items():\n                # route one of (\"nodes\", \"sources\", \"target\", \"edges\")\n                params[route][param_name] = Namespace(parameter=values, indices=indices)\n        return params\n\n    def _param_api(self) -&gt; AutoDeref[str, AutoDeref[str, RefTensor]]:\n        \"\"\"Returns params object passed to `dynamics`.\"\"\"\n        # Construct the base parameter namespace.\n        params = AutoDeref(\n            nodes=AutoDeref(),\n            edges=AutoDeref(),\n            sources=AutoDeref(),\n            targets=AutoDeref(),\n        )\n        for param_name, parameter in {\n            **self.node_params,\n            **self.edge_params,\n        }.items():\n            values = parameter.semantic_values\n            for route, indices in parameter.readers.items():\n                # route one of (\"nodes\", \"sources\", \"target\", \"edges\")\n                params[route][param_name] = RefTensor(values, indices)\n        # Add derived parameters.\n        self.dynamics.write_derived_params(\n            params, chem_indices=self._chem_indices, elec_indices=self._elec_indices\n        )\n        for k, v in params.nodes.items():\n            if k not in params.sources:\n                params.sources[k] = self._source_gather(v)\n                params.targets[k] = self._target_gather(v)\n\n        return params\n\n    # -- Scatter/gather operations -------------------------\n\n    def _source_gather(self, x: Tensor) -&gt; RefTensor:\n        \"\"\"Gathers source node states across edges.\n\n        Args:\n            x: abstractly node-level activation, e.g. voltages,\n                Shape is (n_nodes).\n\n        Returns:\n            RefTensor of edge-level representation.\n              Shape is (n_edges).\n\n        Note, for edge-level access to target node states for elementwise\n        operations.\n\n        Called in _param_api and _state_api.\n        \"\"\"\n        return RefTensor(x, self._source_indices)\n\n    def _target_gather(self, x: Tensor) -&gt; RefTensor:\n        \"\"\"Gathers target node states across edges.\n\n        Args:\n            x: abstractly node-level activation, e.g. voltages.\n                Shape is (n_nodes).\n\n        Returns:\n            RefTensor of edge-level representation.\n              Shape is (n_edges).\n\n         Note, for edge-level access to target node states for elementwise\n         operations.\n\n        Called in _param_api and _state_api.\n        \"\"\"\n        return RefTensor(x, self._target_indices)\n\n    def target_sum(self, x: Tensor) -&gt; Tensor:\n        \"\"\"Scatter sum operation creating target node states from inputs.\n\n        Args:\n            x: abstractly, edge inputs to targets, e.g. currents.\n                Shape is (batch_size, n_edges).\n\n        Returns:\n            RefTensor of node-level input. Shape is (batch_size, n_nodes).\n        \"\"\"\n\n        result = torch.zeros((*x.shape[:-1], self.n_nodes))\n        # signature: tensor.scatter_add_(dim, index, other)\n        result.scatter_add_(\n            -1,  # nodes dim\n            self._target_indices.expand(  # view of index expanded over dims of x\n                *x.shape\n            ),\n            x,\n        )\n        return result\n\n    # ------------------------------------------------------\n\n    def _initial_state(\n        self, params: AutoDeref[str, AutoDeref[str, RefTensor]], batch_size: int\n    ) -&gt; AutoDeref[str, AutoDeref[str, Union[Tensor, RefTensor]]]:\n        \"\"\"Compute the initial state, given the parameters and batch size.\n\n        Args:\n            params: parameter namespace.\n            batch_size: batch size.\n\n        Returns:\n            initial_state: namespace of node, edge, source, and target states.\n        \"\"\"\n        # Initialize the network.\n        state = AutoDeref(nodes=AutoDeref(), edges=AutoDeref())\n        self.dynamics.write_initial_state(state, params)\n\n        # Expand over batch dimension.\n        for k, v in state.nodes.items():\n            state.nodes[k] = v.expand(batch_size, *v.shape)\n        for k, v in state.edges.items():\n            state.edges[k] = v.expand(batch_size, *v.shape)\n\n        return self._state_api(state)\n\n    def _next_state(\n        self,\n        params: AutoDeref[str, AutoDeref[str, RefTensor]],\n        state: AutoDeref[str, AutoDeref[str, Union[Tensor, RefTensor]]],\n        x_t: Tensor,\n        dt: float,\n    ) -&gt; AutoDeref[str, AutoDeref[str, Union[Tensor, RefTensor]]]:\n        \"\"\"Compute the next state, given the current `state` and stimulus `x_t`.\n\n        Args:\n            params: parameters\n            state: current state\n            x_t: stimulus at time t. Shape is (batch_size, n_nodes).\n            dt: time step.\n\n        Returns:\n            next_state: namespace of node, edge, source, and target states.\n\n        Note: simple, elementwise Euler integration.\n        \"\"\"\n        vel = AutoDeref(nodes=AutoDeref(), edges=AutoDeref())\n\n        self.dynamics.write_state_velocity(\n            vel, state, params, self.target_sum, x_t, dt=dt\n        )\n\n        next_state = AutoDeref(\n            nodes=AutoDeref(**{\n                k: state.nodes[k] + vel.nodes[k] * dt for k in state.nodes\n            }),\n            edges=AutoDeref(**{\n                k: state.edges[k] + vel.edges[k] * dt for k in state.edges\n            }),\n        )\n\n        return self._state_api(next_state)\n\n    def _state_api(\n        self, state: AutoDeref[str, AutoDeref[str, Union[Tensor, RefTensor]]]\n    ) -&gt; AutoDeref[str, AutoDeref[str, Union[Tensor, RefTensor]]]:\n        \"\"\"Populate sources and targets states from nodes states.\n\n        Note, optional state hooks are called here (in order of registration).\n        Note, this is returned by _initial_state and _next_state.\n        \"\"\"\n\n        for hook in self._state_hooks:\n            _state = hook(state)\n            if _state is not None:\n                state = _state\n\n        state = AutoDeref(\n            nodes=state.nodes,\n            edges=state.edges,\n            sources=AutoDeref(**valmap(self._source_gather, state.nodes)),\n            targets=AutoDeref(**valmap(self._target_gather, state.nodes)),\n        )\n\n        return state\n\n    def register_state_hook(self, state_hook: Callable, **kwargs) -&gt; None:\n        \"\"\"Register a state hook to retrieve or modify the state.\n\n        E.g. for a targeted perturbation.\n\n        Args:\n            state_hook: provides the callable.\n            kwargs: keyword arguments to pass to the callable.\n\n        Note: the hook is called in _state_api.\n        \"\"\"\n\n        class StateHook:\n            def __init__(self, hook, **kwargs):\n                self.hook = hook\n                self.kwargs = kwargs or {}\n\n            def __call__(self, state):\n                return self.hook(state, **self.kwargs)\n\n        if not isinstance(state_hook, Callable):\n            raise ValueError\n\n        self._state_hooks += (StateHook(state_hook, **kwargs),)\n\n    def clear_state_hooks(self, clear=True):\n        \"\"\"Clear all state hooks.\"\"\"\n        if clear:\n            self._state_hooks = tuple()\n\n    def simulate(\n        self,\n        movie_input: torch.Tensor,\n        dt: float,\n        initial_state: Union[AutoDeref, None] = \"auto\",\n        as_states: bool = False,\n        as_layer_activity: bool = False,\n    ) -&gt; Union[torch.Tensor, AutoDeref]:\n        \"\"\"Simulate the network activity from movie input.\n\n        Args:\n            movie_input: tensor requiring shape (batch_size, n_frames, 1, hexals)\n            dt: integration time constant. Warns if dt &gt; 1/50.\n            initial_state: network activity at the beginning of the simulation.\n                Either use fade_in_state or steady_state, to compute the\n                initial state from grey input or from ramping up the contrast of\n                the first movie frame. Defaults to \"auto\", which uses the\n                steady_state after 1s of grey input.\n            as_states: can return the states as AutoDeref dictionary instead of\n                a tensor. Defaults to False.\n\n        Returns:\n            activity tensor of shape (batch_size, n_frames, #neurons)\n\n        Raises:\n            ValueError if the movie_input is not four-dimensional.\n            ValueError if the integration time step is bigger than 1/50.\n            ValueError if the network is not in evaluation mode or any\n                parameters require grad.\n        \"\"\"\n\n        if len(movie_input.shape) != 4:\n            raise ValueError(\"requires shape (sample, frame, 1, hexals)\")\n\n        if dt &gt; 1 / 50:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"always\")\n                warnings.warn(\n                    (\n                        f\"dt={dt} is very large for integration.\"\n                        \" better choose a smaller dt (&lt;= 1/50 to avoid this warning)\"\n                    ),\n                    IntegrationWarning,\n                    stacklevel=2,\n                )\n\n        batch_size, n_frames = movie_input.shape[:2]\n        if initial_state == \"auto\":\n            initial_state = self.steady_state(1.0, dt, batch_size)\n        with simulation(self):\n            assert self.training is False and all(\n                not p.requires_grad for p in self.parameters()\n            )\n            self.stimulus.zero(batch_size, n_frames)\n            self.stimulus.add_input(movie_input)\n            if as_layer_activity:\n                return LayerActivity(\n                    self.forward(self.stimulus(), dt, initial_state, as_states).cpu(),\n                    self.connectome,\n                    keepref=True,\n                )\n            return self.forward(self.stimulus(), dt, initial_state, as_states)\n\n    def forward(\n        self, x: Tensor, dt: float, state: AutoDeref = None, as_states: bool = False\n    ) -&gt; Union[torch.Tensor, AutoDeref]:\n        \"\"\"Forward pass of the network.\n\n        Args:\n            x: whole-network stimulus of shape (batch_size, n_frames, n_cells).\n            dt: integration time constant.\n            state: initial state of the network. If not given,\n                computed from NetworksDynamics.write_initial_state.\n                initial_state and fade_in_state are convenience functions to\n                compute initial steady states.\n            as_states: if True, returns the states as List[AutoDeref],\n                else concatenates the activity of the nodes and returns a tensor.\n        \"\"\"\n        # To keep the parameters within their valid domain, they get clamped.\n        self.clamp()\n        # Construct the parameter API.\n        params = self._param_api()\n\n        # Initialize the network state.\n        if state is None:\n            state = self._initial_state(params, x.shape[0])\n\n        def handle(state):\n            # loop over the temporal dimension for integration of dynamics\n            for i in range(x.shape[1]):\n                state = self._next_state(params, state, x[:, i], dt)\n                if as_states is False:\n                    yield state.nodes.activity\n                else:\n                    yield state\n\n        if as_states is True:\n            return list(handle(state))\n        return torch.stack(list(handle(state)), dim=1)\n\n    def steady_state(\n        self,\n        t_pre: float,\n        dt: float,\n        batch_size: int,\n        value: float = 0.5,\n        state: Optional[AutoDeref] = None,\n        grad: bool = False,\n        return_last=True,\n    ) -&gt; AutoDeref:\n        \"\"\"State after grey-scale stimulus.\n\n        Args:\n            t_pre: time of the grey-scale stimulus.\n            dt: integration time constant.\n            batch_size: batch size.\n            value: value of the grey-scale stimulus.\n            state: initial state of the network. If not given,\n                computed from NetworksDynamics.write_initial_state.\n                initial_state and fade_in_state are convenience functions to\n                compute initial steady states.\n            grad: if True, the state is computed with gradient.\n\n        Returns:\n            steady state of the network after a grey-scale stimulus.\n        \"\"\"\n        if t_pre is None or t_pre &lt;= 0.0:\n            return state\n\n        if value is None:\n            return state\n\n        self.stimulus.zero(batch_size, int(t_pre / dt))\n        self.stimulus.add_pre_stim(value)\n\n        with self.enable_grad(grad):\n            if return_last:\n                return self(self.stimulus(), dt, as_states=True, state=state)[-1]\n            return self(self.stimulus(), dt, as_states=True, state=state)\n\n    def fade_in_state(\n        self,\n        t_fade_in: float,\n        dt: float,\n        initial_frames,\n        state=None,\n        grad=False,\n    ) -&gt; AutoDeref:\n        \"\"\"State after fade-in stimulus of initial_frames.\n\n        Args:\n            t_fade_in: time of the fade-in stimulus.\n            dt: integration time constant.\n            initial_frames: tensor of shape (batch_size, 1, n_input_elements)\n            state: initial state of the network. If not given,\n                computed from NetworksDynamics.write_initial_state.\n                initial_state and fade_in_state are convenience functions to\n                compute initial steady states.\n            grad: if True, the state is computed with gradient.\n\n\n        initial_frames of shape (batch_size, 1, n_input_elements)\n        \"\"\"\n        if t_fade_in is None or t_fade_in &lt;= 0.0:\n            return state\n\n        batch_size = initial_frames.shape[0]\n\n        # replicate initial frame over int(t_fade_in/dt) frames and fade in\n        # by ramping up the contrast\n        self.stimulus.zero(batch_size, int(t_fade_in / dt))\n\n        initial_frames = (\n            torch.linspace(0, 1, int(t_fade_in / dt))[None, :, None]\n            * (initial_frames.repeat(1, int(t_fade_in / dt), 1) - 0.5)\n            + 0.5\n        )\n        self.stimulus.add_input(initial_frames[:, :, None])\n        with self.enable_grad(grad):\n            return self(self.stimulus(), dt, as_states=True, state=state)[-1]\n\n    def clamp(self):\n        \"\"\"Clamp free parameters to their range specifid in their config.\n\n        Valid configs are `non_negative` to clamp at zero and tuple of the form\n        (min, max) to clamp to an arbitrary range.\n\n        Note, this function also enforces symmetry constraints.\n        \"\"\"\n\n        # clamp parameters\n        for param_name, mode in self.clamp_config.items():\n            param = getattr(self, param_name)\n            if param.requires_grad:\n                if mode is None:\n                    pass\n                elif mode == \"non_negative\":\n                    param.data.clamp_(0)\n                elif isinstance(mode, Iterable) and len(mode) == 2:\n                    param.data.clamp_(*mode)\n                else:\n                    raise NotImplementedError(f\"Clamping mode {mode} not implemented.\")\n\n        # enforce symmetry constraints\n        for param_name, masks in self.symmetry_config.items():\n            param = getattr(self, param_name)\n            if param.requires_grad:\n                for symmetry in masks:\n                    param.data[symmetry] = param.data[symmetry].mean()\n\n    @contextmanager\n    def enable_grad(self, grad=True):\n        \"\"\"Context manager to enable or disable gradient computation.\"\"\"\n        prev = torch.is_grad_enabled()\n        torch.set_grad_enabled(grad)\n        try:\n            yield\n        finally:\n            torch.set_grad_enabled(prev)\n\n    def stimulus_response(\n        self,\n        stim_dataset: SequenceDataset,\n        dt: float,\n        indices: Iterable[int] = None,\n        t_pre: float = 1.0,\n        t_fade_in: float = 0.0,\n        grad: bool = False,\n        default_stim_key: Any = \"lum\",\n        batch_size: int = 1,\n    ):\n        \"\"\"Compute stimulus responses for a given stimulus dataset.\n\n        Args:\n            stim_dataset: stimulus dataset.\n            dt: integration time constant.\n            indices: indices of the stimuli to compute the response for.\n                If not given, all stimuli responses are computed.\n            t_pre: time of the grey-scale stimulus.\n            t_fade_in: time of the fade-in stimulus (slow).\n            grad: if True, the state is computed with gradient.\n            default_stim_key: key of the stimulus in the dataset if it returns\n                a dictionary.\n\n        Note:\n            per default, applies a grey-scale stimulus for 1 second, no\n            fade-in stimulus.\n\n        Returns:\n            iterator over stimuli and respective responses as numpy\n            arrays.\n        \"\"\"\n        stim_dataset.dt = dt\n        if indices is None:\n            indices = np.arange(len(stim_dataset))\n        stim_loader = DataLoader(\n            stim_dataset, batch_size=batch_size, sampler=IndexSampler(indices)\n        )\n\n        stimulus = self.stimulus\n\n        # compute initial state\n        initial_state = self.steady_state(t_pre, dt, batch_size=1, value=0.5)\n\n        with self.enable_grad(grad):\n            logging.info(f\"Computing {len(indices)} stimulus responses.\")\n            for stim in tqdm(\n                stim_loader, desc=\"Batch\", total=len(stim_loader), leave=False\n            ):\n                # when datasets return dictionaries, we assume that the stimulus\n                # is stored under the key `default_stim_key`\n                if isinstance(stim, dict):\n                    stim = stim[default_stim_key]  # (batch, frames, 1, hexals)\n                else:\n                    stim = stim.unsqueeze(-2)  # (batch, frames, 1, hexals)\n\n                # fade in stimulus\n                fade_in_state = self.fade_in_state(\n                    t_fade_in=t_fade_in,\n                    dt=dt,\n                    initial_frames=stim[:, 0],\n                    state=initial_state,\n                )\n\n                def handle_stim(stim, fade_in_state):\n                    # reset stimulus\n                    batch_size, n_frames = stim.shape[:2]\n                    stimulus.zero(batch_size, n_frames)\n\n                    # add stimulus\n                    stimulus.add_input(stim)\n\n                    # compute response\n                    if grad is False:\n                        return (\n                            stim.cpu().numpy(),\n                            self(stimulus(), dt, state=fade_in_state)\n                            .detach()\n                            .cpu()\n                            .numpy(),\n                        )\n                    elif grad is True:\n                        return (\n                            stim.cpu().numpy(),\n                            self(stimulus(), dt, state=fade_in_state),\n                        )\n\n                yield handle_stim(stim, fade_in_state)\n\n    def current_response(\n        self,\n        stim_dataset: SequenceDataset,\n        dt: float,\n        indices: Iterable[int] = None,\n        t_pre: float = 1.0,\n        t_fade_in: float = 0,\n        default_stim_key: Any = \"lum\",\n    ):\n        \"\"\"Compute stimulus currents and responses for a given stimulus dataset.\n\n        Note, requires Dynamics to implement `currents`.\n\n        Args:\n            stim_dataset: stimulus dataset.\n            dt: integration time constant.\n            indices: indices of the stimuli to compute the response for.\n                If not given, all stimuli responses are computed.\n            t_pre: time of the grey-scale stimulus.\n            t_fade_in: time of the fade-in stimulus (slow).\n            grad: if True, the state is computed with gradient.\n            default_stim_key: key of the stimulus in the dataset if it returns\n                a dictionary.\n\n        Returns:\n            iterator over stimuli, currents and respective responses as numpy\n            arrays.\n        \"\"\"\n        self.clamp()\n        # Construct the parameter API.\n        params = self._param_api()\n\n        stim_dataset.dt = dt\n        if indices is None:\n            indices = np.arange(len(stim_dataset))\n        stim_loader = DataLoader(\n            stim_dataset, batch_size=1, sampler=IndexSampler(indices)\n        )\n\n        stimulus = self.stimulus\n        initial_state = self.steady_state(t_pre, dt, batch_size=1, value=0.5)\n        with torch.no_grad():\n            logging.info(f\"Computing {len(indices)} stimulus responses.\")\n            for stim in stim_loader:\n                if isinstance(stim, dict):\n                    stim = stim[default_stim_key].squeeze(-2)\n\n                fade_in_state = self.fade_in_state(\n                    t_fade_in=t_fade_in,\n                    dt=dt,\n                    initial_frames=stim[:, 0].unsqueeze(1),\n                    state=initial_state,\n                )\n\n                def handle_stim(stim, fade_in_state):\n                    # reset stimulus\n                    batch_size, n_frames, _ = stim.shape\n                    stimulus.zero(batch_size, n_frames)\n\n                    # add stimulus\n                    stimulus.add_input(stim.unsqueeze(2))\n\n                    # compute response\n                    states = self(stimulus(), dt, state=fade_in_state, as_states=True)\n                    return (\n                        stim.cpu().numpy().squeeze(),\n                        torch.stack(\n                            [s.nodes.activity.cpu() for s in states],\n                            dim=1,\n                        )\n                        .numpy()\n                        .squeeze(),\n                        torch.stack(\n                            [self.dynamics.currents(s, params).cpu() for s in states],\n                            dim=1,\n                        )\n                        .numpy()\n                        .squeeze(),\n                    )\n\n                # stim, activity, currents\n                yield handle_stim(stim, fade_in_state)\n</code></pre>"},{"location":"reference/network/#flyvision.network.Network.param_api","title":"<code>param_api()</code>","text":"<p>Param api for inspection.</p> <p>Note, that this is not the same as the parameter api passed to the dynamics. This is a convenience function to inspect the parameters, but does not write derived parameters or sources and targets states.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def param_api(self) -&gt; Dict[str, Dict[str, Tensor]]:\n    \"\"\"Param api for inspection.\n\n    Note, that this is not the same as the parameter api passed to the\n    dynamics. This is a convenience function to inspect the parameters,\n    but does not write derived parameters or sources and targets states.\n    \"\"\"\n    # Construct the base parameter namespace.\n    params = Namespace(\n        nodes=Namespace(),\n        edges=Namespace(),\n        sources=Namespace(),\n        targets=Namespace(),\n    )\n    for param_name, parameter in {\n        **self.node_params,\n        **self.edge_params,\n    }.items():\n        values = parameter.semantic_values\n        for route, indices in parameter.readers.items():\n            # route one of (\"nodes\", \"sources\", \"target\", \"edges\")\n            params[route][param_name] = Namespace(parameter=values, indices=indices)\n    return params\n</code></pre>"},{"location":"reference/network/#flyvision.network.Network.target_sum","title":"<code>target_sum(x)</code>","text":"<p>Scatter sum operation creating target node states from inputs.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>abstractly, edge inputs to targets, e.g. currents. Shape is (batch_size, n_edges).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>RefTensor of node-level input. Shape is (batch_size, n_nodes).</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def target_sum(self, x: Tensor) -&gt; Tensor:\n    \"\"\"Scatter sum operation creating target node states from inputs.\n\n    Args:\n        x: abstractly, edge inputs to targets, e.g. currents.\n            Shape is (batch_size, n_edges).\n\n    Returns:\n        RefTensor of node-level input. Shape is (batch_size, n_nodes).\n    \"\"\"\n\n    result = torch.zeros((*x.shape[:-1], self.n_nodes))\n    # signature: tensor.scatter_add_(dim, index, other)\n    result.scatter_add_(\n        -1,  # nodes dim\n        self._target_indices.expand(  # view of index expanded over dims of x\n            *x.shape\n        ),\n        x,\n    )\n    return result\n</code></pre>"},{"location":"reference/network/#flyvision.network.Network.register_state_hook","title":"<code>register_state_hook(state_hook, **kwargs)</code>","text":"<p>Register a state hook to retrieve or modify the state.</p> <p>E.g. for a targeted perturbation.</p> <p>Parameters:</p> Name Type Description Default <code>state_hook</code> <code>Callable</code> <p>provides the callable.</p> required <code>kwargs</code> <p>keyword arguments to pass to the callable.</p> <code>{}</code> <p>Note: the hook is called in _state_api.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def register_state_hook(self, state_hook: Callable, **kwargs) -&gt; None:\n    \"\"\"Register a state hook to retrieve or modify the state.\n\n    E.g. for a targeted perturbation.\n\n    Args:\n        state_hook: provides the callable.\n        kwargs: keyword arguments to pass to the callable.\n\n    Note: the hook is called in _state_api.\n    \"\"\"\n\n    class StateHook:\n        def __init__(self, hook, **kwargs):\n            self.hook = hook\n            self.kwargs = kwargs or {}\n\n        def __call__(self, state):\n            return self.hook(state, **self.kwargs)\n\n    if not isinstance(state_hook, Callable):\n        raise ValueError\n\n    self._state_hooks += (StateHook(state_hook, **kwargs),)\n</code></pre>"},{"location":"reference/network/#flyvision.network.Network.clear_state_hooks","title":"<code>clear_state_hooks(clear=True)</code>","text":"<p>Clear all state hooks.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def clear_state_hooks(self, clear=True):\n    \"\"\"Clear all state hooks.\"\"\"\n    if clear:\n        self._state_hooks = tuple()\n</code></pre>"},{"location":"reference/network/#flyvision.network.Network.simulate","title":"<code>simulate(movie_input, dt, initial_state='auto', as_states=False, as_layer_activity=False)</code>","text":"<p>Simulate the network activity from movie input.</p> <p>Parameters:</p> Name Type Description Default <code>movie_input</code> <code>Tensor</code> <p>tensor requiring shape (batch_size, n_frames, 1, hexals)</p> required <code>dt</code> <code>float</code> <p>integration time constant. Warns if dt &gt; 1/50.</p> required <code>initial_state</code> <code>Union[AutoDeref, None]</code> <p>network activity at the beginning of the simulation. Either use fade_in_state or steady_state, to compute the initial state from grey input or from ramping up the contrast of the first movie frame. Defaults to \u201cauto\u201d, which uses the steady_state after 1s of grey input.</p> <code>'auto'</code> <code>as_states</code> <code>bool</code> <p>can return the states as AutoDeref dictionary instead of a tensor. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Tensor, AutoDeref]</code> <p>activity tensor of shape (batch_size, n_frames, #neurons)</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def simulate(\n    self,\n    movie_input: torch.Tensor,\n    dt: float,\n    initial_state: Union[AutoDeref, None] = \"auto\",\n    as_states: bool = False,\n    as_layer_activity: bool = False,\n) -&gt; Union[torch.Tensor, AutoDeref]:\n    \"\"\"Simulate the network activity from movie input.\n\n    Args:\n        movie_input: tensor requiring shape (batch_size, n_frames, 1, hexals)\n        dt: integration time constant. Warns if dt &gt; 1/50.\n        initial_state: network activity at the beginning of the simulation.\n            Either use fade_in_state or steady_state, to compute the\n            initial state from grey input or from ramping up the contrast of\n            the first movie frame. Defaults to \"auto\", which uses the\n            steady_state after 1s of grey input.\n        as_states: can return the states as AutoDeref dictionary instead of\n            a tensor. Defaults to False.\n\n    Returns:\n        activity tensor of shape (batch_size, n_frames, #neurons)\n\n    Raises:\n        ValueError if the movie_input is not four-dimensional.\n        ValueError if the integration time step is bigger than 1/50.\n        ValueError if the network is not in evaluation mode or any\n            parameters require grad.\n    \"\"\"\n\n    if len(movie_input.shape) != 4:\n        raise ValueError(\"requires shape (sample, frame, 1, hexals)\")\n\n    if dt &gt; 1 / 50:\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"always\")\n            warnings.warn(\n                (\n                    f\"dt={dt} is very large for integration.\"\n                    \" better choose a smaller dt (&lt;= 1/50 to avoid this warning)\"\n                ),\n                IntegrationWarning,\n                stacklevel=2,\n            )\n\n    batch_size, n_frames = movie_input.shape[:2]\n    if initial_state == \"auto\":\n        initial_state = self.steady_state(1.0, dt, batch_size)\n    with simulation(self):\n        assert self.training is False and all(\n            not p.requires_grad for p in self.parameters()\n        )\n        self.stimulus.zero(batch_size, n_frames)\n        self.stimulus.add_input(movie_input)\n        if as_layer_activity:\n            return LayerActivity(\n                self.forward(self.stimulus(), dt, initial_state, as_states).cpu(),\n                self.connectome,\n                keepref=True,\n            )\n        return self.forward(self.stimulus(), dt, initial_state, as_states)\n</code></pre>"},{"location":"reference/network/#flyvision.network.Network.forward","title":"<code>forward(x, dt, state=None, as_states=False)</code>","text":"<p>Forward pass of the network.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>whole-network stimulus of shape (batch_size, n_frames, n_cells).</p> required <code>dt</code> <code>float</code> <p>integration time constant.</p> required <code>state</code> <code>AutoDeref</code> <p>initial state of the network. If not given, computed from NetworksDynamics.write_initial_state. initial_state and fade_in_state are convenience functions to compute initial steady states.</p> <code>None</code> <code>as_states</code> <code>bool</code> <p>if True, returns the states as List[AutoDeref], else concatenates the activity of the nodes and returns a tensor.</p> <code>False</code> Source code in <code>flyvision/network/network.py</code> <pre><code>def forward(\n    self, x: Tensor, dt: float, state: AutoDeref = None, as_states: bool = False\n) -&gt; Union[torch.Tensor, AutoDeref]:\n    \"\"\"Forward pass of the network.\n\n    Args:\n        x: whole-network stimulus of shape (batch_size, n_frames, n_cells).\n        dt: integration time constant.\n        state: initial state of the network. If not given,\n            computed from NetworksDynamics.write_initial_state.\n            initial_state and fade_in_state are convenience functions to\n            compute initial steady states.\n        as_states: if True, returns the states as List[AutoDeref],\n            else concatenates the activity of the nodes and returns a tensor.\n    \"\"\"\n    # To keep the parameters within their valid domain, they get clamped.\n    self.clamp()\n    # Construct the parameter API.\n    params = self._param_api()\n\n    # Initialize the network state.\n    if state is None:\n        state = self._initial_state(params, x.shape[0])\n\n    def handle(state):\n        # loop over the temporal dimension for integration of dynamics\n        for i in range(x.shape[1]):\n            state = self._next_state(params, state, x[:, i], dt)\n            if as_states is False:\n                yield state.nodes.activity\n            else:\n                yield state\n\n    if as_states is True:\n        return list(handle(state))\n    return torch.stack(list(handle(state)), dim=1)\n</code></pre>"},{"location":"reference/network/#flyvision.network.Network.steady_state","title":"<code>steady_state(t_pre, dt, batch_size, value=0.5, state=None, grad=False, return_last=True)</code>","text":"<p>State after grey-scale stimulus.</p> <p>Parameters:</p> Name Type Description Default <code>t_pre</code> <code>float</code> <p>time of the grey-scale stimulus.</p> required <code>dt</code> <code>float</code> <p>integration time constant.</p> required <code>batch_size</code> <code>int</code> <p>batch size.</p> required <code>value</code> <code>float</code> <p>value of the grey-scale stimulus.</p> <code>0.5</code> <code>state</code> <code>Optional[AutoDeref]</code> <p>initial state of the network. If not given, computed from NetworksDynamics.write_initial_state. initial_state and fade_in_state are convenience functions to compute initial steady states.</p> <code>None</code> <code>grad</code> <code>bool</code> <p>if True, the state is computed with gradient.</p> <code>False</code> <p>Returns:</p> Type Description <code>AutoDeref</code> <p>steady state of the network after a grey-scale stimulus.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def steady_state(\n    self,\n    t_pre: float,\n    dt: float,\n    batch_size: int,\n    value: float = 0.5,\n    state: Optional[AutoDeref] = None,\n    grad: bool = False,\n    return_last=True,\n) -&gt; AutoDeref:\n    \"\"\"State after grey-scale stimulus.\n\n    Args:\n        t_pre: time of the grey-scale stimulus.\n        dt: integration time constant.\n        batch_size: batch size.\n        value: value of the grey-scale stimulus.\n        state: initial state of the network. If not given,\n            computed from NetworksDynamics.write_initial_state.\n            initial_state and fade_in_state are convenience functions to\n            compute initial steady states.\n        grad: if True, the state is computed with gradient.\n\n    Returns:\n        steady state of the network after a grey-scale stimulus.\n    \"\"\"\n    if t_pre is None or t_pre &lt;= 0.0:\n        return state\n\n    if value is None:\n        return state\n\n    self.stimulus.zero(batch_size, int(t_pre / dt))\n    self.stimulus.add_pre_stim(value)\n\n    with self.enable_grad(grad):\n        if return_last:\n            return self(self.stimulus(), dt, as_states=True, state=state)[-1]\n        return self(self.stimulus(), dt, as_states=True, state=state)\n</code></pre>"},{"location":"reference/network/#flyvision.network.Network.fade_in_state","title":"<code>fade_in_state(t_fade_in, dt, initial_frames, state=None, grad=False)</code>","text":"<p>State after fade-in stimulus of initial_frames.</p> <p>Parameters:</p> Name Type Description Default <code>t_fade_in</code> <code>float</code> <p>time of the fade-in stimulus.</p> required <code>dt</code> <code>float</code> <p>integration time constant.</p> required <code>initial_frames</code> <p>tensor of shape (batch_size, 1, n_input_elements)</p> required <code>state</code> <p>initial state of the network. If not given, computed from NetworksDynamics.write_initial_state. initial_state and fade_in_state are convenience functions to compute initial steady states.</p> <code>None</code> <code>grad</code> <p>if True, the state is computed with gradient.</p> <code>False</code> <p>initial_frames of shape (batch_size, 1, n_input_elements)</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def fade_in_state(\n    self,\n    t_fade_in: float,\n    dt: float,\n    initial_frames,\n    state=None,\n    grad=False,\n) -&gt; AutoDeref:\n    \"\"\"State after fade-in stimulus of initial_frames.\n\n    Args:\n        t_fade_in: time of the fade-in stimulus.\n        dt: integration time constant.\n        initial_frames: tensor of shape (batch_size, 1, n_input_elements)\n        state: initial state of the network. If not given,\n            computed from NetworksDynamics.write_initial_state.\n            initial_state and fade_in_state are convenience functions to\n            compute initial steady states.\n        grad: if True, the state is computed with gradient.\n\n\n    initial_frames of shape (batch_size, 1, n_input_elements)\n    \"\"\"\n    if t_fade_in is None or t_fade_in &lt;= 0.0:\n        return state\n\n    batch_size = initial_frames.shape[0]\n\n    # replicate initial frame over int(t_fade_in/dt) frames and fade in\n    # by ramping up the contrast\n    self.stimulus.zero(batch_size, int(t_fade_in / dt))\n\n    initial_frames = (\n        torch.linspace(0, 1, int(t_fade_in / dt))[None, :, None]\n        * (initial_frames.repeat(1, int(t_fade_in / dt), 1) - 0.5)\n        + 0.5\n    )\n    self.stimulus.add_input(initial_frames[:, :, None])\n    with self.enable_grad(grad):\n        return self(self.stimulus(), dt, as_states=True, state=state)[-1]\n</code></pre>"},{"location":"reference/network/#flyvision.network.Network.clamp","title":"<code>clamp()</code>","text":"<p>Clamp free parameters to their range specifid in their config.</p> <p>Valid configs are <code>non_negative</code> to clamp at zero and tuple of the form (min, max) to clamp to an arbitrary range.</p> <p>Note, this function also enforces symmetry constraints.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def clamp(self):\n    \"\"\"Clamp free parameters to their range specifid in their config.\n\n    Valid configs are `non_negative` to clamp at zero and tuple of the form\n    (min, max) to clamp to an arbitrary range.\n\n    Note, this function also enforces symmetry constraints.\n    \"\"\"\n\n    # clamp parameters\n    for param_name, mode in self.clamp_config.items():\n        param = getattr(self, param_name)\n        if param.requires_grad:\n            if mode is None:\n                pass\n            elif mode == \"non_negative\":\n                param.data.clamp_(0)\n            elif isinstance(mode, Iterable) and len(mode) == 2:\n                param.data.clamp_(*mode)\n            else:\n                raise NotImplementedError(f\"Clamping mode {mode} not implemented.\")\n\n    # enforce symmetry constraints\n    for param_name, masks in self.symmetry_config.items():\n        param = getattr(self, param_name)\n        if param.requires_grad:\n            for symmetry in masks:\n                param.data[symmetry] = param.data[symmetry].mean()\n</code></pre>"},{"location":"reference/network/#flyvision.network.Network.enable_grad","title":"<code>enable_grad(grad=True)</code>","text":"<p>Context manager to enable or disable gradient computation.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>@contextmanager\ndef enable_grad(self, grad=True):\n    \"\"\"Context manager to enable or disable gradient computation.\"\"\"\n    prev = torch.is_grad_enabled()\n    torch.set_grad_enabled(grad)\n    try:\n        yield\n    finally:\n        torch.set_grad_enabled(prev)\n</code></pre>"},{"location":"reference/network/#flyvision.network.Network.stimulus_response","title":"<code>stimulus_response(stim_dataset, dt, indices=None, t_pre=1.0, t_fade_in=0.0, grad=False, default_stim_key='lum', batch_size=1)</code>","text":"<p>Compute stimulus responses for a given stimulus dataset.</p> <p>Parameters:</p> Name Type Description Default <code>stim_dataset</code> <code>SequenceDataset</code> <p>stimulus dataset.</p> required <code>dt</code> <code>float</code> <p>integration time constant.</p> required <code>indices</code> <code>Iterable[int]</code> <p>indices of the stimuli to compute the response for. If not given, all stimuli responses are computed.</p> <code>None</code> <code>t_pre</code> <code>float</code> <p>time of the grey-scale stimulus.</p> <code>1.0</code> <code>t_fade_in</code> <code>float</code> <p>time of the fade-in stimulus (slow).</p> <code>0.0</code> <code>grad</code> <code>bool</code> <p>if True, the state is computed with gradient.</p> <code>False</code> <code>default_stim_key</code> <code>Any</code> <p>key of the stimulus in the dataset if it returns a dictionary.</p> <code>'lum'</code> Note <p>per default, applies a grey-scale stimulus for 1 second, no fade-in stimulus.</p> <p>Returns:</p> Type Description <p>iterator over stimuli and respective responses as numpy</p> <p>arrays.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def stimulus_response(\n    self,\n    stim_dataset: SequenceDataset,\n    dt: float,\n    indices: Iterable[int] = None,\n    t_pre: float = 1.0,\n    t_fade_in: float = 0.0,\n    grad: bool = False,\n    default_stim_key: Any = \"lum\",\n    batch_size: int = 1,\n):\n    \"\"\"Compute stimulus responses for a given stimulus dataset.\n\n    Args:\n        stim_dataset: stimulus dataset.\n        dt: integration time constant.\n        indices: indices of the stimuli to compute the response for.\n            If not given, all stimuli responses are computed.\n        t_pre: time of the grey-scale stimulus.\n        t_fade_in: time of the fade-in stimulus (slow).\n        grad: if True, the state is computed with gradient.\n        default_stim_key: key of the stimulus in the dataset if it returns\n            a dictionary.\n\n    Note:\n        per default, applies a grey-scale stimulus for 1 second, no\n        fade-in stimulus.\n\n    Returns:\n        iterator over stimuli and respective responses as numpy\n        arrays.\n    \"\"\"\n    stim_dataset.dt = dt\n    if indices is None:\n        indices = np.arange(len(stim_dataset))\n    stim_loader = DataLoader(\n        stim_dataset, batch_size=batch_size, sampler=IndexSampler(indices)\n    )\n\n    stimulus = self.stimulus\n\n    # compute initial state\n    initial_state = self.steady_state(t_pre, dt, batch_size=1, value=0.5)\n\n    with self.enable_grad(grad):\n        logging.info(f\"Computing {len(indices)} stimulus responses.\")\n        for stim in tqdm(\n            stim_loader, desc=\"Batch\", total=len(stim_loader), leave=False\n        ):\n            # when datasets return dictionaries, we assume that the stimulus\n            # is stored under the key `default_stim_key`\n            if isinstance(stim, dict):\n                stim = stim[default_stim_key]  # (batch, frames, 1, hexals)\n            else:\n                stim = stim.unsqueeze(-2)  # (batch, frames, 1, hexals)\n\n            # fade in stimulus\n            fade_in_state = self.fade_in_state(\n                t_fade_in=t_fade_in,\n                dt=dt,\n                initial_frames=stim[:, 0],\n                state=initial_state,\n            )\n\n            def handle_stim(stim, fade_in_state):\n                # reset stimulus\n                batch_size, n_frames = stim.shape[:2]\n                stimulus.zero(batch_size, n_frames)\n\n                # add stimulus\n                stimulus.add_input(stim)\n\n                # compute response\n                if grad is False:\n                    return (\n                        stim.cpu().numpy(),\n                        self(stimulus(), dt, state=fade_in_state)\n                        .detach()\n                        .cpu()\n                        .numpy(),\n                    )\n                elif grad is True:\n                    return (\n                        stim.cpu().numpy(),\n                        self(stimulus(), dt, state=fade_in_state),\n                    )\n\n            yield handle_stim(stim, fade_in_state)\n</code></pre>"},{"location":"reference/network/#flyvision.network.Network.current_response","title":"<code>current_response(stim_dataset, dt, indices=None, t_pre=1.0, t_fade_in=0, default_stim_key='lum')</code>","text":"<p>Compute stimulus currents and responses for a given stimulus dataset.</p> <p>Note, requires Dynamics to implement <code>currents</code>.</p> <p>Parameters:</p> Name Type Description Default <code>stim_dataset</code> <code>SequenceDataset</code> <p>stimulus dataset.</p> required <code>dt</code> <code>float</code> <p>integration time constant.</p> required <code>indices</code> <code>Iterable[int]</code> <p>indices of the stimuli to compute the response for. If not given, all stimuli responses are computed.</p> <code>None</code> <code>t_pre</code> <code>float</code> <p>time of the grey-scale stimulus.</p> <code>1.0</code> <code>t_fade_in</code> <code>float</code> <p>time of the fade-in stimulus (slow).</p> <code>0</code> <code>grad</code> <p>if True, the state is computed with gradient.</p> required <code>default_stim_key</code> <code>Any</code> <p>key of the stimulus in the dataset if it returns a dictionary.</p> <code>'lum'</code> <p>Returns:</p> Type Description <p>iterator over stimuli, currents and respective responses as numpy</p> <p>arrays.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def current_response(\n    self,\n    stim_dataset: SequenceDataset,\n    dt: float,\n    indices: Iterable[int] = None,\n    t_pre: float = 1.0,\n    t_fade_in: float = 0,\n    default_stim_key: Any = \"lum\",\n):\n    \"\"\"Compute stimulus currents and responses for a given stimulus dataset.\n\n    Note, requires Dynamics to implement `currents`.\n\n    Args:\n        stim_dataset: stimulus dataset.\n        dt: integration time constant.\n        indices: indices of the stimuli to compute the response for.\n            If not given, all stimuli responses are computed.\n        t_pre: time of the grey-scale stimulus.\n        t_fade_in: time of the fade-in stimulus (slow).\n        grad: if True, the state is computed with gradient.\n        default_stim_key: key of the stimulus in the dataset if it returns\n            a dictionary.\n\n    Returns:\n        iterator over stimuli, currents and respective responses as numpy\n        arrays.\n    \"\"\"\n    self.clamp()\n    # Construct the parameter API.\n    params = self._param_api()\n\n    stim_dataset.dt = dt\n    if indices is None:\n        indices = np.arange(len(stim_dataset))\n    stim_loader = DataLoader(\n        stim_dataset, batch_size=1, sampler=IndexSampler(indices)\n    )\n\n    stimulus = self.stimulus\n    initial_state = self.steady_state(t_pre, dt, batch_size=1, value=0.5)\n    with torch.no_grad():\n        logging.info(f\"Computing {len(indices)} stimulus responses.\")\n        for stim in stim_loader:\n            if isinstance(stim, dict):\n                stim = stim[default_stim_key].squeeze(-2)\n\n            fade_in_state = self.fade_in_state(\n                t_fade_in=t_fade_in,\n                dt=dt,\n                initial_frames=stim[:, 0].unsqueeze(1),\n                state=initial_state,\n            )\n\n            def handle_stim(stim, fade_in_state):\n                # reset stimulus\n                batch_size, n_frames, _ = stim.shape\n                stimulus.zero(batch_size, n_frames)\n\n                # add stimulus\n                stimulus.add_input(stim.unsqueeze(2))\n\n                # compute response\n                states = self(stimulus(), dt, state=fade_in_state, as_states=True)\n                return (\n                    stim.cpu().numpy().squeeze(),\n                    torch.stack(\n                        [s.nodes.activity.cpu() for s in states],\n                        dim=1,\n                    )\n                    .numpy()\n                    .squeeze(),\n                    torch.stack(\n                        [self.dynamics.currents(s, params).cpu() for s in states],\n                        dim=1,\n                    )\n                    .numpy()\n                    .squeeze(),\n                )\n\n            # stim, activity, currents\n            yield handle_stim(stim, fade_in_state)\n</code></pre>"},{"location":"reference/network/#initialization","title":"Initialization","text":""},{"location":"reference/network/#flyvision.network.initialization","title":"<code>initialization</code>","text":"<p>The parameters that the networks can be initialized with. Each parameter is a type on its own, because different parameters are shared differently. These types handle the initialization of indices to perform gather and scatter opera- tions. Parameter types can be initialized from a range of initial distribution types.</p> to maintain compatibility with old configurations, e.g. to reinitialize <p>a trained network, careful when refactoring any of these types or syntax.</p>"},{"location":"reference/network/#flyvision.network.initialization.InitialDistribution","title":"<code>InitialDistribution</code>","text":"<p>Initial distribution base class.</p> <p>Attributes:</p> Name Type Description <code>raw_values</code> <code>Tensor</code> <p>initial parameters must store raw_values as attribute in their init.</p> <code>readers</code> <code>Dict[str, Tensor]</code> <p>readers will be written by the network during initialization.</p> to add a new initial distribution type, subclass this <p>class and implement the init method. The init method should take the param_config as its first argument, and should store the attribute raw_values as a torch.nn.Parameter.</p> An example of a viable param_config is <p>param_config = Namespace(     requires_grad=True,     initial_dist=\u201dNormal\u201d,     mean=0,     std=1,     mode=\u201dsample\u201d, )</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>class InitialDistribution:\n    \"\"\"Initial distribution base class.\n\n    Attributes:\n        raw_values: initial parameters must store raw_values as attribute in\n            their __init__.\n        readers: readers will be written by the network during initialization.\n\n    Extension point: to add a new initial distribution type, subclass this\n        class and implement the __init__ method. The __init__ method\n        should take the param_config as its first argument, and should store\n        the attribute raw_values as a torch.nn.Parameter.\n\n    An example of a viable param_config is:\n        param_config = Namespace(\n            requires_grad=True,\n            initial_dist=\"Normal\",\n            mean=0,\n            std=1,\n            mode=\"sample\",\n        )\n    \"\"\"\n\n    raw_values: Tensor\n    readers: Dict[str, Tensor]\n\n    # def __new__(cls, param_config: Namespace, *args, **kwargs):\n    #     return forward_subclass(cls, param_config, subclass_key=\"initial_dist\")\n\n    @property\n    def semantic_values(self):\n        \"\"\"Optional reparametrization of raw values invoked for computation.\"\"\"\n        return self.raw_values\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__} (semantic values): \\n{self.semantic_values}\"\n\n    def __len__(self):\n        return len(self.raw_values)\n\n    def clamp(self, values, mode):\n        \"\"\"To clamp the raw_values of the parameters at initialization.\n\n        Note, mild clash with raw_values/semantic_values reparametrization.\n        Parameters that use reparametrization in terms of semantic_values\n        should not use clamp.\n        \"\"\"\n        if mode == \"non_negative\":\n            values.clamp_(min=0)\n        elif isinstance(mode, Iterable) and len(mode) == 2:\n            values.clamp_(*mode)\n        elif mode in [False, None]:\n            return values\n        else:\n            raise ParameterConfigError(f\"{mode} not a valid argument for clamp\")\n        return values\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.InitialDistribution.semantic_values","title":"<code>semantic_values</code>  <code>property</code>","text":"<p>Optional reparametrization of raw values invoked for computation.</p>"},{"location":"reference/network/#flyvision.network.initialization.InitialDistribution.clamp","title":"<code>clamp(values, mode)</code>","text":"<p>To clamp the raw_values of the parameters at initialization.</p> <p>Note, mild clash with raw_values/semantic_values reparametrization. Parameters that use reparametrization in terms of semantic_values should not use clamp.</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>def clamp(self, values, mode):\n    \"\"\"To clamp the raw_values of the parameters at initialization.\n\n    Note, mild clash with raw_values/semantic_values reparametrization.\n    Parameters that use reparametrization in terms of semantic_values\n    should not use clamp.\n    \"\"\"\n    if mode == \"non_negative\":\n        values.clamp_(min=0)\n    elif isinstance(mode, Iterable) and len(mode) == 2:\n        values.clamp_(*mode)\n    elif mode in [False, None]:\n        return values\n    else:\n        raise ParameterConfigError(f\"{mode} not a valid argument for clamp\")\n    return values\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.Value","title":"<code>Value</code>","text":"<p>               Bases: <code>InitialDistribution</code></p> <p>Initializes parameters with a single value.</p> Example param_config <p>param_config = Namespace(     requires_grad=True,     initial_dist=\u201dValue\u201d,     value=0, )</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>class Value(InitialDistribution):\n    \"\"\"Initializes parameters with a single value.\n\n    Example param_config:\n        param_config = Namespace(\n            requires_grad=True,\n            initial_dist=\"Value\",\n            value=0,\n        )\n    \"\"\"\n\n    # def __init__(self, param_config: Namespace) -&gt; None:\n    #     _values = torch.tensor(param_config.value).float()\n    #     _values = self.clamp(_values, param_config)\n    #     self.raw_values = nn.Parameter(\n    #         _values, requires_grad=param_config.requires_grad\n    #     )\n\n    def __init__(self, value, requires_grad, clamp=False, **kwargs) -&gt; None:\n        _values = torch.tensor(value).float()\n        _values = self.clamp(_values, clamp)\n        self.raw_values = nn.Parameter(_values, requires_grad=requires_grad)\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.Normal","title":"<code>Normal</code>","text":"<p>               Bases: <code>InitialDistribution</code></p> <p>Initializes parameters independently from normal distributions.</p> Example param_config <p>param_config = Namespace(     requires_grad=True,     initial_dist=\u201dNormal\u201d,     mean=0,     std=1,     mode=\u201dsample\u201d, )</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>class Normal(InitialDistribution):\n    \"\"\"Initializes parameters independently from normal distributions.\n\n    Example param_config:\n        param_config = Namespace(\n            requires_grad=True,\n            initial_dist=\"Normal\",\n            mean=0,\n            std=1,\n            mode=\"sample\",\n        )\n    \"\"\"\n\n    def __init__(\n        self, mean, std, requires_grad, mode=\"sample\", clamp=False, seed=None, **kwargs\n    ) -&gt; None:\n        if mode == \"mean\":\n            _values = torch.tensor(mean).float()\n        elif mode == \"sample\":\n            # set seed for reproducibility and avoid seeding the global RNG\n            generator = torch.Generator(device=device)\n            if seed is not None:\n                generator.manual_seed(seed)\n            else:\n                generator.seed()\n            try:\n                _values = torch.normal(\n                    torch.tensor(mean).float(),\n                    torch.tensor(std).float(),\n                    generator=generator,\n                )\n            except RuntimeError as e:\n                raise RuntimeError(\n                    f\"Failed to sample from normal with mean {mean} and std {std}\"\n                ) from e\n        else:\n            raise ValueError(\"Mode must be either mean or sample.\")\n        _values = self.clamp(_values, clamp)\n        self.raw_values = nn.Parameter(_values, requires_grad=requires_grad)\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.Lognormal","title":"<code>Lognormal</code>","text":"<p>               Bases: <code>Normal</code></p> <p>Initializes parameters independently from lognormal distributions.</p> Example param_config <p>param_config = Namespace(     requires_grad=True,     initial_dist=\u201dLognormal\u201d,     mean=0,     std=1,     mode=\u201dsample\u201d, )</p> <p>Note, the lognormal distribution reparametrizes a normal through semantic values.</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>class Lognormal(Normal):\n    \"\"\"Initializes parameters independently from lognormal distributions.\n\n    Example param_config:\n        param_config = Namespace(\n            requires_grad=True,\n            initial_dist=\"Lognormal\",\n            mean=0,\n            std=1,\n            mode=\"sample\",\n        )\n\n    Note, the lognormal distribution reparametrizes a normal through semantic\n    values.\n    \"\"\"\n\n    # __init__ = Normal.__init__\n\n    @property\n    def semantic_values(self):\n        \"\"\"n_syn ~ self._values.exp().\"\"\"\n        return self.raw_values.exp()\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.Lognormal.semantic_values","title":"<code>semantic_values</code>  <code>property</code>","text":"<p>n_syn ~ self._values.exp().</p>"},{"location":"reference/network/#flyvision.network.initialization.Parameter","title":"<code>Parameter</code>","text":"<p>Base class for all parameters to share across nodes or edges.</p> <p>Parameters:</p> Name Type Description Default <code>param_config</code> <code>Namespace</code> <p>Namespace containing parameter configuration.</p> required <code>connectome</code> <code>ConnectomeDir</code> <p>Connectome object.</p> required <p>Attributes:</p> Name Type Description <code>parameter</code> <code>InitialDistribution</code> <p>InitialDistribution object.</p> <code>indices</code> <code>Tensor</code> <p>Indices for parameter sharing.</p> <code>keys</code> <code>List[Any]</code> <p>Keys to access individual parameter values associated with certain identifiers.</p> <code>symmetry_masks</code> <code>List[Tensor]</code> <p>Symmetry masks that can be configured optionally to apply further symmetry constraints to the parameter values.</p> Extension point <p>subclasses must implement init(self, param_config, connectome_dir). init must configure the above attributes. init should be decorated with @deepcopy_config when init updates param_config to ensure param_config is not mutated in the outer scope, . init udpates param_config to contain key value pairs informed by connectome and matching the desired InitialDistribution. init stores <code>parameter</code> from InitialDistribution(param_config), which constructs and holds the nn.Parameter. init stores <code>indices</code> for parameter sharing through <code>get_scatter_indices(dataframe, grouped_dataframe, groupby)</code>. init stores <code>keys</code> to access individual parameter values associated with certain identifiers. init stores <code>symmetry_masks</code> that can be configured optionally to apply further symmetry constraints to the parameter values.</p> <p>Example:     class MyParameter(Parameter):         def init(self, param_config, connectome_dir):             nodes_dir = connectome.nodes</p> <pre><code>        nodes = pd.DataFrame(\n            {k: byte_to_str(nodes_dir[k][:]) for k in param_config.groupby}\n        )\n        grouped_nodes = nodes.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).first()\n\n        param_config[\"type\"] = grouped_nodes[\"type\"].values\n        param_config[\"mean\"] = np.repeat(param_config[\"mean\"],\n                                         len(grouped_nodes))\n        param_config[\"std\"] = np.repeat(param_config[\"std\"],\n                                        len(grouped_nodes))\n\n        self.parameter = InitialDistribution(param_config)\n        self.indices = get_scatter_indices(nodes,\n                                           grouped_nodes,\n                                           param_config.groupby)\n        self.keys = param_config[\"type\"].tolist()\n        self.symmetry_masks = symmetry_masks(\n            param_config.get(\"symmetric\", []), self.keys\n        )\nparam_config = Namespace(\n        type=\"MyParameter\",\n        mean=0,\n        std=1,\n        groupby=[\"type\"],\n        requires_grad=True\n    )\nparam = Parameter(param_config, connectome)\ntype(param) == MyParameter\n</code></pre> Source code in <code>flyvision/network/initialization.py</code> <pre><code>class Parameter:\n    \"\"\"Base class for all parameters to share across nodes or edges.\n\n    Args:\n        param_config: Namespace containing parameter configuration.\n        connectome: Connectome object.\n\n    Attributes:\n        parameter: InitialDistribution object.\n        indices: Indices for parameter sharing.\n        keys: Keys to access individual parameter values associated with\n            certain identifiers.\n        symmetry_masks: Symmetry masks that can be configured optionally to\n            apply further symmetry constraints to the parameter values.\n\n    Extension point:\n        subclasses must implement __init__(self, param_config, connectome_dir).\n        __init__ must configure the above attributes.\n        __init__ should be decorated with @deepcopy_config when __init__ updates\n        param_config to ensure param_config is not mutated in the outer scope, .\n        __init__ udpates param_config to contain key value pairs informed by\n        connectome and matching the desired InitialDistribution.\n        __init__ stores `parameter` from InitialDistribution(param_config), which\n        constructs and holds the nn.Parameter.\n        __init__ stores `indices` for parameter sharing through\n        `get_scatter_indices(dataframe, grouped_dataframe, groupby)`.\n        __init__ stores `keys` to access individual\n        parameter values associated with certain identifiers.\n        __init__ stores `symmetry_masks` that can be configured optionally\n        to apply further symmetry constraints to the parameter values.\n\n        Example:\n            class MyParameter(Parameter):\n                def __init__(self, param_config, connectome_dir):\n                    nodes_dir = connectome.nodes\n\n                    nodes = pd.DataFrame(\n                        {k: byte_to_str(nodes_dir[k][:]) for k in param_config.groupby}\n                    )\n                    grouped_nodes = nodes.groupby(\n                        param_config.groupby, as_index=False, sort=False\n                    ).first()\n\n                    param_config[\"type\"] = grouped_nodes[\"type\"].values\n                    param_config[\"mean\"] = np.repeat(param_config[\"mean\"],\n                                                     len(grouped_nodes))\n                    param_config[\"std\"] = np.repeat(param_config[\"std\"],\n                                                    len(grouped_nodes))\n\n                    self.parameter = InitialDistribution(param_config)\n                    self.indices = get_scatter_indices(nodes,\n                                                       grouped_nodes,\n                                                       param_config.groupby)\n                    self.keys = param_config[\"type\"].tolist()\n                    self.symmetry_masks = symmetry_masks(\n                        param_config.get(\"symmetric\", []), self.keys\n                    )\n            param_config = Namespace(\n                    type=\"MyParameter\",\n                    mean=0,\n                    std=1,\n                    groupby=[\"type\"],\n                    requires_grad=True\n                )\n            param = Parameter(param_config, connectome)\n            type(param) == MyParameter\n    \"\"\"\n\n    parameter: InitialDistribution\n    indices: torch.Tensor\n    symmetry_masks: List[torch.Tensor]\n    keys: List[Any]\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeDir):\n        pass\n\n    def __repr__(self):\n        init_arg_names = list(self.__init__.__annotations__.keys())\n        dir_type = self.__init__.__annotations__[init_arg_names[1]].__name__\n        return f\"{self.__class__.__name__}({self.config}, {dir_type})\"\n\n    def __getitem__(self, key):\n        if key in self.keys:\n            if self.parameter.raw_values.dim() == 0:\n                return self.parameter.raw_values\n            return self.parameter.raw_values[self.keys.index(key)]\n        else:\n            raise ValueError(key)\n\n    def __len__(self):\n        return len(self.raw_values)\n\n    # -- InitialDistribution API\n\n    @property\n    def raw_values(self) -&gt; torch.Tensor:\n        return self.parameter.raw_values\n\n    @property\n    def semantic_values(self) -&gt; torch.Tensor:\n        return self.parameter.semantic_values\n\n    @property\n    def readers(self) -&gt; Dict[str, torch.Tensor]:\n        return self.parameter.readers\n\n    @readers.setter\n    def readers(self, value) -&gt; None:\n        self.parameter.readers = value\n\n    def _symmetry(self):\n        \"\"\"Return symmetry constraints from symmetry masks for debugging.\"\"\"\n        keys = np.array(self.keys)\n        return [keys[mask.cpu()] for mask in self.symmetry_masks]\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.RestingPotential","title":"<code>RestingPotential</code>","text":"<p>               Bases: <code>Parameter</code></p> <p>Initialize resting potentials a.k.a. biases for cell types.</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>class RestingPotential(Parameter):\n    \"\"\"Initialize resting potentials a.k.a. biases for cell types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeDir):\n        nodes_dir = connectome.nodes\n\n        nodes = pd.DataFrame({\n            k: byte_to_str(nodes_dir[k][:]) for k in param_config.groupby\n        })\n        grouped_nodes = nodes.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).first()\n\n        param_config[\"type\"] = grouped_nodes[\"type\"].values\n        param_config[\"mean\"] = np.repeat(param_config[\"mean\"], len(grouped_nodes))\n        param_config[\"std\"] = np.repeat(param_config[\"std\"], len(grouped_nodes))\n\n        self.parameter = forward_subclass(\n            InitialDistribution, param_config, subclass_key=\"initial_dist\"\n        )\n        self.indices = get_scatter_indices(nodes, grouped_nodes, param_config.groupby)\n        self.keys = param_config[\"type\"].tolist()\n        self.symmetry_masks = symmetry_masks(param_config.get(\"symmetric\", []), self.keys)\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.TimeConstant","title":"<code>TimeConstant</code>","text":"<p>               Bases: <code>Parameter</code></p> <p>Initialize time constants for cell types.</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>class TimeConstant(Parameter):\n    \"\"\"Initialize time constants for cell types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeDir):\n        nodes_dir = connectome.nodes\n\n        nodes = pd.DataFrame({\n            k: byte_to_str(nodes_dir[k][:]) for k in param_config.groupby\n        })\n        grouped_nodes = nodes.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).first()\n\n        param_config[\"type\"] = grouped_nodes[\"type\"].values\n        param_config[\"value\"] = np.repeat(param_config[\"value\"], len(grouped_nodes))\n\n        self.indices = get_scatter_indices(nodes, grouped_nodes, param_config.groupby)\n        self.parameter = forward_subclass(\n            InitialDistribution, param_config, subclass_key=\"initial_dist\"\n        )\n        self.keys = param_config[\"type\"].tolist()\n        self.symmetry_masks = symmetry_masks(param_config.get(\"symmetric\", []), self.keys)\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.SynapseSign","title":"<code>SynapseSign</code>","text":"<p>               Bases: <code>Parameter</code></p> <p>Initialize synapse signs for edge types.</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>class SynapseSign(Parameter):\n    \"\"\"Initialize synapse signs for edge types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeDir) -&gt; None:\n        edges_dir = connectome.edges\n\n        edges = pd.DataFrame({\n            k: byte_to_str(edges_dir[k][:]) for k in [*param_config.groupby, \"sign\"]\n        })\n        grouped_edges = edges.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).first()\n\n        param_config.source_type = grouped_edges.source_type.values\n        param_config.target_type = grouped_edges.target_type.values\n        param_config.value = grouped_edges.sign.values\n\n        self.indices = get_scatter_indices(edges, grouped_edges, param_config.groupby)\n        self.parameter = forward_subclass(\n            InitialDistribution, param_config, subclass_key=\"initial_dist\"\n        )\n        self.keys = list(\n            zip(\n                param_config.source_type.tolist(),\n                param_config.target_type.tolist(),\n            )\n        )\n        self.symmetry_masks = symmetry_masks(param_config.get(\"symmetric\", []), self.keys)\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.SynapseCount","title":"<code>SynapseCount</code>","text":"<p>               Bases: <code>Parameter</code></p> <p>Initialize synapse counts for edge types.</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>class SynapseCount(Parameter):\n    \"\"\"Initialize synapse counts for edge types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeDir) -&gt; None:\n        mode = param_config.get(\"mode\", \"\")\n        if mode != \"mean\":\n            raise NotImplementedError(\n                f\"SynapseCount does not implement {mode}. Implement \"\n                \"a custom Parameter subclass.\"\n            )\n\n        edges_dir = connectome.edges\n\n        edges = pd.DataFrame({\n            k: byte_to_str(edges_dir[k][:]) for k in [*param_config.groupby, \"n_syn\"]\n        })\n        grouped_edges = edges.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).mean()\n\n        param_config.source_type = grouped_edges.source_type.values\n        param_config.target_type = grouped_edges.target_type.values\n        param_config.du = grouped_edges.du.values\n        param_config.dv = grouped_edges.dv.values\n\n        param_config.mode = \"mean\"\n        param_config.mean = np.log(grouped_edges.n_syn.values)\n\n        self.indices = get_scatter_indices(edges, grouped_edges, param_config.groupby)\n        self.parameter = forward_subclass(\n            InitialDistribution, param_config, subclass_key=\"initial_dist\"\n        )\n        self.keys = list(\n            zip(\n                param_config.source_type.tolist(),\n                param_config.target_type.tolist(),\n                param_config.du.tolist(),\n                param_config.dv.tolist(),\n            )\n        )\n        self.symmetry_masks = symmetry_masks(param_config.get(\"symmetric\", []), self.keys)\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.SynapseCountScaling","title":"<code>SynapseCountScaling</code>","text":"<p>               Bases: <code>Parameter</code></p> <p>Initialize synapse count scaling for edge types.</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>class SynapseCountScaling(Parameter):\n    \"\"\"Initialize synapse count scaling for edge types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeDir) -&gt; None:\n        edges_dir = connectome.edges\n\n        edges = pd.DataFrame({\n            k: byte_to_str(edges_dir[k][:]) for k in [*param_config.groupby, \"n_syn\"]\n        })\n        grouped_edges = edges.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).mean()\n\n        # to initialize synapse strengths with 1/&lt;N&gt;_rf\n        syn_strength = 1 / grouped_edges.n_syn.values  # 1/&lt;N&gt;_rf\n\n        # scale synapse strengths of chemical and electrical synapses\n        # individually\n        syn_strength[grouped_edges[grouped_edges.edge_type == \"chem\"].index] *= getattr(\n            param_config, \"scale_chem\", 0.01\n        )\n        syn_strength[grouped_edges[grouped_edges.edge_type == \"elec\"].index] *= getattr(\n            param_config, \"scale_elec\", 0.01\n        )\n\n        param_config.target_type = grouped_edges.target_type.values\n        param_config.source_type = grouped_edges.source_type.values\n        param_config.value = syn_strength\n\n        self.indices = get_scatter_indices(edges, grouped_edges, param_config.groupby)\n        self.parameter = forward_subclass(\n            InitialDistribution, param_config, subclass_key=\"initial_dist\"\n        )\n        self.keys = list(\n            zip(\n                param_config.source_type.tolist(),\n                param_config.target_type.tolist(),\n            )\n        )\n        self.symmetry_masks = symmetry_masks(param_config.get(\"symmetric\", []), self.keys)\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.deepcopy_config","title":"<code>deepcopy_config(f)</code>","text":"<p>Decorator to deepcopy the parameter configuration.</p> <p>Note, this is necessary because the parameter configuration is updated in the init method of the parameter classes and prevents mutation of the param_config in the outer scope.</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>def deepcopy_config(f):\n    \"\"\"Decorator to deepcopy the parameter configuration.\n\n    Note, this is necessary because the parameter configuration is updated\n    in the __init__ method of the parameter classes and prevents mutation of the\n    param_config in the outer scope.\n    \"\"\"\n\n    @functools.wraps(f)\n    def wrapper(cls, param_config, connectome):\n        cls.config = deepcopy(param_config)\n        return f(cls, deepcopy(param_config), connectome)\n\n    return wrapper\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.get_scatter_indices","title":"<code>get_scatter_indices(dataframe, grouped_dataframe, groupby)</code>","text":"<p>Indices for scattering operations to share parameters.</p> <p>Maps each node/edge from the complete computational graph to a parameter index.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>dataframe of nodes or edges of the graph.</p> required <code>grouped_dataframe</code> <code>list</code> <p>aggregated version of the same dataframe.</p> required <code>groupby</code> <code>list</code> <p>the same columns from which the grouped_dataframe was constructed.</p> required <p>For N elements that are grouped into M groups, this function returns N indices from 0 to M-1 that can be used to scatter the parameters of the M groups to the N elements.</p> <p>To illustrate, consider the following simplified example:     elements = [\u201cA\u201d, \u201cA\u201d, \u201cA\u201d, \u201cB\u201d, \u201cB\u201d, \u201cC\u201d, \u201cD\u201d, \u201cD\u201d, \u201cE\u201d]     groups = [\u201cA\u201d, \u201cB\u201d, \u201cC\u201d, \u201cD\u201d, \u201cE\u201d]     parameter = [1, 2, 3, 4, 5]     # get_scatter_indices would return     scatter_indices = [0, 0, 0, 1, 1, 2, 3, 3, 4]     scattered_parameters = [parameter[idx] for idx in scatter_indices]     scattered_parameters == [1, 1, 1, 2, 2, 3, 4, 4, 5]</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>def get_scatter_indices(\n    dataframe: pd.DataFrame, grouped_dataframe: pd.DataFrame, groupby: List[str]\n) -&gt; Tensor:\n    \"\"\"Indices for scattering operations to share parameters.\n\n    Maps each node/edge from the complete computational graph to a parameter\n    index.\n\n    Args:\n        dataframe (pd.DataFrame): dataframe of nodes or edges of the graph.\n        grouped_dataframe (list): aggregated version of the same dataframe.\n        groupby (list): the same columns from which the grouped_dataframe was\n            constructed.\n\n    For N elements that are grouped into M groups, this function\n    returns N indices from 0 to M-1 that can be used to scatter the\n    parameters of the M groups to the N elements.\n\n    To illustrate, consider the following simplified example:\n        elements = [\"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"D\", \"E\"]\n        groups = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n        parameter = [1, 2, 3, 4, 5]\n        # get_scatter_indices would return\n        scatter_indices = [0, 0, 0, 1, 1, 2, 3, 3, 4]\n        scattered_parameters = [parameter[idx] for idx in scatter_indices]\n        scattered_parameters == [1, 1, 1, 2, 2, 3, 4, 4, 5]\n    \"\"\"\n    ungrouped_elements = zip(*[dataframe[k][:] for k in groupby])\n    grouped_elements = zip(*[grouped_dataframe[k][:] for k in groupby])\n    to_index = {k: i for i, k in enumerate(grouped_elements)}\n    return torch.tensor([to_index[k] for k in ungrouped_elements])\n</code></pre>"},{"location":"reference/network/#flyvision.network.initialization.symmetry_masks","title":"<code>symmetry_masks(symmetric, keys, as_mask=False)</code>","text":"<p>Masks subsets of parameters for joint constraints e.g. to their mean.</p> <p>Parameters:</p> Name Type Description Default <code>symmetric</code> <code>List[Any]</code> <p>contains subsets of keys that point to the subsets of parameters to be indexed.</p> required <code>keys</code> <code>List[Any]</code> <p>list of keys that point to individual parameter values.</p> required <code>as_mask</code> <code>bool</code> <p>if True, returns a boolean mask, otherwise integer indices.</p> <code>False</code> <p>Returns:</p> Type Description <code>List[Tensor]</code> <p>list of masks List[torch.BoolTensor]</p> <p>Note: this is experimental for configuration-based fine-grained shared parameter optimization, e.g. for models includig multi-compartment cells or gap junctions. Example 1: for node type parameters with individual node types as keys     symmetric = [[\u201cT4a\u201d, \u201cT4b\u201d, \u201cT4c\u201d, \u201cT4d\u201d],                  [\u201cT5a\u201d, \u201cT5b\u201d, \u201cT5c\u201d, \u201cT5d\u201d]] would be used to constrain the parameter values of all T4 subtypes to their joint mean and the parameter values of all T5 subtypes to their joint mean. Exaple 2: for edge type parameters with individual edge types as keys     symmetric = [[(\u201cCT1(M10)\u201d, \u201cCT1(Lo1)\u201d), (\u201cCT1(Lo1)\u201d, \u201cCT1(M10)\u201d)]] would be used to constrain the edge parameter of the directed edge from CT1(M10) to CT1(Lo1) and the directed edge from CT1(Lo1) to CT1(M10) to their joint mean.</p> Source code in <code>flyvision/network/initialization.py</code> <pre><code>def symmetry_masks(\n    symmetric: List[Any], keys: List[Any], as_mask: bool = False\n) -&gt; List[torch.Tensor]:\n    \"\"\"Masks subsets of parameters for joint constraints e.g. to their mean.\n\n    Args:\n        symmetric: contains subsets of keys that point to the subsets\n            of parameters to be indexed.\n        keys: list of keys that point to individual parameter values.\n        as_mask: if True, returns a boolean mask, otherwise integer indices.\n\n    Returns:\n        list of masks List[torch.BoolTensor]\n\n    Note: this is experimental for configuration-based fine-grained shared\n    parameter optimization, e.g. for models includig multi-compartment cells\n    or gap junctions.\n    Example 1:\n    for node type parameters with individual node types as keys\n        symmetric = [[\"T4a\", \"T4b\", \"T4c\", \"T4d\"],\n                     [\"T5a\", \"T5b\", \"T5c\", \"T5d\"]]\n    would be used to constrain the parameter values of all T4 subtypes to\n    their joint mean and the parameter values of all T5 subtypes to their\n    joint mean.\n    Exaple 2:\n    for edge type parameters with individual edge types as keys\n        symmetric = [[(\"CT1(M10)\", \"CT1(Lo1)\"), (\"CT1(Lo1)\", \"CT1(M10)\")]]\n    would be used to constrain the edge parameter of the directed edge from\n    CT1(M10) to CT1(Lo1) and the directed edge from CT1(Lo1) to CT1(M10) to\n    their joint mean.\n    \"\"\"\n    if not symmetric:\n        return []\n    symmetry_masks = []  # type: List[torch.Tensor]\n    keys = atleast_column_vector(keys)\n    for identifiers in symmetric:\n        identifiers = atleast_column_vector(identifiers)\n        # to allow identifiers like [None, \"A\", None, 0]\n        # for parameters that have tuples as keys\n        columns = np.arange(identifiers.shape[1] + 1)[\n            np.where((identifiers is not None).all(axis=0))\n        ]\n        try:\n            symmetry_masks.append(\n                torch.tensor(\n                    where_equal_rows(\n                        identifiers[:, columns], keys[:, columns], as_mask=as_mask\n                    )\n                )\n            )\n        except Exception as e:\n            raise ValueError(\n                f\"{identifiers} cannot be a symmetry constraint\"\n                f\" for parameter with keys {keys}: {e}\"\n            ) from e\n    return symmetry_masks\n</code></pre>"},{"location":"reference/network/#analysis","title":"Analysis","text":""},{"location":"reference/network/#flyvision.network.NetworkView","title":"<code>NetworkView</code>","text":"<p>IO interface for network.</p> <p>Parameters:</p> Name Type Description Default <code>network_dir</code> <code>Union[str, PathLike, NetworkDir]</code> <p>directory of the network.</p> required <code>network_class</code> <code>Module</code> <p>network class.</p> <code>Network</code> <code>root_dir</code> <code>PathLike</code> <p>root directory.</p> <code>results_dir</code> <code>connectome_getter</code> <code>Callable</code> <p>connectome getter.</p> <code>flyvision_connectome</code> <code>checkpoint_mapper</code> <code>Callable</code> <p>checkpoint mapper.</p> <code>resolve_checkpoints</code> <code>best_checkpoint_fn</code> <code>Callable</code> <p>best checkpoint function.</p> <code>best_checkpoint_default_fn</code> <code>best_checkpoint_fn_kwargs</code> <code>dict</code> <p>best checkpoint function kwargs.</p> <code>{'validation_subdir': 'validation', 'loss_file_name': 'loss'}</code> <code>recover_fn</code> <code>Callable</code> <p>recover function</p> <code>recover_network</code> Source code in <code>flyvision/network/network.py</code> <pre><code>class NetworkView:\n    \"\"\"IO interface for network.\n\n    Args:\n        network_dir: directory of the network.\n        network_class: network class.\n        root_dir: root directory.\n        connectome_getter: connectome getter.\n        checkpoint_mapper: checkpoint mapper.\n        best_checkpoint_fn: best checkpoint function.\n        best_checkpoint_fn_kwargs: best checkpoint function kwargs.\n        recover_fn: recover function\n    \"\"\"\n\n    def __init__(\n        self,\n        network_dir: Union[str, PathLike, NetworkDir],\n        network_class: nn.Module = Network,\n        root_dir: PathLike = flyvision.results_dir,\n        connectome_getter: Callable = flyvision_connectome,\n        checkpoint_mapper: Callable = resolve_checkpoints,\n        best_checkpoint_fn: Callable = best_checkpoint_default_fn,\n        best_checkpoint_fn_kwargs: dict = {\n            \"validation_subdir\": \"validation\",\n            \"loss_file_name\": \"loss\",\n        },\n        recover_fn: Callable = recover_network,\n    ):\n        self.network_class = network_class\n        self.dir, self.name = self._resolve_dir(network_dir, root_dir)\n        self.root_dir = root_dir\n        self.connectome_getter = connectome_getter\n        self.checkpoint_mapper = checkpoint_mapper\n        self.connectome_view = connectome_getter(self.dir)\n        self.connectome = self.connectome_view.dir\n        self.checkpoints = checkpoint_mapper(self.dir)\n        self.memory = Memory(\n            location=self.dir.path / \"__cache__\", verbose=0, backend=\"xarray_dataset_h5\"\n        )\n        self.best_checkpoint_fn = best_checkpoint_fn\n        self.best_checkpoint_fn_kwargs = best_checkpoint_fn_kwargs\n        self.recover_fn = recover_fn\n        self._network = CheckpointedNetwork(\n            self.network_class,\n            self.dir.config.network.to_dict(),\n            self.name,\n            self.get_checkpoint(\"best\"),\n            self.recover_fn,\n            network=None,\n        )\n        self._decoder = None\n        self._initialized = {\"network\": None, \"decoder\": None}\n        self.cache = FIFOCache(maxsize=3)\n        logging.info(f\"Initialized network view at {str(self.dir.path)}.\")\n\n    def __getattribute__(self, attr):\n        try:\n            return object.__getattribute__(self, attr)\n        except AttributeError:\n            connectome_view = object.__getattribute__(self, \"connectome_view\")\n            try:\n                return getattr(connectome_view, attr)\n            except AttributeError:\n                raise AttributeError(  # noqa: B904\n                    f\"'{self.__class__.__name__}' object has no attribute '{attr}'\"\n                )\n\n    def _clear_cache(self):\n        self.cache = self.cache.__class__(maxsize=self.cache.maxsize)\n\n    def _clear_memory(self):\n        self.memory.clear()\n\n    def get_checkpoint(self, checkpoint=\"best\"):\n        \"\"\"Return the best checkpoint index.\"\"\"\n        if checkpoint == \"best\":\n            return self.best_checkpoint_fn(\n                self.dir.path,\n                **self.best_checkpoint_fn_kwargs,\n            )\n        return self.checkpoints.paths[checkpoint]\n\n    def network(\n        self, checkpoint=\"best\", network: Optional[Any] = None, lazy=False\n    ) -&gt; CheckpointedNetwork:\n        \"\"\"Lazy loading of network instance.\"\"\"\n        self._network = CheckpointedNetwork(\n            self.network_class,\n            self.dir.config.network.to_dict(),\n            self.name,\n            self.get_checkpoint(checkpoint),\n            self.recover_fn,\n            # to avoid reinitialization, allow passing the network instance\n            network=network or self._network.network,\n        )\n        if self._network.network is not None and not lazy:\n            # then the correct checkpoint needs to be set\n            self._network.recover()\n        return self._network\n\n    def init_network(self, checkpoint=\"best\", network: Optional[Any] = None) -&gt; Network:\n        \"\"\"Initialize the network.\n\n        Args:\n            network: network instance to initialize to avoid reinitialization.\n\n        Returns:\n            network instance.\n        \"\"\"\n        checkpointed_network = self.network(checkpoint=checkpoint, network=network)\n\n        if checkpointed_network.network is not None:\n            return checkpointed_network.network\n        checkpointed_network.init()\n        return checkpointed_network.recover()\n\n    def init_decoder(self, checkpoint=\"best\", decoder=None):\n        \"\"\"Initialize the decoder.\n\n        Args:\n            decoder: decoder instance to initialize.\n\n        Returns:\n            decoder instance.\n        \"\"\"\n        checkpointed_network = self.network(checkpoint=checkpoint)\n        if (\n            self._initialized[\"decoder\"] == checkpointed_network.checkpoint\n            and decoder is None\n        ):\n            return self.decoder\n        self.decoder = decoder or init_decoder(\n            self.dir.config.task.decoder, self.connectome\n        )\n        recover_decoder(self.decoder, checkpointed_network.checkpoint)\n        self._initialized[\"decoder\"] = checkpointed_network.checkpoint\n        return self.decoder\n\n    def _resolve_dir(self, network_dir, root_dir):\n        if isinstance(network_dir, (PathLike, str)):\n            with set_root_context(flyvision.results_dir):\n                network_dir = Directory(network_dir)\n        if not network_dir.config.type == \"NetworkDir\":\n            raise ValueError(\n                f\"Expected NetworkDir, found {network_dir.config.type} \"\n                f\"at {network_dir.path}.\"\n            )\n        name = str(network_dir.path).replace(str(root_dir) + \"/\", \"\")\n        return network_dir, name\n\n    @wraps(stimulus_responses.flash_responses)\n    @context_aware_cache\n    def flash_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate flash responses.\"\"\"\n        return stimulus_responses.flash_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.moving_edge_responses)\n    @context_aware_cache\n    def movingedge_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate moving edge responses.\"\"\"\n        return stimulus_responses.moving_edge_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.moving_bar_responses)\n    @context_aware_cache\n    def movingbar_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate moving bar responses.\"\"\"\n        return stimulus_responses.moving_bar_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.naturalistic_stimuli_responses)\n    @context_aware_cache\n    def naturalistic_stimuli_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate naturalistic stimuli responses.\"\"\"\n        return stimulus_responses.naturalistic_stimuli_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.central_impulses_responses)\n    @context_aware_cache\n    def central_impulses_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate central ommatidium impulses responses.\"\"\"\n        return stimulus_responses.central_impulses_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.spatial_impulses_responses)\n    @context_aware_cache\n    def spatial_impulses_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate spatial ommatidium impulses responses.\"\"\"\n        return stimulus_responses.spatial_impulses_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.optimal_stimulus_responses)\n    @context_aware_cache\n    def optimal_stimulus_responses(self, cell_type, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate optimal stimuli responses.\"\"\"\n        return stimulus_responses.optimal_stimulus_responses(\n            self, cell_type, *args, **kwargs\n        )\n</code></pre>"},{"location":"reference/network/#flyvision.network.NetworkView.get_checkpoint","title":"<code>get_checkpoint(checkpoint='best')</code>","text":"<p>Return the best checkpoint index.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def get_checkpoint(self, checkpoint=\"best\"):\n    \"\"\"Return the best checkpoint index.\"\"\"\n    if checkpoint == \"best\":\n        return self.best_checkpoint_fn(\n            self.dir.path,\n            **self.best_checkpoint_fn_kwargs,\n        )\n    return self.checkpoints.paths[checkpoint]\n</code></pre>"},{"location":"reference/network/#flyvision.network.NetworkView.network","title":"<code>network(checkpoint='best', network=None, lazy=False)</code>","text":"<p>Lazy loading of network instance.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def network(\n    self, checkpoint=\"best\", network: Optional[Any] = None, lazy=False\n) -&gt; CheckpointedNetwork:\n    \"\"\"Lazy loading of network instance.\"\"\"\n    self._network = CheckpointedNetwork(\n        self.network_class,\n        self.dir.config.network.to_dict(),\n        self.name,\n        self.get_checkpoint(checkpoint),\n        self.recover_fn,\n        # to avoid reinitialization, allow passing the network instance\n        network=network or self._network.network,\n    )\n    if self._network.network is not None and not lazy:\n        # then the correct checkpoint needs to be set\n        self._network.recover()\n    return self._network\n</code></pre>"},{"location":"reference/network/#flyvision.network.NetworkView.init_network","title":"<code>init_network(checkpoint='best', network=None)</code>","text":"<p>Initialize the network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Optional[Any]</code> <p>network instance to initialize to avoid reinitialization.</p> <code>None</code> <p>Returns:</p> Type Description <code>Network</code> <p>network instance.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def init_network(self, checkpoint=\"best\", network: Optional[Any] = None) -&gt; Network:\n    \"\"\"Initialize the network.\n\n    Args:\n        network: network instance to initialize to avoid reinitialization.\n\n    Returns:\n        network instance.\n    \"\"\"\n    checkpointed_network = self.network(checkpoint=checkpoint, network=network)\n\n    if checkpointed_network.network is not None:\n        return checkpointed_network.network\n    checkpointed_network.init()\n    return checkpointed_network.recover()\n</code></pre>"},{"location":"reference/network/#flyvision.network.NetworkView.init_decoder","title":"<code>init_decoder(checkpoint='best', decoder=None)</code>","text":"<p>Initialize the decoder.</p> <p>Parameters:</p> Name Type Description Default <code>decoder</code> <p>decoder instance to initialize.</p> <code>None</code> <p>Returns:</p> Type Description <p>decoder instance.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>def init_decoder(self, checkpoint=\"best\", decoder=None):\n    \"\"\"Initialize the decoder.\n\n    Args:\n        decoder: decoder instance to initialize.\n\n    Returns:\n        decoder instance.\n    \"\"\"\n    checkpointed_network = self.network(checkpoint=checkpoint)\n    if (\n        self._initialized[\"decoder\"] == checkpointed_network.checkpoint\n        and decoder is None\n    ):\n        return self.decoder\n    self.decoder = decoder or init_decoder(\n        self.dir.config.task.decoder, self.connectome\n    )\n    recover_decoder(self.decoder, checkpointed_network.checkpoint)\n    self._initialized[\"decoder\"] = checkpointed_network.checkpoint\n    return self.decoder\n</code></pre>"},{"location":"reference/network/#flyvision.network.NetworkView.flash_responses","title":"<code>flash_responses(*args, **kwargs)</code>","text":"<p>Generate flash responses.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>@wraps(stimulus_responses.flash_responses)\n@context_aware_cache\ndef flash_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate flash responses.\"\"\"\n    return stimulus_responses.flash_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network/#flyvision.network.NetworkView.movingedge_responses","title":"<code>movingedge_responses(*args, **kwargs)</code>","text":"<p>Generate moving edge responses.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>@wraps(stimulus_responses.moving_edge_responses)\n@context_aware_cache\ndef movingedge_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate moving edge responses.\"\"\"\n    return stimulus_responses.moving_edge_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network/#flyvision.network.NetworkView.movingbar_responses","title":"<code>movingbar_responses(*args, **kwargs)</code>","text":"<p>Generate moving bar responses.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>@wraps(stimulus_responses.moving_bar_responses)\n@context_aware_cache\ndef movingbar_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate moving bar responses.\"\"\"\n    return stimulus_responses.moving_bar_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network/#flyvision.network.NetworkView.naturalistic_stimuli_responses","title":"<code>naturalistic_stimuli_responses(*args, **kwargs)</code>","text":"<p>Generate naturalistic stimuli responses.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>@wraps(stimulus_responses.naturalistic_stimuli_responses)\n@context_aware_cache\ndef naturalistic_stimuli_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate naturalistic stimuli responses.\"\"\"\n    return stimulus_responses.naturalistic_stimuli_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network/#flyvision.network.NetworkView.central_impulses_responses","title":"<code>central_impulses_responses(*args, **kwargs)</code>","text":"<p>Generate central ommatidium impulses responses.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>@wraps(stimulus_responses.central_impulses_responses)\n@context_aware_cache\ndef central_impulses_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate central ommatidium impulses responses.\"\"\"\n    return stimulus_responses.central_impulses_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network/#flyvision.network.NetworkView.spatial_impulses_responses","title":"<code>spatial_impulses_responses(*args, **kwargs)</code>","text":"<p>Generate spatial ommatidium impulses responses.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>@wraps(stimulus_responses.spatial_impulses_responses)\n@context_aware_cache\ndef spatial_impulses_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate spatial ommatidium impulses responses.\"\"\"\n    return stimulus_responses.spatial_impulses_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network/#flyvision.network.NetworkView.optimal_stimulus_responses","title":"<code>optimal_stimulus_responses(cell_type, *args, **kwargs)</code>","text":"<p>Generate optimal stimuli responses.</p> Source code in <code>flyvision/network/network.py</code> <pre><code>@wraps(stimulus_responses.optimal_stimulus_responses)\n@context_aware_cache\ndef optimal_stimulus_responses(self, cell_type, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate optimal stimuli responses.\"\"\"\n    return stimulus_responses.optimal_stimulus_responses(\n        self, cell_type, *args, **kwargs\n    )\n</code></pre>"},{"location":"reference/network/#flyvision.network.EnsembleView","title":"<code>EnsembleView</code>","text":"<p>               Bases: <code>Ensemble</code></p> <p>A view of an ensemble of trained networks.</p> Source code in <code>flyvision/network/ensemble_view.py</code> <pre><code>class EnsembleView(Ensemble):\n    \"\"\"A view of an ensemble of trained networks.\"\"\"\n\n    def __init__(\n        self,\n        path: Union[str, PathLike, Iterable, EnsembleDir, Ensemble],\n        network_class: nn.Module = Network,\n        root_dir: PathLike = flyvision.results_dir,\n        connectome_getter: Callable = flyvision_connectome,\n        checkpoint_mapper: Callable = resolve_checkpoints,\n        best_checkpoint_fn: Callable = best_checkpoint_default_fn,\n        best_checkpoint_fn_kwargs: dict = {\n            \"validation_subdir\": \"validation\",\n            \"loss_file_name\": \"loss\",\n        },\n        recover_fn: Callable = recover_network,\n        try_sort=False,\n    ):\n        init_args = {\n            \"path\": path,\n            \"network_class\": network_class,\n            \"root_dir\": root_dir,\n            \"connectome_getter\": connectome_getter,\n            \"checkpoint_mapper\": checkpoint_mapper,\n            \"best_checkpoint_fn\": best_checkpoint_fn,\n            \"best_checkpoint_fn_kwargs\": best_checkpoint_fn_kwargs,\n            \"recover_fn\": recover_fn,\n            \"try_sort\": try_sort,\n        }\n        if isinstance(path, Ensemble):\n            init_args = path._init_args\n        super().__init__(**init_args)\n\n    @wraps(plots.loss_curves)\n    def training_loss(self, **kwargs):\n        task_error = self.task_error()\n        losses = np.array([nv.dir.loss[:] for nv in self.values()])\n        return plots.loss_curves(\n            losses,\n            cbar=True,\n            colors=task_error.colors,\n            cmap=task_error.cmap,\n            norm=task_error.norm,\n            xlabel=\"iterations\",\n            ylabel=\"training loss\",\n            **kwargs,\n        )\n\n    @wraps(plots.loss_curves)\n    def validation_loss(self, validation_subdir=None, loss_file_name=None, **kwargs):\n        task_error = self.task_error()\n        losses = self.validation_losses(validation_subdir, loss_file_name)\n        return plots.loss_curves(\n            losses,\n            cbar=True,\n            colors=task_error.colors,\n            cmap=task_error.cmap,\n            norm=task_error.norm,\n            xlabel=\"checkpoints\",\n            ylabel=\"validation loss\",\n            **kwargs,\n        )\n\n    @wraps(plots.histogram)\n    def task_error_histogram(self, **kwargs):\n        \"\"\"Plot a histogram of the validation losses of the ensemble.\"\"\"\n        losses = self.min_validation_losses()\n        return plots.histogram(\n            losses, xlabel=\"task error\", ylabel=\"number models\", **kwargs\n        )\n\n    @wraps(plots.violins)\n    def node_parameters(self, key, max_per_ax=34, **kwargs):\n        \"\"\"Return the node parameters of the ensemble.\"\"\"\n        parameters = self.parameters()[f\"nodes_{key}\"]\n        parameter_keys = self.parameter_keys()[f\"nodes_{key}\"]\n        return plots.violins(\n            parameter_keys, parameters, ylabel=key, max_per_ax=max_per_ax, **kwargs\n        )\n\n    @wraps(plots.violins)\n    def edge_parameters(self, key, max_per_ax=120, **kwargs):\n        \"\"\"Return the edge parameters of the ensemble.\"\"\"\n        parameters = self.parameters()[f\"edges_{key}\"]\n        parameter_keys = self.parameter_keys()[f\"edges_{key}\"]\n        variable_names = np.array([\n            f\"{source}-&gt;{target}\" for source, target in parameter_keys\n        ])\n        return plots.violins(\n            variable_names,\n            variable_values=parameters,\n            ylabel=key,\n            max_per_ax=max_per_ax,\n            **kwargs,\n        )\n\n    @wraps(plots.heatmap)\n    def dead_or_alive(self, **kwargs):\n        \"\"\"Return the number of dead cells in the ensemble.\"\"\"\n        responses = self.naturalistic_stimuli_responses()\n        dead_count = (responses['responses'].values &lt; 0).all(axis=(1, 2))\n        return plots.heatmap(\n            dead_count,\n            ylabels=np.arange(len(self)),\n            xlabels=responses.cell_type.values,\n            size_scale=15,\n            cbar=False,\n            **kwargs,\n        )\n\n    @wraps(plot_fris)\n    def flash_response_index(self, cell_types: List[str] = None, **kwargs):\n        \"\"\"Plot the flash response indices of the ensemble.\"\"\"\n        responses = self.flash_responses()\n        fris = flash_response_index(responses, radius=6)\n        if cell_types is not None:\n            fris = fris.custom.where(cell_type=cell_types)\n        else:\n            cell_types = fris.cell_type.values\n        task_error = self.task_error()\n        best_index = np.argmin(task_error.values)\n        return plot_fris(\n            fris.values,\n            cell_types,\n            scatter_best=True,\n            scatter_best_index=best_index,\n            scatter_best_color=cm.get_cmap(\"Blues\")(1.0),\n            **kwargs,\n        )\n\n    @wraps(plot_dsis)\n    def direction_selectivity_index(self, **kwargs):\n        \"\"\"Plot the direction selectivity indices of the ensemble.\"\"\"\n        responses = self.movingedge_responses()\n        dsis = direction_selectivity_index(responses)\n        task_error = self.task_error()\n        best_index = np.argmin(task_error.values)\n        return plot_dsis(\n            dsis,\n            responses.cell_type,\n            bold_output_type_labels=False,\n            figsize=[10, 1.2],\n            color_known_types=True,\n            fontsize=6,\n            scatter_best_index=best_index,\n            scatter_best_color=cm.get_cmap(\"Blues\")(1.0),\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/network/#flyvision.network.EnsembleView.task_error_histogram","title":"<code>task_error_histogram(**kwargs)</code>","text":"<p>Plot a histogram of the validation losses of the ensemble.</p> Source code in <code>flyvision/network/ensemble_view.py</code> <pre><code>@wraps(plots.histogram)\ndef task_error_histogram(self, **kwargs):\n    \"\"\"Plot a histogram of the validation losses of the ensemble.\"\"\"\n    losses = self.min_validation_losses()\n    return plots.histogram(\n        losses, xlabel=\"task error\", ylabel=\"number models\", **kwargs\n    )\n</code></pre>"},{"location":"reference/network/#flyvision.network.EnsembleView.node_parameters","title":"<code>node_parameters(key, max_per_ax=34, **kwargs)</code>","text":"<p>Return the node parameters of the ensemble.</p> Source code in <code>flyvision/network/ensemble_view.py</code> <pre><code>@wraps(plots.violins)\ndef node_parameters(self, key, max_per_ax=34, **kwargs):\n    \"\"\"Return the node parameters of the ensemble.\"\"\"\n    parameters = self.parameters()[f\"nodes_{key}\"]\n    parameter_keys = self.parameter_keys()[f\"nodes_{key}\"]\n    return plots.violins(\n        parameter_keys, parameters, ylabel=key, max_per_ax=max_per_ax, **kwargs\n    )\n</code></pre>"},{"location":"reference/network/#flyvision.network.EnsembleView.edge_parameters","title":"<code>edge_parameters(key, max_per_ax=120, **kwargs)</code>","text":"<p>Return the edge parameters of the ensemble.</p> Source code in <code>flyvision/network/ensemble_view.py</code> <pre><code>@wraps(plots.violins)\ndef edge_parameters(self, key, max_per_ax=120, **kwargs):\n    \"\"\"Return the edge parameters of the ensemble.\"\"\"\n    parameters = self.parameters()[f\"edges_{key}\"]\n    parameter_keys = self.parameter_keys()[f\"edges_{key}\"]\n    variable_names = np.array([\n        f\"{source}-&gt;{target}\" for source, target in parameter_keys\n    ])\n    return plots.violins(\n        variable_names,\n        variable_values=parameters,\n        ylabel=key,\n        max_per_ax=max_per_ax,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/network/#flyvision.network.EnsembleView.dead_or_alive","title":"<code>dead_or_alive(**kwargs)</code>","text":"<p>Return the number of dead cells in the ensemble.</p> Source code in <code>flyvision/network/ensemble_view.py</code> <pre><code>@wraps(plots.heatmap)\ndef dead_or_alive(self, **kwargs):\n    \"\"\"Return the number of dead cells in the ensemble.\"\"\"\n    responses = self.naturalistic_stimuli_responses()\n    dead_count = (responses['responses'].values &lt; 0).all(axis=(1, 2))\n    return plots.heatmap(\n        dead_count,\n        ylabels=np.arange(len(self)),\n        xlabels=responses.cell_type.values,\n        size_scale=15,\n        cbar=False,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/network/#flyvision.network.EnsembleView.flash_response_index","title":"<code>flash_response_index(cell_types=None, **kwargs)</code>","text":"<p>Plot the flash response indices of the ensemble.</p> Source code in <code>flyvision/network/ensemble_view.py</code> <pre><code>@wraps(plot_fris)\ndef flash_response_index(self, cell_types: List[str] = None, **kwargs):\n    \"\"\"Plot the flash response indices of the ensemble.\"\"\"\n    responses = self.flash_responses()\n    fris = flash_response_index(responses, radius=6)\n    if cell_types is not None:\n        fris = fris.custom.where(cell_type=cell_types)\n    else:\n        cell_types = fris.cell_type.values\n    task_error = self.task_error()\n    best_index = np.argmin(task_error.values)\n    return plot_fris(\n        fris.values,\n        cell_types,\n        scatter_best=True,\n        scatter_best_index=best_index,\n        scatter_best_color=cm.get_cmap(\"Blues\")(1.0),\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/network/#flyvision.network.EnsembleView.direction_selectivity_index","title":"<code>direction_selectivity_index(**kwargs)</code>","text":"<p>Plot the direction selectivity indices of the ensemble.</p> Source code in <code>flyvision/network/ensemble_view.py</code> <pre><code>@wraps(plot_dsis)\ndef direction_selectivity_index(self, **kwargs):\n    \"\"\"Plot the direction selectivity indices of the ensemble.\"\"\"\n    responses = self.movingedge_responses()\n    dsis = direction_selectivity_index(responses)\n    task_error = self.task_error()\n    best_index = np.argmin(task_error.values)\n    return plot_dsis(\n        dsis,\n        responses.cell_type,\n        bold_output_type_labels=False,\n        figsize=[10, 1.2],\n        color_known_types=True,\n        fontsize=6,\n        scatter_best_index=best_index,\n        scatter_best_color=cm.get_cmap(\"Blues\")(1.0),\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/network_view/","title":"Network view","text":""},{"location":"reference/optimal_stimuli/","title":"Optimal Stimuli","text":""},{"location":"reference/optimal_stimuli/#flyvision.analysis.optimal_stimuli","title":"<code>optimal_stimuli</code>","text":""},{"location":"reference/optimal_stimuli/#flyvision.analysis.optimal_stimuli.FindOptimalStimuli","title":"<code>FindOptimalStimuli</code>","text":"<p>Methods to derive optimal stimuli for cells from stimuli dataset.</p> <p>Parameters:</p> Name Type Description Default <code>network_view</code> <code>NetworkView</code> <p>network view.</p> required <code>stimuli</code> <code>StimulusDataset | str</code> <p>stimuli dataset. Defaults to \u201cdefault\u201d (AugmentedSintelLum).</p> <code>'default'</code> Source code in <code>flyvision/analysis/optimal_stimuli.py</code> <pre><code>class FindOptimalStimuli:\n    \"\"\"Methods to derive optimal stimuli for cells from stimuli dataset.\n\n    Args:\n        network_view: network view.\n        stimuli: stimuli dataset.\n            Defaults to \"default\" (AugmentedSintelLum).\n    \"\"\"\n\n    def __init__(\n        self,\n        network_view: flyvision.NetworkView,\n        stimuli: StimulusDataset | str = \"default\",\n    ):\n        self.nv = network_view\n        self.network = network_view.init_network()  # type: flyvision.Network\n        for param in self.network.parameters():\n            param.requires_grad = False\n        self.central_cells_index = self.network.connectome.central_cells_index[:]\n        self.stimuli = (\n            AugmentedSintel(tasks=[\"lum\"], dt=1 / 100, temporal_split=True)\n            if stimuli == \"default\"\n            else stimuli\n        )\n\n    def optimal_stimuli(\n        self,\n        cell_type,\n        dt=1 / 100,\n        indices=None,\n    ):\n        \"\"\"Finds optimal stimuli for a given cell type in stimuli dataset.\n\n        Args:\n            cell_type (str): node type.\n            dt (float, optional): time step. Defaults to 1 / 100.\n            t_pre (float, optional): pre-stimulus time. Defaults to 0.\n            t_fade_in (float, optional): fade-in time. Defaults to 2.0.\n            batch_size (int, optional): batch size. Defaults to 4.\n            indices (list, optional): indices of stimuli. Defaults to None.\n        \"\"\"\n        responses = self.nv.naturalistic_stimuli_responses()\n        cell_responses = responses['responses'].custom.where(cell_type=cell_type)\n\n        argmax = cell_responses.argmax(dim=(\"sample\", \"frame\"))['sample'].item()\n        if indices is not None:\n            argmax = indices[argmax]\n        nat_opt_stim = self.stimuli[argmax][\"lum\"]\n\n        n_frames = nat_opt_stim.shape[0]\n        initial_state = self.network.steady_state(1.0, dt, 1)\n        stimulus = Stimulus(self.network.connectome, 1, n_frames)\n        stimulus.zero()\n        stimulus.add_input(nat_opt_stim[None])\n        response = self.network(stimulus(), dt, state=initial_state).detach().cpu()\n        response = LayerActivity(response, self.network.connectome, keepref=True)[\n            cell_type\n        ]\n\n        return OptimalStimulus(nat_opt_stim[None, :], response[:, :, None])\n\n    def regularized_optimal_stimuli(\n        self,\n        cell_type,\n        l2_act=1,\n        lr=1e-2,\n        l2_stim=1,\n        n_iters=100,\n        dt=1 / 100,\n        indices=None,\n    ):\n        \"\"\"Regularizes the optimal stimulus such that the central node activity of the\n        given type remains but the mean square of the input pixels is minimized.\n\n        Args:\n            cell_type (str): node type.\n            l2_act (float, optional): L2 regularization strength for the activity.\n            Defaults to 1.\n            lr (float, optional): learning rate. Defaults to 1e-2.\n            l2_stim (float, optional): L2 regularization strength for the stimulus.\n            Defaults to 1.\n            n_iters (int, optional): number of iterations. Defaults to 100.\n            dt (float, optional): time step. Defaults to 1 / 100.\n            t_pre (float, optional): pre-stimulus time. Defaults to 0.\n            t_fade_in (float, optional): fade-in time. Defaults to 2.0.\n            batch_size (int, optional): batch size. Defaults to 4.\n            indices (list, optional): indices of stimuli. Defaults to None.\n        \"\"\"\n\n        optim_stimuli = self.optimal_stimuli(\n            cell_type=cell_type,\n            dt=dt,\n            indices=indices,\n        )\n        non_nan = ~torch.isnan(\n            optim_stimuli.stimulus[0, :, 0, optim_stimuli.stimulus.shape[-1] // 2]\n        )\n        reg_opt_stim = optim_stimuli.stimulus.clone()\n        reg_opt_stim = reg_opt_stim[:, non_nan]\n        reg_opt_stim.requires_grad = True\n\n        central_target_response = (\n            optim_stimuli.response.to(non_nan.device)[\n                :, non_nan, :, optim_stimuli.response.shape[-1] // 2\n            ]\n            .clone()\n            .detach()\n            .squeeze()\n        )\n\n        optim = torch.optim.Adam([reg_opt_stim], lr=lr)\n\n        n_frames = reg_opt_stim.shape[1]\n\n        stim = Stimulus(self.network.connectome, 1, n_frames)\n\n        layer_activity = LayerActivity(None, self.network.connectome, keepref=True)\n\n        initial_state = self.network.steady_state(1.0, dt, 1)\n\n        losses = []\n        for _ in range(n_iters):\n            optim.zero_grad()\n            stim.zero()\n            stim.add_input(reg_opt_stim)\n            activities = self.network(stim(), dt, state=initial_state)\n            layer_activity.update(activities)\n            central_predicted_response = layer_activity.central[cell_type].squeeze()\n\n            act_loss = (\n                l2_act\n                * ((central_predicted_response - central_target_response) ** 2).sum()\n            )\n            stim_loss = l2_stim * ((reg_opt_stim - 0.5) ** 2).mean(dim=0).sum()\n            loss = act_loss + stim_loss\n            loss.backward(retain_graph=True)\n            optim.step()\n            losses.append(loss.detach().cpu().numpy().item())\n\n        stim.zero()\n        reg_opt_stim.requires_grad = False\n        stim.add_input(reg_opt_stim)\n        activities = self.network(stim(), dt, state=initial_state)\n        layer_activity.update(activities)\n\n        reg_opt_stim = reg_opt_stim.detach().cpu()\n        rnmei_response = layer_activity[cell_type].detach().cpu()\n        central_predicted_response = central_predicted_response.detach().cpu()\n        central_target_response = central_target_response.detach().cpu()\n        return RegularizedOptimalStimulus(\n            optim_stimuli,\n            reg_opt_stim,\n            rnmei_response,\n            central_predicted_response,\n            central_target_response,\n            losses,\n        )\n</code></pre>"},{"location":"reference/optimal_stimuli/#flyvision.analysis.optimal_stimuli.FindOptimalStimuli.optimal_stimuli","title":"<code>optimal_stimuli(cell_type, dt=1 / 100, indices=None)</code>","text":"<p>Finds optimal stimuli for a given cell type in stimuli dataset.</p> <p>Parameters:</p> Name Type Description Default <code>cell_type</code> <code>str</code> <p>node type.</p> required <code>dt</code> <code>float</code> <p>time step. Defaults to 1 / 100.</p> <code>1 / 100</code> <code>t_pre</code> <code>float</code> <p>pre-stimulus time. Defaults to 0.</p> required <code>t_fade_in</code> <code>float</code> <p>fade-in time. Defaults to 2.0.</p> required <code>batch_size</code> <code>int</code> <p>batch size. Defaults to 4.</p> required <code>indices</code> <code>list</code> <p>indices of stimuli. Defaults to None.</p> <code>None</code> Source code in <code>flyvision/analysis/optimal_stimuli.py</code> <pre><code>def optimal_stimuli(\n    self,\n    cell_type,\n    dt=1 / 100,\n    indices=None,\n):\n    \"\"\"Finds optimal stimuli for a given cell type in stimuli dataset.\n\n    Args:\n        cell_type (str): node type.\n        dt (float, optional): time step. Defaults to 1 / 100.\n        t_pre (float, optional): pre-stimulus time. Defaults to 0.\n        t_fade_in (float, optional): fade-in time. Defaults to 2.0.\n        batch_size (int, optional): batch size. Defaults to 4.\n        indices (list, optional): indices of stimuli. Defaults to None.\n    \"\"\"\n    responses = self.nv.naturalistic_stimuli_responses()\n    cell_responses = responses['responses'].custom.where(cell_type=cell_type)\n\n    argmax = cell_responses.argmax(dim=(\"sample\", \"frame\"))['sample'].item()\n    if indices is not None:\n        argmax = indices[argmax]\n    nat_opt_stim = self.stimuli[argmax][\"lum\"]\n\n    n_frames = nat_opt_stim.shape[0]\n    initial_state = self.network.steady_state(1.0, dt, 1)\n    stimulus = Stimulus(self.network.connectome, 1, n_frames)\n    stimulus.zero()\n    stimulus.add_input(nat_opt_stim[None])\n    response = self.network(stimulus(), dt, state=initial_state).detach().cpu()\n    response = LayerActivity(response, self.network.connectome, keepref=True)[\n        cell_type\n    ]\n\n    return OptimalStimulus(nat_opt_stim[None, :], response[:, :, None])\n</code></pre>"},{"location":"reference/optimal_stimuli/#flyvision.analysis.optimal_stimuli.FindOptimalStimuli.regularized_optimal_stimuli","title":"<code>regularized_optimal_stimuli(cell_type, l2_act=1, lr=0.01, l2_stim=1, n_iters=100, dt=1 / 100, indices=None)</code>","text":"<p>Regularizes the optimal stimulus such that the central node activity of the given type remains but the mean square of the input pixels is minimized.</p> <p>Parameters:</p> Name Type Description Default <code>cell_type</code> <code>str</code> <p>node type.</p> required <code>l2_act</code> <code>float</code> <p>L2 regularization strength for the activity.</p> <code>1</code> <code>lr</code> <code>float</code> <p>learning rate. Defaults to 1e-2.</p> <code>0.01</code> <code>l2_stim</code> <code>float</code> <p>L2 regularization strength for the stimulus.</p> <code>1</code> <code>n_iters</code> <code>int</code> <p>number of iterations. Defaults to 100.</p> <code>100</code> <code>dt</code> <code>float</code> <p>time step. Defaults to 1 / 100.</p> <code>1 / 100</code> <code>t_pre</code> <code>float</code> <p>pre-stimulus time. Defaults to 0.</p> required <code>t_fade_in</code> <code>float</code> <p>fade-in time. Defaults to 2.0.</p> required <code>batch_size</code> <code>int</code> <p>batch size. Defaults to 4.</p> required <code>indices</code> <code>list</code> <p>indices of stimuli. Defaults to None.</p> <code>None</code> Source code in <code>flyvision/analysis/optimal_stimuli.py</code> <pre><code>def regularized_optimal_stimuli(\n    self,\n    cell_type,\n    l2_act=1,\n    lr=1e-2,\n    l2_stim=1,\n    n_iters=100,\n    dt=1 / 100,\n    indices=None,\n):\n    \"\"\"Regularizes the optimal stimulus such that the central node activity of the\n    given type remains but the mean square of the input pixels is minimized.\n\n    Args:\n        cell_type (str): node type.\n        l2_act (float, optional): L2 regularization strength for the activity.\n        Defaults to 1.\n        lr (float, optional): learning rate. Defaults to 1e-2.\n        l2_stim (float, optional): L2 regularization strength for the stimulus.\n        Defaults to 1.\n        n_iters (int, optional): number of iterations. Defaults to 100.\n        dt (float, optional): time step. Defaults to 1 / 100.\n        t_pre (float, optional): pre-stimulus time. Defaults to 0.\n        t_fade_in (float, optional): fade-in time. Defaults to 2.0.\n        batch_size (int, optional): batch size. Defaults to 4.\n        indices (list, optional): indices of stimuli. Defaults to None.\n    \"\"\"\n\n    optim_stimuli = self.optimal_stimuli(\n        cell_type=cell_type,\n        dt=dt,\n        indices=indices,\n    )\n    non_nan = ~torch.isnan(\n        optim_stimuli.stimulus[0, :, 0, optim_stimuli.stimulus.shape[-1] // 2]\n    )\n    reg_opt_stim = optim_stimuli.stimulus.clone()\n    reg_opt_stim = reg_opt_stim[:, non_nan]\n    reg_opt_stim.requires_grad = True\n\n    central_target_response = (\n        optim_stimuli.response.to(non_nan.device)[\n            :, non_nan, :, optim_stimuli.response.shape[-1] // 2\n        ]\n        .clone()\n        .detach()\n        .squeeze()\n    )\n\n    optim = torch.optim.Adam([reg_opt_stim], lr=lr)\n\n    n_frames = reg_opt_stim.shape[1]\n\n    stim = Stimulus(self.network.connectome, 1, n_frames)\n\n    layer_activity = LayerActivity(None, self.network.connectome, keepref=True)\n\n    initial_state = self.network.steady_state(1.0, dt, 1)\n\n    losses = []\n    for _ in range(n_iters):\n        optim.zero_grad()\n        stim.zero()\n        stim.add_input(reg_opt_stim)\n        activities = self.network(stim(), dt, state=initial_state)\n        layer_activity.update(activities)\n        central_predicted_response = layer_activity.central[cell_type].squeeze()\n\n        act_loss = (\n            l2_act\n            * ((central_predicted_response - central_target_response) ** 2).sum()\n        )\n        stim_loss = l2_stim * ((reg_opt_stim - 0.5) ** 2).mean(dim=0).sum()\n        loss = act_loss + stim_loss\n        loss.backward(retain_graph=True)\n        optim.step()\n        losses.append(loss.detach().cpu().numpy().item())\n\n    stim.zero()\n    reg_opt_stim.requires_grad = False\n    stim.add_input(reg_opt_stim)\n    activities = self.network(stim(), dt, state=initial_state)\n    layer_activity.update(activities)\n\n    reg_opt_stim = reg_opt_stim.detach().cpu()\n    rnmei_response = layer_activity[cell_type].detach().cpu()\n    central_predicted_response = central_predicted_response.detach().cpu()\n    central_target_response = central_target_response.detach().cpu()\n    return RegularizedOptimalStimulus(\n        optim_stimuli,\n        reg_opt_stim,\n        rnmei_response,\n        central_predicted_response,\n        central_target_response,\n        losses,\n    )\n</code></pre>"},{"location":"reference/optimal_stimuli/#flyvision.analysis.optimal_stimuli.GenerateOptimalStimuli","title":"<code>GenerateOptimalStimuli</code>","text":"<p>Methods to generate optimal stimuli for cells from random noise.</p> Source code in <code>flyvision/analysis/optimal_stimuli.py</code> <pre><code>class GenerateOptimalStimuli:\n    \"\"\"Methods to generate optimal stimuli for cells from random noise.\"\"\"\n\n    def __init__(self, network_view: flyvision.NetworkView):\n        self.network = network_view.init_network()  # type: flyvision.Network\n\n        for param in self.network.parameters():\n            param.requires_grad = False\n\n    def artificial_optimal_stimuli(\n        self,\n        cell_type,\n        t_stim=49 / 200,\n        dt=1 / 100,\n        lr=1e-2,\n        weight_central=1.0,\n        weight_mei=600 * 5,\n        n_iters=200,\n        random_seed=0,\n        last_only=True,\n    ):\n        \"\"\"Artificial stimuli, maximally exciting the central node of a given type.\n\n        Returns:\n            tensor: rectified input stimulus of shape #frames, 1, #hexals\n            tensor: node activity of shape 1, #frames, #hexals\n        \"\"\"\n        n_frames = int(t_stim / dt)\n        n_hexals = hex_utils.get_num_hexals(self.network.config.connectome.extent)\n\n        initial_state = self.network.steady_state(1.0, dt, 1)\n\n        # Prepare pre stimulus.\n        stimulus = Stimulus(self.network.connectome, 1, n_frames)\n\n        # Initialize maximally excitatory tensors per time bin.\n        torch.manual_seed(random_seed)\n        art_opt_stim = torch.rand(1, n_frames, 1, n_hexals, device=flyvision.device)\n\n        art_opt_stim.data.clamp_(0, 1)\n        art_opt_stim.requires_grad = True\n\n        # Initialize optimizer for the stimuli.\n        optim = torch.optim.Adam([art_opt_stim], lr=lr)\n\n        # Memorize surround_index for the loop.\n        central_index = stimulus.central_cells_index[cell_type]\n\n        optimize_frames = [range(n_frames)[-1]] if last_only else list(range(n_frames))\n\n        def optimize(mei):\n            # Reset stimulus.\n            stimulus.zero()\n            stimulus.add_input(mei)\n            # Reset optimizer.\n            optim.zero_grad()\n\n            central_loss = 0\n            # Stimulate network.\n            activity = self.network(stimulus(), dt, state=initial_state)\n            central_activity = activity[:, :, central_index].squeeze()\n\n            central_loss -= (\n                weight_central * torch.exp(central_activity[optimize_frames]).mean()\n            )\n\n            mei_loss = weight_mei * ((mei - 0.5) ** 2).mean()\n            loss = central_loss + mei_loss\n            loss.backward(retain_graph=True)\n            optim.step()\n            mei.data.clamp_(0, 1)\n            return (\n                loss.detach().cpu().numpy(),\n                central_loss.detach().cpu().numpy(),\n                mei_loss.detach().cpu().numpy(),\n            )\n\n        losses = []\n        for _ in range(n_iters):\n            loss = optimize(art_opt_stim)\n            losses.append(loss)\n\n        losses = np.array(losses)\n\n        art_opt_stim.requires_grad = False\n        # Stimulate network with whole sequence.\n        stimulus.zero()\n        stimulus.add_input(art_opt_stim)\n        activity = self.network(stimulus(), dt, state=initial_state)\n        responses = activity.detach().cpu().numpy()[:, :, stimulus.layer_index[cell_type]]\n\n        art_opt_stim = art_opt_stim.cpu().numpy()\n        return GeneratedOptimalStimulus(art_opt_stim, responses, losses)\n</code></pre>"},{"location":"reference/optimal_stimuli/#flyvision.analysis.optimal_stimuli.GenerateOptimalStimuli.artificial_optimal_stimuli","title":"<code>artificial_optimal_stimuli(cell_type, t_stim=49 / 200, dt=1 / 100, lr=0.01, weight_central=1.0, weight_mei=600 * 5, n_iters=200, random_seed=0, last_only=True)</code>","text":"<p>Artificial stimuli, maximally exciting the central node of a given type.</p> <p>Returns:</p> Name Type Description <code>tensor</code> <p>rectified input stimulus of shape #frames, 1, #hexals</p> <code>tensor</code> <p>node activity of shape 1, #frames, #hexals</p> Source code in <code>flyvision/analysis/optimal_stimuli.py</code> <pre><code>def artificial_optimal_stimuli(\n    self,\n    cell_type,\n    t_stim=49 / 200,\n    dt=1 / 100,\n    lr=1e-2,\n    weight_central=1.0,\n    weight_mei=600 * 5,\n    n_iters=200,\n    random_seed=0,\n    last_only=True,\n):\n    \"\"\"Artificial stimuli, maximally exciting the central node of a given type.\n\n    Returns:\n        tensor: rectified input stimulus of shape #frames, 1, #hexals\n        tensor: node activity of shape 1, #frames, #hexals\n    \"\"\"\n    n_frames = int(t_stim / dt)\n    n_hexals = hex_utils.get_num_hexals(self.network.config.connectome.extent)\n\n    initial_state = self.network.steady_state(1.0, dt, 1)\n\n    # Prepare pre stimulus.\n    stimulus = Stimulus(self.network.connectome, 1, n_frames)\n\n    # Initialize maximally excitatory tensors per time bin.\n    torch.manual_seed(random_seed)\n    art_opt_stim = torch.rand(1, n_frames, 1, n_hexals, device=flyvision.device)\n\n    art_opt_stim.data.clamp_(0, 1)\n    art_opt_stim.requires_grad = True\n\n    # Initialize optimizer for the stimuli.\n    optim = torch.optim.Adam([art_opt_stim], lr=lr)\n\n    # Memorize surround_index for the loop.\n    central_index = stimulus.central_cells_index[cell_type]\n\n    optimize_frames = [range(n_frames)[-1]] if last_only else list(range(n_frames))\n\n    def optimize(mei):\n        # Reset stimulus.\n        stimulus.zero()\n        stimulus.add_input(mei)\n        # Reset optimizer.\n        optim.zero_grad()\n\n        central_loss = 0\n        # Stimulate network.\n        activity = self.network(stimulus(), dt, state=initial_state)\n        central_activity = activity[:, :, central_index].squeeze()\n\n        central_loss -= (\n            weight_central * torch.exp(central_activity[optimize_frames]).mean()\n        )\n\n        mei_loss = weight_mei * ((mei - 0.5) ** 2).mean()\n        loss = central_loss + mei_loss\n        loss.backward(retain_graph=True)\n        optim.step()\n        mei.data.clamp_(0, 1)\n        return (\n            loss.detach().cpu().numpy(),\n            central_loss.detach().cpu().numpy(),\n            mei_loss.detach().cpu().numpy(),\n        )\n\n    losses = []\n    for _ in range(n_iters):\n        loss = optimize(art_opt_stim)\n        losses.append(loss)\n\n    losses = np.array(losses)\n\n    art_opt_stim.requires_grad = False\n    # Stimulate network with whole sequence.\n    stimulus.zero()\n    stimulus.add_input(art_opt_stim)\n    activity = self.network(stimulus(), dt, state=initial_state)\n    responses = activity.detach().cpu().numpy()[:, :, stimulus.layer_index[cell_type]]\n\n    art_opt_stim = art_opt_stim.cpu().numpy()\n    return GeneratedOptimalStimulus(art_opt_stim, responses, losses)\n</code></pre>"},{"location":"reference/optimal_stimuli/#flyvision.analysis.optimal_stimuli.plot_stim_response","title":"<code>plot_stim_response(stim, response, dt, u, v, max_extent=6, subtract_baseline=True, seconds=0.2, steps=10, columns=10, suptitle='', plot_resp=True, hlines=True, vlines=True, time_axis=True, peak_central=False, wspace=-0.2, peak_last=True, fontsize=5, ylabel='', ylabelrotation=90, figsize=[5, 1], label_peak_response=False, fig=None, axes=None, crange=None, trace_axis=False, trace_label=None, trace_axis_offset=0.1, trace_color=None)</code>","text":"<p>Plots spatio-temporal stimulus and response on regular hex lattices.</p> Source code in <code>flyvision/analysis/optimal_stimuli.py</code> <pre><code>def plot_stim_response(\n    stim,\n    response,\n    dt,\n    u,\n    v,\n    max_extent=6,\n    subtract_baseline=True,\n    seconds=0.2,\n    steps=10,\n    columns=10,\n    suptitle=\"\",\n    plot_resp=True,\n    hlines=True,\n    vlines=True,\n    time_axis=True,\n    peak_central=False,\n    wspace=-0.2,\n    peak_last=True,\n    fontsize=5,\n    ylabel=\"\",\n    ylabelrotation=90,\n    figsize=[5, 1],\n    label_peak_response=False,\n    fig=None,\n    axes=None,\n    crange=None,\n    trace_axis=False,\n    trace_label=None,\n    trace_axis_offset=0.1,\n    trace_color=None,\n):\n    \"\"\"Plots spatio-temporal stimulus and response on regular hex lattices.\"\"\"\n    stim = tensor_utils.to_numpy(stim).squeeze()\n    mask = ~np.isnan(stim).any(axis=-1).squeeze()\n    response = tensor_utils.to_numpy(response).squeeze()\n    stim = stim[mask]\n    response = response[mask]\n\n    if subtract_baseline:\n        response -= response[0]\n\n    argmax = np.nanargmax(response[:, response.shape[-1] // 2])\n\n    n_frames = response.shape[0]\n    time = np.arange(n_frames) * dt\n    steps = int(seconds / dt)\n    t_argmax = time[argmax]\n\n    if peak_central:\n        start = argmax - steps // 2\n        end = argmax + steps // 2\n        if start &lt; 0:\n            start = 0\n            end = steps\n        peak_last = False\n\n    if peak_last:\n        start = argmax - steps\n        end = argmax\n        if start &lt; 0:\n            start = 0\n            end = steps\n\n    _t_steps = time[start:end]\n\n    # resample in time in case seconds, number of columns, dt does not match\n    time_index = np.linspace(0, len(_t_steps), 2 * columns, endpoint=False).astype(int)\n    _t_steps = _t_steps[time_index]\n\n    # breakpoint()\n    t_steps_stim = _t_steps[0::2]\n    t_steps_resp = _t_steps[1::2]\n\n    _u, _v = hex_utils.get_hex_coords(max_extent)\n    x, y = hex_utils.hex_to_pixel(_u, _v)\n    xmin, xmax = x.min(), x.max()\n    ymin, ymax = y.min(), y.max()\n    elev = 0\n    azim = 0\n\n    if fig is None or axes is None:\n        if plot_resp:\n            x, y = hex_utils.hex_rows(2, columns)\n            fig, axes, pos = plt_utils.ax_scatter(\n                x,\n                y,\n                figsize=figsize,\n                hpad=0,\n                wpad=0.07,\n                wspace=-0.7,\n                hspace=-0.5,\n            )\n            axes = np.array(axes).reshape(2, columns)\n\n        else:\n            fig, axes = plt_utils.divide_figure_to_grid(\n                np.arange(10).reshape(1, 10),\n                wspace=wspace,\n                as_matrix=True,\n                figsize=figsize,\n            )\n\n    crange = crange or np.abs(np.nanmax(response))\n    for i, t in enumerate(t_steps_stim):\n        # plot stimulus\n        mask = np.where(np.abs(time - t) &lt;= 1e-15, True, False)\n        _stim = stim[mask].squeeze()\n        plots.quick_hex_scatter(\n            _stim,\n            vmin=0,\n            vmax=1,\n            cbar=False,\n            max_extent=max_extent,\n            fig=fig,\n            ax=axes[0, i],\n        )\n\n        if hlines:\n            axes[0, i].hlines(elev, xmin, xmax, color=\"#006400\", linewidth=0.25)\n        if vlines:\n            axes[0, i].vlines(azim, ymin, ymax, color=\"#006400\", linewidth=0.25)\n\n        if plot_resp:\n            # --- plot response\n\n            mask = np.where(np.abs(time - t_steps_resp[i]) &lt;= 1e-15, True, False)\n            _resp = response[mask].squeeze()\n            plots.hex_scatter(\n                u,\n                v,\n                _resp,\n                fill=True,\n                # edgecolor=\"0.3\",\n                # edgewidth=0.1,\n                cmap=plt.cm.coolwarm,\n                vmin=-crange,\n                vmax=crange,\n                midpoint=0,\n                cbar=False,\n                max_extent=max_extent,\n                fig=fig,\n                ax=axes[1, i],\n            )\n            if t_steps_resp[i] == t_argmax and label_peak_response:\n                axes[1, i].set_title(\"peak\", fontsize=fontsize)\n\n            if hlines:\n                axes[1, i].hlines(elev, xmin, xmax, color=\"#006400\", linewidth=0.25)\n            if vlines:\n                axes[1, i].vlines(azim, ymin, ymax, color=\"#006400\", linewidth=0.25)\n\n    if trace_axis:\n        left = fig.transFigure.inverted().transform(\n            axes[0, 0].transData.transform((0, 0))\n        )[0]\n        right = fig.transFigure.inverted().transform(\n            axes[-1, -1].transData.transform((0, 0))\n        )[0]\n\n        lefts, bottoms, rights, tops = np.array([\n            ax.get_position().extents for ax in axes.flatten()\n        ]).T\n\n        trace_axis = fig.add_axes(\n            (\n                left,\n                bottoms.min() - trace_axis_offset,\n                right - left,\n                trace_axis_offset - 0.05 * trace_axis_offset,\n            ),\n            label=\"trace_axis\",\n        )\n        plt_utils.rm_spines(\n            trace_axis, (\"top\", \"right\"), rm_yticks=False, rm_xticks=False\n        )\n\n        data_centers_in_points = np.array([\n            ax.transData.transform((0, 0)) for ax in axes.flatten(order=\"F\")\n        ])\n        trace_axis.tick_params(axis=\"both\", labelsize=fontsize)\n        if plot_resp:\n            xticks = trace_axis.transData.inverted().transform(data_centers_in_points)[\n                1::2, 0\n            ]\n            trace_axis.set_xticks(xticks)\n            ticklabels = np.round(_t_steps * 1000, 0)\n            trace_axis.set_xticklabels((ticklabels - ticklabels.max())[1::2])\n        else:\n            xticks = trace_axis.transData.inverted().transform(data_centers_in_points)[\n                :, 0\n            ]\n            trace_axis.set_xticks(xticks)\n            ticklabels = np.round(t_steps_stim * 1000, 0)\n            trace_axis.set_xticklabels((ticklabels - ticklabels.max()))\n        trace_axis.set_xlabel(\"time (ms)\", fontsize=fontsize, labelpad=2)\n        plt_utils.set_spine_tick_params(\n            trace_axis,\n            spinewidth=0.25,\n            tickwidth=0.25,\n            ticklength=3,\n            ticklabelpad=2,\n            spines=(\"top\", \"right\", \"bottom\", \"left\"),\n        )\n        xlim = trace_axis.get_xlim()\n        mask = (time &gt;= _t_steps.min()) &amp; (time &lt;= _t_steps.max())\n\n        time = np.linspace(xticks.min(), xticks.max(), mask.sum())\n\n        trace_axis.plot(\n            time,\n            response[mask, response.shape[-1] // 2],\n            label=trace_label,\n            color=trace_color,\n        )\n        trace_axis.set_xlim(*xlim)\n        trace_axis.set_ylabel(\"central\\nresponse\", fontsize=fontsize)\n        # flyvision.plots.trim_axis(trace_axis)\n\n        time_axis = False\n\n    if time_axis:\n        left = fig.transFigure.inverted().transform(\n            axes[0, 0].transData.transform((0, 0))\n        )[0]\n        right = fig.transFigure.inverted().transform(\n            axes[-1, -1].transData.transform((0, 0))\n        )[0]\n\n        lefts, bottoms, rights, tops = np.array([\n            ax.get_position().extents for ax in axes.flatten()\n        ]).T\n\n        time_axis = fig.add_axes((left, bottoms.min(), right - left, 0.01))\n        plt_utils.rm_spines(\n            time_axis, (\"left\", \"top\", \"right\"), rm_yticks=True, rm_xticks=False\n        )\n\n        data_centers_in_points = np.array([\n            ax.transData.transform((0, 0)) for ax in axes.flatten(order=\"F\")\n        ])\n        time_axis.tick_params(axis=\"both\", labelsize=fontsize)\n        if plot_resp:\n            time_axis.set_xticks(\n                time_axis.transData.inverted().transform(data_centers_in_points)[1::2, 0]\n            )\n            ticklabels = np.round(_t_steps * 1000, 0)\n            time_axis.set_xticklabels((ticklabels - ticklabels.max())[1::2])\n        else:\n            time_axis.set_xticks(\n                time_axis.transData.inverted().transform(data_centers_in_points)[:, 0]\n            )\n            ticklabels = np.round(t_steps_stim * 1000, 0)\n            time_axis.set_xticklabels((ticklabels - ticklabels.max()))\n        time_axis.set_xlabel(\"time (ms)\", fontsize=fontsize, labelpad=2)\n        plt_utils.set_spine_tick_params(\n            time_axis,\n            spinewidth=0.25,\n            tickwidth=0.25,\n            ticklength=3,\n            ticklabelpad=2,\n            spines=(\"top\", \"right\", \"bottom\", \"left\"),\n        )\n\n    if ylabel:\n        lefts, bottoms, rights, tops = np.array([\n            ax.get_position().extents for ax in axes.flatten()\n        ]).T\n        ylabel_axis = fig.add_axes((\n            lefts.min(),\n            bottoms.min(),\n            0.01,\n            tops.max() - bottoms.min(),\n        ))\n        plt_utils.rm_spines(\n            ylabel_axis,\n            (\"left\", \"top\", \"right\", \"bottom\"),\n            rm_yticks=True,\n            rm_xticks=True,\n        )\n        ylabel_axis.set_ylabel(ylabel, fontsize=fontsize, rotation=ylabelrotation)\n        ylabel_axis.patch.set_alpha(0)\n\n    if plot_resp and ylabel is not None:\n        axes[0, 0].annotate(\n            \"stimulus\",\n            xy=(0, 0.5),\n            ha=\"right\",\n            va=\"center\",\n            fontsize=fontsize,\n            rotation=90,\n            xycoords=\"axes fraction\",\n        )\n        axes[1, 0].annotate(\n            \"response\",\n            xy=(0, 0.5),\n            ha=\"right\",\n            va=\"center\",\n            fontsize=fontsize,\n            rotation=90,\n            xycoords=\"axes fraction\",\n        )\n\n    if suptitle:\n        lefts, bottoms, rights, tops = np.array([\n            ax.get_position().extents for ax in axes.flatten()\n        ]).T\n        fig.suptitle(suptitle, fontsize=fontsize, y=tops.max(), va=\"bottom\")\n\n    plt_utils.set_spine_tick_params(\n        fig.axes[-1],\n        spinewidth=0.25,\n        tickwidth=0.25,\n        ticklength=3,\n        ticklabelpad=2,\n        spines=(\"top\", \"right\", \"bottom\", \"left\"),\n    )\n\n    fig.crange = crange\n\n    return StimResponsePlot(\n        stim,\n        response,\n        dt,\n        u,\n        v,\n        time,\n        _t_steps,\n        t_steps_stim,\n        t_steps_resp,\n        xmin,\n        xmax,\n        ymin,\n        ymax,\n        subtract_baseline,\n        steps,\n        fig,\n        axes,\n        time_axis,\n        trace_axis,\n        argmax,\n        t_argmax,\n    )\n</code></pre>"},{"location":"reference/sintel/","title":"Sintel dataset","text":""},{"location":"reference/sintel/#flyvision.datasets.sintel","title":"<code>sintel</code>","text":""},{"location":"reference/sintel/#flyvision.datasets.sintel.MultiTaskSintel","title":"<code>MultiTaskSintel</code>","text":"<p>               Bases: <code>MultiTaskDataset</code></p> <p>Sintel dataset.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <p>list of tasks to include. May include</p> <code>['flow']</code> <code>`flow`</code> <code>or `depth`. Default</code> <p>[\u201cflow\u201d].</p> required <code>boxfilter</code> <p>key word arguments for the BoxEye filter. Default: dict(extent=15, kernel_size=13).</p> <code>dict(extent=15, kernel_size=13)</code> <code>n_frames</code> <p>number of frames to render for each sequence. Default: 19.</p> <code>19</code> <code>center_crop_fraction</code> <p>fraction of the image to keep after cropping. Default: 0.7.</p> <code>0.7</code> <code>vertical_splits</code> <p>number of vertical splits of each frame. Default: 3.</p> <code>3</code> <code>dt</code> <p>sampling and integration time constant. Default: 0.02s.</p> <code>1 / 50</code> <code>augment</code> <p>turns augmentation on and off. Default: True.</p> <code>True</code> <code>random_temporal_crop</code> <p>randomly crops a temporal window of length <code>n_frames</code> from each sequence. Default: True.</p> <code>True</code> <code>all_frames</code> <p>if True, all frames are returned. If False, only <code>n_frames</code>. Default: False. Takes precedence over <code>random_temporal_crop</code>.</p> <code>False</code> <code>resampling</code> <p>if True, piecewise-constant resamples the input sequence to the target framerate (1/dt). Default: True.</p> <code>True</code> <code>interpolate</code> <p>if True, linearly interpolates the target sequence to the the target framerate (1/dt). Default: True.</p> <code>True</code> <code>p_flip</code> <p>probability of flipping the sequence across hexagonal axes.</p> <code>0.5</code> <code>p_rot</code> <p>probability of rotating the sequence by n*60 degrees.</p> <code>5 / 6</code> <code>contrast_std</code> <p>standard deviation of the contrast augmentation.</p> <code>0.2</code> <code>brightness_std</code> <p>standard deviation of the brightness augmentation.</p> <code>0.1</code> <code>gaussian_white_noise</code> <p>standard deviation of the pixel-wise gaussian white noise.</p> <code>0.08</code> <code>gamma_std</code> <p>standard deviation of the gamma augmentation.</p> <code>None</code> <code>_init_cache</code> <p>if True, caches the dataset in memory. Default: True.</p> <code>True</code> <code>unittest</code> <p>if True, only renders a single sequence.</p> <code>False</code> <code>unittest</code> <p>if True, only renders a single sequence.</p> <code>False</code> <p>Attributes (overriding MultiTaskDataset):     framerate: framerate of the original sequences.     dt: sampling and integration time constant.     n_sequences: number of sequences in the dataset.     augment: turns augmentation on and off.     t_pre: warmup time.     t_post cooldown time.     get_item: return an item of the dataset.     tasks: a list of all tasks.     task_weights: a weighting of each task.     task_weights_sum: sum of all indicated task weights to normalize loss.     losses: a loss function for each task.</p> Additional attributes <p>spec: configuration. sintel_path: path to the raw Sintel data. n_frames: number of sequence frames to sample from. sample_all: to sample from all sequence frames. lum_paths: paths to all luminosity, i.e. input data, for sequences     under taining/final. flow_paths: paths to all flow data for sequences under training/final. depth_paths: paths to all depth data for sequences under training/final. segmentation_paths: paths to all segmentation data for sequences under     training/final. cam_paths: paths to all camera data for sequences under training/final. frames_per_scene: number of frames that each sequence contains. interpolate: to interpolate targets. resampling: to supersample in time in case dt &lt; 1/framerate. boxfilter: boxfilter configuration that is used to fly eye render the     raw data as a preprocessing. vertical_splits: number of vertical splits to augment the raw data. p_flip: probability to flip under augmentation. p_rot: probability to rotate under augmentation. contrast: a contrast for augmentation is sampled     from exp(N(0, contrast)). brightness: a brightness for augmentation is sampled     from N(0, brightness). noise_std: standard deviation for hexal-wise gaussian noise. cached_samples: all preprocessed sequences for fast dataloading cached on     \u2018gpu\u2019 or \u2018cpu\u2019. fixed_sampling: deprecated. Causes to sample input and target frames in     in a temporally covering way in preprocessing. original_flow_units: to sample flow target in original units (Pixels)     and with downwards facing y of the image plane. depth_augment_contrast: to scale the contrast of objects by the     inverse of their square distances. This removes the background from     sequences. rendered: Directory pointing to preprocessed sequences. map_seq_id_to_splits: a dictionary to map raw sequence indices to the     vertically split sequence indices. arg_df: a table with index, name, and frame information on each sequence. hmin, hmax: extreme values of all cached luminosity. extent: extent of the boxfilter, i.e. the fly eye. depth_augment: augmentation callable. jitter: augmentation callable. rotate: augmentation callable. flip: augmentation callable. noise: augmentation callable.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if any element in tasks is invalid.</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>class MultiTaskSintel(MultiTaskDataset):\n    \"\"\"Sintel dataset.\n\n    Args:\n        tasks: list of tasks to include. May include\n        `flow` or `depth`. Default: [\"flow\"].\n        boxfilter: key word arguments for the BoxEye filter.\n            Default: dict(extent=15, kernel_size=13).\n        n_frames: number of frames to render for each sequence.\n            Default: 19.\n        center_crop_fraction: fraction of the image to keep after\n            cropping. Default: 0.7.\n        vertical_splits: number of vertical splits of each frame.\n            Default: 3.\n        dt: sampling and integration time constant. Default: 0.02s.\n        augment: turns augmentation on and off. Default: True.\n        random_temporal_crop: randomly crops a temporal window of length\n            `n_frames` from each sequence. Default: True.\n        all_frames: if True, all frames are returned. If False, only `n_frames`.\n            Default: False. Takes precedence over `random_temporal_crop`.\n        resampling: if True, piecewise-constant resamples the input sequence to\n            the target framerate (1/dt). Default: True.\n        interpolate: if True, linearly interpolates the target sequence to the\n            the target framerate (1/dt). Default: True.\n        p_flip: probability of flipping the sequence across hexagonal axes.\n        p_rot: probability of rotating the sequence by n*60 degrees.\n        contrast_std: standard deviation of the contrast augmentation.\n        brightness_std: standard deviation of the brightness augmentation.\n        gaussian_white_noise: standard deviation of the pixel-wise gaussian white noise.\n        gamma_std: standard deviation of the gamma augmentation.\n        _init_cache: if True, caches the dataset in memory. Default: True.\n        unittest: if True, only renders a single sequence.\n\n        unittest: if True, only renders a single sequence.\n\n    Attributes (overriding MultiTaskDataset):\n        framerate: framerate of the original sequences.\n        dt: sampling and integration time constant.\n        n_sequences: number of sequences in the dataset.\n        augment: turns augmentation on and off.\n        t_pre: warmup time.\n        t_post cooldown time.\n        get_item: return an item of the dataset.\n        tasks: a list of all tasks.\n        task_weights: a weighting of each task.\n        task_weights_sum: sum of all indicated task weights to normalize loss.\n        losses: a loss function for each task.\n\n    Additional attributes:\n        spec: configuration.\n        sintel_path: path to the raw Sintel data.\n        n_frames: number of sequence frames to sample from.\n        sample_all: to sample from all sequence frames.\n        lum_paths: paths to all luminosity, i.e. input data, for sequences\n            under taining/final.\n        flow_paths: paths to all flow data for sequences under training/final.\n        depth_paths: paths to all depth data for sequences under training/final.\n        segmentation_paths: paths to all segmentation data for sequences under\n            training/final.\n        cam_paths: paths to all camera data for sequences under training/final.\n        frames_per_scene: number of frames that each sequence contains.\n        interpolate: to interpolate targets.\n        resampling: to supersample in time in case dt &lt; 1/framerate.\n        boxfilter: boxfilter configuration that is used to fly eye render the\n            raw data as a preprocessing.\n        vertical_splits: number of vertical splits to augment the raw data.\n        p_flip: probability to flip under augmentation.\n        p_rot: probability to rotate under augmentation.\n        contrast: a contrast for augmentation is sampled\n            from exp(N(0, contrast)).\n        brightness: a brightness for augmentation is sampled\n            from N(0, brightness).\n        noise_std: standard deviation for hexal-wise gaussian noise.\n        cached_samples: all preprocessed sequences for fast dataloading cached on\n            'gpu' or 'cpu'.\n        fixed_sampling: deprecated. Causes to sample input and target frames in\n            in a temporally covering way in preprocessing.\n        original_flow_units: to sample flow target in original units (Pixels)\n            and with downwards facing y of the image plane.\n        depth_augment_contrast: to scale the contrast of objects by the\n            inverse of their square distances. This removes the background from\n            sequences.\n        rendered: Directory pointing to preprocessed sequences.\n        map_seq_id_to_splits: a dictionary to map raw sequence indices to the\n            vertically split sequence indices.\n        arg_df: a table with index, name, and frame information on each sequence.\n        hmin, hmax: extreme values of all cached luminosity.\n        extent: extent of the boxfilter, i.e. the fly eye.\n        depth_augment: augmentation callable.\n        jitter: augmentation callable.\n        rotate: augmentation callable.\n        flip: augmentation callable.\n        noise: augmentation callable.\n\n    Raises:\n        ValueError: if any element in tasks is invalid.\n    \"\"\"\n\n    framerate: int = 24\n    dt: float = 1 / 50\n    n_sequences: int = 0\n    t_pre: float = 0.0\n    t_post: float = 0.0\n    tasks: List[str] = []\n    task_weights: Dict[str, float] = dict()\n    task_weights_sum: float = 1.0\n    losses: Dict[str, Callable] = dict()\n    loss_kwargs: Dict[str, Any] = dict()\n\n    # augmentation callables\n    jitter: ContrastBrightness\n    rotate: HexRotate\n    flip: HexFlip\n    noise: PixelNoise\n\n    # other non-trivial structures\n    arg_df: pd.DataFrame\n    rendered: RenderedSintel\n    cached_sequences: List[Dict[str, torch.Tensor]]\n\n    valid_tasks = [\"lum\", \"flow\", \"depth\"]\n\n    def __init__(\n        self,\n        tasks=[\"flow\"],\n        boxfilter=dict(extent=15, kernel_size=13),\n        vertical_splits=3,\n        n_frames=19,\n        center_crop_fraction=0.7,\n        dt=1 / 50,\n        augment=True,\n        random_temporal_crop=True,\n        all_frames=False,\n        resampling=True,\n        interpolate=True,\n        p_flip=0.5,\n        p_rot=5 / 6,\n        contrast_std=0.2,\n        brightness_std=0.1,\n        gaussian_white_noise=0.08,\n        gamma_std=None,\n        _init_cache=True,\n        unittest=False,\n        flip_axes=[0, 1],\n        task_weights=None,\n    ):\n        def check_tasks(tasks):\n            invalid_tasks = [x for x in tasks if x not in self.valid_tasks]\n            if invalid_tasks:\n                raise ValueError(f\"invalid tasks {invalid_tasks}\")\n\n            tasks = [v for v in self.valid_tasks if v in tasks]  # sort\n            # because the input 'lum' is always required\n            data_keys = tasks if \"lum\" in tasks else [\"lum\", *tasks]\n            return tasks, data_keys\n\n        self.tasks, self.data_keys = check_tasks(tasks)\n        self._init_task_weights(task_weights)\n        self.interpolate = interpolate\n        self.n_frames = n_frames if not unittest else 3\n        self.dt = dt\n\n        self.all_frames = all_frames\n        self.resampling = resampling\n\n        self.boxfilter = boxfilter\n        self.extent = boxfilter[\"extent\"]\n        assert vertical_splits &gt;= 1\n        self.vertical_splits = vertical_splits\n        self.center_crop_fraction = center_crop_fraction\n\n        self.p_flip = p_flip\n        self.p_rot = p_rot\n        self.contrast_std = contrast_std\n        self.brightness_std = brightness_std\n        self.gaussian_white_noise = gaussian_white_noise\n        self.gamma_std = gamma_std\n        self.random_temporal_crop = random_temporal_crop\n        self.flip_axes = flip_axes\n        self.fix_augmentation_params = False\n\n        self.init_augmentation()\n        self._augmentations_are_initialized = True\n        # note: self.augment is a property with a setter that relies on\n        # _augmentations_are_initialized\n        self.augment = augment\n\n        self.unittest = unittest\n\n        self.sintel_path = download_sintel(depth=\"depth\" in tasks)\n        self.rendered = RenderedSintel(\n            tasks=tasks,\n            boxfilter=boxfilter,\n            vertical_splits=vertical_splits,\n            n_frames=n_frames,\n            center_crop_fraction=center_crop_fraction,\n            unittest=unittest,\n        )\n        self.meta = sintel_meta(\n            self.rendered, self.sintel_path, n_frames, vertical_splits, \"depth\" in tasks\n        )\n\n        self.config = Namespace(\n            tasks=tasks,\n            interpolate=interpolate,\n            n_frames=n_frames,\n            dt=dt,\n            augment=augment,\n            all_frames=all_frames,\n            resampling=resampling,\n            boxfilter=boxfilter,\n            vertical_splits=vertical_splits,\n            p_flip=p_flip,\n            p_rot=p_rot,\n            contrast_std=contrast_std,\n            brightness_std=brightness_std,\n            gaussian_white_noise=gaussian_white_noise,\n            gamma_std=gamma_std,\n            center_crop_fraction=center_crop_fraction,\n        )\n\n        self.n_sequences = len(self.rendered)\n\n        self.arg_df = pd.DataFrame(\n            dict(\n                index=np.arange(self.n_sequences),\n                original_index=self.meta.sequence_indices.repeat(vertical_splits),\n                name=sorted(self.rendered.keys()),\n                original_n_frames=self.meta.frames_per_scene.repeat(vertical_splits),\n            )\n        )\n\n        if _init_cache:\n            self.init_cache()\n\n    def init_cache(self):\n        self.cached_sequences = [\n            {\n                key: torch.tensor(val, dtype=torch.float32)\n                for key, val in self.rendered(seq_id).items()\n                if key in self.data_keys\n            }\n            for seq_id in range(self.n_sequences)\n        ]\n\n    def __setattr__(self, name, value):\n        # some changes have no effect cause they are fixed, or set by the pre-rendering\n        if name == \"framerate\":\n            raise AttributeError(\"cannot change framerate\")\n        if hasattr(self, \"rendered\") and name in self.rendered.config:\n            raise AttributeError(\"cannot change attribute of rendered initialization\")\n        super().__setattr__(name, value)\n        # also update augmentation if it is already initialized\n        if getattr(self, \"_augmentations_are_initialized\", False):\n            self.update_augmentation(name, value)\n\n    def update_augmentation(self, name, value):\n        if name == \"dt\":\n            self.piecewise_resample.target_framerate = 1 / value\n            self.linear_interpolate.target_framerate = 1 / value\n        if name in [\"all_frames\", \"random_temporal_crop\"]:\n            self.temporal_crop.all_frames = value\n            self.temporal_crop.random = value\n        if name in [\"contrast_std\", \"brightness_std\"]:\n            self.jitter.contrast_std = value\n            self.jitter.brightness_std = value\n        if name == \"p_rot\":\n            self.rotate.p_rot = value\n        if name == \"p_flip\":\n            self.flip.p_flip = value\n        if name == \"gaussian_white_noise\":\n            self.noise.std = value\n        if name == \"gamma_std\":\n            self.gamma_correct.std = value\n\n    def init_augmentation(\n        self,\n    ) -&gt; None:\n        \"\"\"Initialize augmentation callables.\"\"\"\n        self.temporal_crop = CropFrames(\n            self.n_frames, all_frames=self.all_frames, random=self.random_temporal_crop\n        )\n        self.jitter = ContrastBrightness(\n            contrast_std=self.contrast_std, brightness_std=self.brightness_std\n        )\n        self.rotate = HexRotate(self.extent, p_rot=self.p_rot)\n        self.flip = HexFlip(self.extent, p_flip=self.p_flip, flip_axes=self.flip_axes)\n        self.noise = PixelNoise(self.gaussian_white_noise)\n\n        self.piecewise_resample = Interpolate(\n            self.framerate, 1 / self.dt, mode=\"nearest-exact\"\n        )\n        self.linear_interpolate = Interpolate(\n            self.framerate,\n            1 / self.dt,\n            mode=\"linear\",\n        )\n        self.gamma_correct = GammaCorrection(1, self.gamma_std)\n\n    def set_augmentation_params(\n        self,\n        n_rot: Optional[int] = None,\n        flip_axis: Optional[int] = None,\n        contrast_factor: Optional[float] = None,\n        brightness_factor: Optional[float] = None,\n        gaussian_white_noise: Optional[float] = None,\n        gamma: Optional[float] = None,\n        start_frame: Optional[int] = None,\n        total_sequence_length: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"To set augmentation callable parameters at each call of get item.\"\"\"\n        if not self.fix_augmentation_params:\n            self.rotate.set_or_sample(n_rot)\n            self.flip.set_or_sample(flip_axis)\n            self.jitter.set_or_sample(contrast_factor, brightness_factor)\n            self.noise.set_or_sample(gaussian_white_noise)\n            self.gamma_correct.set_or_sample(gamma)\n            self.temporal_crop.set_or_sample(\n                start=start_frame, total_sequence_length=total_sequence_length\n            )\n\n    def get_item(self, key: int) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"Returns a dataset sample.\n\n        Note: usually invoked with indexing of self, e.g. self[0:10].\n        \"\"\"\n        return self.apply_augmentation(self.cached_sequences[key])\n\n    @contextmanager\n    def augmentation(self, abool: bool):\n        \"\"\"Contextmanager to turn augmentation on or off in a code block.\n\n        Example usage:\n            &gt;&gt;&gt; with dataset.augmentation(True):\n            &gt;&gt;&gt;    for i, data in enumerate(dataloader):\n            &gt;&gt;&gt;        ...  # all data is augmented\n        \"\"\"\n        augmentations = [\n            \"temporal_crop\",\n            \"jitter\",\n            \"rotate\",\n            \"flip\",\n            \"noise\",\n            \"piecewise_resample\",\n            \"linear_interpolate\",\n            \"gamma_correct\",\n        ]\n        states = {key: getattr(self, key).augment for key in augmentations}\n        _augment = self.augment\n        try:\n            self.augment = abool\n            yield\n        finally:\n            self.augment = _augment\n            for key in augmentations:\n                getattr(self, key).augment = states[key]\n\n    @property\n    def augment(self):\n        return self._augment\n\n    @augment.setter\n    def augment(self, value):\n        self._augment = value\n        if not self._augmentations_are_initialized:\n            return\n        # note: random_temporal_crop can override augment=True\n        self.temporal_crop.random = self.random_temporal_crop if value else False\n        self.jitter.augment = value\n        self.rotate.augment = value\n        self.flip.augment = value\n        self.noise.augment = value\n        # note: these two are not affected by augment\n        self.piecewise_resample.augment = self.resampling\n        self.linear_interpolate.augment = self.interpolate\n        self.gamma_correct.augment = value\n\n    def apply_augmentation(\n        self,\n        data: Dict[str, torch.Tensor],\n        n_rot: Optional[int] = None,\n        flip_axis: Optional[int] = None,\n        contrast_factor: Optional[float] = None,\n        brightness_factor: Optional[float] = None,\n        gaussian_white_noise: Optional[float] = None,\n        gamma: Optional[float] = None,\n    ) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"To augment a sample from the dataset.\"\"\"\n\n        self.set_augmentation_params(\n            n_rot=n_rot,\n            flip_axis=flip_axis,\n            contrast_factor=contrast_factor,\n            brightness_factor=brightness_factor,\n            gaussian_white_noise=gaussian_white_noise,\n            gamma=gamma,\n            start_frame=None,\n            total_sequence_length=data[\"lum\"].shape[0],\n        )\n\n        def transform_lum(lum):\n            return self.piecewise_resample(\n                self.rotate(\n                    self.flip(\n                        self.jitter(\n                            self.noise(self.temporal_crop(lum)),\n                        ),\n                    )\n                )\n            )\n\n        def transform_target(target):\n            if self.interpolate:\n                return self.linear_interpolate(\n                    self.rotate(self.flip(self.temporal_crop(target)))\n                )\n            return self.piecewise_resample(\n                self.rotate(self.flip(self.temporal_crop(target)))\n            )\n\n        return {\n            **{\"lum\": transform_lum(data[\"lum\"])},\n            **{\n                target: transform_target(data[target])\n                for target in self.tasks\n                if target in [\"flow\", \"depth\"]\n            },\n        }\n\n    def original_sequence_index(self, key):\n        \"\"\"Get the original sequence index from an index of the split.\"\"\"\n        for index, splits in self.meta.sequence_index_to_splits.items():\n            if key in splits:\n                return index\n        raise ValueError(f\"key {key} not found in splits\")\n\n    def cartesian_sequence(\n        self,\n        key,\n        vertical_splits=None,\n        outwidth=716,\n        center_crop_fraction=None,\n        sampling=slice(1, None, None),\n    ):\n        \"\"\"To return the cartesian sequence of a fly eye rendered sequence.\"\"\"\n\n        # we want to retrieve the original scene which is possibly split\n        # into multiple ones\n        key = self.original_sequence_index(key)\n        lum_path = self.meta.lum_paths[key]\n        images = np.array([\n            sample_lum(path) for path in sorted(lum_path.iterdir())[sampling]\n        ])\n        return split(\n            images,\n            outwidth,\n            vertical_splits or self.vertical_splits,\n            center_crop_fraction or self.center_crop_fraction,\n        )\n\n    def cartesian_flow(\n        self,\n        key,\n        vertical_splits=None,\n        outwidth=417,\n        center_crop_fraction=None,\n        sampling=slice(None, None, None),\n    ):\n        \"\"\"To return the cartesian flow of a fly eye rendered flow.\"\"\"\n        key = self.original_sequence_index(key)\n        flow_path = self.meta.flow_paths[key]\n        flow = np.array([\n            sample_flow(path) for path in sorted(flow_path.iterdir())[sampling]\n        ])\n\n        return split(\n            flow,\n            outwidth,\n            vertical_splits or self.vertical_splits,\n            center_crop_fraction or self.center_crop_fraction,\n        )\n\n    def cartesian_depth(\n        self,\n        key,\n        vertical_splits=None,\n        outwidth=417,\n        center_crop_fraction=None,\n        sampling=slice(1, None, None),\n    ):\n        \"\"\"To return the cartesian depth of a fly eye rendered depth.\"\"\"\n        key = self.original_sequence_index(key)\n        flow_path = self.meta.depth_paths[key]\n        depth = np.array([\n            sample_depth(path) for path in sorted(flow_path.iterdir())[sampling]\n        ])\n\n        return split(\n            depth,\n            outwidth,\n            vertical_splits or self.vertical_splits,\n            center_crop_fraction or self.center_crop_fraction,\n        )\n\n    def original_train_and_validation_indices(self):\n        \"\"\"For the VanillaCNN that uses this dataset, this method returns the\n        indices required for the dataloader.\n        \"\"\"\n        _validation = [\n            \"ambush_2\",\n            \"bamboo_1\",\n            \"bandage_1\",\n            \"cave_4\",\n            \"market_2\",\n            \"mountain_1\",\n        ]\n\n        train = [\n            \"alley_1\",\n            \"alley_2\",\n            \"ambush_4\",\n            \"ambush_5\",\n            \"ambush_6\",\n            \"ambush_7\",\n            \"bamboo_2\",\n            \"bandage_2\",\n            \"cave_2\",\n            \"market_5\",\n            \"market_6\",\n            \"shaman_2\",\n            \"shaman_3\",\n            \"sleeping_1\",\n            \"sleeping_2\",\n            \"temple_2\",\n            \"temple_3\",\n        ]\n\n        train_indices = [\n            i\n            for i, name in enumerate(self.arg_df.name)\n            if any([scene_name in name for scene_name in train])\n        ]\n        val_indices = [\n            i\n            for i, name in enumerate(self.arg_df.name)\n            if any([scene_name in name for scene_name in _validation])\n        ]\n        # these were dropped by the pytorch dataload because of the chosen\n        # batchsize in the original training run\n        val_indices.remove(37)\n        val_indices.remove(38)\n        return train_indices, val_indices\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.MultiTaskSintel.init_augmentation","title":"<code>init_augmentation()</code>","text":"<p>Initialize augmentation callables.</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>def init_augmentation(\n    self,\n) -&gt; None:\n    \"\"\"Initialize augmentation callables.\"\"\"\n    self.temporal_crop = CropFrames(\n        self.n_frames, all_frames=self.all_frames, random=self.random_temporal_crop\n    )\n    self.jitter = ContrastBrightness(\n        contrast_std=self.contrast_std, brightness_std=self.brightness_std\n    )\n    self.rotate = HexRotate(self.extent, p_rot=self.p_rot)\n    self.flip = HexFlip(self.extent, p_flip=self.p_flip, flip_axes=self.flip_axes)\n    self.noise = PixelNoise(self.gaussian_white_noise)\n\n    self.piecewise_resample = Interpolate(\n        self.framerate, 1 / self.dt, mode=\"nearest-exact\"\n    )\n    self.linear_interpolate = Interpolate(\n        self.framerate,\n        1 / self.dt,\n        mode=\"linear\",\n    )\n    self.gamma_correct = GammaCorrection(1, self.gamma_std)\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.MultiTaskSintel.set_augmentation_params","title":"<code>set_augmentation_params(n_rot=None, flip_axis=None, contrast_factor=None, brightness_factor=None, gaussian_white_noise=None, gamma=None, start_frame=None, total_sequence_length=None)</code>","text":"<p>To set augmentation callable parameters at each call of get item.</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>def set_augmentation_params(\n    self,\n    n_rot: Optional[int] = None,\n    flip_axis: Optional[int] = None,\n    contrast_factor: Optional[float] = None,\n    brightness_factor: Optional[float] = None,\n    gaussian_white_noise: Optional[float] = None,\n    gamma: Optional[float] = None,\n    start_frame: Optional[int] = None,\n    total_sequence_length: Optional[int] = None,\n) -&gt; None:\n    \"\"\"To set augmentation callable parameters at each call of get item.\"\"\"\n    if not self.fix_augmentation_params:\n        self.rotate.set_or_sample(n_rot)\n        self.flip.set_or_sample(flip_axis)\n        self.jitter.set_or_sample(contrast_factor, brightness_factor)\n        self.noise.set_or_sample(gaussian_white_noise)\n        self.gamma_correct.set_or_sample(gamma)\n        self.temporal_crop.set_or_sample(\n            start=start_frame, total_sequence_length=total_sequence_length\n        )\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.MultiTaskSintel.get_item","title":"<code>get_item(key)</code>","text":"<p>Returns a dataset sample.</p> <p>Note: usually invoked with indexing of self, e.g. self[0:10].</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>def get_item(self, key: int) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"Returns a dataset sample.\n\n    Note: usually invoked with indexing of self, e.g. self[0:10].\n    \"\"\"\n    return self.apply_augmentation(self.cached_sequences[key])\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.MultiTaskSintel.augmentation","title":"<code>augmentation(abool)</code>","text":"<p>Contextmanager to turn augmentation on or off in a code block.</p> Example usage <p>with dataset.augmentation(True):    for i, data in enumerate(dataloader):        \u2026  # all data is augmented</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>@contextmanager\ndef augmentation(self, abool: bool):\n    \"\"\"Contextmanager to turn augmentation on or off in a code block.\n\n    Example usage:\n        &gt;&gt;&gt; with dataset.augmentation(True):\n        &gt;&gt;&gt;    for i, data in enumerate(dataloader):\n        &gt;&gt;&gt;        ...  # all data is augmented\n    \"\"\"\n    augmentations = [\n        \"temporal_crop\",\n        \"jitter\",\n        \"rotate\",\n        \"flip\",\n        \"noise\",\n        \"piecewise_resample\",\n        \"linear_interpolate\",\n        \"gamma_correct\",\n    ]\n    states = {key: getattr(self, key).augment for key in augmentations}\n    _augment = self.augment\n    try:\n        self.augment = abool\n        yield\n    finally:\n        self.augment = _augment\n        for key in augmentations:\n            getattr(self, key).augment = states[key]\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.MultiTaskSintel.apply_augmentation","title":"<code>apply_augmentation(data, n_rot=None, flip_axis=None, contrast_factor=None, brightness_factor=None, gaussian_white_noise=None, gamma=None)</code>","text":"<p>To augment a sample from the dataset.</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>def apply_augmentation(\n    self,\n    data: Dict[str, torch.Tensor],\n    n_rot: Optional[int] = None,\n    flip_axis: Optional[int] = None,\n    contrast_factor: Optional[float] = None,\n    brightness_factor: Optional[float] = None,\n    gaussian_white_noise: Optional[float] = None,\n    gamma: Optional[float] = None,\n) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"To augment a sample from the dataset.\"\"\"\n\n    self.set_augmentation_params(\n        n_rot=n_rot,\n        flip_axis=flip_axis,\n        contrast_factor=contrast_factor,\n        brightness_factor=brightness_factor,\n        gaussian_white_noise=gaussian_white_noise,\n        gamma=gamma,\n        start_frame=None,\n        total_sequence_length=data[\"lum\"].shape[0],\n    )\n\n    def transform_lum(lum):\n        return self.piecewise_resample(\n            self.rotate(\n                self.flip(\n                    self.jitter(\n                        self.noise(self.temporal_crop(lum)),\n                    ),\n                )\n            )\n        )\n\n    def transform_target(target):\n        if self.interpolate:\n            return self.linear_interpolate(\n                self.rotate(self.flip(self.temporal_crop(target)))\n            )\n        return self.piecewise_resample(\n            self.rotate(self.flip(self.temporal_crop(target)))\n        )\n\n    return {\n        **{\"lum\": transform_lum(data[\"lum\"])},\n        **{\n            target: transform_target(data[target])\n            for target in self.tasks\n            if target in [\"flow\", \"depth\"]\n        },\n    }\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.MultiTaskSintel.original_sequence_index","title":"<code>original_sequence_index(key)</code>","text":"<p>Get the original sequence index from an index of the split.</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>def original_sequence_index(self, key):\n    \"\"\"Get the original sequence index from an index of the split.\"\"\"\n    for index, splits in self.meta.sequence_index_to_splits.items():\n        if key in splits:\n            return index\n    raise ValueError(f\"key {key} not found in splits\")\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.MultiTaskSintel.cartesian_sequence","title":"<code>cartesian_sequence(key, vertical_splits=None, outwidth=716, center_crop_fraction=None, sampling=slice(1, None, None))</code>","text":"<p>To return the cartesian sequence of a fly eye rendered sequence.</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>def cartesian_sequence(\n    self,\n    key,\n    vertical_splits=None,\n    outwidth=716,\n    center_crop_fraction=None,\n    sampling=slice(1, None, None),\n):\n    \"\"\"To return the cartesian sequence of a fly eye rendered sequence.\"\"\"\n\n    # we want to retrieve the original scene which is possibly split\n    # into multiple ones\n    key = self.original_sequence_index(key)\n    lum_path = self.meta.lum_paths[key]\n    images = np.array([\n        sample_lum(path) for path in sorted(lum_path.iterdir())[sampling]\n    ])\n    return split(\n        images,\n        outwidth,\n        vertical_splits or self.vertical_splits,\n        center_crop_fraction or self.center_crop_fraction,\n    )\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.MultiTaskSintel.cartesian_flow","title":"<code>cartesian_flow(key, vertical_splits=None, outwidth=417, center_crop_fraction=None, sampling=slice(None, None, None))</code>","text":"<p>To return the cartesian flow of a fly eye rendered flow.</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>def cartesian_flow(\n    self,\n    key,\n    vertical_splits=None,\n    outwidth=417,\n    center_crop_fraction=None,\n    sampling=slice(None, None, None),\n):\n    \"\"\"To return the cartesian flow of a fly eye rendered flow.\"\"\"\n    key = self.original_sequence_index(key)\n    flow_path = self.meta.flow_paths[key]\n    flow = np.array([\n        sample_flow(path) for path in sorted(flow_path.iterdir())[sampling]\n    ])\n\n    return split(\n        flow,\n        outwidth,\n        vertical_splits or self.vertical_splits,\n        center_crop_fraction or self.center_crop_fraction,\n    )\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.MultiTaskSintel.cartesian_depth","title":"<code>cartesian_depth(key, vertical_splits=None, outwidth=417, center_crop_fraction=None, sampling=slice(1, None, None))</code>","text":"<p>To return the cartesian depth of a fly eye rendered depth.</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>def cartesian_depth(\n    self,\n    key,\n    vertical_splits=None,\n    outwidth=417,\n    center_crop_fraction=None,\n    sampling=slice(1, None, None),\n):\n    \"\"\"To return the cartesian depth of a fly eye rendered depth.\"\"\"\n    key = self.original_sequence_index(key)\n    flow_path = self.meta.depth_paths[key]\n    depth = np.array([\n        sample_depth(path) for path in sorted(flow_path.iterdir())[sampling]\n    ])\n\n    return split(\n        depth,\n        outwidth,\n        vertical_splits or self.vertical_splits,\n        center_crop_fraction or self.center_crop_fraction,\n    )\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.MultiTaskSintel.original_train_and_validation_indices","title":"<code>original_train_and_validation_indices()</code>","text":"<p>For the VanillaCNN that uses this dataset, this method returns the indices required for the dataloader.</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>def original_train_and_validation_indices(self):\n    \"\"\"For the VanillaCNN that uses this dataset, this method returns the\n    indices required for the dataloader.\n    \"\"\"\n    _validation = [\n        \"ambush_2\",\n        \"bamboo_1\",\n        \"bandage_1\",\n        \"cave_4\",\n        \"market_2\",\n        \"mountain_1\",\n    ]\n\n    train = [\n        \"alley_1\",\n        \"alley_2\",\n        \"ambush_4\",\n        \"ambush_5\",\n        \"ambush_6\",\n        \"ambush_7\",\n        \"bamboo_2\",\n        \"bandage_2\",\n        \"cave_2\",\n        \"market_5\",\n        \"market_6\",\n        \"shaman_2\",\n        \"shaman_3\",\n        \"sleeping_1\",\n        \"sleeping_2\",\n        \"temple_2\",\n        \"temple_3\",\n    ]\n\n    train_indices = [\n        i\n        for i, name in enumerate(self.arg_df.name)\n        if any([scene_name in name for scene_name in train])\n    ]\n    val_indices = [\n        i\n        for i, name in enumerate(self.arg_df.name)\n        if any([scene_name in name for scene_name in _validation])\n    ]\n    # these were dropped by the pytorch dataload because of the chosen\n    # batchsize in the original training run\n    val_indices.remove(37)\n    val_indices.remove(38)\n    return train_indices, val_indices\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.RenderedSintel","title":"<code>RenderedSintel</code>","text":"<p>               Bases: <code>Directory</code></p> <p>Rendering and referencing rendered sintel data.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>List[str]</code> <p>list of tasks to include in the rendering. May include</p> <code>['flow']</code> <code>`flow`</code> <code>or `depth`. Default</code> <p>[\u201cflow\u201d].</p> required <code>boxfilter</code> <code>Dict[str, int]</code> <p>key word arguments for the BoxEye filter. Default: dict(extent=15, kernel_size=13).</p> <code>dict(extent=15, kernel_size=13)</code> <code>n_frames</code> <code>int</code> <p>number of frames to render for each sequence. Default: 19.</p> <code>19</code> <code>center_crop_fraction</code> <code>float</code> <p>fraction of the image to keep after cropping. Default: 0.7.</p> <code>0.7</code> <code>vertical_splits</code> <code>int</code> <p>number of vertical splits of each frame. Default: 3.</p> <code>3</code> <code>unittest</code> <p>if True, only renders a single sequence.</p> <code>False</code> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>@root(renderings_dir)\nclass RenderedSintel(Directory):\n    \"\"\"Rendering and referencing rendered sintel data.\n\n    Args:\n        tasks: list of tasks to include in the rendering. May include\n        `flow` or `depth`. Default: [\"flow\"].\n        boxfilter: key word arguments for the BoxEye filter.\n            Default: dict(extent=15, kernel_size=13).\n        n_frames: number of frames to render for each sequence.\n            Default: 19.\n        center_crop_fraction: fraction of the image to keep after\n            cropping. Default: 0.7.\n        vertical_splits: number of vertical splits of each frame.\n            Default: 3.\n        unittest: if True, only renders a single sequence.\n    \"\"\"\n\n    def __init__(\n        self,\n        tasks: List[str] = [\"flow\"],\n        boxfilter: Dict[str, int] = dict(extent=15, kernel_size=13),\n        vertical_splits: int = 3,\n        n_frames: int = 19,\n        center_crop_fraction: float = 0.7,\n        unittest=False,\n    ):\n        # always downloads and renders flow data, but optionally also depth\n        render_depth = \"depth\" in tasks\n        sintel_path = download_sintel(depth=render_depth)\n        boxfilter = BoxEye(**boxfilter)\n\n        lum_paths = (sintel_path / \"training/final\").iterdir()\n\n        for i, lum_path in enumerate(tqdm(sorted(lum_paths), desc=\"Rendering\")):\n            # renders all frames for all sequences which have more than n_frames\n            if len(list(lum_path.iterdir())) - 1 &gt;= n_frames:\n                flow_path = sintel_path / \"training/flow\" / lum_path.name\n                depth_path = sintel_path / \"training/depth\" / lum_path.name\n\n                # -- Flow from naturalistic input ------------------------------\n                # Y[n] = f(X[1], ..., X[n])\n                # n X   Y\n                # 0 [x]  n.e.  # not in data\n                # 1 [1]  [1]\n                # 2 [2]  [2]\n                # ...\n                # n [n]  [n]\n\n                # (frames, height, width)\n                lum = load_sequence(\n                    lum_path, sample_lum, start=1, end=None if not unittest else 4\n                )\n                # (splits, frames, height, width)\n                lum_split = split(\n                    lum,\n                    boxfilter.min_frame_size[1] + 2 * boxfilter.kernel_size,\n                    vertical_splits,\n                    center_crop_fraction,\n                )\n                # (frames, splits, 1, #hexals)\n                lum_hex = boxfilter(lum_split).cpu()\n\n                # (frames, 2, height, width)\n                flow = load_sequence(\n                    flow_path, sample_flow, end=None if not unittest else 3\n                )\n                # (splits, frames, 2, height, width)\n                flow_split = split(\n                    flow,\n                    boxfilter.min_frame_size[1] + 2 * boxfilter.kernel_size,\n                    vertical_splits,\n                    center_crop_fraction,\n                )\n                # (frames, splits, 2, #hexals)\n                flow_hex = torch.cat(\n                    (\n                        boxfilter(flow_split[:, :, 0], ftype=\"sum\"),\n                        boxfilter(flow_split[:, :, 1], ftype=\"sum\"),\n                    ),\n                    dim=2,\n                ).cpu()\n                if render_depth:\n                    # (frames, height, width)\n                    depth = load_sequence(\n                        depth_path,\n                        sample_depth,\n                        start=1,\n                        end=None if not unittest else 4,\n                    )\n                    # (splits, frames, height, width)\n                    depth_splits = split(\n                        depth,\n                        boxfilter.min_frame_size[1] + 2 * boxfilter.kernel_size,\n                        vertical_splits,\n                        center_crop_fraction,\n                    )\n                    # (frames, splits, 1, #hexals)\n                    depth_hex = boxfilter(depth_splits, ftype=\"median\").cpu()\n\n                # -- store -----------------------------------------------------\n                for j in range(lum_hex.shape[0]):\n                    path = f\"sequence_{i:02d}_{lum_path.name}_split_{j:02d}\"\n\n                    self[f\"{path}/lum\"] = lum_hex[j]\n\n                    self[f\"{path}/flow\"] = flow_hex[j]\n\n                    if render_depth:\n                        self[f\"{path}/depth\"] = depth_hex[j]\n            if unittest:\n                break\n\n    def __call__(self, seq_id):\n        \"\"\"Returns all rendered data for a given sequence index of sorted files.\"\"\"\n        # load all stored h5 files into memory.\n        data = self[sorted(self)[seq_id]]\n        return {key: data[key][:] for key in sorted(data)}\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.RenderedSintel.__call__","title":"<code>__call__(seq_id)</code>","text":"<p>Returns all rendered data for a given sequence index of sorted files.</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>def __call__(self, seq_id):\n    \"\"\"Returns all rendered data for a given sequence index of sorted files.\"\"\"\n    # load all stored h5 files into memory.\n    data = self[sorted(self)[seq_id]]\n    return {key: data[key][:] for key in sorted(data)}\n</code></pre>"},{"location":"reference/sintel/#flyvision.datasets.sintel.AugmentedSintel","title":"<code>AugmentedSintel</code>","text":"<p>               Bases: <code>MultiTaskSintel</code></p> <p>Sintel dataset with controlled, rich augmentation.</p> <p>No nan-padding is applied.</p> returns all data and can be used to evaluate networks on a richer <p>dataset.</p> <p>Expands MultiTaskSintel with methods to hold a trained network directory and return responses for specific augmentation parameters.</p> <p>Parameters:</p> Name Type Description Default <code>n_frames</code> <p>number of sequence frames to sample from.</p> <code>19</code> <code>flip_axes</code> <p>list of axes to flip over.</p> <code>[0, 1]</code> <code>n_rotations</code> <p>list of number of rotations to perform.</p> <code>[0, 1, 2, 3, 4, 5]</code> <code>temporal_split</code> <p>to enable temporally controlled augmentation (experimental).</p> <code>False</code> <code>build_stim_on_init</code> <p>to build the augmented stimulus in cache.</p> <code>True</code> <code>dt</code> <p>integration and sampling time constant.</p> <code>1 / 50</code> Kwargs <p>See list of arguments for MultiTaskSintel. Overrides resampling, init_cache, and augment.</p> <p>Attributes:</p> Name Type Description <code>sequences</code> <p>augmented, cached sequences.</p> Source code in <code>flyvision/datasets/sintel.py</code> <pre><code>class AugmentedSintel(MultiTaskSintel):\n    \"\"\"Sintel dataset with controlled, rich augmentation.\n\n    No nan-padding is applied.\n\n    Note: returns all data and can be used to evaluate networks on a richer\n        dataset.\n\n    Expands MultiTaskSintel with methods to hold a trained network directory\n    and return responses for specific augmentation parameters.\n\n    Args:\n        n_frames: number of sequence frames to sample from.\n        flip_axes: list of axes to flip over.\n        n_rotations: list of number of rotations to perform.\n        temporal_split: to enable temporally controlled augmentation\n            (experimental).\n        build_stim_on_init: to build the augmented stimulus in cache.\n        dt: integration and sampling time constant.\n\n    Kwargs:\n        See list of arguments for MultiTaskSintel.\n        Overrides resampling, init_cache, and augment.\n\n    Attributes:\n        sequences: augmented, cached sequences.\n        ~ see MultiTasksintel\n    \"\"\"\n\n    cached_sequences: List[Dict[str, torch.Tensor]]\n    valid_flip_axes = [0, 1, 2, 3]\n    valid_rotations = [0, 1, 2, 3, 4, 5]\n\n    def __init__(\n        self,\n        n_frames=19,\n        flip_axes=[0, 1],\n        n_rotations=[0, 1, 2, 3, 4, 5],\n        build_stim_on_init=True,\n        temporal_split=False,\n        augment=True,\n        dt=1 / 50,\n        tasks=[\"flow\"],\n        interpolate=True,\n        all_frames=False,\n        random_temporal_crop=False,\n        boxfilter=dict(extent=15, kernel_size=13),\n        vertical_splits=3,\n        contrast_std=None,\n        brightness_std=None,\n        gaussian_white_noise=None,\n        gamma_std=None,\n        center_crop_fraction=0.7,\n        unittest=False,\n        **kwargs,\n    ):\n        if any([arg not in self.valid_flip_axes for arg in flip_axes]):\n            raise ValueError(f\"invalid flip axes {flip_axes}\")\n\n        if any([arg not in self.valid_rotations for arg in n_rotations]):\n            raise ValueError(f\"invalid rotations {n_rotations}\")\n\n        super().__init__(\n            tasks=tasks,\n            interpolate=interpolate,\n            n_frames=n_frames,\n            dt=dt,\n            augment=augment,\n            all_frames=all_frames,\n            resampling=True,\n            random_temporal_crop=random_temporal_crop,\n            boxfilter=boxfilter,\n            vertical_splits=vertical_splits,\n            p_flip=0,\n            p_rot=0,\n            contrast_std=contrast_std,\n            brightness_std=brightness_std,\n            gaussian_white_noise=gaussian_white_noise,\n            gamma_std=gamma_std,\n            center_crop_fraction=center_crop_fraction,\n            unittest=unittest,\n            _init_cache=True,\n        )\n\n        self.flip_axes = flip_axes\n        self.n_rotations = n_rotations\n        self.temporal_split = temporal_split\n\n        self._built = False\n        if build_stim_on_init:\n            self._build()\n            self._built = True\n\n    def _build(self):\n        # to deterministically apply temporal augmentation/binning of sequences\n        # into ceil(sequence_length / n_frames) bins\n        (\n            self.cached_sequences,\n            self.original_repeats,\n        ) = temporal_split_cached_samples(\n            self.cached_sequences, self.n_frames, split=self.temporal_split\n        )\n\n        vsplit_index, original_index, name = (\n            self.arg_df[[\"index\", \"original_index\", \"name\"]]\n            .values.repeat(self.original_repeats, axis=0)\n            .T\n        )\n        tsplit_index = np.arange(len(self.cached_sequences))\n\n        n_frames = [d[\"lum\"].shape[0] for d in self.cached_sequences]\n\n        self.params = [\n            (*p[0], p[1], p[2])\n            for p in list(\n                product(\n                    zip(\n                        name,\n                        original_index,\n                        vsplit_index,\n                        tsplit_index,\n                        n_frames,\n                    ),\n                    self.flip_axes,\n                    self.n_rotations,\n                )\n            )\n        ]\n\n        self.arg_df = pd.DataFrame(\n            self.params,\n            columns=[\n                \"name\",\n                \"original_index\",\n                \"vertical_split_index\",\n                \"temporal_split_index\",\n                \"frames\",\n                \"flip_ax\",\n                \"n_rot\",\n            ],\n        )\n        # breakpoint()\n        # apply deterministic geometric augmentation\n        cached_sequences = {}\n        for i, (_, _, _, sample, _, flip_ax, n_rot) in enumerate(self.params):\n            self.flip.axis = flip_ax\n            self.rotate.n_rot = n_rot\n            cached_sequences[i] = {\n                key: self.rotate(self.flip(value))\n                for key, value in self.cached_sequences[sample].items()\n            }\n        self.cached_sequences = cached_sequences\n\n        # disable deterministically applied augmentation, such that in case\n        # self.augment is True, the other augmentation types can be applied\n        # randomly\n        self.flip.augment = False\n        self.rotate.augment = False\n        # default to cropping 0 to n_frames\n        self.temporal_crop.random = False\n        if self.temporal_split:\n            self.temporal_crop.augment = False\n\n    def __len__(self):\n        return len(self.cached_sequences)\n\n    def _original_length(self):\n        return len(self) // self.vertical_splits\n\n    def get_random_data_split(self, fold, n_folds, shuffle=True, seed=0):\n        train_seq_index, val_seq_index = self.get_random_data_split(\n            fold,\n            n_folds=n_folds,\n            shuffle=True,\n            seed=seed,\n        )\n\n        # adapt to the temporal split to make sure no bleed over from train to\n        # val\n        train_seq_index = [\n            split\n            for seq_id in self.train_seq_index\n            for split in self.dataset.meta.sequence_index_to_splits[seq_id]\n        ]\n        val_seq_index = [\n            split\n            for seq_id in self.val_seq_index\n            for split in self.dataset.meta.sequence_index_to_splits[seq_id]\n        ]\n        return train_seq_index, val_seq_index\n\n    def pad_nans(self, data, pad_to_length=None):\n        if pad_to_length is not None:\n            data = {}\n            for key, value in data.items():\n                data[key] = nnf.pad(\n                    value,\n                    pad=(0, 0, 0, 0, 0, pad_to_length),\n                    mode=\"constant\",\n                    value=np.nan,\n                )\n            return data\n        return data\n\n    def get_item(self, key, pad_to_length=None):\n        if self.augment:\n            return self.pad_nans(\n                self.apply_augmentation(self.cached_sequences[key], n_rot=0, flip_axis=0),\n                pad_to_length,\n            )\n        return self.pad_nans(self.cached_sequences[key], pad_to_length)\n\n    def get(self, sequence, flip_ax, n_rot):\n        key = self._key(sequence, flip_ax, n_rot)\n        return self[key]\n\n    def _key(self, sequence, flip_ax, n_rot):\n        try:\n            mask = self.mask(sequence, flip_ax, n_rot)\n            return np.arange(len(self))[mask].item()\n        except ValueError as e:\n            raise ValueError(\n                f\"sequence: {sequence}, flip_ax: {flip_ax}, n_rot: {n_rot} invalid.\"\n            ) from e\n\n    def _params(self, key):\n        return self.arg_df.iloc[key].values\n\n    def mask(self, sequence=None, flip_ax=None, n_rot=None):\n        values = self.arg_df.iloc[:, 1:].values\n        _nans = np.isnan(values)\n        values = values.astype(object)\n        values[_nans] = \"None\"\n\n        def iterparam(param, name, axis, and_condition):\n            condition = np.zeros(len(values)).astype(bool)\n            if isinstance(param, Iterable) and not isinstance(param, str):\n                for p in param:\n                    _new = values.take(axis, axis=1) == p\n                    assert any(_new), f\"{name} {p} not in dataset.\"\n                    condition = np.logical_or(condition, _new)\n            else:\n                _new = values.take(axis, axis=1) == param\n                assert any(_new), f\"{name} {param} not in dataset.\"\n                condition = np.logical_or(condition, _new)\n            return condition &amp; and_condition\n\n        condition = np.ones(len(values)).astype(bool)\n        if sequence is not None:\n            condition = iterparam(sequence, \"temporal_split_index\", -4, condition)\n        if flip_ax is not None:\n            condition = iterparam(flip_ax, \"flip_ax\", -2, condition)\n        if n_rot is not None:\n            condition = iterparam(n_rot, \"n_rot\", -1, condition)\n        return condition\n\n    def response(\n        self,\n        node_type=None,\n        sequence=None,\n        flip_ax=None,\n        n_rot=None,\n        rm_nans=False,\n    ):\n        assert self.tnn\n        mask = self.mask(sequence=sequence, flip_ax=flip_ax, n_rot=n_rot)\n\n        if node_type is not None:\n            responses = self.central_activity[node_type][mask][:, :, None]\n        else:\n            responses = self.central_activity[:][mask]\n\n        if rm_nans:\n            return remove_nans(responses)\n\n        return responses.squeeze()\n</code></pre>"},{"location":"reference/solver/","title":"Task Training","text":""},{"location":"reference/solver/#flyvision.solver","title":"<code>solver</code>","text":"<p>Solvers for training, testing, checkpointing and recovering of networks.</p>"},{"location":"reference/solver/#flyvision.solver.SolverProtocol","title":"<code>SolverProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>SolverProtocol implements training, testing, checkpointing etc. of networks.</p> Source code in <code>flyvision/solver.py</code> <pre><code>class SolverProtocol(Protocol):\n    \"\"\"SolverProtocol implements training, testing, checkpointing etc. of networks.\"\"\"\n\n    name: str\n    config: Optional[Union[dict, Namespace]]\n\n    def __init__(\n        self, name: str = \"\", config: Optional[Union[dict, Namespace]] = None\n    ) -&gt; None: ...\n\n    dir: Directory = None\n    network: Network = None\n    decoder: Dict[str, nn.Module] = None\n    task: Task = None\n    optimizer: object = None\n    penalty: object = None\n    scheduler: object = None\n\n    def train(self) -&gt; None: ...\n\n    def checkpoint(self) -&gt; None: ...\n\n    def test(self) -&gt; None: ...\n\n    def recover(self) -&gt; None: ...\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.MultiTaskSolver","title":"<code>MultiTaskSolver</code>","text":"<p>Implements training, testing, checkpoint, recovering of flyvis networks.</p> <p>Gives access to the network, decoder, task, optimizer, penalty and scheduler and the directory where the results are stored.</p> <p>Note: specify delete_if_exists=True to delete the directory if it already exists.</p> Example <p>from flyvision.utils.config_utils import get_default_config config = get_default_config(overrides=[\u201ctask_name=flow\u201d, \u201cnetwork_id=0\u201d]) solver = MultiTaskSolver(\u201ctest\u201d, config) solver.train()</p> Source code in <code>flyvision/solver.py</code> <pre><code>class MultiTaskSolver:\n    \"\"\"Implements training, testing, checkpoint, recovering of flyvis networks.\n\n    Gives access to the network, decoder, task, optimizer, penalty and scheduler and\n    the directory where the results are stored.\n\n    Note: specify delete_if_exists=True to delete the directory if it already exists.\n\n    Example:\n        from flyvision.utils.config_utils import get_default_config\n        config = get_default_config(overrides=[\"task_name=flow\", \"network_id=0\"])\n        solver = MultiTaskSolver(\"test\", config)\n        solver.train()\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str = \"\",\n        config: Optional[Union[dict, Namespace]] = None,\n        init_network: bool = True,\n        init_decoder: bool = True,\n        init_task: bool = True,\n        init_optim: bool = True,\n        init_penalties: bool = True,\n        init_scheduler: bool = True,\n        delete_if_exists: bool = False,\n    ) -&gt; None:\n        name = name or config[\"network_name\"]\n        assert isinstance(name, str), \"Provided name argument is not a string.\"\n        self.dir = NetworkDir(\n            name, {**(config or {}), **dict(delete_if_exists=delete_if_exists)}\n        )\n\n        self.path = self.dir.path\n\n        self.config = self.dir.config\n\n        self.iteration = 0\n        self._val_loss = float(\"inf\")\n        self.checkpoint_path = self.dir.path / \"chkpts\"\n        checkpoints = resolve_checkpoints(self.dir)\n        self.checkpoints = checkpoints.indices\n        self._last_chkpt_ind = -1\n        self._curr_chkpt_ind = -1\n\n        self._initialized = self._init_solver(\n            init_network=init_network,\n            init_decoder=init_decoder,\n            init_task=init_task,\n            init_optim=init_optim,\n            init_penalties=init_penalties,\n            init_scheduler=init_scheduler,\n        )\n\n        logging.info(\"Initialized solver.\")\n        logging.info(repr(self.config))\n\n    def _init_solver(\n        self,\n        init_network=False,\n        init_decoder=False,\n        init_task=False,\n        init_optim=False,\n        init_penalties=False,\n        init_scheduler=False,\n    ):\n        \"\"\"Initialize solver.\"\"\"\n        initialized = []\n\n        if init_network:\n            self.network = Network(self.config.network)\n            initialized.append(\"network\")\n\n        if init_task:\n            self.task = Task(**self.config.task)\n            initialized.append(\"task\")\n\n            if init_decoder:\n                self.decoder = self.task.init_decoder(self.network.connectome)\n                initialized.append(\"decoder\")\n\n        if init_optim:\n            self.optimizer = self._init_optimizer(\n                self.config.optim, self.network, self.decoder\n            )\n            initialized.append(\"optim\")\n\n        if init_penalties:\n            self.penalty = Penalty(self.config.penalizer, self.network)\n            initialized.append(\"penalties\")\n\n        if init_scheduler:\n            self.scheduler = HyperParamScheduler(\n                self.config.scheduler,\n                self.network,\n                self.task,\n                self.optimizer,\n                self.penalty,\n            )\n            self.scheduler(self.iteration)\n            initialized.append(\"scheduler\")\n\n        return initialized\n\n    @staticmethod\n    def _init_optimizer(\n        optim: Namespace, network: Network, decoder: Optional[Dict[str, nn.Module]]\n    ) -&gt; torch.optim.Optimizer:\n        \"\"\"Initializes the optim of network and decoder.\"\"\"\n\n        def decoder_parameters(decoder: Dict[str, nn.Module]):\n            \"\"\"Returns decoder parameters.\"\"\"\n            params = []\n            for nn_module in decoder.values():\n                params.append(\n                    dict(\n                        params=[w for w in nn_module.parameters()],\n                        **config.optim_dec,\n                    )\n                )\n            return params\n\n        config = optim.deepcopy()\n\n        optim_type = config.pop(\"type\", \"Adam\")\n        optim = torch.optim.__dict__[optim_type]\n        logging.info(\"Initializing %s for network and decoder.\", optim.__name__)\n\n        param_groups = [dict(params=network.parameters(), **config.optim_net)]\n\n        if decoder:\n            param_groups.extend(decoder_parameters(decoder))\n\n        return optim(param_groups)\n\n    def train(self, overfit=False, initial_checkpoint=True) -&gt; None:\n        \"\"\"Trains the network by backprop through time.\n        Args:\n            overfit (bool): If true, the dataloader is substituted by a\n                single-sequence loader and augmentation is turned off. Defaults to\n                False.\n            initial_checkpoint (bool): to disable the initial checkpoint when debugging.\n\n        Raises:\n            OverflowError: raised if the activity or loss reports Nan values for more\n            than 100 iterations.\n\n        Stores:\n            dir / loss.h5\n            dir / loss_&lt;task&gt;.h5\n            dir / activity.h5\n            dir / activity_min.h5\n            dir / activity_max.h5\n        \"\"\"\n        # pdb.set_trace()\n        # return if iterations have already been trained.\n        if self.iteration &gt;= self.task.n_iters:\n            return\n\n        # to debug code within the training loop the initial checkpoint should be\n        # disabled\n        if initial_checkpoint:\n            self.checkpoint()\n\n        logging.info(\"Starting training.\")\n        # The overfit_data dataloader only contains a single sequence and\n        # this is to debug the model architecture, configs etc.\n        dataloader = self.task.overfit_data if overfit else self.task.train_data\n        # For overfitting we also turn the augmentation off.\n        augment = not overfit\n\n        # The number of full presentations of the training data is derived from the\n        # preset number of training iterations, the length of the dataloader and the\n        # current iteration.\n        n_epochs = np.ceil((self.task.n_iters - self.iteration) / len(dataloader)).astype(\n            int\n        )\n\n        # This is after how many epochs the training states are checkpointed.\n        chkpt_every_epoch = self.config.scheduler.chkpt_every_epoch\n\n        logging.info(\"Training for %s epochs.\", n_epochs)\n        logging.info(\"Checkpointing every %s epochs.\", chkpt_every_epoch)\n\n        # Initialize data structures to store the loss and activity over iterations.\n        loss_over_iters = []\n        activity_over_iters = []\n        activity_min_over_iters = []\n        activity_max_over_iters = []\n        loss_per_task = {f\"loss_{task}\": [] for task in self.task.dataset.tasks}\n\n        start_time = time.time()\n        with self.task.dataset.augmentation(augment):\n            for epoch in range(n_epochs):\n                # The default is to compute a steady state for each epoch, then\n                # it's computed here. Note: unless done per iteration, parameter updates\n                # within epochs are not considered in the steady state.\n                steady_state = self.network.steady_state(\n                    t_pre=self.config.get(\"t_pre_train\", 0.5),\n                    dt=self.task.dataset.dt,\n                    batch_size=dataloader.batch_size,\n                    value=0.5,\n                )\n\n                for _, data in enumerate(dataloader):\n\n                    def handle_batch(data, steady_state):\n                        \"\"\"Closure to free memory by garbage collector effectively.\"\"\"\n\n                        # Resets the stimulus buffer (samples, frames, neurons).\n                        n_samples, n_frames, _, _ = data[\"lum\"].shape\n                        self.network.stimulus.zero(n_samples, n_frames)\n\n                        # Add batch of hex-videos (#frames, #samples, #hexals) as\n                        # photorecptor stimuli.\n                        self.network.stimulus.add_input(data[\"lum\"])\n\n                        # Reset gradients.\n                        self.optimizer.zero_grad()\n\n                        # Run stimulus through network.\n                        activity = self.network(\n                            self.network.stimulus(),\n                            self.task.dataset.dt,\n                            state=steady_state,\n                        )\n\n                        losses = {task: 0 for task in self.task.dataset.tasks}\n                        for task in self.task.dataset.tasks:\n                            y = data[task]\n                            y_est = self.decoder[task](activity)\n\n                            # to pass additional kwargs to the loss function, these\n                            # can either come from the decoder instance or from\n                            # the data batch from the dataset\n                            loss_kwargs = {\n                                **getattr(self.decoder[task], \"loss_kwargs\", {}),\n                                **data.get(\"loss_kwargs\", {}),\n                            }\n\n                            losses[task] = self.task.dataset.loss(\n                                y_est, y, task, **loss_kwargs\n                            )\n\n                        # Sum all task losses. The weighting of the tasks is done in the\n                        # loss function.\n                        loss = sum(losses.values())\n\n                        # Compute gradients.\n                        loss.backward(retain_graph=True)\n                        # Update parameters.\n                        self.optimizer.step()\n\n                        # Activity and parameter dependent penalties.\n                        self.penalty(activity=activity, iteration=self.iteration)\n\n                        # Log results.\n                        loss = loss.detach().cpu()\n                        for task in self.task.dataset.tasks:\n                            loss_per_task[f\"loss_{task}\"].append(\n                                losses[task].detach().cpu()\n                            )\n                        loss_over_iters.append(loss)\n                        activity = activity.detach().cpu()\n                        mean_activity = activity.mean()\n                        activity_over_iters.append(mean_activity)\n                        activity_min_over_iters.append(activity.min())\n                        activity_max_over_iters.append(activity.max())\n                        return loss, mean_activity\n\n                    # Call closure.\n                    loss, mean_activity = handle_batch(data, steady_state)\n\n                    # Increment iteration count.\n                    self.iteration += 1\n\n                # Interrupt training if the network explodes.\n                if torch.isnan(loss) or torch.isnan(mean_activity):\n                    logging.warning(\"Network exploded.\")\n                    raise OverflowError(\"Invalid values encountered in trace.\")\n\n                # The scheduling of hyperparams are functions of the iteration\n                # however, we allow steps only after full presentations of the data.\n                if epoch + 1 != n_epochs:\n                    self.scheduler(self.iteration)\n                    logging.info(\"Scheduled paremeters for iteration %s.\", self.iteration)\n\n                # Checkpointing.\n                if (epoch % chkpt_every_epoch == 0) or (epoch + 1 == n_epochs):\n                    self.dir.loss = loss_over_iters\n                    self.dir.activity = activity_over_iters\n                    self.dir.activity_min = activity_min_over_iters\n                    self.dir.activity_max = activity_max_over_iters\n\n                    for task in self.task.dataset.tasks:\n                        self.dir[f\"loss_{task}\"] = loss_per_task[f\"loss_{task}\"]\n\n                    self.checkpoint()\n\n                logging.info(\"Finished epoch.\")\n\n        time_elapsed = time.time() - start_time\n        time_trained = self.dir.time_trained[()] if \"time_trained\" in self.dir else 0\n        self.dir.time_trained = time_elapsed + time_trained\n        logging.info(\"Finished training.\")\n\n    def checkpoint(self):\n        \"\"\"Creates a checkpoint.\n\n        Validates on the validation data calling ~self.test.\n        Validates on a training batch calling ~self.track_batch.\n        Stores a checkpoint of the network, decoder and optimizer parameters using\n        pytorch's pickle function.\n\n        Stores:\n            dir / chkpt_index.h5 (List): numerical identifier of the checkpoint.\n            dir / chkpt_iter.h5 (List): iteration at which this checkpoint was recorded.\n            dir / best_chkpt_index.h5 (int): chkpt index at which the val loss is\n            minimal.\n            dir / dt.h5 (float): the current time constant of the dataset.\n            dir / chkpts / chkpt_&lt;chkpt_index&gt; (dict): the state dicts of the network,\n                decoder and optimizer.\n        \"\"\"\n        self._last_chkpt_ind += 1\n        self._curr_chkpt_ind += 1\n\n        # Tracking of validation loss and training batch loss.\n        logging.info(\"Test on validation data.\")\n        val_loss = self.test(\n            dataloader=self.task.val_data, subdir=\"validation\", track_loss=True\n        )\n        logging.info(\"Test on validation batch.\")\n        _ = self.test(\n            dataloader=self.task.val_batch, subdir=\"validation_batch\", track_loss=True\n        )\n        logging.info(\"Test on training data.\")\n        _ = self.test(dataloader=self.task.train_data, subdir=\"training\", track_loss=True)\n        logging.info(\"Test on training batch.\")\n        _ = self.test(\n            dataloader=self.task.train_batch, subdir=\"training_batch\", track_loss=True\n        )\n\n        logging.info(\"Saving state dicts.\")\n        # Store state of pytorch modules.\n        nn_state_dict = self.network.state_dict()\n        dec_state_dict = {}\n        if self.decoder:\n            dec_state_dict = valmap(lambda x: x.state_dict(), self.decoder)\n        chkpt = {\n            \"network\": nn_state_dict,\n            \"decoder\": dec_state_dict,\n            \"optim\": self.optimizer.state_dict(),\n            \"time\": time.ctime(),\n            \"val_loss\": val_loss,\n            \"iteration\": self.iteration - 1,\n            \"dt\": self.task.dataset.dt,\n        }\n        if hasattr(self, \"penalty\"):\n            chkpt.update(self.penalty._chkpt())\n        torch.save(chkpt, self.checkpoint_path / f\"chkpt_{self._last_chkpt_ind:05}\")\n\n        # Append chkpt index.\n        self.checkpoints.append(self._last_chkpt_ind)\n        self.dir.extend(\"chkpt_index\", [self._last_chkpt_ind])\n        self.dir.extend(\"chkpt_iter\", [self.iteration - 1])\n        self.dir.dt = self.task.dataset.dt\n\n        # Overwrite best val loss.\n        if val_loss &lt; self._val_loss:\n            self.dir.best_chkpt_index = self._last_chkpt_ind\n            self._val_loss = val_loss\n\n        logging.info(\"Checkpointed.\")\n\n    @torch.no_grad()\n    def test(\n        self,\n        dataloader: torch.utils.data.DataLoader,\n        subdir: str = \"validation\",\n        track_loss: bool = False,\n        t_pre: float = 0.25,\n    ) -&gt; float:\n        \"\"\"Tests the network on a given dataloader.\n\n        Args:\n            dataloader: data to test on.\n            subdir: name of subdirectory. Defaults to 'validation'.\n            track_loss: whether to store the loss in dir.subdir.\n            t_pre: warmup time before the stimulus starts.\n\n        Returns:\n            float: validation loss\n\n        Stores:\n            dir.&lt;subdir&gt;.loss_&lt;task&gt; (List): loss per task, averaged over whole dataset.\n            dir.&lt;subdir&gt;.iteration (List): iteration when this was called.\n            dir.&lt;subdir&gt;.loss (List): average loss over tasks.\n        \"\"\"\n        self._eval()\n        logging.info(\"Test\")\n\n        # Update hypterparams.\n        self.scheduler(self.iteration)\n\n        initial_state = self.network.steady_state(\n            t_pre=t_pre,\n            dt=self.task.dataset.dt,\n            batch_size=dataloader.batch_size,\n            value=0.5,\n        )\n        losses = {task: () for task in self.task.dataset.tasks}  # type: Dict[str, Tuple]\n\n        with self.task.dataset.augmentation(False):\n            for _, data in enumerate(dataloader):\n                n_samples, n_frames, _, _ = data[\"lum\"].shape\n                self.network.stimulus.zero(n_samples, n_frames)\n\n                self.network.stimulus.add_input(data[\"lum\"])\n\n                activity = self.network(\n                    self.network.stimulus(),\n                    self.task.dataset.dt,\n                    state=initial_state,\n                )\n\n                for task in self.task.dataset.tasks:\n                    y = data[task]\n                    y_est = self.decoder[task](activity)\n\n                    loss_kwargs = {\n                        **getattr(self.decoder[task], \"loss_kwargs\", {}),\n                        **data.get(\"loss_kwargs\", {}),\n                    }\n                    losses[task] += (\n                        self.task.dataset.loss(y_est, y, task, **loss_kwargs)\n                        .detach()\n                        .cpu()\n                        .item(),\n                    )\n\n        # track loss per task.\n        avg_loss_per_task = {}\n        for task in self.task.dataset.tasks:\n            # average the loss over the whole dataset\n            avg_loss_per_task[task] = np.mean(losses[task])\n            if track_loss:\n                self.dir[subdir].extend(\"loss\" + \"_\" + task, [avg_loss_per_task[task]])\n\n        # average the loss over all tasks with equal weight\n        summed_loss = sum(avg_loss_per_task.values())\n        val_loss = summed_loss / len(avg_loss_per_task)\n\n        if track_loss:\n            self.dir[subdir].extend(\"iteration\", [self.iteration])\n            self.dir[subdir].extend(\"loss\", [val_loss])\n\n        self._train()\n\n        return val_loss\n\n    def _train(self):\n        \"\"\"Sets nn.Modules to train state.\"\"\"\n        self.network.train()\n        if self.decoder is not None:\n            for decoder in self.decoder.values():\n                decoder.train()\n\n    def _eval(self):\n        \"\"\"Sets nn.Modules to eval state.\"\"\"\n        self.network.eval()\n        if self.decoder is not None:\n            for decoder in self.decoder.values():\n                decoder.eval()\n\n    def get_checkpoints(\n        self,\n        checkpoint: Union[int, str] = \"best\",\n        validation_subdir: str = \"validation\",\n        loss_file_name: str = \"loss\",\n    ):\n        \"\"\"Returns the path to a checkpoint. This can be passed to the recover methods\n        along with the nn.Module instances to create instances from checkpoints\n        independently of the solver.\n        \"\"\"\n        return resolve_checkpoints(\n            self.dir, checkpoint, validation_subdir, loss_file_name\n        )\n\n    def recover(\n        self,\n        network: bool = True,\n        decoder: bool = True,\n        optimizer: bool = True,\n        penalty: bool = True,\n        checkpoint: Union[\n            int, str\n        ] = \"best\",  # -1 for last, 'best' for best based on validation\n        validation_subdir: str = \"validation\",  # required if checkpoint == 'best'\n        loss_file_name: str = \"loss\",\n        strict: bool = True,\n        force: bool = False,\n    ):\n        \"\"\"Recovers the solver state from a checkpoint.\n\n        Args:\n            network: recover network parameters. Defaults to True.\n            decoder: recover decoder parameters. Defaults to True.\n            optimizer: recover optimizer parameters. Defaults to True.\n            penalty: recover penalty parameters. Defaults to True.\n            checkpoint: index of the checkpoint to recover. Defaults to \"best\".\n                \"best\" for best based on tracked validation, -1 for last.\n            validation_subdir: name of the subdir to base the best checkpoint on.\n                Required if checkpoint == 'best'. Defaults to \"validation\".\n            loss_file_name: name of the loss to base the best checkpoint on. Defaults\n                to \"epe\". Assumed to be a subdir of validation.\n            strict: whether to load the state dict of the decoders strictly.\n                Defaults to True.\n            force: force recovery of checkpoint if _curr_chkpt_ind is arelady\n                the same as the checkpoint index. Defaults to False.\n        \"\"\"\n        checkpoints = resolve_checkpoints(\n            self.dir, checkpoint, validation_subdir, loss_file_name\n        )\n\n        if checkpoint.index is None or not any((network, decoder, optimizer, penalty)):\n            logging.info(\"No checkpoint found. Continuing with initialized parameters.\")\n            return\n\n        if checkpoints.index == self._curr_chkpt_ind and not force:\n            logging.info(\"Checkpoint already recovered.\")\n            return\n\n        # Set the current and last checkpoint index. New checkpoints incrementally\n        # increase the last checkpoint index.\n        self._last_chkpt_ind = checkpoints.indices[-1]\n        self._curr_chkpt_ind = checkpoints.index\n\n        # Load checkpoint data.\n        state_dict = torch.load(checkpoints.path)\n        logging.info(f\"Checkpoint {checkpoints.path} loaded.\")\n\n        self.iteration = state_dict.get(\"iteration\", None)\n\n        if \"scheduler\" in self._initialized:\n            # Set the scheduler to the right iteration.\n            self.scheduler(self.iteration)\n\n        # The _val_loss variable is used to keep track of the best checkpoint according\n        # to the evaluation routine during training.\n        self._val_loss = state_dict.pop(\"val_loss\", float(\"inf\"))\n\n        if network and \"network\" in self._initialized:\n            recover_network(self.network, state_dict)\n        if decoder and \"decoder\" in self._initialized:\n            recover_decoder(self.decoder, state_dict, strict=strict)\n        if optimizer and \"optim\" in self._initialized:\n            recover_optimizer(self.optimizer, state_dict)\n        if penalty and \"penalties\" in self._initialized:\n            recover_penalty_optimizers(self.penalty.optimizers, state_dict)\n\n        logging.info(\"Recovered modules.\")\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.MultiTaskSolver.train","title":"<code>train(overfit=False, initial_checkpoint=True)</code>","text":"<p>Trains the network by backprop through time. Args:     overfit (bool): If true, the dataloader is substituted by a         single-sequence loader and augmentation is turned off. Defaults to         False.     initial_checkpoint (bool): to disable the initial checkpoint when debugging.</p> <p>Raises:</p> Type Description <code>OverflowError</code> <p>raised if the activity or loss reports Nan values for more</p> Stores <p>dir / loss.h5 dir / loss_.h5 dir / activity.h5 dir / activity_min.h5 dir / activity_max.h5 Source code in <code>flyvision/solver.py</code> <pre><code>def train(self, overfit=False, initial_checkpoint=True) -&gt; None:\n    \"\"\"Trains the network by backprop through time.\n    Args:\n        overfit (bool): If true, the dataloader is substituted by a\n            single-sequence loader and augmentation is turned off. Defaults to\n            False.\n        initial_checkpoint (bool): to disable the initial checkpoint when debugging.\n\n    Raises:\n        OverflowError: raised if the activity or loss reports Nan values for more\n        than 100 iterations.\n\n    Stores:\n        dir / loss.h5\n        dir / loss_&lt;task&gt;.h5\n        dir / activity.h5\n        dir / activity_min.h5\n        dir / activity_max.h5\n    \"\"\"\n    # pdb.set_trace()\n    # return if iterations have already been trained.\n    if self.iteration &gt;= self.task.n_iters:\n        return\n\n    # to debug code within the training loop the initial checkpoint should be\n    # disabled\n    if initial_checkpoint:\n        self.checkpoint()\n\n    logging.info(\"Starting training.\")\n    # The overfit_data dataloader only contains a single sequence and\n    # this is to debug the model architecture, configs etc.\n    dataloader = self.task.overfit_data if overfit else self.task.train_data\n    # For overfitting we also turn the augmentation off.\n    augment = not overfit\n\n    # The number of full presentations of the training data is derived from the\n    # preset number of training iterations, the length of the dataloader and the\n    # current iteration.\n    n_epochs = np.ceil((self.task.n_iters - self.iteration) / len(dataloader)).astype(\n        int\n    )\n\n    # This is after how many epochs the training states are checkpointed.\n    chkpt_every_epoch = self.config.scheduler.chkpt_every_epoch\n\n    logging.info(\"Training for %s epochs.\", n_epochs)\n    logging.info(\"Checkpointing every %s epochs.\", chkpt_every_epoch)\n\n    # Initialize data structures to store the loss and activity over iterations.\n    loss_over_iters = []\n    activity_over_iters = []\n    activity_min_over_iters = []\n    activity_max_over_iters = []\n    loss_per_task = {f\"loss_{task}\": [] for task in self.task.dataset.tasks}\n\n    start_time = time.time()\n    with self.task.dataset.augmentation(augment):\n        for epoch in range(n_epochs):\n            # The default is to compute a steady state for each epoch, then\n            # it's computed here. Note: unless done per iteration, parameter updates\n            # within epochs are not considered in the steady state.\n            steady_state = self.network.steady_state(\n                t_pre=self.config.get(\"t_pre_train\", 0.5),\n                dt=self.task.dataset.dt,\n                batch_size=dataloader.batch_size,\n                value=0.5,\n            )\n\n            for _, data in enumerate(dataloader):\n\n                def handle_batch(data, steady_state):\n                    \"\"\"Closure to free memory by garbage collector effectively.\"\"\"\n\n                    # Resets the stimulus buffer (samples, frames, neurons).\n                    n_samples, n_frames, _, _ = data[\"lum\"].shape\n                    self.network.stimulus.zero(n_samples, n_frames)\n\n                    # Add batch of hex-videos (#frames, #samples, #hexals) as\n                    # photorecptor stimuli.\n                    self.network.stimulus.add_input(data[\"lum\"])\n\n                    # Reset gradients.\n                    self.optimizer.zero_grad()\n\n                    # Run stimulus through network.\n                    activity = self.network(\n                        self.network.stimulus(),\n                        self.task.dataset.dt,\n                        state=steady_state,\n                    )\n\n                    losses = {task: 0 for task in self.task.dataset.tasks}\n                    for task in self.task.dataset.tasks:\n                        y = data[task]\n                        y_est = self.decoder[task](activity)\n\n                        # to pass additional kwargs to the loss function, these\n                        # can either come from the decoder instance or from\n                        # the data batch from the dataset\n                        loss_kwargs = {\n                            **getattr(self.decoder[task], \"loss_kwargs\", {}),\n                            **data.get(\"loss_kwargs\", {}),\n                        }\n\n                        losses[task] = self.task.dataset.loss(\n                            y_est, y, task, **loss_kwargs\n                        )\n\n                    # Sum all task losses. The weighting of the tasks is done in the\n                    # loss function.\n                    loss = sum(losses.values())\n\n                    # Compute gradients.\n                    loss.backward(retain_graph=True)\n                    # Update parameters.\n                    self.optimizer.step()\n\n                    # Activity and parameter dependent penalties.\n                    self.penalty(activity=activity, iteration=self.iteration)\n\n                    # Log results.\n                    loss = loss.detach().cpu()\n                    for task in self.task.dataset.tasks:\n                        loss_per_task[f\"loss_{task}\"].append(\n                            losses[task].detach().cpu()\n                        )\n                    loss_over_iters.append(loss)\n                    activity = activity.detach().cpu()\n                    mean_activity = activity.mean()\n                    activity_over_iters.append(mean_activity)\n                    activity_min_over_iters.append(activity.min())\n                    activity_max_over_iters.append(activity.max())\n                    return loss, mean_activity\n\n                # Call closure.\n                loss, mean_activity = handle_batch(data, steady_state)\n\n                # Increment iteration count.\n                self.iteration += 1\n\n            # Interrupt training if the network explodes.\n            if torch.isnan(loss) or torch.isnan(mean_activity):\n                logging.warning(\"Network exploded.\")\n                raise OverflowError(\"Invalid values encountered in trace.\")\n\n            # The scheduling of hyperparams are functions of the iteration\n            # however, we allow steps only after full presentations of the data.\n            if epoch + 1 != n_epochs:\n                self.scheduler(self.iteration)\n                logging.info(\"Scheduled paremeters for iteration %s.\", self.iteration)\n\n            # Checkpointing.\n            if (epoch % chkpt_every_epoch == 0) or (epoch + 1 == n_epochs):\n                self.dir.loss = loss_over_iters\n                self.dir.activity = activity_over_iters\n                self.dir.activity_min = activity_min_over_iters\n                self.dir.activity_max = activity_max_over_iters\n\n                for task in self.task.dataset.tasks:\n                    self.dir[f\"loss_{task}\"] = loss_per_task[f\"loss_{task}\"]\n\n                self.checkpoint()\n\n            logging.info(\"Finished epoch.\")\n\n    time_elapsed = time.time() - start_time\n    time_trained = self.dir.time_trained[()] if \"time_trained\" in self.dir else 0\n    self.dir.time_trained = time_elapsed + time_trained\n    logging.info(\"Finished training.\")\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.MultiTaskSolver.checkpoint","title":"<code>checkpoint()</code>","text":"<p>Creates a checkpoint.</p> <p>Validates on the validation data calling ~self.test. Validates on a training batch calling ~self.track_batch. Stores a checkpoint of the network, decoder and optimizer parameters using pytorch\u2019s pickle function.</p> Stores <p>dir / chkpt_index.h5 (List): numerical identifier of the checkpoint. dir / chkpt_iter.h5 (List): iteration at which this checkpoint was recorded. dir / best_chkpt_index.h5 (int): chkpt index at which the val loss is minimal. dir / dt.h5 (float): the current time constant of the dataset. dir / chkpts / chkpt_ (dict): the state dicts of the network,     decoder and optimizer. Source code in <code>flyvision/solver.py</code> <pre><code>def checkpoint(self):\n    \"\"\"Creates a checkpoint.\n\n    Validates on the validation data calling ~self.test.\n    Validates on a training batch calling ~self.track_batch.\n    Stores a checkpoint of the network, decoder and optimizer parameters using\n    pytorch's pickle function.\n\n    Stores:\n        dir / chkpt_index.h5 (List): numerical identifier of the checkpoint.\n        dir / chkpt_iter.h5 (List): iteration at which this checkpoint was recorded.\n        dir / best_chkpt_index.h5 (int): chkpt index at which the val loss is\n        minimal.\n        dir / dt.h5 (float): the current time constant of the dataset.\n        dir / chkpts / chkpt_&lt;chkpt_index&gt; (dict): the state dicts of the network,\n            decoder and optimizer.\n    \"\"\"\n    self._last_chkpt_ind += 1\n    self._curr_chkpt_ind += 1\n\n    # Tracking of validation loss and training batch loss.\n    logging.info(\"Test on validation data.\")\n    val_loss = self.test(\n        dataloader=self.task.val_data, subdir=\"validation\", track_loss=True\n    )\n    logging.info(\"Test on validation batch.\")\n    _ = self.test(\n        dataloader=self.task.val_batch, subdir=\"validation_batch\", track_loss=True\n    )\n    logging.info(\"Test on training data.\")\n    _ = self.test(dataloader=self.task.train_data, subdir=\"training\", track_loss=True)\n    logging.info(\"Test on training batch.\")\n    _ = self.test(\n        dataloader=self.task.train_batch, subdir=\"training_batch\", track_loss=True\n    )\n\n    logging.info(\"Saving state dicts.\")\n    # Store state of pytorch modules.\n    nn_state_dict = self.network.state_dict()\n    dec_state_dict = {}\n    if self.decoder:\n        dec_state_dict = valmap(lambda x: x.state_dict(), self.decoder)\n    chkpt = {\n        \"network\": nn_state_dict,\n        \"decoder\": dec_state_dict,\n        \"optim\": self.optimizer.state_dict(),\n        \"time\": time.ctime(),\n        \"val_loss\": val_loss,\n        \"iteration\": self.iteration - 1,\n        \"dt\": self.task.dataset.dt,\n    }\n    if hasattr(self, \"penalty\"):\n        chkpt.update(self.penalty._chkpt())\n    torch.save(chkpt, self.checkpoint_path / f\"chkpt_{self._last_chkpt_ind:05}\")\n\n    # Append chkpt index.\n    self.checkpoints.append(self._last_chkpt_ind)\n    self.dir.extend(\"chkpt_index\", [self._last_chkpt_ind])\n    self.dir.extend(\"chkpt_iter\", [self.iteration - 1])\n    self.dir.dt = self.task.dataset.dt\n\n    # Overwrite best val loss.\n    if val_loss &lt; self._val_loss:\n        self.dir.best_chkpt_index = self._last_chkpt_ind\n        self._val_loss = val_loss\n\n    logging.info(\"Checkpointed.\")\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.MultiTaskSolver.test","title":"<code>test(dataloader, subdir='validation', track_loss=False, t_pre=0.25)</code>","text":"<p>Tests the network on a given dataloader.</p> <p>Parameters:</p> Name Type Description Default <code>dataloader</code> <code>DataLoader</code> <p>data to test on.</p> required <code>subdir</code> <code>str</code> <p>name of subdirectory. Defaults to \u2018validation\u2019.</p> <code>'validation'</code> <code>track_loss</code> <code>bool</code> <p>whether to store the loss in dir.subdir.</p> <code>False</code> <code>t_pre</code> <code>float</code> <p>warmup time before the stimulus starts.</p> <code>0.25</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>validation loss</p> Stores <p>dir..loss_ (List): loss per task, averaged over whole dataset. dir..iteration (List): iteration when this was called. dir..loss (List): average loss over tasks. Source code in <code>flyvision/solver.py</code> <pre><code>@torch.no_grad()\ndef test(\n    self,\n    dataloader: torch.utils.data.DataLoader,\n    subdir: str = \"validation\",\n    track_loss: bool = False,\n    t_pre: float = 0.25,\n) -&gt; float:\n    \"\"\"Tests the network on a given dataloader.\n\n    Args:\n        dataloader: data to test on.\n        subdir: name of subdirectory. Defaults to 'validation'.\n        track_loss: whether to store the loss in dir.subdir.\n        t_pre: warmup time before the stimulus starts.\n\n    Returns:\n        float: validation loss\n\n    Stores:\n        dir.&lt;subdir&gt;.loss_&lt;task&gt; (List): loss per task, averaged over whole dataset.\n        dir.&lt;subdir&gt;.iteration (List): iteration when this was called.\n        dir.&lt;subdir&gt;.loss (List): average loss over tasks.\n    \"\"\"\n    self._eval()\n    logging.info(\"Test\")\n\n    # Update hypterparams.\n    self.scheduler(self.iteration)\n\n    initial_state = self.network.steady_state(\n        t_pre=t_pre,\n        dt=self.task.dataset.dt,\n        batch_size=dataloader.batch_size,\n        value=0.5,\n    )\n    losses = {task: () for task in self.task.dataset.tasks}  # type: Dict[str, Tuple]\n\n    with self.task.dataset.augmentation(False):\n        for _, data in enumerate(dataloader):\n            n_samples, n_frames, _, _ = data[\"lum\"].shape\n            self.network.stimulus.zero(n_samples, n_frames)\n\n            self.network.stimulus.add_input(data[\"lum\"])\n\n            activity = self.network(\n                self.network.stimulus(),\n                self.task.dataset.dt,\n                state=initial_state,\n            )\n\n            for task in self.task.dataset.tasks:\n                y = data[task]\n                y_est = self.decoder[task](activity)\n\n                loss_kwargs = {\n                    **getattr(self.decoder[task], \"loss_kwargs\", {}),\n                    **data.get(\"loss_kwargs\", {}),\n                }\n                losses[task] += (\n                    self.task.dataset.loss(y_est, y, task, **loss_kwargs)\n                    .detach()\n                    .cpu()\n                    .item(),\n                )\n\n    # track loss per task.\n    avg_loss_per_task = {}\n    for task in self.task.dataset.tasks:\n        # average the loss over the whole dataset\n        avg_loss_per_task[task] = np.mean(losses[task])\n        if track_loss:\n            self.dir[subdir].extend(\"loss\" + \"_\" + task, [avg_loss_per_task[task]])\n\n    # average the loss over all tasks with equal weight\n    summed_loss = sum(avg_loss_per_task.values())\n    val_loss = summed_loss / len(avg_loss_per_task)\n\n    if track_loss:\n        self.dir[subdir].extend(\"iteration\", [self.iteration])\n        self.dir[subdir].extend(\"loss\", [val_loss])\n\n    self._train()\n\n    return val_loss\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.MultiTaskSolver.get_checkpoints","title":"<code>get_checkpoints(checkpoint='best', validation_subdir='validation', loss_file_name='loss')</code>","text":"<p>Returns the path to a checkpoint. This can be passed to the recover methods along with the nn.Module instances to create instances from checkpoints independently of the solver.</p> Source code in <code>flyvision/solver.py</code> <pre><code>def get_checkpoints(\n    self,\n    checkpoint: Union[int, str] = \"best\",\n    validation_subdir: str = \"validation\",\n    loss_file_name: str = \"loss\",\n):\n    \"\"\"Returns the path to a checkpoint. This can be passed to the recover methods\n    along with the nn.Module instances to create instances from checkpoints\n    independently of the solver.\n    \"\"\"\n    return resolve_checkpoints(\n        self.dir, checkpoint, validation_subdir, loss_file_name\n    )\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.MultiTaskSolver.recover","title":"<code>recover(network=True, decoder=True, optimizer=True, penalty=True, checkpoint='best', validation_subdir='validation', loss_file_name='loss', strict=True, force=False)</code>","text":"<p>Recovers the solver state from a checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>bool</code> <p>recover network parameters. Defaults to True.</p> <code>True</code> <code>decoder</code> <code>bool</code> <p>recover decoder parameters. Defaults to True.</p> <code>True</code> <code>optimizer</code> <code>bool</code> <p>recover optimizer parameters. Defaults to True.</p> <code>True</code> <code>penalty</code> <code>bool</code> <p>recover penalty parameters. Defaults to True.</p> <code>True</code> <code>checkpoint</code> <code>Union[int, str]</code> <p>index of the checkpoint to recover. Defaults to \u201cbest\u201d. \u201cbest\u201d for best based on tracked validation, -1 for last.</p> <code>'best'</code> <code>validation_subdir</code> <code>str</code> <p>name of the subdir to base the best checkpoint on. Required if checkpoint == \u2018best\u2019. Defaults to \u201cvalidation\u201d.</p> <code>'validation'</code> <code>loss_file_name</code> <code>str</code> <p>name of the loss to base the best checkpoint on. Defaults to \u201cepe\u201d. Assumed to be a subdir of validation.</p> <code>'loss'</code> <code>strict</code> <code>bool</code> <p>whether to load the state dict of the decoders strictly. Defaults to True.</p> <code>True</code> <code>force</code> <code>bool</code> <p>force recovery of checkpoint if _curr_chkpt_ind is arelady the same as the checkpoint index. Defaults to False.</p> <code>False</code> Source code in <code>flyvision/solver.py</code> <pre><code>def recover(\n    self,\n    network: bool = True,\n    decoder: bool = True,\n    optimizer: bool = True,\n    penalty: bool = True,\n    checkpoint: Union[\n        int, str\n    ] = \"best\",  # -1 for last, 'best' for best based on validation\n    validation_subdir: str = \"validation\",  # required if checkpoint == 'best'\n    loss_file_name: str = \"loss\",\n    strict: bool = True,\n    force: bool = False,\n):\n    \"\"\"Recovers the solver state from a checkpoint.\n\n    Args:\n        network: recover network parameters. Defaults to True.\n        decoder: recover decoder parameters. Defaults to True.\n        optimizer: recover optimizer parameters. Defaults to True.\n        penalty: recover penalty parameters. Defaults to True.\n        checkpoint: index of the checkpoint to recover. Defaults to \"best\".\n            \"best\" for best based on tracked validation, -1 for last.\n        validation_subdir: name of the subdir to base the best checkpoint on.\n            Required if checkpoint == 'best'. Defaults to \"validation\".\n        loss_file_name: name of the loss to base the best checkpoint on. Defaults\n            to \"epe\". Assumed to be a subdir of validation.\n        strict: whether to load the state dict of the decoders strictly.\n            Defaults to True.\n        force: force recovery of checkpoint if _curr_chkpt_ind is arelady\n            the same as the checkpoint index. Defaults to False.\n    \"\"\"\n    checkpoints = resolve_checkpoints(\n        self.dir, checkpoint, validation_subdir, loss_file_name\n    )\n\n    if checkpoint.index is None or not any((network, decoder, optimizer, penalty)):\n        logging.info(\"No checkpoint found. Continuing with initialized parameters.\")\n        return\n\n    if checkpoints.index == self._curr_chkpt_ind and not force:\n        logging.info(\"Checkpoint already recovered.\")\n        return\n\n    # Set the current and last checkpoint index. New checkpoints incrementally\n    # increase the last checkpoint index.\n    self._last_chkpt_ind = checkpoints.indices[-1]\n    self._curr_chkpt_ind = checkpoints.index\n\n    # Load checkpoint data.\n    state_dict = torch.load(checkpoints.path)\n    logging.info(f\"Checkpoint {checkpoints.path} loaded.\")\n\n    self.iteration = state_dict.get(\"iteration\", None)\n\n    if \"scheduler\" in self._initialized:\n        # Set the scheduler to the right iteration.\n        self.scheduler(self.iteration)\n\n    # The _val_loss variable is used to keep track of the best checkpoint according\n    # to the evaluation routine during training.\n    self._val_loss = state_dict.pop(\"val_loss\", float(\"inf\"))\n\n    if network and \"network\" in self._initialized:\n        recover_network(self.network, state_dict)\n    if decoder and \"decoder\" in self._initialized:\n        recover_decoder(self.decoder, state_dict, strict=strict)\n    if optimizer and \"optim\" in self._initialized:\n        recover_optimizer(self.optimizer, state_dict)\n    if penalty and \"penalties\" in self._initialized:\n        recover_penalty_optimizers(self.penalty.optimizers, state_dict)\n\n    logging.info(\"Recovered modules.\")\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.Penalty","title":"<code>Penalty</code>","text":"<p>Penalties on specific parameters.</p> <p>Parameters:</p> Name Type Description Default <code>solver</code> <code>MultiTaskSolver</code> <p>the solver instance.</p> required Example configurations passed to the network object Source code in <code>flyvision/solver.py</code> <pre><code>class Penalty:\n    \"\"\"Penalties on specific parameters.\n\n    Args:\n        solver (MultiTaskSolver): the solver instance.\n\n    Example configurations passed to the network object:\n        # Example 1: Penalize the resting potential of all cell types.\n        bias=Namespace(\n                type=\"RestingPotential\",\n                groupby=[\"type\"],\n                initial_dist=\"Normal\",\n                mode=\"sample\",\n                requires_grad=True,\n                mean=0.5,\n                std=0.05,\n                penalize=Namespace(activity=True),\n                seed=0,\n            )\n        # Example 2: add a weight decay penalty to all synapse strengths.\n        syn_strength=Namespace(\n                type=\"SynapseCountScaling\",\n                initial_dist=\"Value\",\n                requires_grad=True,\n                scale_elec=0.01,\n                scale_chem=0.01,\n                clamp=\"non_negative\",\n                groupby=[\"source_type\", \"target_type\", \"edge_type\"],\n                penalize=Namespace(function=\"weight_decay\", kwargs=dict(lambda=1e-3,)),\n            )\n    \"\"\"\n\n    solver: object\n    central_cells_index: np.ndarray\n    parameter_config: Namespace\n    activity_penalty: float\n    activity_baseline: float\n    activity_penalty_stop_iter: int\n    parameter_optim: torch.optim.Optimizer = None\n    activity_optim: torch.optim.Optimizer = None\n    optimizers: Dict[str, torch.optim.Optimizer]\n    default_optim: torch.optim.Optimizer = torch.optim.SGD\n\n    def __init__(self, penalty: Namespace, network: Network):\n        self.config = penalty\n        self.network = network\n        self.central_cells_index = self.network.connectome.central_cells_index[:]\n\n        self.parameter_config = self.get_configs()\n        self.init_optim()\n        self.init_hparams()\n\n    def __repr__(self):\n        return (\n            f\"Penalty(\"\n            f\"parameter_config={self.parameter_config}, \"\n            f\"activity_penalty={self.activity_penalty}, \"\n            f\"activity_baseline={self.activity_baseline}, \"\n            f\"activity_penalty_stop_iter={self.activity_penalty_stop_iter}, \"\n            f\"below_baseline_penalty_weight={self.below_baseline_penalty_weight}, \"\n            f\"above_baseline_penalty_weight={self.above_baseline_penalty_weight}\"\n            f\")\"\n        )\n\n    def __call__(self, activity, iteration):\n        \"\"\"Run all configured penalties.\"\"\"\n        if self.parameter_optim:\n            self.param_penalty_step()\n        if self.activity_optim:\n            if (\n                self.activity_penalty_stop_iter is None\n                or iteration &lt; self.activity_penalty_stop_iter\n            ):\n                self.activity_penalty_step(activity, retain_graph=False)\n            else:\n                self.activity_optim = None\n\n    def init_optim(self):\n        \"\"\"Initialize the individual optimizer instances with the correct set of\n        parameters.\"\"\"\n        self.optimizers = {}\n        self.param_list_func_pen = []\n        self.param_list_act_pen = []\n\n        # collect the parameters that need to be penalized\n        # either by a function or by activity\n        for name, config in self.parameter_config.items():\n            if \"function\" in config and any(list(config.kwargs.values())):\n                self.param_list_func_pen.append(name)\n            if getattr(config, \"activity\", False):\n                self.param_list_act_pen.append(name)\n\n        if self.param_list_func_pen:\n            self.parameter_optim = self.default_optim(\n                (getattr(self.network, param) for param in self.param_list_func_pen),\n                lr=1e-3,\n            )  # LR is overwritten by scheduler.\n            self.optimizers.update(dict(parameter_optim=self.parameter_optim))\n\n        if self.param_list_act_pen:\n            self.activity_optim = self.default_optim(\n                (getattr(self.network, param) for param in self.param_list_act_pen),\n                lr=1e-3,\n            )  # LR is overwritten by scheduler.\n            self.optimizers.update(dict(activity_optim=self.activity_optim))\n\n    def init_hparams(self):\n        \"\"\"Initialize the hyperparameters for the activity penalty.\"\"\"\n        config = self.config.get(\"activity_penalty\", Namespace())\n\n        # collecting activity penalty parameters\n        (\n            self.activity_penalty,\n            self.activity_baseline,\n            self.activity_penalty_stop_iter,\n            self.below_baseline_penalty_weight,\n            self.above_baseline_penalty_weight,\n        ) = (\n            config.get(\"activity_penalty\", None),\n            config.get(\"activity_baseline\", None),\n            config.get(\"stop_iter\", None),\n            config.get(\"below_baseline_penalty_weight\", None),\n            config.get(\"above_baseline_penalty_weight\", None),\n        )\n\n        if (\n            not any((\n                self.activity_penalty,\n                self.activity_baseline,\n                self.below_baseline_penalty_weight,\n                self.above_baseline_penalty_weight,\n            ))\n            and self.param_list_act_pen\n        ):\n            raise ValueError(\n                \"Activity penalty is enabled but no activity penalty parameters are \"\n                \"set.\"\n            )\n\n    def get_configs(self) -&gt; Namespace:\n        \"\"\"Returns a dictionary of all parameters that need to be penalized.\"\"\"\n        node_config = Namespace({\n            \"nodes_\" + k: v.pop(\"penalize\", None)\n            for k, v in self.network.config.node_config.deepcopy().items()\n        })\n        edge_config = Namespace({\n            \"edges_\" + k: v.pop(\"penalize\", None)\n            for k, v in self.network.config.edge_config.deepcopy().items()\n        })\n        return valfilter(\n            lambda v: v is not None,\n            Namespace(**node_config, **edge_config),\n            factory=Namespace,\n        )\n\n    def _chkpt(self):\n        \"\"\"Returns a dictionary of all state dicts of all optimizer instances.\"\"\"\n        _chkpt = {}\n        for key, optim in self.optimizers.items():\n            if optim is not None:\n                _chkpt[key] = optim.state_dict()\n        return _chkpt\n\n    def param_penalty_step(self):\n        \"\"\"Apply all the penalties on the individual parameters.\"\"\"\n        self.parameter_optim.zero_grad()\n        penalty = 0\n        for param, config in self.parameter_config.items():\n            if getattr(config, \"function\", False):\n                penalty += getattr(self, config.function)(param, config)\n        penalty.backward()\n        self.parameter_optim.step()\n        self.network.clamp()\n\n    def activity_penalty_step(self, activity, retain_graph=True):\n        \"\"\"Penalizes parameters tracked in activity_optim for too high or low acticity.\n\n        Encourages the central nodes to have a higher temporal mean activity, remedying\n        dead neurons.\n\n        Args:\n            activity (tensor): network activity of shape (n_samples, n_frames, n_nodes).\n        \"\"\"\n        self.activity_optim.zero_grad()\n        n_samples, n_frames, n_nodes = activity.shape\n        # the temporal average activity of the central nodes after a couple of frames\n        # to avoid the initial transient response\n        activity_mean = activity[:, n_frames // 4 :, self.central_cells_index].mean(\n            dim=1\n        )  # (n_samples, n_node_types)\n        penalty = (\n            self.activity_penalty\n            * (\n                asymmetric_weighting(\n                    self.activity_baseline - activity_mean,\n                    self.below_baseline_penalty_weight,\n                    self.above_baseline_penalty_weight,\n                )\n                ** 2\n            ).mean()\n        )\n        penalty.backward(retain_graph=retain_graph)\n        self.activity_optim.step()\n        self.network.clamp()\n\n    # -- Penalty functions --\n\n    def weight_decay(self, param, config):\n        \"\"\"Adds weight decay to the loss.\"\"\"\n        w = getattr(self.network, param)\n        return config.kwargs[\"lambda\"] * (w**2).sum()\n\n    def prior(self, param, config):\n        \"\"\"L2 penalty towards initial values.\"\"\"\n        _key = \"edge_config\" if param.startswith(\"edges\") else \"node_config\"\n        # TODO: check that this stores the actual initial values. This might be a\n        # convenient but suboptimal implementation if the initial values are cast\n        # to tensors at each iteration\n        prior = torch.tensor(\n            getattr(self.network.config, _key)[\n                param.replace(\"edges_\", \"\").replace(\"nodes_\", \"\")\n            ].value,\n            dtype=torch.float32,\n        )\n        return (\n            config.kwargs[\"lambda\"] * ((getattr(self.network, param) - prior) ** 2).sum()\n        )\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.Penalty--example-1-penalize-the-resting-potential-of-all-cell-types","title":"Example 1: Penalize the resting potential of all cell types.","text":"<p>bias=Namespace(         type=\u201dRestingPotential\u201d,         groupby=[\u201ctype\u201d],         initial_dist=\u201dNormal\u201d,         mode=\u201dsample\u201d,         requires_grad=True,         mean=0.5,         std=0.05,         penalize=Namespace(activity=True),         seed=0,     )</p>"},{"location":"reference/solver/#flyvision.solver.Penalty--example-2-add-a-weight-decay-penalty-to-all-synapse-strengths","title":"Example 2: add a weight decay penalty to all synapse strengths.","text":"<p>syn_strength=Namespace(         type=\u201dSynapseCountScaling\u201d,         initial_dist=\u201dValue\u201d,         requires_grad=True,         scale_elec=0.01,         scale_chem=0.01,         clamp=\u201dnon_negative\u201d,         groupby=[\u201csource_type\u201d, \u201ctarget_type\u201d, \u201cedge_type\u201d],         penalize=Namespace(function=\u201dweight_decay\u201d, kwargs=dict(lambda=1e-3,)),     )</p>"},{"location":"reference/solver/#flyvision.solver.Penalty.__call__","title":"<code>__call__(activity, iteration)</code>","text":"<p>Run all configured penalties.</p> Source code in <code>flyvision/solver.py</code> <pre><code>def __call__(self, activity, iteration):\n    \"\"\"Run all configured penalties.\"\"\"\n    if self.parameter_optim:\n        self.param_penalty_step()\n    if self.activity_optim:\n        if (\n            self.activity_penalty_stop_iter is None\n            or iteration &lt; self.activity_penalty_stop_iter\n        ):\n            self.activity_penalty_step(activity, retain_graph=False)\n        else:\n            self.activity_optim = None\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.Penalty.init_optim","title":"<code>init_optim()</code>","text":"<p>Initialize the individual optimizer instances with the correct set of parameters.</p> Source code in <code>flyvision/solver.py</code> <pre><code>def init_optim(self):\n    \"\"\"Initialize the individual optimizer instances with the correct set of\n    parameters.\"\"\"\n    self.optimizers = {}\n    self.param_list_func_pen = []\n    self.param_list_act_pen = []\n\n    # collect the parameters that need to be penalized\n    # either by a function or by activity\n    for name, config in self.parameter_config.items():\n        if \"function\" in config and any(list(config.kwargs.values())):\n            self.param_list_func_pen.append(name)\n        if getattr(config, \"activity\", False):\n            self.param_list_act_pen.append(name)\n\n    if self.param_list_func_pen:\n        self.parameter_optim = self.default_optim(\n            (getattr(self.network, param) for param in self.param_list_func_pen),\n            lr=1e-3,\n        )  # LR is overwritten by scheduler.\n        self.optimizers.update(dict(parameter_optim=self.parameter_optim))\n\n    if self.param_list_act_pen:\n        self.activity_optim = self.default_optim(\n            (getattr(self.network, param) for param in self.param_list_act_pen),\n            lr=1e-3,\n        )  # LR is overwritten by scheduler.\n        self.optimizers.update(dict(activity_optim=self.activity_optim))\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.Penalty.init_hparams","title":"<code>init_hparams()</code>","text":"<p>Initialize the hyperparameters for the activity penalty.</p> Source code in <code>flyvision/solver.py</code> <pre><code>def init_hparams(self):\n    \"\"\"Initialize the hyperparameters for the activity penalty.\"\"\"\n    config = self.config.get(\"activity_penalty\", Namespace())\n\n    # collecting activity penalty parameters\n    (\n        self.activity_penalty,\n        self.activity_baseline,\n        self.activity_penalty_stop_iter,\n        self.below_baseline_penalty_weight,\n        self.above_baseline_penalty_weight,\n    ) = (\n        config.get(\"activity_penalty\", None),\n        config.get(\"activity_baseline\", None),\n        config.get(\"stop_iter\", None),\n        config.get(\"below_baseline_penalty_weight\", None),\n        config.get(\"above_baseline_penalty_weight\", None),\n    )\n\n    if (\n        not any((\n            self.activity_penalty,\n            self.activity_baseline,\n            self.below_baseline_penalty_weight,\n            self.above_baseline_penalty_weight,\n        ))\n        and self.param_list_act_pen\n    ):\n        raise ValueError(\n            \"Activity penalty is enabled but no activity penalty parameters are \"\n            \"set.\"\n        )\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.Penalty.get_configs","title":"<code>get_configs()</code>","text":"<p>Returns a dictionary of all parameters that need to be penalized.</p> Source code in <code>flyvision/solver.py</code> <pre><code>def get_configs(self) -&gt; Namespace:\n    \"\"\"Returns a dictionary of all parameters that need to be penalized.\"\"\"\n    node_config = Namespace({\n        \"nodes_\" + k: v.pop(\"penalize\", None)\n        for k, v in self.network.config.node_config.deepcopy().items()\n    })\n    edge_config = Namespace({\n        \"edges_\" + k: v.pop(\"penalize\", None)\n        for k, v in self.network.config.edge_config.deepcopy().items()\n    })\n    return valfilter(\n        lambda v: v is not None,\n        Namespace(**node_config, **edge_config),\n        factory=Namespace,\n    )\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.Penalty.param_penalty_step","title":"<code>param_penalty_step()</code>","text":"<p>Apply all the penalties on the individual parameters.</p> Source code in <code>flyvision/solver.py</code> <pre><code>def param_penalty_step(self):\n    \"\"\"Apply all the penalties on the individual parameters.\"\"\"\n    self.parameter_optim.zero_grad()\n    penalty = 0\n    for param, config in self.parameter_config.items():\n        if getattr(config, \"function\", False):\n            penalty += getattr(self, config.function)(param, config)\n    penalty.backward()\n    self.parameter_optim.step()\n    self.network.clamp()\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.Penalty.activity_penalty_step","title":"<code>activity_penalty_step(activity, retain_graph=True)</code>","text":"<p>Penalizes parameters tracked in activity_optim for too high or low acticity.</p> <p>Encourages the central nodes to have a higher temporal mean activity, remedying dead neurons.</p> <p>Parameters:</p> Name Type Description Default <code>activity</code> <code>tensor</code> <p>network activity of shape (n_samples, n_frames, n_nodes).</p> required Source code in <code>flyvision/solver.py</code> <pre><code>def activity_penalty_step(self, activity, retain_graph=True):\n    \"\"\"Penalizes parameters tracked in activity_optim for too high or low acticity.\n\n    Encourages the central nodes to have a higher temporal mean activity, remedying\n    dead neurons.\n\n    Args:\n        activity (tensor): network activity of shape (n_samples, n_frames, n_nodes).\n    \"\"\"\n    self.activity_optim.zero_grad()\n    n_samples, n_frames, n_nodes = activity.shape\n    # the temporal average activity of the central nodes after a couple of frames\n    # to avoid the initial transient response\n    activity_mean = activity[:, n_frames // 4 :, self.central_cells_index].mean(\n        dim=1\n    )  # (n_samples, n_node_types)\n    penalty = (\n        self.activity_penalty\n        * (\n            asymmetric_weighting(\n                self.activity_baseline - activity_mean,\n                self.below_baseline_penalty_weight,\n                self.above_baseline_penalty_weight,\n            )\n            ** 2\n        ).mean()\n    )\n    penalty.backward(retain_graph=retain_graph)\n    self.activity_optim.step()\n    self.network.clamp()\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.Penalty.weight_decay","title":"<code>weight_decay(param, config)</code>","text":"<p>Adds weight decay to the loss.</p> Source code in <code>flyvision/solver.py</code> <pre><code>def weight_decay(self, param, config):\n    \"\"\"Adds weight decay to the loss.\"\"\"\n    w = getattr(self.network, param)\n    return config.kwargs[\"lambda\"] * (w**2).sum()\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.Penalty.prior","title":"<code>prior(param, config)</code>","text":"<p>L2 penalty towards initial values.</p> Source code in <code>flyvision/solver.py</code> <pre><code>def prior(self, param, config):\n    \"\"\"L2 penalty towards initial values.\"\"\"\n    _key = \"edge_config\" if param.startswith(\"edges\") else \"node_config\"\n    # TODO: check that this stores the actual initial values. This might be a\n    # convenient but suboptimal implementation if the initial values are cast\n    # to tensors at each iteration\n    prior = torch.tensor(\n        getattr(self.network.config, _key)[\n            param.replace(\"edges_\", \"\").replace(\"nodes_\", \"\")\n        ].value,\n        dtype=torch.float32,\n    )\n    return (\n        config.kwargs[\"lambda\"] * ((getattr(self.network, param) - prior) ** 2).sum()\n    )\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.HyperParamScheduler","title":"<code>HyperParamScheduler</code>","text":"<p>Schedules hyperparameters per training iteration.</p> <p>Calling the scheduler instance updates the respective hyperparameters per training iteration.</p> Source code in <code>flyvision/solver.py</code> <pre><code>class HyperParamScheduler:\n    \"\"\"Schedules hyperparameters per training iteration.\n\n    Calling the scheduler instance updates the respective hyperparameters per training\n    iteration.\n    \"\"\"\n\n    def __init__(\n        self,\n        scheduler: Namespace,\n        network: Optional[Network],\n        task: Optional[Task],\n        optimizer: Optional[torch.optim.Optimizer],\n        penalizer: Optional[Penalty],\n    ):\n        self.config = scheduler.deepcopy()\n        self.scheduled_params = self.config.deepcopy()\n        self.network = network\n        self.task = task\n        self.optimizer = optimizer\n        self.penalizer = penalizer\n\n        self.stop_iter = scheduler.get(\"sched_stop_iter\", self.task.n_iters)\n        self._current_iteration = 0\n\n        self.scheduled_params = Namespace()\n        for key, param in self.config.items():\n            try:\n                schedfn_config = SchedulerFunction(**param)\n                logging.info(f\"Init schedule for {key}\")\n            except TypeError:\n                # lazy way to skip the parameter if it's not a SchedulerFunction\n                continue\n\n            # these are the parameters that are scheduled\n            param.array = getattr(self, schedfn_config.function)(\n                self.stop_iter,\n                self.task.n_iters,\n                param.start,\n                param.stop,\n                param.steps,\n            )\n            self.scheduled_params[key] = param\n\n    def __call__(self, iteration):\n        self._current_iteration = iteration\n        for key, param in self.scheduled_params.items():\n            try:\n                setattr(self, key, param.array[iteration])\n            except IndexError as e:\n                if iteration &gt;= self.stop_iter:\n                    setattr(self, key, param.array[-1])\n                else:\n                    raise e\n        logging.info(self)\n\n    def __repr__(self):\n        return \"Scheduler. Iteration: {}/{}.\\nCurrent values: {}.\".format(\n            self._current_iteration,\n            self.task.n_iters,\n            self._params(),\n        )\n\n    def _params(self):\n        params = {}\n        for key, _param in self.scheduled_params.items():\n            value = getattr(self, key)\n            params[key] = value\n        return params\n\n    # -------- Decaying parameters\n\n    @property\n    def dt(self):\n        return self.task.dataset.dt\n\n    @dt.setter\n    def dt(self, value):\n        self.task.dataset.dt = value\n\n    @property\n    def lr_net(self):\n        if self.optimizer is None:\n            return\n        return self.optimizer.param_groups[0][\"lr\"]\n\n    @lr_net.setter\n    def lr_net(self, value):\n        if self.optimizer is None:\n            return\n        self.optimizer.param_groups[0][\"lr\"] = value\n\n    @property\n    def lr_dec(self):\n        if self.optimizer is None:\n            return\n        return [param_group[\"lr\"] for param_group in self.optimizer.param_groups[1:]]\n\n    @lr_dec.setter\n    def lr_dec(self, value):\n        if self.optimizer is None:\n            return\n        for param_group in self.optimizer.param_groups[1:]:\n            param_group[\"lr\"] = value\n\n    @property\n    def lr_pen(self):\n        if self.penalizer is None:\n            return\n        return [\n            param_group[\"lr\"]\n            for optim in self.penalizer.optimizers.values()\n            for param_group in optim.param_groups\n        ]\n\n    @lr_pen.setter\n    def lr_pen(self, value):\n        if self.penalizer is None:\n            return\n        for optim in self.penalizer.optimizers.values():\n            if optim is not None:\n                for param_group in optim.param_groups:\n                    param_group[\"lr\"] = value\n\n    @property\n    def relu_leak(self):\n        if self.network is None:\n            return\n        return getattr(self.network.dynamics.activation, \"negative_slope\", None)\n\n    @relu_leak.setter\n    def relu_leak(self, value):\n        if self.network is None:\n            return\n        if hasattr(self.network.dynamics.activation, \"negative_slope\"):\n            self.network.dynamics.activation.negative_slope = value\n\n    @property\n    def activity_penalty(self):\n        if self.penalizer is None:\n            return\n        return self.penalizer.activity_penalty\n\n    @activity_penalty.setter\n    def activity_penalty(self, value):\n        if self.penalizer is None:\n            return\n        self.penalizer.activity_penalty = value\n\n    # -------- Decay Options\n\n    @staticmethod\n    def linear(stop_iter, n_iterations, start, stop, steps):\n        f = np.linspace(start, stop, stop_iter)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n\n    @staticmethod\n    def stepwise(stop_iter, n_iterations, start, stop, steps):\n        f = np.linspace(start, stop, steps).repeat(stop_iter / steps)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n\n    @staticmethod\n    def stepwise_2ndhalf(stop_iter, n_iterations, start, stop, steps):\n        \"\"\"Decays within half of the iterations and remains constant then.\"\"\"\n        f = np.linspace(start, stop, steps).repeat((stop_iter / 2) / steps)\n        return np.pad(f, (n_iterations - len(f) + 1, 0), constant_values=start)\n\n    @staticmethod\n    def stepwise_half(stop_iter, n_iterations, start, stop, steps):\n        \"\"\"Decays within half of the iterations and remains constant then.\"\"\"\n        f = np.linspace(start, stop, steps).repeat((stop_iter / 2) / steps)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n\n    @staticmethod\n    def steponential(stop_iter, n_iterations, start, stop, steps):\n        x = (1 / stop) ** (1 / steps)\n        values = start / x ** np.arange(steps)\n        f = values.repeat(stop_iter / steps)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=values[-1])\n\n    @staticmethod\n    def steponential_inv(stop_iter, n_iterations, start, stop, steps):\n        _start = steps\n        _stop = 0\n        x = 1 / _stop\n        values = _start / x ** np.arange(steps)\n        f = values.repeat(stop_iter / steps)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=values[-1])\n\n    @staticmethod\n    def exponential(stop_iter, n_iterations, start, stop, steps):\n        tau = -stop_iter / (np.log(stop + 1e-15) - np.log(start))\n        f = start * np.exp(-np.arange(stop_iter) / tau)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n\n    @staticmethod\n    def exponential_half(stop_iter, n_iterations, start, stop, steps):\n        tau = -int((stop_iter / 2)) / (np.log(stop) - np.log(start))\n        f = start * np.exp(-np.arange(int(stop_iter / 2)) / tau)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.HyperParamScheduler.stepwise_2ndhalf","title":"<code>stepwise_2ndhalf(stop_iter, n_iterations, start, stop, steps)</code>  <code>staticmethod</code>","text":"<p>Decays within half of the iterations and remains constant then.</p> Source code in <code>flyvision/solver.py</code> <pre><code>@staticmethod\ndef stepwise_2ndhalf(stop_iter, n_iterations, start, stop, steps):\n    \"\"\"Decays within half of the iterations and remains constant then.\"\"\"\n    f = np.linspace(start, stop, steps).repeat((stop_iter / 2) / steps)\n    return np.pad(f, (n_iterations - len(f) + 1, 0), constant_values=start)\n</code></pre>"},{"location":"reference/solver/#flyvision.solver.HyperParamScheduler.stepwise_half","title":"<code>stepwise_half(stop_iter, n_iterations, start, stop, steps)</code>  <code>staticmethod</code>","text":"<p>Decays within half of the iterations and remains constant then.</p> Source code in <code>flyvision/solver.py</code> <pre><code>@staticmethod\ndef stepwise_half(stop_iter, n_iterations, start, stop, steps):\n    \"\"\"Decays within half of the iterations and remains constant then.\"\"\"\n    f = np.linspace(start, stop, steps).repeat((stop_iter / 2) / steps)\n    return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n</code></pre>"},{"location":"reference/tasks/","title":"Task","text":""},{"location":"reference/tasks/#decoder","title":"Decoder","text":""},{"location":"reference/tasks/#flyvision.task.decoder","title":"<code>decoder</code>","text":"<p>Modules for decoding the DMN activity.</p>"},{"location":"reference/tasks/#flyvision.task.decoder.ActivityDecoder","title":"<code>ActivityDecoder</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>flyvision/task/decoder.py</code> <pre><code>class ActivityDecoder(nn.Module):\n    dvs_channels: Dict[str, torch.Tensor]\n\n    def __init__(self, connectome):\n        \"\"\"ActivityDecoder.\n\n        Args:\n            connectome (Datawrap): connectome datawrap with keys\n                connectome.output_cell_types.\n        \"\"\"\n        super().__init__()\n        self.dvs_channels = LayerActivity(None, connectome, use_central=False)\n        self.num_parameters = n_params(self)\n        radius = connectome.config.extent\n        self.u, self.v = get_hex_coords(radius)\n        self.u -= self.u.min()\n        self.v -= self.v.min()\n        self.H, self.W = self.u.max() + 1, self.v.max() + 1\n\n    def forward(self, activity):\n        \"\"\"\n        Args:\n            activity (tensor): tensor of shape n_samples, n_frames, n_cells.\n\n        Returns:\n            tensor (tensor): tensor of shape\n                    n_samples, n_frames, output_cell_types, n_hexals.\n        \"\"\"\n        self.dvs_channels.update(activity)\n        return self.dvs_channels\n</code></pre>"},{"location":"reference/tasks/#flyvision.task.decoder.ActivityDecoder.__init__","title":"<code>__init__(connectome)</code>","text":"<p>ActivityDecoder.</p> <p>Parameters:</p> Name Type Description Default <code>connectome</code> <code>Datawrap</code> <p>connectome datawrap with keys connectome.output_cell_types.</p> required Source code in <code>flyvision/task/decoder.py</code> <pre><code>def __init__(self, connectome):\n    \"\"\"ActivityDecoder.\n\n    Args:\n        connectome (Datawrap): connectome datawrap with keys\n            connectome.output_cell_types.\n    \"\"\"\n    super().__init__()\n    self.dvs_channels = LayerActivity(None, connectome, use_central=False)\n    self.num_parameters = n_params(self)\n    radius = connectome.config.extent\n    self.u, self.v = get_hex_coords(radius)\n    self.u -= self.u.min()\n    self.v -= self.v.min()\n    self.H, self.W = self.u.max() + 1, self.v.max() + 1\n</code></pre>"},{"location":"reference/tasks/#flyvision.task.decoder.ActivityDecoder.forward","title":"<code>forward(activity)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>activity</code> <code>tensor</code> <p>tensor of shape n_samples, n_frames, n_cells.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>tensor</code> <p>tensor of shape     n_samples, n_frames, output_cell_types, n_hexals.</p> Source code in <code>flyvision/task/decoder.py</code> <pre><code>def forward(self, activity):\n    \"\"\"\n    Args:\n        activity (tensor): tensor of shape n_samples, n_frames, n_cells.\n\n    Returns:\n        tensor (tensor): tensor of shape\n                n_samples, n_frames, output_cell_types, n_hexals.\n    \"\"\"\n    self.dvs_channels.update(activity)\n    return self.dvs_channels\n</code></pre>"},{"location":"reference/tasks/#flyvision.task.decoder.GlobalAvgPool","title":"<code>GlobalAvgPool</code>","text":"<p>               Bases: <code>Module</code></p> <p>Returns the average over the last dimension.</p> Source code in <code>flyvision/task/decoder.py</code> <pre><code>class GlobalAvgPool(nn.Module):\n    \"\"\"Returns the average over the last dimension.\"\"\"\n\n    def forward(self, x):\n        return x.mean(dim=-1)\n</code></pre>"},{"location":"reference/tasks/#flyvision.task.decoder.Conv2dConstWeight","title":"<code>Conv2dConstWeight</code>","text":"<p>               Bases: <code>Conv2d</code></p> <p>Pytorch\u2019s Conv2d layer with optional constant weight initialization.</p> Source code in <code>flyvision/task/decoder.py</code> <pre><code>class Conv2dConstWeight(nn.Conv2d):\n    \"\"\"\n    Pytorch's Conv2d layer with optional constant weight initialization.\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel_size,\n        const_weight,\n        stride=1,\n        padding=0,\n        **kwargs,\n    ):\n        super().__init__(\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride=stride,\n            padding=padding,\n            **kwargs,\n        )\n        if const_weight is not None and self.weight is not None:\n            self.weight.data.fill_(const_weight)\n        if const_weight is not None and self.bias is not None:\n            self.bias.data.fill_(const_weight)\n</code></pre>"},{"location":"reference/tasks/#flyvision.task.decoder.Conv2dHexSpace","title":"<code>Conv2dHexSpace</code>","text":"<p>               Bases: <code>Conv2dConstWeight</code></p> <p>Convolution with regularly, hexagonally shaped filters (in cart. map storage).</p> <p>Reference to map storage: https://www.redblobgames.com/grids/hexagons/#map-storage</p> <p>Note: kernel_size must be odd!</p> Source code in <code>flyvision/task/decoder.py</code> <pre><code>class Conv2dHexSpace(Conv2dConstWeight):\n    \"\"\"\n    Convolution with regularly, hexagonally shaped filters (in cart. map storage).\n\n    Reference to map storage:\n    https://www.redblobgames.com/grids/hexagons/#map-storage\n\n    Note: kernel_size must be odd!\n    \"\"\"\n\n    _clip = False\n\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel_size,\n        const_weight=1e-3,\n        stride=1,\n        padding=0,\n        **kwargs,\n    ):\n        super().__init__(\n            in_channels,\n            out_channels,\n            kernel_size,\n            const_weight,\n            stride=stride,\n            padding=padding,\n            **kwargs,\n        )\n\n        if not kernel_size % 2:\n            raise ValueError(f\"{kernel_size} is even. Must be odd.\")\n        if kernel_size &gt; 1:\n            u, v = get_hex_coords(kernel_size // 2)\n            u -= u.min()\n            v -= v.min()\n            mask = np.zeros(tuple(self.weight.shape))\n            mask[:, :, u, v] = 1\n            self.mask = torch.tensor(mask, device=\"cpu\")\n            self.weight.data.mul_(self.mask.to(device))\n            self._filter_to_hex = True\n        else:\n            self._filter_to_hex = False\n\n    def filter_to_hex(self):\n        self.weight.data.mul_(self.mask.to(device))\n\n    def forward(self, x):\n        if self._filter_to_hex:\n            self.filter_to_hex()\n        return super().forward(x)\n</code></pre>"},{"location":"reference/tasks/#flyvision.task.decoder.DecoderGAVP","title":"<code>DecoderGAVP</code>","text":"<p>               Bases: <code>ActivityDecoder</code></p> <p>Fully convolutional decoder with optional global average pooling.</p> Source code in <code>flyvision/task/decoder.py</code> <pre><code>class DecoderGAVP(ActivityDecoder):\n    \"\"\"Fully convolutional decoder with optional global average pooling.\"\"\"\n\n    def __init__(\n        self,\n        connectome,\n        shape,\n        kernel_size,\n        p_dropout=0.5,\n        batch_norm=True,\n        n_out_features=None,\n        const_weight=None,\n        normalize_last=True,\n        activation=\"Softplus\",\n    ):\n        super().__init__(connectome)\n        p = int((kernel_size - 1) / 2)\n        in_channels = len(connectome.output_cell_types)\n        out_channels = shape[-1]\n        self._out_channels = out_channels\n        self.out_channels = (\n            out_channels * n_out_features if n_out_features is not None else out_channels\n        )\n        self.n_out_features = n_out_features\n\n        self.base = []\n        for c in shape[:-1]:\n            if c == 0:\n                continue\n            self.base.append(\n                Conv2dHexSpace(\n                    in_channels,\n                    c,\n                    kernel_size,\n                    const_weight=const_weight,\n                    padding=p,\n                )\n            )\n            if batch_norm:\n                self.base.append(nn.BatchNorm2d(c))\n            self.base.append(getattr(nn, activation)())\n            if p_dropout:\n                self.base.append(nn.Dropout(p_dropout))\n            in_channels = c\n        self.base = nn.Sequential(*self.base)\n\n        self.decoder = []\n        if len(self.base) == 0 and batch_norm:\n            self.decoder.append(nn.BatchNorm2d(in_channels))\n        self.decoder.append(\n            Conv2dHexSpace(\n                in_channels,\n                self.out_channels + 1 if normalize_last else self.out_channels,\n                kernel_size,\n                const_weight=const_weight,\n                padding=p,\n            )\n        )\n        self.decoder = nn.Sequential(*self.decoder)\n\n        self.n_out_features = n_out_features\n        self.head = []\n        if n_out_features is not None:\n            self.head.append(GlobalAvgPool())\n        self.head = nn.Sequential(*self.head)\n\n        self.normalize_last = normalize_last\n\n        self.num_parameters = n_params(self)\n        logging.info(f\"Initialized decoder with {self.num_parameters} parameters.\")\n        logging.info(repr(self))\n\n    def forward(self, activity):\n        self.dvs_channels.update(activity)\n        # Ensure that the outputs of the dvs-model are rectified potentials.\n        x = nnf.relu(self.dvs_channels.output)\n\n        # (n_frames, #samples, #outputneurons, n_hexals)\n        n_samples, n_frames, in_channels, n_hexals = x.shape\n\n        # Store hexals in square map.\n        # (n_frames, #samples, #outputneurons, H, W)\n        x_map = torch.zeros([n_samples, n_frames, in_channels, self.H, self.W])\n        x_map[:, :, :, self.u, self.v] = x\n\n        # Concatenate actual batch dimension with the frame dimension.\n        # torch.flatten(x_map, 0, 1)  # (#samples*n_frames, #outputneurons, H, W)\n        x_map = x_map.view(-1, in_channels, self.H, self.W)\n\n        # Run decoder.\n        # (n_frames*#samples, out_channels + 1, H, W)\n        out = self.decoder(self.base(x_map))\n\n        if self.normalize_last:\n            # Do some normalization with the additional channel.\n            # (n_frames*#samples, out_channels, H, W)\n            out = out[:, : self.out_channels] / (\n                nnf.softplus(out[:, self.out_channels :]) + 1\n            )\n\n        # Bring back into shape: # (#samples, n_frames, out_channels, n_hexals)\n        out = out.view(n_samples, n_frames, self.out_channels, self.H, self.W)[\n            :, :, :, self.u, self.v\n        ]\n\n        if self.n_out_features is not None:\n            out = self.head(out).view(\n                n_samples, n_frames, self._out_channels, self.n_out_features\n            )\n\n        return out\n</code></pre>"},{"location":"reference/tasks/#task-config","title":"Task config","text":""},{"location":"reference/tasks/#flyvision.task.tasks","title":"<code>tasks</code>","text":""},{"location":"reference/tasks/#flyvision.task.tasks.Task","title":"<code>Task</code>","text":"<p>Defines a task for a multi-task dataset from configurations.</p> Source code in <code>flyvision/task/tasks.py</code> <pre><code>class Task:\n    \"\"\"Defines a task for a multi-task dataset from configurations.\"\"\"\n\n    def __init__(\n        self,\n        dataset: Namespace,\n        decoder: Namespace,\n        loss: Namespace,\n        batch_size=4,\n        n_iters=250_000,\n        n_folds=4,\n        fold=1,\n        seed=0,\n        original_split=False,\n    ):\n        self.batch_size = batch_size\n        self.n_iters = n_iters\n        self.n_folds = n_folds\n        self.fold = fold\n        self.seed = seed\n        self.decoder = decoder\n\n        # Initialize dataset.\n        self.dataset = forward_subclass(MultiTaskDataset, dataset)  # type: MultiTaskDataset\n        self.dataset.losses = Namespace({\n            task: getattr(objectives, config) for task, config in loss.items()\n        })\n\n        if original_split:\n            self.train_seq_index, self.val_seq_index = (\n                self.dataset.original_train_and_validation_indices()\n            )\n        else:\n            self.train_seq_index, self.val_seq_index = self.dataset.get_random_data_split(\n                fold, n_folds, seed\n            )\n\n        # Initialize dataloaders.\n        self.train_data = DataLoader(\n            self.dataset,\n            batch_size=batch_size,\n            sampler=sampler.SubsetRandomSampler(self.train_seq_index),\n            drop_last=True,\n        )\n        self.train_batch = DataLoader(\n            self.dataset,\n            batch_size=batch_size,\n            sampler=IndexSampler(self.train_seq_index[:batch_size]),\n            drop_last=False,\n        )\n        logging.info(\n            \"Initialized dataloader with training sequence indices \\n\"\n            f\"{self.train_seq_index}\"\n        )\n\n        self.val_data = DataLoader(\n            self.dataset,\n            batch_size=1,\n            sampler=IndexSampler(self.val_seq_index),\n        )\n        self.val_batch = DataLoader(\n            self.dataset,\n            batch_size=batch_size,\n            sampler=IndexSampler(self.val_seq_index[:batch_size]),\n        )\n        logging.info(\n            \"Initialized dataloader with validation sequence indices \\n\"\n            f\"{self.val_seq_index}\"\n        )\n\n        # Initialize overfitting loader.\n        self.overfit_data = DataLoader(self.dataset, sampler=IndexSampler([0]))\n\n    def init_decoder(self, connectome):\n        return init_decoder(self.decoder, connectome)\n</code></pre>"},{"location":"reference/tasks/#flyvision.task.tasks.init_decoder","title":"<code>init_decoder(config, connectome)</code>","text":"<p>Initialize decoders.</p> <p>Returns:</p> Type Description <code>Dict[str, ActivityDecoder]</code> <p>Dict[str, ActivityDecoder]: A dictionary of decoders.</p> <p>Example config:</p> <pre><code>decoder = Namespace(\n    flow=Namespace(\n        type=\"DecoderGAVP\",\n        shape=[8, 2],\n        kernel_size=5,\n        const_weight=0.001,\n        p_dropout=0.5,\n    ),\n    depth=Namespace(\n        type=\"DecoderGAVP\",\n        shape=[8, 1],\n        kernel_size=5,\n        const_weight=0.001,\n        p_dropout=0.5,\n    ),\n    lum=Namespace(\n        type=\"DecoderGAVP\",\n        shape=[8, 3],\n        n_out_features=2,\n        kernel_size=5,\n        const_weight=0.001,\n        p_dropout=0.5,\n    ),\n    shared=False,\n)\n</code></pre> Source code in <code>flyvision/task/tasks.py</code> <pre><code>def init_decoder(config: Dict, connectome: ConnectomeDir) -&gt; Dict[str, ActivityDecoder]:\n    \"\"\"Initialize decoders.\n\n    Returns:\n        Dict[str, ActivityDecoder]: A dictionary of decoders.\n\n    Example config:\n\n        decoder = Namespace(\n            flow=Namespace(\n                type=\"DecoderGAVP\",\n                shape=[8, 2],\n                kernel_size=5,\n                const_weight=0.001,\n                p_dropout=0.5,\n            ),\n            depth=Namespace(\n                type=\"DecoderGAVP\",\n                shape=[8, 1],\n                kernel_size=5,\n                const_weight=0.001,\n                p_dropout=0.5,\n            ),\n            lum=Namespace(\n                type=\"DecoderGAVP\",\n                shape=[8, 3],\n                n_out_features=2,\n                kernel_size=5,\n                const_weight=0.001,\n                p_dropout=0.5,\n            ),\n            shared=False,\n        )\n    \"\"\"\n\n    config = config.deepcopy()\n\n    def init(conf):\n        return forward_subclass(ActivityDecoder, {**conf, \"connectome\": connectome})\n\n    decoder = valmap(init, config)\n\n    return decoder\n</code></pre>"},{"location":"reference/tasks/#objectives","title":"Objectives","text":""},{"location":"reference/tasks/#flyvision.task.objectives","title":"<code>objectives</code>","text":"<p>Loss functions compatible with torch loss function API.</p>"},{"location":"reference/tasks/#flyvision.task.objectives.l2norm","title":"<code>l2norm(y_est, y_gt, **kwargs)</code>","text":"<p>Mean root cumulative squared error across last three dimensions</p> Source code in <code>flyvision/task/objectives.py</code> <pre><code>def l2norm(y_est, y_gt, **kwargs):\n    \"\"\"\n    Mean root cumulative squared error across last three dimensions\n    \"\"\"\n    return (((y_est - y_gt) ** 2).sum(dim=(1, 2, 3))).sqrt().mean()\n</code></pre>"},{"location":"reference/tasks/#flyvision.task.objectives.epe","title":"<code>epe(y_est, y_gt, **kwargs)</code>","text":"<p>Average endpointerror, conventionally reported in optic flow tasks. Susceptible to outliers because it is squaring the errors.</p> <p>(#samples, #frames, ndim, #hexals or #features)</p> Source code in <code>flyvision/task/objectives.py</code> <pre><code>def epe(y_est, y_gt, **kwargs):\n    \"\"\"\n    Average endpointerror, conventionally reported in optic flow tasks.\n    Susceptible to outliers because it is squaring the errors.\n\n    (#samples, #frames, ndim, #hexals or #features)\n    \"\"\"\n    return torch.sqrt(((y_est - y_gt) ** 2).sum(dim=2)).mean()\n</code></pre>"}]}