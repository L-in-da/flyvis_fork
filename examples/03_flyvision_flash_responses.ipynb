{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uu-bb4z8t_lP"
   },
   "source": [
    "# Flash responses\n",
    "\n",
    "This notebook introduces flash responses and the flash response index (FRI). The FRI measures if a cell depolarizes to bright or to dark increments in a visual input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You can skip the next cells if you are not on google colab but run this locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXV7OZMrugGF"
   },
   "source": [
    "**Select GPU runtime**\n",
    "\n",
    "Only for usage on google colab: to run the notebook on a GPU select Menu -> Runtime -> Change runtime type -> GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "sWG39Aevugmr"
   },
   "outputs": [],
   "source": [
    "#@markdown **Check access to GPU**\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    import torch\n",
    "    try:\n",
    "      cuda_name = torch.cuda.get_device_name()\n",
    "      print(f\"Name of the assigned GPU / CUDA device: {cuda_name}\")\n",
    "    except RuntimeError:\n",
    "      import warnings\n",
    "      warnings.warn(\"You have not selected Runtime Type: 'GPU' or Google could not assign you one. Please revisit the settings as described above or proceed on CPU (slow).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-B9TA8nfzmN3"
   },
   "source": [
    "**Install Flyvis**\n",
    "\n",
    "The notebook requires installing our package `flyvis`. You may need to restart your session after running the code block below with Menu -> Runtime -> Restart session. Then, imports from `flyvis` should succeed without issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Dkhfe5XBuksW"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    #@markdown **Install Flyvis**\n",
    "    %%capture\n",
    "    !git clone https://github.com/flyvis/flyvis-dev.git\n",
    "    %cd /content/flyvis-dev\n",
    "    !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5ts-Vr9Uq3A"
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fz7783IyuwKs"
   },
   "source": [
    "## Flash stimuli\n",
    "\n",
    "To elicit flash responses, experimenters show a flashing dot to the subject in the center of their field of view. We generate and render these stimuli with the `Flashes` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5Hfyy3tyTQG"
   },
   "outputs": [],
   "source": [
    "# import dataset and visualization helper\n",
    "from flyvision.animations.hexscatter import HexScatter\n",
    "from flyvision.datasets.flashes import Flashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lI7elnklmcrh"
   },
   "outputs": [],
   "source": [
    "# initialize dataset\n",
    "dataset = Flashes(\n",
    "    dynamic_range=[0, 1],  # min and max pixel intensity values, must be in range [0, 1]\n",
    "    t_stim=1.0,  # duration of flash\n",
    "    t_pre=1.0,  # duration of period between flashes\n",
    "    dt=1 / 200,  # temporal resolution of rendered video\n",
    "    radius=[-1, 6],  # radius of flashing dot. -1 fills entire field of view\n",
    "    alternations=(0, 1, 0),  # flashing pattern, off - on - off\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "h5LOmW2RwYRv",
    "outputId": "fab46ba2-40d1-4689-bd1f-3e6a4e9bbecb"
   },
   "outputs": [],
   "source": [
    "# view stimulus parameters\n",
    "dataset.arg_df\n",
    "# the dataset has four samples, one corresponding to each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "7g9pyNQcmmbz",
    "outputId": "64d777d1-135a-4a68-a183-1681e21e2e2d"
   },
   "outputs": [],
   "source": [
    "# visualize single sample\n",
    "animation = HexScatter(\n",
    "    dataset[3][None, ::50, None], vmin=0, vmax=1\n",
    ")  # intensity=1, radius=6\n",
    "animation.animate_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9NDyBDbwqhd"
   },
   "source": [
    "## Network flash response\n",
    "\n",
    "Now that we have generated the stimulus, we can use it to drive a trained connectome-constrained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "freOR6U0GWzS"
   },
   "outputs": [],
   "source": [
    "from flyvision.network import NetworkView\n",
    "\n",
    "# model are already sorted by task error\n",
    "# we take the best task-performing model, model 0000\n",
    "network_view = NetworkView(\"opticflow/000/0000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YH1IS5XwupKG"
   },
   "outputs": [],
   "source": [
    "# rebuild network from checkpoint\n",
    "network = network_view.init_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJe0xut_7D7j"
   },
   "outputs": [],
   "source": [
    "# check out function for running network simulation\n",
    "help(network.simulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrRZHtrPTgYr"
   },
   "outputs": [],
   "source": [
    "# compute network responses to all flash stimuli\n",
    "# inputs should be of shape (#samples, #frames, 1, #hexals) so we unsqueeze the 2nd dimension\n",
    "responses = network.simulate(torch.stack(dataset[:]).unsqueeze(2), dt=dataset.dt)\n",
    "responses = responses.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMDaiOxA4Nn_"
   },
   "source": [
    "### FlashResponseView\n",
    "We've now computed network flash responses for all cells in the network. The `FlashResponseView` class allows us fast and flexible analysis and operations on the stored responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5Cqe7psSAl9"
   },
   "outputs": [],
   "source": [
    "from flyvision.analysis.flash_responses import FlashResponseView\n",
    "from flyvision.utils.nodes_edges_utils import CellTypeArray\n",
    "\n",
    "# extract cell responses in central column\n",
    "central_responses = responses[:, :, network.connectome.central_cells_index[:]]\n",
    "# wrap responses for easy access by cell type\n",
    "responses_array = CellTypeArray(\n",
    "    central_responses,\n",
    "    cell_types=network.connectome.unique_cell_types[:].astype(str),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4PRa8r84Kgt"
   },
   "outputs": [],
   "source": [
    "# initialize FlashResponseView\n",
    "frv = FlashResponseView(\n",
    "    arg_df=dataset.arg_df, config=dataset.config, responses=responses_array\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unO9i3aL5FaS"
   },
   "source": [
    "### Response traces\n",
    "\n",
    "We can plot single-cell response traces with `FlashResponseView.plot_traces()`. Here, we plot responses of L1 cells to flashes with radius 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "hVFv9WjqqlfP",
    "outputId": "75315389-668f-4105-fded-3ca98677c941"
   },
   "outputs": [],
   "source": [
    "# %#matplotlib inline\n",
    "fig, *_ = frv.plot_traces(\"L1\", radius=6)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FOTQtIR5RMu"
   },
   "source": [
    "### Flash response index (FRI)\n",
    "\n",
    "The flash response index (FRI) is a measure of the strength of contrast tuning of a particular cell. It is computed as the difference between the cell's peak voltage in response to on-flashes (intensity = 1) and off-flashes (intensity = 0), divided by the sum of those peak values.\n",
    "\n",
    "That is, given a single neuron's response to on-flashes `r_on` and off-flashes `r_off` (both of `shape=(T,)`), we can compute the flash response index with\n",
    "\n",
    "```\n",
    "r_on_max = max(r_on)\n",
    "r_off_max = max(r_off)\n",
    "fri = (r_on_max - r_off_max) / (r_on_max + r_off_max + 1e-16)\n",
    "```\n",
    "\n",
    "with the additional `1e-16` simply for numerical stability. Before this calculation, the response traces are shifted to be non-negative.\n",
    "\n",
    "The flash response index can take on values between $-1$, when the off response is much stronger (or more positive) than the on response, to $1$, when the on response is much stronger (or more positive) than the off response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSuPrIG97qwE"
   },
   "source": [
    "For the L1 cell plotted before, we can see that it displays a positive response to off flashes and a negative response to on flashes, so we expect a negative flash response index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WajUh0L8X-sO",
    "outputId": "46ac48f8-aba5-479e-e0b4-9e8704f2ea40"
   },
   "outputs": [],
   "source": [
    "# get FRI for L1 cell\n",
    "fri_l1 = frv.cell_type(\"L1\").fri(radius=6).responses.array.item()\n",
    "print(fri_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myPGKYPDTmES"
   },
   "source": [
    "### FRI correlation\n",
    "\n",
    "With the `fri()` function we can also compute FRIs for every cell type at once. Since the tuning of some cell types have been determined experimentally, we can then compare our model to experimental findings by computing the correlation between the model FRIs for known cell types with their expected tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwlNfeC_oXu-",
    "outputId": "0039cdb0-b3be-46b0-8146-d0b76ddf23ad"
   },
   "outputs": [],
   "source": [
    "from flyvision.analysis.flash_responses import fri_correlation_to_known\n",
    "from flyvision.utils.groundtruth_utils import polarity\n",
    "\n",
    "# compute FRis for all cell types\n",
    "fri_all = frv.fri(radius=6)\n",
    "# get FRi values and corresponding cell types\n",
    "fris = fri_all.responses.array[0]\n",
    "cell_types = fri_all.responses.cell_types\n",
    "# compute correlation\n",
    "fri_corr = fri_correlation_to_known(fris, cell_types)\n",
    "print(fri_corr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "bgCc9oKcXRAs",
    "outputId": "7e8cb29a-50e0-452e-85b2-2302621166a1"
   },
   "outputs": [],
   "source": [
    "# manually extract model and true FRIs for plotting\n",
    "known_cell_types = [k for k, v in polarity.items() if v != 0]\n",
    "model_fris = [fri_all.responses[k].item() for k in known_cell_types]\n",
    "true_fris = [polarity[k] for k in known_cell_types]\n",
    "# plot\n",
    "plt.figure(figsize=[2, 1])\n",
    "plt.scatter(model_fris, true_fris, color=\"k\", s=10)\n",
    "plt.xlabel(\"predicted FRI\")\n",
    "plt.ylabel(\"putative FRI (true tuning)\")\n",
    "plt.axvline(0, linestyle=\"--\", color=\"black\")\n",
    "plt.axhline(0, linestyle=\"--\", color=\"black\")\n",
    "\n",
    "plt.axhspan(0, 2, 0, 0.5, color=\"red\", zorder=-10)\n",
    "plt.axhspan(0, 2, 0.5, 1.0, color=\"green\", zorder=-10)\n",
    "plt.axhspan(-2, 0, 0, 0.5, color=\"green\", zorder=-10)\n",
    "plt.axhspan(-2, 0, 0.5, 1.0, color=\"red\", zorder=-10)\n",
    "\n",
    "plt.xlim(-1.05, 1.05)\n",
    "plt.ylim(-2, 2)\n",
    "plt.title(f\"Correlation = {fri_corr[0]}\")\n",
    "plt.yticks([-1, 1], [\"OFF\", \"ON\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3h50RJyZy2Q"
   },
   "source": [
    "As we can see, for all except two cell types, the model correctly predicts the cell's tuning (positive or negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrG_yZ6IaVdD"
   },
   "source": [
    "## Ensemble responses\n",
    "\n",
    "Now we can compare tuning properties across an ensemble of trained models. First we need to again simulate the network responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAci8A5MYu9d"
   },
   "outputs": [],
   "source": [
    "from flyvision.ensemble import EnsembleView\n",
    "\n",
    "ensemble = EnsembleView(\"opticflow/000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Xnl1wqFkPlp"
   },
   "outputs": [],
   "source": [
    "central_cells_index = ensemble[ensemble.names[0]].connectome.central_cells_index[:]\n",
    "with ensemble.ratio(\n",
    "    best=0.20\n",
    "):  # take only top 20% (10 in this case) of models, for speed\n",
    "    responses = np.stack(\n",
    "        [\n",
    "            resp[:, :, central_cells_index].copy()\n",
    "            for resp in ensemble.simulate(\n",
    "                torch.stack(dataset[:]).unsqueeze(2).to(\"cuda\"), dt=dataset.dt\n",
    "            )\n",
    "        ],\n",
    "        axis=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fy2rQgEBuXuj"
   },
   "source": [
    "We again use `FlashResponseView` to wrap around the network flash responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcHD3FkDqq6y"
   },
   "outputs": [],
   "source": [
    "responses_array = CellTypeArray(\n",
    "    responses,\n",
    "    cell_types=network.connectome.unique_cell_types[:].astype(str),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EQuiNYSt8LG"
   },
   "outputs": [],
   "source": [
    "frv = FlashResponseView(\n",
    "    arg_df=dataset.arg_df,\n",
    "    config=dataset.config,\n",
    "    responses=responses_array,\n",
    "    stim_sample_dim=1,\n",
    "    temporal_dim=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e342YYovvEPw"
   },
   "source": [
    "### Response traces\n",
    "\n",
    "We can once again plot response traces for a single cell type. We subtract the initial value of each trace to center the data before plotting, as the network neuron activities are in arbitrary units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "id": "iRbLjqKcvBkz",
    "outputId": "e9caffe4-0025-47e5-d195-a8805469bfeb"
   },
   "outputs": [],
   "source": [
    "centered = frv - frv.responses.array[:, :, [0]]\n",
    "fig, ax = centered.plot_traces(\"L1\", radius=6)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_O9bDAuGv8xC"
   },
   "source": [
    "Though the scaling varies, all networks recover the same tuning for L1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYgWkeNbwDbJ"
   },
   "source": [
    "### Flash response index (FRI)\n",
    "\n",
    "We can also compute flash response indices for each network in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIJcPWIKvLja",
    "outputId": "91048e37-8d39-48df-d956-c01e5da30c3f"
   },
   "outputs": [],
   "source": [
    "# get FRI for L1 cell\n",
    "fri_l1 = frv.cell_type(\"L1\").fri(radius=6).responses.array.squeeze().tolist()\n",
    "print(fri_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbKyqrQewUNf"
   },
   "source": [
    "All models recover similar flash response indices for this cell type. We can also plot the distribution of FRIs per cell type across the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXR0NcX4wQDc"
   },
   "outputs": [],
   "source": [
    "# compute FRIs for all cell types\n",
    "fri_all = frv.fri(radius=6)\n",
    "# get FRI values and corresponding cell types\n",
    "fris = fri_all.responses.array.squeeze()\n",
    "cell_types = fri_all.responses.cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "aqxdwgnswsUf",
    "outputId": "79230e4d-ecff-449e-9054-805c661b114b"
   },
   "outputs": [],
   "source": [
    "from flyvision.analysis.flash_responses import plot_fris\n",
    "\n",
    "fig, ax = plot_fris(\n",
    "    fris,\n",
    "    cell_types,\n",
    "    scatter_best=True,\n",
    "    scatter_all=True,\n",
    "    bold_output_type_labels=True,\n",
    "    output_cell_types=ensemble[ensemble.names[0]]\n",
    "    .connectome.output_cell_types[:]\n",
    "    .astype(str),\n",
    "    known_first=True,\n",
    "    figsize=[14, 2],\n",
    "    cmap=plt.cm.Greys_r,\n",
    "    ylim=(-1, 1),\n",
    "    color_known_types=True,\n",
    "    fontsize=10,\n",
    "    scatter_best_index=0,\n",
    "    scatter_best_color=plt.get_cmap(\"Blues\")(1.0),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhJO6lMvX3fo"
   },
   "source": [
    "### FRI correlation\n",
    "\n",
    "Lastly, we look at the correlations to ground-truth tuning across the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "Y8yyYrc7PgG0",
    "outputId": "bf69683d-811e-4307-e8e0-d1d957f29545"
   },
   "outputs": [],
   "source": [
    "from flyvision.plots.plots import violin_groups\n",
    "\n",
    "# compute correlation\n",
    "fri_corr = fri_correlation_to_known(fris, cell_types)\n",
    "\n",
    "fig, ax, *_ = violin_groups(\n",
    "    np.array(fri_corr)[None, None, :],\n",
    "    ylabel=\"FRI correlation\",\n",
    "    figsize=(2, 2),\n",
    "    xlim=(0, 1),\n",
    "    xticklabels=[],\n",
    "    colors=[plt.get_cmap(\"Pastel1\")(0.0)],\n",
    "    scatter_edge_color=\"gray\",\n",
    "    scatter_radius=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jorqXMxCZ4B4"
   },
   "source": [
    "Models in general have very good match to known single-neuron tuning properties, with median correlation around 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
