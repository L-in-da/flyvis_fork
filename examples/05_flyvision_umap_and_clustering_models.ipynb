{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster analysis based on naturalistic stimuli responses\n",
    "\n",
    "This notebook illustrates how to cluster the models of an ensemble after nonlinear dimensionality reduction on their predicted responses to naturalistic stimuli. This can be done for any cell type. Here we provide a detailed example focusing on clustering based on T4c responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select GPU runtime**\n",
    "\n",
    "To run the notebook on a GPU select Menu -> Runtime -> Change runtime type -> GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown **Check access to GPU**\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    import torch\n",
    "\n",
    "    try:\n",
    "        cuda_name = torch.cuda.get_device_name()\n",
    "        print(f\"Name of the assigned GPU / CUDA device: {cuda_name}\")\n",
    "    except RuntimeError:\n",
    "        import warnings\n",
    "\n",
    "        warnings.warn(\n",
    "            \"You have not selected Runtime Type: 'GPU' or Google could not assign you one. Please revisit the settings as described above or proceed on CPU (slow).\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install Flyvis**\n",
    "\n",
    "The notebook requires installing our package `flyvis`. You may need to restart your session after running the code block below with Menu -> Runtime -> Restart session. Then, imports from `flyvis` should succeed without issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    #@markdown **Install Flyvis**\n",
    "    %%capture\n",
    "    !git clone https://github.com/flyvis/flyvis-dev.git\n",
    "    %cd /content/flyvis-dev\n",
    "    !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naturalistic stimuli dataset (Sintel)\n",
    "We load the dataset with our custom augmentations. The dataset contains movie sequences from the publicly available computer-animated movie Sintel rendered to the hexagonal lattice structure of the fly eye. For a more detailed introduction to the dataset class and parameters see the notebook on the optic flow task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flyvision\n",
    "from flyvision.datasets.sintel import AugmentedSintel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1 / 200  # can be changed for other temporal resolutions\n",
    "dataset = AugmentedSintel(tasks=[\"lum\"], dt=dt, temporal_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view stimulus parameters\n",
    "dataset.arg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = dataset[0][\"lum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one sequence contains 80 frames with 721 hexals each\n",
    "sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = flyvision.animations.HexScatter(sequence[None], vmin=0, vmax=1)\n",
    "animation.animate_in_notebook(frames=np.arange(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble responses to a single sequence\n",
    "We compute the responses of all models in the stored ensemble to the first sequence of the augmented Sintel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyvision import results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We load the ensemble trained on the optic flow task\n",
    "ensemble = flyvision.ensemble.EnsembleView(results_dir / \"flow/0000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ensemble.simulate` provides an efficient method to return responses of all networks within the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = np.array(list(ensemble.simulate(sequence[None], dataset.dt, fade_in=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CentralActivity` is an interface to the response tensor of 45k cells that allows dict- and attribute-style access to the responses of the central cells of the different cell types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyvision.utils.activity_utils import CentralActivity\n",
    "\n",
    "central_responses = CentralActivity(responses, ensemble[0].connectome, keepref=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the central T4c responses for the whole ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = \"T4c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = sequence.shape[0]\n",
    "time = np.arange(0, n_frames * dataset.dt, dataset.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ensemble.task_error().colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = flyvision.plots.plt_utils.init_plot([2, 2], fontsize=5)\n",
    "for model_id, response in enumerate(central_responses[cell_type]):\n",
    "    r = response.squeeze()\n",
    "    ax.plot(\n",
    "        time,\n",
    "        (r - r[0]) / np.abs(r).max(),\n",
    "        c=colors[model_id],\n",
    "        zorder=len(ensemble) - model_id,\n",
    "    )\n",
    "ax.set_xlabel(\"time in s\", fontsize=5)\n",
    "ax.set_ylabel(\"response (a.u.)\", fontsize=5)\n",
    "ax.set_title(f\"{cell_type} responses across the ensemble\", fontsize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the across models of the ensemble the predictions for T4c vary. Our goal is to understand the underlying structure in those variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear dimensionality reduction (UMAP) and Gaussian Mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import subplot_mosaic\n",
    "\n",
    "from flyvision.analysis.clustering import EnsembleEmbedding, get_cluster_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters for umap embedding\n",
    "\n",
    "embedding_kwargs = {\n",
    "    \"min_dist\": 0.105,\n",
    "    \"spread\": 9.0,\n",
    "    \"n_neighbors\": 5,\n",
    "    \"random_state\": 42,\n",
    "    \"n_epochs\": 1500,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the UMAP embedding of the ensemble based on the T4c responses of the single models to the single sequence for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_responses[:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = EnsembleEmbedding(central_responses)\n",
    "t4c_embedding = embedding(\"T4c\", embedding_kwargs=embedding_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_error = ensemble.task_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = t4c_embedding.plot(colors=task_error.colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these scatterpoints in 2d represents a single time series plotted above.\n",
    "\n",
    "We fit a Gaussian Mixture of 2 to 5 components to this embedding to label the clusters. We select the final number of Gaussian Mixture components that minimize the Bayesian Information Criterion (BIC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifiy parameters for Gaussian Mixture\n",
    "\n",
    "gm_kwargs = {\n",
    "    \"range_n_clusters\": [1, 2, 3, 4, 5],\n",
    "    \"n_init\": 100,\n",
    "    \"max_iter\": 1000,\n",
    "    \"random_state\": 42,\n",
    "    \"tol\": 0.001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_clustering = t4c_embedding.cluster.gaussian_mixture(**gm_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingplot = gm_clustering.plot(\n",
    "    task_error=task_error.values, colors=task_error.colors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the labels to disambiguate the time series data that we plotted above. We expect that these labels aggregate similar time series together and different time series separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_indices = get_cluster_to_indices(\n",
    "    embeddingplot.cluster.embedding.mask,\n",
    "    embeddingplot.cluster.labels,\n",
    "    ensemble.task_error(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = {}\n",
    "CMAPS = [\"Blues_r\", \"Reds_r\", \"Greens_r\", \"Oranges_r\", \"Purples_r\"]\n",
    "\n",
    "for cluster_id in cluster_to_indices:\n",
    "    cluster_colors[cluster_id] = ensemble.task_error(cmap=CMAPS[cluster_id]).colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = flyvision.plots.plt_utils.init_plot([2, 2], fontsize=5)\n",
    "for cluster_id, model_ids in cluster_to_indices.items():\n",
    "    for model_id, response in zip(\n",
    "        model_ids, central_responses[cell_type][np.array(model_ids)]\n",
    "    ):\n",
    "        r = response.squeeze()\n",
    "        ax.plot(\n",
    "            time, (r - r[0]) / np.abs(r).max(), c=cluster_colors[cluster_id][model_id]\n",
    "        )\n",
    "\n",
    "ax.set_xlabel(\"time in s\", fontsize=5)\n",
    "ax.set_ylabel(\"response (a.u.)\", fontsize=5)\n",
    "ax.set_title(f\"{cell_type} responses across the ensemble\", fontsize=5)\n",
    "ylim = ax.get_ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes, _ = flyvision.plots.plt_utils.get_axis_grid(\n",
    "    cluster_to_indices, fontsize=5, figsize=[5, 4], wspace=0.3, hspace=0.5\n",
    ")\n",
    "for cluster_id, model_ids in cluster_to_indices.items():\n",
    "    ax = axes[cluster_id]\n",
    "    for model_id, response in zip(\n",
    "        model_ids, central_responses[cell_type][np.array(model_ids)]\n",
    "    ):\n",
    "        r = response.squeeze()\n",
    "        ax.plot(\n",
    "            time, (r - r[0]) / np.abs(r).max(), c=cluster_colors[cluster_id][model_id]\n",
    "        )\n",
    "    ax.set_xlabel(\"time in s\", fontsize=5)\n",
    "    ax.set_ylabel(\"response (a.u.)\", fontsize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering has led us to 5 qualitatively distinct predictions from the ensemble for this cell and sequence. This is a first lead for an underlying structure in these predictions. We will get an even better estimate once we use more sequences for the clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering based on the ensemble responses to the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyvision.utils.activity_utils import StimulusResponseIndexer\n",
    "from flyvision.utils.activity_utils import CellTypeArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this analysis is costly, we randomly select a subset of samples from the dataset of 2268 sequences to illustrate how it scales (one may set 'indices' to None to compute all responses). We can also include only the best x-% of models if we wanted. Skip ahead to the next section to download the precomputed clusterings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "indices = np.random.choice(np.arange(len(dataset)), replace=False, size=64)\n",
    "\n",
    "\n",
    "with ensemble.ratio(best=1.0):\n",
    "    responses = np.stack(\n",
    "        list(\n",
    "            ensemble.simulate_from_dataset(\n",
    "                dataset,\n",
    "                dt=1 / 200,\n",
    "                indices=indices,\n",
    "                batch_size=4,\n",
    "                central_cell_only=True,\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_df = dataset.arg_df.loc[indices].reset_index(drop=True)\n",
    "sri = StimulusResponseIndexer(\n",
    "    arg_df,\n",
    "    CellTypeArray(responses, ensemble[0].connectome),\n",
    "    dt=dataset.dt,\n",
    "    t_pre=0,\n",
    "    temporal_dim=2,\n",
    "    stim_sample_dim=1,\n",
    ")\n",
    "\n",
    "centered = sri - sri.responses.array[:, :, [0]]\n",
    "centered /= sri.abs().max(dims=(1, 2), keepdims=True)\n",
    "\n",
    "centered.plot_traces(\"T4c\", plot_kwargs=dict(legend=[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we plot the centered T4c responses across all models and stimuli we see again lots of structure. The amount of data would now make it difficult to disambiguate them all at this scale manually. It would also be easier to interpret differences in responses to simple stimuli rather than to naturalistic stimuli.\n",
    "\n",
    "That's why we again first compute a non-linear dimensionality reduction of these traces to 2d and then we cluster to understand the structure in the dataset. The dim. reduction just pretends that traces from individual movie sequences are a single long trace that needs to be embedded. Afterwards we interpret differences in these clusters in responses to simple stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_responses = CentralActivity(responses, ensemble[0].connectome, keepref=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = EnsembleEmbedding(central_responses)\n",
    "t4c_embedding = embedding(\"T4c\", embedding_kwargs=embedding_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_kwargs = {'range_n_clusters': [2, 3, 3, 4, 5],\n",
    " 'n_init': 100,\n",
    " 'max_iter': 1000,\n",
    " 'random_state': 42,\n",
    " 'tol': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ensemble.ratio(best=1.0):\n",
    "    task_error = ensemble.task_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "embeddingplot = t4c_embedding.cluster.gaussian_mixture(**gm_kwargs).plot(\n",
    "    task_error=task_error.values, colors=task_error.colors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clustering looks already very close to the result in the paper! Note though that this is still based on a small subset of the Sintel dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the clustering to discover tuning predictions in responses to simple stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect that the clustering based on naturalistic stimuli will also disambiguate the different tuning predictions from different models for simple stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_indices = get_cluster_to_indices(\n",
    "    embeddingplot.cluster.embedding.mask,\n",
    "    embeddingplot.cluster.labels,\n",
    "    ensemble.task_error(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define different colormaps for clusters\n",
    "cluster_colors = {}\n",
    "CMAPS = [\"Blues_r\", \"Reds_r\", \"Greens_r\", \"Oranges_r\", \"Purples_r\"]\n",
    "\n",
    "for cluster_id in cluster_to_indices:\n",
    "    cluster_colors[cluster_id] = ensemble.task_error(cmap=CMAPS[cluster_id]).colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustered voltage responses to moving edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyvision.datasets.moving_bar import MovingEdge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mer_dataset = MovingEdge(\n",
    "    offsets=[-10, 11],  # offset of bar from center in 1 * radians(2.25) led size\n",
    "    intensities=[0, 1],  # intensity of bar\n",
    "    speeds=[19],  # speed of bar in 1 * radians(5.8) / s\n",
    "    height=80,  # height of moving bar in 1 * radians(2.25) led size\n",
    "    post_pad_mode=\"continue\",  # for post-stimulus period, continue with the last frame of the stimulus\n",
    "    t_pre=1.0,  # duration of pre-stimulus period\n",
    "    t_post=1.0,  # duration of post-stimulus period\n",
    "    dt=1 / 200,  # temporal resolution of rendered video\n",
    "    angles=list(np.arange(0, 360, 30)),  # motion direction (orthogonal to edge)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_cells_index = ensemble[0].connectome.central_cells_index[:]\n",
    "with ensemble.ratio(best=1.0):  # take only top 20% (10 in this case) of models\n",
    "    mer = np.stack(\n",
    "        list(\n",
    "            ensemble.simulate_from_dataset(\n",
    "                mer_dataset,\n",
    "                dt=mer_dataset.dt,\n",
    "                batch_size=4,\n",
    "                central_cell_only=True,\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_array = CellTypeArray(\n",
    "    mer,\n",
    "    cell_types=ensemble[0].connectome.unique_cell_types[:].astype(str),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyvision.analysis.moving_bar_responses import MovingEdgeResponseView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merv = MovingEdgeResponseView(\n",
    "    arg_df=mer_dataset.arg_df,\n",
    "    responses=responses_array,\n",
    "    config=mer_dataset.config,\n",
    "    stim_sample_dim=1,\n",
    "    temporal_dim=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered = (\n",
    "    merv.between_seconds(-0.5, 1.0)\n",
    "    - merv.between_seconds(-0.5, 1.0).responses.array[:, :, [0]]\n",
    ")\n",
    "centered /= centered.abs().max(dims=(1, 2), keepdims=True)\n",
    "centered.plot_traces(\n",
    "    cell_type=\"T4c\",\n",
    "    angle=90,\n",
    "    intensity=1,\n",
    "    plot_kwargs=dict(figsize=(2.4, 1.8), fontsize=6),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes, _ = flyvision.plots.plt_utils.get_axis_grid(\n",
    "    cluster_to_indices, fontsize=5, figsize=[5, 4], wspace=0.3, hspace=0.5\n",
    ")\n",
    "for cluster_id, model_ids in cluster_to_indices.items():\n",
    "    ax = axes[cluster_id]\n",
    "    centered[model_ids, :, :].plot_traces(\n",
    "        cell_type=\"T4c\",\n",
    "        angle=90,\n",
    "        intensity=1,\n",
    "        plot_kwargs=dict(\n",
    "            figsize=(2.4, 1.8),\n",
    "            fontsize=6,\n",
    "            fig=fig,\n",
    "            ax=ax,\n",
    "            title=f\"cluster {cluster_id}\",\n",
    "            color=cluster_colors[cluster_id][model_ids]\n",
    "        ),\n",
    "    )\n",
    "    ax.set_xlabel(\"time in s\", fontsize=5)\n",
    "    ax.set_ylabel(\"response (a.u.)\", fontsize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustered peak voltage responses to moving edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merv.plot_angular_tuning(cell_type=\"T4c\", intensity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes, _ = flyvision.plots.plt_utils.get_axis_grid(\n",
    "    cluster_to_indices,\n",
    "    fontsize=5,\n",
    "    figsize=[5, 4],\n",
    "    wspace=0.3,\n",
    "    hspace=0.5,\n",
    "    projection=\"polar\",\n",
    ")\n",
    "for cluster_id, model_ids in cluster_to_indices.items():\n",
    "    ax = axes[cluster_id]\n",
    "    merv[model_ids, :, :].plot_angular_tuning(\n",
    "        cell_type=\"T4c\", intensity=1, colors=cluster_colors[cluster_id][model_ids],\n",
    "        fig=fig, ax=ax\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, the models quite nicely predict clustered neural responses. We discovered all of these clusters simply by using UMAP and Gaussian Mixtures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load precomputed umap and clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the computational requirement of recording and embedding all responses and for consistency we also show how to use the precomputed embeddings and clusterings from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = \"T4c\"\n",
    "clustering = ensemble.clustering(cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_error = ensemble.task_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingplot = clustering.plot(task_error=task_error.values,\n",
    "                                colors=task_error.colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this embedding and clustering one can proceed in the same way as above to plot the tunings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.398px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
