{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321052ca",
   "metadata": {},
   "source": [
    "# Optic flow task\n",
    "\n",
    "\n",
    "This notebook illustrates the optic flow task and how to use it with our pretrained fly visual system model and decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e57181",
   "metadata": {},
   "source": [
    "# The Sintel dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828f1e0",
   "metadata": {},
   "source": [
    "We use the Sintel dataset to train out models as described in the paper. More infos about the Sintel dataset can be found on the official Sintel website: http://sintel.is.tue.mpg.de/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccced4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from flyvision.datasets.sintel import MultiTaskSintel\n",
    "from flyvision.animations.sintel import SintelSample\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d04d4",
   "metadata": {},
   "source": [
    "The class `MultiTaskSintel` loads, preprocesses, renders, and augments the sintel data. It adheres to the pytorch dataset primitive. It provides the interface to the input data and the output data for the flyvision networks. Note: the fly-eye rendering we use here we introduce in notebook 7 already.\n",
    "\n",
    "This is the full setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiTaskSintel(tasks=[\"flow\"],\n",
    "        boxfilter=dict(extent=15, kernel_size=13),\n",
    "        # Because the fly eye rendering is square \n",
    "        # and sintel is wide, we can crop sintel \n",
    "        # in width and render three sequences from one. \n",
    "        # This allows us to statically augment our dataset \n",
    "        # a bit already before we proceed with the random augmentations. \n",
    "        # We end up with 3 * 23 sequences. \n",
    "        vertical_splits=3,\n",
    "        n_frames=19,\n",
    "        center_crop_fraction=0.7,\n",
    "        dt=1 / 50,\n",
    "        augment=True,\n",
    "        # From sequences with more than n_frames, we randomly sample the start frame.\n",
    "        random_temporal_crop=True,\n",
    "        all_frames=False,\n",
    "        # We resample movie frames to the effective framerate given by 1/dt\n",
    "        resampling=True,\n",
    "        # We interpolate the flow arrows to 1/dt.\n",
    "        interpolate=True,\n",
    "        # We flip with equal probability (using one flip-axis).\n",
    "        p_flip=0.5,\n",
    "        # We rotate with equal probability (using five fold rotation symmetry of the hex-grid).\n",
    "        p_rot=5 / 6,\n",
    "        # We randomly adjust contrast and brightness.\n",
    "        contrast_std=0.2,\n",
    "        brightness_std=0.1,\n",
    "        # We add random white noise pixelweise.\n",
    "        gaussian_white_noise=0.08,\n",
    "        gamma_std=None,\n",
    "        _init_cache=True,\n",
    "        unittest=False,\n",
    "        flip_axes=[0, 1],\n",
    "        task_weights=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100cfd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `dataset.arg_df` tracks the sequence index, identity etc.\n",
    "dataset.arg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c644434",
   "metadata": {},
   "source": [
    "## Single sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31dee12",
   "metadata": {},
   "source": [
    "First, let's chunk this into smaller digestable pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8815b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiTaskSintel(\n",
    "    tasks=[\"flow\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=1,\n",
    "    dt=1 / 24,\n",
    "    augment=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80862c9",
   "metadata": {},
   "source": [
    "The first sample. For the target, the pixel-accurate motion vectors, the color indicates the direction of motion of the respective input pixel. The saturation indicates the magnitude of motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "lum = dataset[0][\"lum\"]\n",
    "flow = dataset[0][\"flow\"]\n",
    "\n",
    "animation = SintelSample(lum[None], flow[None])\n",
    "animation.animate_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972c819",
   "metadata": {},
   "source": [
    "Sintel has more groundtruth annotations. We support depth and flow because we know with certainty that these are relevant for the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a61180",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiTaskSintel(\n",
    "    tasks=[\"depth\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=1,\n",
    "    dt=1 / 24,\n",
    "    augment=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3563cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lum1 = dataset[0][\"lum\"]\n",
    "depth1 = dataset[0][\"depth\"]\n",
    "\n",
    "animation = SintelSample(lum1[None], depth1[None])\n",
    "animation.animate_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995a27ac",
   "metadata": {},
   "source": [
    "# Augmenting the dataset step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44b341",
   "metadata": {},
   "source": [
    "We apply rich augmentations to the dataset of naturalistic sequences because the dataset is otherwise relatively small. This might lead to overfitting to, e.g., predicting motion mostly into well-represented directons or of objects of specific contrasts etc. Using rich augmentations, we 'ask' the network to generalize better and invariantly compute motion regardless of direction, contrast, brightness, pixel noise, temporal appearance etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1704218",
   "metadata": {},
   "source": [
    "## Vertical splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2f65f",
   "metadata": {},
   "source": [
    "First, we split each sequence into three sequences vertically to leverage a wider extent of the video than if we would only render the center. We precompute these renderings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42de189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyvision.plots.plots import quick_hex_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8884486",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiTaskSintel(\n",
    "    tasks=[\"flow\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=3,\n",
    "    dt=1 / 24,\n",
    "    augment=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318ee23",
   "metadata": {},
   "source": [
    "Sintel has 23 movie sequences originally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedcac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(dataset.arg_df.original_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc35f13",
   "metadata": {},
   "source": [
    "Each original sequence is 436 pixel in height times 1024 pixel in width in cartesian coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = dataset.cartesian_sequence(0, vertical_splits=1, center_crop_fraction=1.0)\n",
    "print(sequence.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841a6f86",
   "metadata": {},
   "source": [
    "With the vertical crops, we end up with 3 * 23 sequences. The `dataset.arg_df` tracks the sequence index, identity etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.arg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.imshow(sequence[0, 0], cmap=plt.cm.binary_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ee479",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3)\n",
    "_ = quick_hex_scatter(dataset[0]['lum'][0].flatten(), fig=fig, ax=axes[0], cbar=False)\n",
    "_ = quick_hex_scatter(dataset[1]['lum'][0].flatten(), fig=fig, ax=axes[1], cbar=False)\n",
    "_ = quick_hex_scatter(dataset[2]['lum'][0].flatten(), fig=fig, ax=axes[2], cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106bb40c",
   "metadata": {},
   "source": [
    "## Random temporal crops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c1f76",
   "metadata": {},
   "source": [
    "We train on 19 frames ~ 792ms movie. Most sequences have 49 frames. To use the whole temporal content, we stochastically sample start and end frame ~ ((1, 19), (2, 20), ..., (31, 49))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0000cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiTaskSintel(\n",
    "    tasks=[\"flow\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=3,\n",
    "    n_frames=19,\n",
    "    dt=1 / 24,\n",
    "    augment=True,\n",
    "    random_temporal_crop=True,\n",
    "    all_frames=False,\n",
    "    resampling=False,\n",
    "    interpolate=False,\n",
    "    p_flip=0,\n",
    "    p_rot=0,\n",
    "    contrast_std=None,\n",
    "    brightness_std=None,\n",
    "    gaussian_white_noise=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4165bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two samples from the same original sequence should have stochastically different start and end frames.\n",
    "lum1 = dataset[0]['lum']\n",
    "lum2 = dataset[0]['lum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a893d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = SintelSample(lum1[None], lum2[None], title2=\"input\")\n",
    "animation.animate_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f1d233",
   "metadata": {},
   "source": [
    "## Flips and rotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b405c781",
   "metadata": {},
   "source": [
    "Next, we flip stochastically across 2 axes and or rotate a random number of times around the center. We implement this to be fast to do so at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiTaskSintel(\n",
    "    tasks=[\"flow\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=3,\n",
    "    n_frames=19,\n",
    "    dt=1 / 24,\n",
    "    augment=True,\n",
    "    random_temporal_crop=False,\n",
    "    all_frames=False,\n",
    "    resampling=False,\n",
    "    interpolate=False,\n",
    "    p_flip=1/2,\n",
    "    p_rot=5/6,\n",
    "    contrast_std=None,\n",
    "    brightness_std=None,\n",
    "    gaussian_white_noise=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two samples from the same original sequence should have stochastically different orientation.\n",
    "lum1 = dataset[0]['lum']\n",
    "lum2 = dataset[0]['lum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ed843",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = SintelSample(lum1[None], lum2[None], title2=\"input\")\n",
    "animation.animate_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ef94f4",
   "metadata": {},
   "source": [
    "Flow vectors need to be flipped and rotated accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two samples from the same original sequence should have stochastically different orientation.\n",
    "data = dataset[0]\n",
    "lum1 = data['lum']\n",
    "flow1 = data['flow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a4e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = SintelSample(lum1[None], flow1[None])\n",
    "animation.animate_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e77a35",
   "metadata": {},
   "source": [
    "## Further augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b689d",
   "metadata": {},
   "source": [
    "Besides that, we also augment the input with random contrasts and brightnesses and random gaussian pixel noise, while the motion stays the same. This pretends that the same motion takes place under different illumination conditions and signal to noise ratios.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16bdaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiTaskSintel(\n",
    "    tasks=[\"flow\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=3,\n",
    "    n_frames=19,\n",
    "    dt=1 / 24,\n",
    "    augment=True,\n",
    "    random_temporal_crop=False,\n",
    "    all_frames=False,\n",
    "    resampling=False,\n",
    "    interpolate=False,\n",
    "    p_flip=0,\n",
    "    p_rot=0,\n",
    "    contrast_std=0.2,\n",
    "    brightness_std=0.1,\n",
    "    gaussian_white_noise=0.08,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lum1 = dataset[0]['lum']\n",
    "lum2 = dataset[0]['lum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = SintelSample(lum1[None], lum2[None], title2=\"input\")\n",
    "animation.animate_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77927238",
   "metadata": {},
   "source": [
    "# Framerate of the dataset and integration time step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed4cc42",
   "metadata": {},
   "source": [
    "The Sintel dataset is originally rendered at 24 frames per second, i.e., one frame every 42ms. The fruit fly neurons are able to respond to temporal differences as fast as 5-20ms. Therefore, we resample every frame multiple times to pretend that the movie was originally sampled at such a faster framerate. For the motion fields, we interpolate flow vectors in time instead of resampling them, which hopefully gives a better learning signal to the network. We have to trade-off speed of the numerical integration and memory consumption during optimization with the simulation accuracy by choosing time steps between 5-20ms. We chose to train networks at the upper bount of 20ms and evaluate them more accurately at 5-10ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiTaskSintel(\n",
    "    tasks=[\"flow\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=3,\n",
    "    n_frames=19,\n",
    "    dt=1 / 50,\n",
    "    augment=False,\n",
    "    resampling=True,\n",
    "    interpolate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92929640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, every input frame appears twice and target frames are interpolated.\n",
    "data = dataset[0]\n",
    "lum1 = data['lum']\n",
    "flow1 = data['flow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8000f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = SintelSample(lum1[None], flow1[None])\n",
    "animation.animate_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5debf32",
   "metadata": {},
   "source": [
    "# Computing responses to the Sintel data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a655e25d",
   "metadata": {},
   "source": [
    "Before we get to training a network, we look at a few responses to these type of sequences of individual neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024619be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyvision.network import NetworkView, Network\n",
    "from flyvision.utils.activity_utils import LayerActivity\n",
    "\n",
    "from flyvision.datasets.sintel import MultiTaskSintel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new network instance\n",
    "network = Network()\n",
    "\n",
    "# Alternative: uncomment to use a pretrained network\n",
    "# network_view = NetworkView(network_dir=\"opticflow/000/0000\", \n",
    "#                            checkpoint=\"best_chkpt\", \n",
    "#                            validation_subdir=\"\", \n",
    "#                            loss_file_name=\"validation_loss\")\n",
    "# network = network_view.init_network(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_activity = LayerActivity(None, network.connectome, keepref=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9aec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiTaskSintel(\n",
    "    tasks=[\"flow\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=1,\n",
    "    n_frames=19,\n",
    "    dt=1/50,\n",
    "    augment=False,\n",
    "    resampling=True,\n",
    "    interpolate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac8a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_state = network.fade_in_state(1.0, dataset.dt, dataset[0][\"lum\"][[0]])\n",
    "responses = network.simulate(dataset[0][\"lum\"][None], dataset.dt, initial_state=stationary_state).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[3, 2])\n",
    "layer_activity.update(responses)\n",
    "r = layer_activity.central.T4c.squeeze().numpy()\n",
    "time = np.arange(0, r.shape[0], 1) * dataset.dt\n",
    "plt.plot(time, r)\n",
    "plt.xlabel(\"time in s\")\n",
    "plt.ylabel(\"voltage (a.u.)\")\n",
    "plt.title(\"response of central T4c cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f699420f",
   "metadata": {},
   "source": [
    "# Decoding the task from the neural activity\n",
    "\n",
    "We need to predict the pixel-accurate flow field that Sintel gives us. For that we decode the voltages of a bunch of cell types. The decoder and the network are trained end-to-end. Here an example of a forward pass through the whole pipeline in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyvision.network import NetworkView\n",
    "from flyvision.utils.activity_utils import LayerActivity\n",
    "\n",
    "from flyvision.datasets.sintel import MultiTaskSintel\n",
    "from flyvision.decoder import DecoderGAVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = DecoderGAVP(network.connectome, shape=[8, 2], kernel_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiTaskSintel(\n",
    "    tasks=[\"flow\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=1,\n",
    "    all_frames=True,\n",
    "    dt=1/50,\n",
    "    augment=False,\n",
    "    resampling=True,\n",
    "    interpolate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c73d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "lum = data[\"lum\"]\n",
    "flow = data[\"flow\"]\n",
    "\n",
    "stationary_state = network.fade_in_state(1.0, dataset.dt, lum[[0]])\n",
    "responses = network.simulate(lum[None], dataset.dt, initial_state=stationary_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0a1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decoder(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f82e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = SintelSample(lum[None], flow[None], prediction=y_pred.detach().cpu())\n",
    "animation.animate_in_notebook(frames=np.arange(lum.shape[0])[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b391a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_pred - flow) ** 2).sqrt().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1705f",
   "metadata": {},
   "source": [
    "# Training network and decoder on a single batch\n",
    "\n",
    "We now train the network on a single batch to validate that the pipeline works.\n",
    "\n",
    "Note: this is intentional overfitting for illustration. These networks won't develop meaningful function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8766757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from flyvision.network import NetworkView, Network\n",
    "from flyvision.decoder import DecoderGAVP\n",
    "from flyvision.utils.activity_utils import LayerActivity\n",
    "\n",
    "from flyvision.datasets.sintel import MultiTaskSintel\n",
    "from flyvision.objectives import L2Norm, EPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8675bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = DecoderGAVP(network.connectome, shape=[8, 2], kernel_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a212c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiTaskSintel(\n",
    "    tasks=[\"flow\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=1,\n",
    "    n_frames=19,\n",
    "    dt=1/50,\n",
    "    augment=False,\n",
    "    resampling=True,\n",
    "    interpolate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pre=0.5\n",
    "dt = 1/50\n",
    "batch_size=4\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fd138",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam((*network.parameters(), *decoder.parameters()), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a520a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = EPE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bdec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "errors = []\n",
    "\n",
    "initial_state = network.steady_state(t_pre, dt, batch_size)\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    lum = batch[\"lum\"]\n",
    "    flow = batch[\"flow\"]\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    network.stimulus.zero()\n",
    "    network.stimulus.add_input(lum)\n",
    "    \n",
    "    activity = network(network.stimulus(), dt=1/50, state=initial_state)\n",
    "    y_pred = decoder(activity)\n",
    "\n",
    "    batch_error = loss_fn(y_pred, flow)\n",
    "    errors.append(batch_error.cpu().item())\n",
    "    batch_error.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88cbc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf98c235",
   "metadata": {},
   "source": [
    "Did this make the task predictions better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d8f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "lum = data[\"lum\"]\n",
    "flow = data[\"flow\"]\n",
    "\n",
    "stationary_state = network.fade_in_state(1.0, dataset.dt, lum[[0]])\n",
    "responses = network.simulate(lum[None], dataset.dt, initial_state=stationary_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcef7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decoder(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ba8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = SintelSample(lum[None], flow[None], prediction=y_pred.detach().cpu())\n",
    "animation.animate_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165fb99",
   "metadata": {},
   "source": [
    "This network and decoder trained to predict this single sample gives a more sensible prediction than the random parameter networks. However, this network and decoder are overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba2d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_pred - flow) ** 2).sqrt().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfcbca",
   "metadata": {},
   "source": [
    "# Evaluating trained networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd210d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyvision.network import NetworkView\n",
    "from flyvision.utils.activity_utils import LayerActivity\n",
    "\n",
    "from flyvision.datasets.sintel import MultiTaskSintel\n",
    "from flyvision.decoder import DecoderGAVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082074d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_view = NetworkView(network_dir=\"opticflow/000/0000\", \n",
    "                           checkpoint=\"best_chkpt\", \n",
    "                           validation_subdir=\"\", \n",
    "                           loss_file_name=\"validation_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff7f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = network_view.init_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9525f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = network_view.init_decoder()[\"flow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8138939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiTaskSintel(\n",
    "    tasks=[\"flow\"],\n",
    "    boxfilter=dict(extent=15, kernel_size=13),\n",
    "    vertical_splits=1,\n",
    "    all_frames=False,\n",
    "    n_frames=19,\n",
    "    dt=1/50,\n",
    "    augment=False,\n",
    "    resampling=True,\n",
    "    interpolate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a6a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [dataset[i] for i in range(4)]\n",
    "lum = torch.stack([d[\"lum\"] for d in data])\n",
    "flow = torch.stack([d[\"flow\"] for d in data])\n",
    "\n",
    "stationary_state = network.fade_in_state(1.0, dataset.dt, lum[:, 0])\n",
    "responses = network.simulate(lum, dataset.dt, initial_state=stationary_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812adba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decoder(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd429e",
   "metadata": {},
   "source": [
    "For example this network sees spotty motion into all directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c12429",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = SintelSample(lum, flow, prediction=y_pred.detach().cpu())\n",
    "animation.animate_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05857459",
   "metadata": {},
   "source": [
    "The error may not be as good as the overfitted example because this network generalized across the whole-dataset at the expense of accuracy for single samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_pred - flow) ** 2).sqrt().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea2b60e",
   "metadata": {},
   "source": [
    "# Evaluating ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e019540",
   "metadata": {},
   "source": [
    "Last, we evaluated the task error of the 50 trained networks on a held out set of sequences. We evaluate the task error across all checkpoints during training and show the minimal one in the histrogram below. This checkpoint we analyse with respect to it's tuning predictions as shown in the next notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyvision.ensemble import EnsembleView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = EnsembleView(\"opticflow/000\", \n",
    "                        checkpoint='best_chkpt',\n",
    "                        validation_subdir='',\n",
    "                        loss_file_name='validation_loss',\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.loss_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276eb4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
