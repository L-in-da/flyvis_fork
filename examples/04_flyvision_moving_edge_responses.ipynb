{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uu-bb4z8t_lP"
   },
   "source": [
    "# Moving edge responses\n",
    "\n",
    "This notebook introduces moving edge responses and the direction selectivity index (DSI). The DSI measures motion selectivity of cells to visual input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXV7OZMrugGF"
   },
   "source": [
    "**Select GPU runtime**\n",
    "\n",
    "To run the notebook on a GPU select Menu -> Runtime -> Change runtime type -> GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "sWG39Aevugmr"
   },
   "outputs": [],
   "source": [
    "# @markdown **Check access to GPU**\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    import torch\n",
    "\n",
    "    try:\n",
    "        cuda_name = torch.cuda.get_device_name()\n",
    "        print(f\"Name of the assigned GPU / CUDA device: {cuda_name}\")\n",
    "    except RuntimeError:\n",
    "        import warnings\n",
    "\n",
    "        warnings.warn(\n",
    "            \"You have not selected Runtime Type: 'GPU' or Google could not assign you one. Please revisit the settings as described above or proceed on CPU (slow).\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-B9TA8nfzmN3"
   },
   "source": [
    "**Install Flyvis**\n",
    "\n",
    "The notebook requires installing our package `flyvis`. You may need to restart your session after running the code block below with Menu -> Runtime -> Restart session. Then, imports from `flyvis` should succeed without issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Dkhfe5XBuksW"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    #@markdown **Install Flyvis**\n",
    "    %%capture\n",
    "    !git clone https://github.com/flyvis/flyvis-dev.git\n",
    "    %cd /content/flyvis-dev\n",
    "    !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5ts-Vr9Uq3A"
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fz7783IyuwKs"
   },
   "source": [
    "## Moving edge stimuli\n",
    "\n",
    "To elicit moving edge responses and characterise the motion selectivity of neurons, experimenters show an ON or OFF edge moving in different cardinal directions. We generate and render these stimuli with the `MovingEdge` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5Hfyy3tyTQG"
   },
   "outputs": [],
   "source": [
    "# import dataset and visualization helper\n",
    "from flyvision.datasets.moving_bar import MovingEdge\n",
    "from flyvision.animations.hexscatter import HexScatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lI7elnklmcrh"
   },
   "outputs": [],
   "source": [
    "# initialize dataset\n",
    "# make the dataset\n",
    "dataset = MovingEdge(\n",
    "    offsets=[-10, 11],  # offset of bar from center in 1 * radians(2.25) led size\n",
    "    intensities=[0, 1],  # intensity of bar\n",
    "    speeds=[19],  # speed of bar in 1 * radians(5.8) / s\n",
    "    height=80,  # height of moving bar in 1 * radians(2.25) led size\n",
    "    post_pad_mode=\"continue\",  # for post-stimulus period, continue with the last frame of the stimulus\n",
    "    t_pre=1.0,  # duration of pre-stimulus period\n",
    "    t_post=1.0,  # duration of post-stimulus period\n",
    "    dt=1 / 200,  # temporal resolution of rendered video\n",
    "    angles=list(np.arange(0, 360, 30)),  # motion direction (orthogonal to edge)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "h5LOmW2RwYRv",
    "outputId": "fab46ba2-40d1-4689-bd1f-3e6a4e9bbecb"
   },
   "outputs": [],
   "source": [
    "# view stimulus parameters\n",
    "dataset.arg_df\n",
    "# the dataset has four samples, one corresponding to each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "7g9pyNQcmmbz",
    "outputId": "64d777d1-135a-4a68-a183-1681e21e2e2d"
   },
   "outputs": [],
   "source": [
    "# visualize single sample\n",
    "# %#matplotlib notebook\n",
    "animation = HexScatter(\n",
    "    dataset[3][None, ::25, None], vmin=0, vmax=1\n",
    ")  # intensity=1, radius=6\n",
    "animation.animate_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9NDyBDbwqhd"
   },
   "source": [
    "## Moving edge response\n",
    "\n",
    "Now that we have generated the stimulus, we can use it to drive a trained connectome-constrained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "freOR6U0GWzS"
   },
   "outputs": [],
   "source": [
    "from flyvision import results_dir\n",
    "from flyvision.network import NetworkView\n",
    "\n",
    "# model are already sorted by task error\n",
    "# we take the best task-performing model, model 0000\n",
    "network_view = NetworkView(\"opticflow/000/0000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YH1IS5XwupKG"
   },
   "outputs": [],
   "source": [
    "# rebuild network from checkpoint\n",
    "network = network_view.init_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = np.concatenate(\n",
    "    [\n",
    "        ret[1]\n",
    "        for ret in network.stimulus_response(\n",
    "            stim_dataset=dataset,\n",
    "            dt=dataset.dt,\n",
    "            t_pre=0.0,\n",
    "        )\n",
    "    ],\n",
    "    axis=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMDaiOxA4Nn_"
   },
   "source": [
    "### MovingEdgeResponseView\n",
    "We've now computed network moving edge responses for all cells in the network. The `MovingEdgeResponseView` class allows us fast and flexible analysis and operations on the stored responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5Cqe7psSAl9"
   },
   "outputs": [],
   "source": [
    "from flyvision.utils.nodes_edges_utils import CellTypeArray\n",
    "from flyvision.analysis.moving_bar_responses import MovingEdgeResponseView\n",
    "\n",
    "# extract cell responses in central column\n",
    "central_responses = responses[:, :, network.connectome.central_cells_index[:]]\n",
    "# wrap responses for easy access by cell type\n",
    "responses_array = CellTypeArray(\n",
    "    central_responses,\n",
    "    cell_types=network.connectome.unique_cell_types[:].astype(str),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4PRa8r84Kgt"
   },
   "outputs": [],
   "source": [
    "# initialize MovingEdgeResponseView\n",
    "merv = MovingEdgeResponseView(\n",
    "    arg_df=dataset.arg_df, responses=responses_array, config=dataset.config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unO9i3aL5FaS"
   },
   "source": [
    "### Response traces\n",
    "We can plot single-cell response traces with `MovingEdgeResponseView.plot_traces()`. Here, we plot responses of T4c cells to edges with intensity 1 (ON edges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "hVFv9WjqqlfP",
    "outputId": "75315389-668f-4105-fded-3ca98677c941"
   },
   "outputs": [],
   "source": [
    "# %#matplotlib inline\n",
    "merv.plot_traces(\n",
    "    cell_type=\"T4c\",\n",
    "    groupby=[\"angle\"],\n",
    "    intensity=1,\n",
    "    t_start=-0.5,\n",
    "    t_end=1.0,\n",
    "    plot_kwargs=dict(\n",
    "        figsize=(2.4, 1.8),\n",
    "        fontsize=6,\n",
    "        color=[plt.cm.hsv(x) for x in np.arange(0, 1, 1 / 12)],\n",
    "    ),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FOTQtIR5RMu"
   },
   "source": [
    "### Direction selectivity index (DSI)\n",
    "\n",
    "The **Direction Selectivity Index (DSI)** quantifies a cell's preference for stimuli moving in a particular direction.\n",
    "\n",
    "The DSI is derived from the following steps:\n",
    "1. Obtain the neuron's peak responses to stimuli moving in different directions $\\theta$ and at different speeds $S$.\n",
    "2. Rectify these peak responses to ensure they are non-negative.\n",
    "3. Compute the DSI using the equation:\n",
    "\n",
    "$$\n",
    "DSI_{t_i}(I) = \\frac{1}{\\lvert S \\rvert} \\sum_{S \\in S} \\left\\lvert \\frac{\\sum_{\\theta \\in \\Theta} r^{peak}_{t_{central}}(I, S, \\theta) e^{i\\theta}}{\\max_{I \\in I} \\left\\lvert \\sum_{\\theta \\in \\Theta} r^{peak}_{t_{central}}(I, S, \\theta) \\right\\rvert} \\right\\rvert\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $DSI_{t_i}(I)$ is the Direction Selectivity Index for cell type $t_i$ at stimulus intensity $I$.\n",
    "- $\\lvert S \\rvert$ is the number of different speeds at which stimuli are moved.\n",
    "- $r^{peak}_{t_{central}}(I, S, \\theta)$ represents the rectified peak response of the central cell in hexagonal space of a cell type, for a given stimulus intensity $I$, speed $S$, and direction $\\theta$.\n",
    "- $\\theta$ is varied across all tested directions $\\Theta$.\n",
    "- $e^{i\\theta}$ introduces the directional component by weighting the response by the complex exponential of the angle of movement.\n",
    "- The denominator normalizes the responses, ensuring that DSI values range from 0 to 1.\n",
    "\n",
    "The DSI values range from 0 to 1. A DSI of 0 indicates no directional preference, while a DSI of 1 indicates a strong preference for a specific direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSuPrIG97qwE"
   },
   "source": [
    "For the T4c cell plotted before, we can see that it preferentially responds to ON edges moving at an angle of 60 degrees, so we expect to see a large DSI. We can compute the DSI with `MovingEdgeResponseView.dsi()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get DSI for T4c cell\n",
    "dsi_T4c = merv.where_stim_args(intensity=1).cell_type(\"T4c\").dsi()[:].squeeze()\n",
    "print(f\"T4c DSI: {dsi_T4c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the preferred direction of the cell with `MovingEdgeResponseView.preferred_direction()` (this is the direction that the tuning lobe points towards). We would expect the preferred direction to be around 60 degrees based on the response traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferred_direction = (\n",
    "    merv.where_stim_args(intensity=1)\n",
    "    .cell_type(\"T4c\")\n",
    "    .preferred_direction()[:]\n",
    "    .squeeze()\n",
    ")\n",
    "print(f\"T4c preferred direction: {preferred_direction / np.pi * 180} degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect the direction selecity of a cell type visually, by plotting the angular tuning with `MovingEdgeResponseView.plot_angular_tuning()`. Here we see clearly how the cell is tuned to stimuli moving at a 60 degree angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merv.plot_angular_tuning(cell_type=\"T4c\", intensity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myPGKYPDTmES"
   },
   "source": [
    "### DSI  and tuning curve correlation\n",
    "\n",
    "With the `dsi()` function we can also compute DSIs for every cell type at once. Since the selectivity of some cell types have been determined experimentally, we can then compare our model to experimental findings by computing the correlation between the model DSIs for known cell types with their expected motion selectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwlNfeC_oXu-",
    "outputId": "0039cdb0-b3be-46b0-8146-d0b76ddf23ad"
   },
   "outputs": [],
   "source": [
    "from flyvision.analysis.moving_bar_responses import dsi_correlation_to_known\n",
    "\n",
    "# compute DSIs for all cell types\n",
    "dsi_all = merv.dsi()\n",
    "# get DSI values and corresponding cell type\n",
    "off_dsis = dsi_all.where_stim_args(intensity=0)\n",
    "on_dsis = dsi_all.where_stim_args(intensity=1)\n",
    "dsis = np.stack([off_dsis[:], on_dsis[:]], axis=0)[:, :, 0]  # remove temproal dim\n",
    "cell_types = dsi_all.responses.cell_types\n",
    "# compute correlation\n",
    "dsi_corr = dsi_correlation_to_known(dsis, cell_types, respect_contrast=True).squeeze()\n",
    "print(f\"DSI correlation = {dsi_corr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, for certain cell types, their actual tuning curves have also been measured experimentally, so we can correlate our model cell's tuning to the true values. For T4c, the cell is known to tune to stimuli moving at 90 degrees, so the correlation should be relatively high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyvision.analysis.moving_bar_responses import tuning_curve_correlation_to_known\n",
    "\n",
    "# compute DSIs for all cell types\n",
    "tuning_curve, (angles, intensities) = merv.tuning_curves()\n",
    "# get DSI values and corresponding cell type\n",
    "tc_corr = tuning_curve_correlation_to_known(\n",
    "    tuning=tuning_curve, angles=angles, intensities=intensities\n",
    ")\n",
    "print(f\"T4c tuning curve correlation = {tc_corr['T4c']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, tuning curves for all T4 and T5 cells have been measured, so we can compute the correlation for all 8 cell types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "print(f\"Tuning curve correlations: \\n{pprint.pformat(tc_corr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the model yields accurate predictions for all T4 and T5 cell types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrG_yZ6IaVdD"
   },
   "source": [
    "## Ensemble responses\n",
    "\n",
    "Now we can compare motion selectivity properties across an ensemble of trained models. First we need to again simulate the network responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAci8A5MYu9d"
   },
   "outputs": [],
   "source": [
    "from flyvision.ensemble import EnsembleView\n",
    "\n",
    "ensemble = EnsembleView(\"opticflow/000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Xnl1wqFkPlp"
   },
   "outputs": [],
   "source": [
    "central_cells_index = ensemble[ensemble.names[0]].connectome.central_cells_index[:]\n",
    "with ensemble.ratio(\n",
    "    best=0.20\n",
    "):  # take only top 20% (10 in this case) of models\n",
    "    responses = np.stack(\n",
    "        [\n",
    "            np.concatenate(\n",
    "                [\n",
    "                    ret[1][:, :, central_cells_index]\n",
    "                    for ret in net.stimulus_response(\n",
    "                        stim_dataset=dataset,\n",
    "                        dt=dataset.dt,\n",
    "                        t_pre=0.0,\n",
    "                    )\n",
    "                ],\n",
    "                axis=0,\n",
    "            )\n",
    "            for net in ensemble.yield_networks()\n",
    "        ],\n",
    "        axis=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fy2rQgEBuXuj"
   },
   "source": [
    "We again use `MovingEdgeResponseView` to wrap around the network responses to moving edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcHD3FkDqq6y"
   },
   "outputs": [],
   "source": [
    "responses_array = CellTypeArray(\n",
    "    responses,\n",
    "    cell_types=network.connectome.unique_cell_types[:].astype(str),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EQuiNYSt8LG"
   },
   "outputs": [],
   "source": [
    "merv = MovingEdgeResponseView(\n",
    "    arg_df=dataset.arg_df,\n",
    "    responses=responses_array,\n",
    "    config=dataset.config,\n",
    "    stim_sample_dim=1,\n",
    "    temporal_dim=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e342YYovvEPw"
   },
   "source": [
    "### Response traces\n",
    "\n",
    "We can once again plot response traces for a single cell type. We subtract the initial value of each trace and rescale by the maximum value before plotting, as the network neuron activities are in arbitrary units. We plot only T4c responses to ON edges moving at a 90-degree angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "id": "iRbLjqKcvBkz",
    "outputId": "e9caffe4-0025-47e5-d195-a8805469bfeb"
   },
   "outputs": [],
   "source": [
    "centered = (\n",
    "    merv.between_seconds(-0.5, 1.0)\n",
    "    - merv.between_seconds(-0.5, 1.0).responses.array[:, :, [0]]\n",
    ")\n",
    "centered /= centered.abs().max(dims=(1, 2), keepdims=True)\n",
    "centered.plot_traces(\n",
    "    cell_type=\"T4c\",\n",
    "    angle=90,\n",
    "    intensity=1,\n",
    "    plot_kwargs=dict(figsize=(2.4, 1.8), fontsize=6),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_O9bDAuGv8xC"
   },
   "source": [
    "Though for most networks T4c responses are correctly predicted to the stimuli, there are some networks in the ensemble with different tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYgWkeNbwDbJ"
   },
   "source": [
    "### Direction selectivity index (DSI)\n",
    "\n",
    "We can also compute direction selectivity indices for each network in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIJcPWIKvLja",
    "outputId": "91048e37-8d39-48df-d956-c01e5da30c3f"
   },
   "outputs": [],
   "source": [
    "# get DSI for T4c cell\n",
    "dsi_l1 = merv.where_stim_args(intensity=1).cell_type(\"T4c\").dsi()[:].squeeze().tolist()\n",
    "print(f\"T4c DSIs: {pprint.pformat(dsi_l1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbKyqrQewUNf"
   },
   "source": [
    "Most networks in this group recover some direction selectivity for T4c. We can also plot the distribution of DSIs per cell type for both ON and OFF-edge stimuli across the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXR0NcX4wQDc"
   },
   "outputs": [],
   "source": [
    "# compute FRIs for all cell types\n",
    "dsi_all = merv.dsi()\n",
    "# get FRI values and corresponding cell types\n",
    "dsis = dsi_all.responses.array.squeeze()\n",
    "cell_types = dsi_all.responses.cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "aqxdwgnswsUf",
    "outputId": "79230e4d-ecff-449e-9054-805c661b114b"
   },
   "outputs": [],
   "source": [
    "from flyvision.analysis.moving_bar_responses import plot_dsis\n",
    "\n",
    "fig, ax = plot_dsis(\n",
    "    dsis,\n",
    "    cell_types,\n",
    "    bold_output_type_labels=True,\n",
    "    output_cell_types=ensemble[ensemble.names[0]]\n",
    "    .connectome.output_cell_types[:]\n",
    "    .astype(str),\n",
    "    figsize=[10, 1.2],\n",
    "    color_known_types=True,\n",
    "    fontsize=6,\n",
    "    scatter_best_index=0,\n",
    "    scatter_best_color=plt.get_cmap(\"Blues\")(1.0),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhJO6lMvX3fo"
   },
   "source": [
    "### DSI correlation\n",
    "\n",
    "Lastly, we look at the correlations to ground-truth DSIs and tuning curves across the ensemble. This provides us with a high-level understanding of the accuracy of known motion tuning predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_dsis = dsi_all.where_stim_args(intensity=0)\n",
    "on_dsis = dsi_all.where_stim_args(intensity=1)\n",
    "dsis = np.stack([off_dsis[:], on_dsis[:]], axis=0)[:, :, 0]  # remove temproal dim\n",
    "cell_types = dsi_all.responses.cell_types\n",
    "dsi_corr = dsi_correlation_to_known(dsis, cell_types, respect_contrast=True)\n",
    "\n",
    "tuning_curve, (angles, intensities) = merv.tuning_curves()\n",
    "tc_corr = tuning_curve_correlation_to_known(\n",
    "    tuning_curve, angles, intensities, aggregate_dims=3\n",
    ")\n",
    "\n",
    "t4_corr = np.median(\n",
    "    [tc_corr[cell_type].squeeze() for cell_type in [\"T4a\", \"T4b\", \"T4c\", \"T4d\"]], axis=0\n",
    ")\n",
    "t5_corr = np.median(\n",
    "    [tc_corr[cell_type].squeeze() for cell_type in [\"T5a\", \"T5b\", \"T5c\", \"T5d\"]], axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "Y8yyYrc7PgG0",
    "outputId": "bf69683d-811e-4307-e8e0-d1d957f29545"
   },
   "outputs": [],
   "source": [
    "from flyvision.plots.plots import violin_groups\n",
    "\n",
    "fig, ax, *_ = violin_groups(\n",
    "    np.stack([dsi_corr, t4_corr, t5_corr], axis=0)[:, None, :],\n",
    "    [\"DSI\", \"T4 tuning\", \"T5 tuning\"],\n",
    "    ylabel=\"correlation\",\n",
    "    figsize=(1.8, 1.5),\n",
    "    ylim=(-1, 1),\n",
    "    colors=[\n",
    "        plt.get_cmap(\"Dark2\")(0.125),\n",
    "        plt.get_cmap(\"Dark2\")(0),\n",
    "        plt.get_cmap(\"Dark2\")(0.25),\n",
    "    ],\n",
    "    color_by=\"experiments\",\n",
    "    scatter_edge_color=\"gray\",\n",
    "    scatter_radius=5,\n",
    "    violin_alpha=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jorqXMxCZ4B4"
   },
   "source": [
    "<!-- ... Models in general have very good match to known single-neuron tuning properties, with median correlation around $0.8$. -->"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
